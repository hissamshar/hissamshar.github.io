
[{"content":" ","date":"2026-01-06","externalUrl":null,"permalink":"/","section":"","summary":"\u003c!-- Chatbot Popup --\u003e\n\u003cscript async type=\"module\" src=\"https://interfaces.zapier.com/assets/web-components/zapier-interfaces/zapier-interfaces.esm.js\"\u003e\u003c/script\u003e\n\u003cp\u003e\u003czapier-interfaces-chatbot-embed\nis-popup=\"true\"\nchatbot-id=\"cmik2u33w000d13tvhblr5sjm\"\u003e\n\u003c/zapier-interfaces-chatbot-embed\u003e\u003c/p\u003e","title":"","type":"page"},{"content":"","date":"2026-01-06","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","date":"2026-01-06","externalUrl":null,"permalink":"/tags/cli/","section":"Tags","summary":"","title":"Cli","type":"tags"},{"content":"","date":"2026-01-06","externalUrl":null,"permalink":"/tags/email/","section":"Tags","summary":"","title":"Email","type":"tags"},{"content":"","date":"2026-01-06","externalUrl":null,"permalink":"/categories/git/","section":"Categories","summary":"","title":"Git","type":"categories"},{"content":"","date":"2026-01-06","externalUrl":null,"permalink":"/tags/git/","section":"Tags","summary":"","title":"Git","type":"tags"},{"content":"","date":"2026-01-06","externalUrl":null,"permalink":"/tags/gmail/","section":"Tags","summary":"","title":"Gmail","type":"tags"},{"content":"Using git send-email allows you to send patches directly from the command line, a workflow favored by many open-source projects (like the Linux kernel and SourceHut). This guide walks you through setting up git send-email with Gmail and sending your first patch.\n1. Installation # First, ensure you have the necessary tools installed. On Ubuntu/Debian, run:\nsudo apt install git git-email 2. Configuring Gmail # To use Gmail with git send-email, you need to configure authentication:\nEnable Two-Factor Authentication (2FA) on your Google account if you haven\u0026rsquo;t already. Generate an App Password: Go to your Google Account \u0026gt; Security \u0026gt; App passwords. Create a new one for \u0026ldquo;Mail\u0026rdquo; or \u0026ldquo;Custom\u0026rdquo; (name it \u0026ldquo;git\u0026rdquo;). Configure Git: Run the following command (substituting your password with the App Password you just generated): git config --global sendemail.smtpPass \u0026#39;your_app_password_here\u0026#39; Next, add your SMTP server details to your global .gitconfig:\ngit config --global sendemail.smtpserver smtp.gmail.com git config --global sendemail.smtpuser you@gmail.com git config --global sendemail.smtpencryption ssl git config --global sendemail.smtpserverport 465 Make sure to replace you@gmail.com with your actual email address.\nIf you haven\u0026rsquo;t set your global user details yet, do so now:\ngit config --global user.email \u0026#34;you@gmail.com\u0026#34; git config --global user.name \u0026#34;Your Name\u0026#34; Note: It is possible to use OAuth 2.0 instead of App Passwords, but it requires more complex setup with git-credential-oauth.\n3. sending Your First Patch # Let\u0026rsquo;s test the configuration by sending a patch to a test repository.\nClone and Modify # Clone the test drive repository:\ngit clone https://git.sr.ht/~sircmpwn/email-test-drive cd email-test-drive Create a change to commit:\necho \u0026#34;I\u0026#39;m about to try git send-email\u0026#34; \u0026gt; your-name # Replace \u0026#39;your-name\u0026#39; with your actual identifier or name file Commit the change:\ngit add your-name git commit -m \u0026#34;Demonstrate that I can use git send-email\u0026#34; Send the Email # The README for this test repo asks us to send patches to ~sircmpwn/email-test-drive@lists.sr.ht.\ngit send-email --to=\u0026#34;~sircmpwn/email-test-drive@lists.sr.ht\u0026#34; HEAD^ Follow the prompts (you can ignore Message-ID for now). If successful, your email should appear in the mailing list archives.\n4. Handling Feedback (The Workflow) # Wait for feedback. In this test flow, a bot will likely reply to your email. If you need to make changes based on feedback:\nEdit the file: Make the requested changes. Amend the commit: git commit -a --amend Send v2: # Set default To address to save time git config sendemail.to \u0026#34;~sircmpwn/email-test-drive@lists.sr.ht\u0026#34; # Send version 2 with annotation git send-email --annotate -v2 HEAD^ Using --annotate opens your editor, allowing you to add a \u0026ldquo;cover letter\u0026rdquo; or comments under the --- line, like:\nSubject: [PATCH v2] Demonstrate that I can use git send-email --- This fixes the issues raised from the first patch. your-name | 1 + 1 file changed, 1 insertion(+) 5. Advanced Tips # Sending Multiple Patches # To send a series of commits (e.g., the last 3):\ngit send-email HEAD~3 Cover Letters # For complex series, add a cover letter to explain the context:\ngit send-email --cover-letter origin/master This generates a template ([PATCH 0/N]) where you can describe the goal of the series.\nSign-off # Many projects (like Linux) require a \u0026ldquo;Signed-off-by\u0026rdquo; line (DCO).\ngit send-email --signoff # Or configure it globally git config format.signOff yes Always Annotate # To review every email before sending:\ngit config --global sendemail.annotate yes Happy Hacking!\n","date":"2026-01-06","externalUrl":null,"permalink":"/posts/git-email-setup/","section":"Posts","summary":"Learn how to configure git send-email with Gmail, including 2FA setup, app passwords, and sending your first patch to a mailing list.","title":"Setting Up Git Send-Email with Gmail","type":"posts"},{"content":"","date":"2026-01-06","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","date":"2026-01-06","externalUrl":null,"permalink":"/tags/tutorial/","section":"Tags","summary":"","title":"Tutorial","type":"tags"},{"content":"","date":"2026-01-06","externalUrl":null,"permalink":"/categories/version-control/","section":"Categories","summary":"","title":"Version Control","type":"categories"},{"content":"Using git send-email allows you to send patches directly from the command line, a workflow favored by many open-source projects (like the Linux kernel and SourceHut). This guide walks you through setting up git send-email with Gmail and sending your first patch.\n1. Installation # First, ensure you have the necessary tools installed. On Ubuntu/Debian, run:\nsudo apt install git git-email 2. Configuring Gmail # To use Gmail with git send-email, you need to configure authentication:\nEnable Two-Factor Authentication (2FA) on your Google account if you haven\u0026rsquo;t already. Generate an App Password: Go to your Google Account \u0026gt; Security \u0026gt; App passwords. Create a new one for \u0026ldquo;Mail\u0026rdquo; or \u0026ldquo;Custom\u0026rdquo; (name it \u0026ldquo;git\u0026rdquo;). Configure Git: Run the following command (substituting your password with the App Password you just generated): git config --global sendemail.smtpPass \u0026#39;your_app_password_here\u0026#39; Next, add your SMTP server details to your global .gitconfig:\ngit config --global sendemail.smtpserver smtp.gmail.com git config --global sendemail.smtpuser you@gmail.com git config --global sendemail.smtpencryption ssl git config --global sendemail.smtpserverport 465 Make sure to replace you@gmail.com with your actual email address.\nIf you haven\u0026rsquo;t set your global user details yet, do so now:\ngit config --global user.email \u0026#34;you@gmail.com\u0026#34; git config --global user.name \u0026#34;Your Name\u0026#34; Note: It is possible to use OAuth 2.0 instead of App Passwords, but it requires more complex setup with git-credential-oauth.\n3. sending Your First Patch # Let\u0026rsquo;s test the configuration by sending a patch to a test repository.\nClone and Modify # Clone the test drive repository:\ngit clone https://git.sr.ht/~sircmpwn/email-test-drive cd email-test-drive Create a change to commit:\necho \u0026#34;I\u0026#39;m about to try git send-email\u0026#34; \u0026gt; your-name # Replace \u0026#39;your-name\u0026#39; with your actual identifier or name file Commit the change:\ngit add your-name git commit -m \u0026#34;Demonstrate that I can use git send-email\u0026#34; Send the Email # The README for this test repo asks us to send patches to ~sircmpwn/email-test-drive@lists.sr.ht.\ngit send-email --to=\u0026#34;~sircmpwn/email-test-drive@lists.sr.ht\u0026#34; HEAD^ Follow the prompts (you can ignore Message-ID for now). If successful, your email should appear in the mailing list archives.\n4. Handling Feedback (The Workflow) # Wait for feedback. In this test flow, a bot will likely reply to your email. If you need to make changes based on feedback:\nEdit the file: Make the requested changes. Amend the commit: git commit -a --amend Send v2: # Set default To address to save time git config sendemail.to \u0026#34;~sircmpwn/email-test-drive@lists.sr.ht\u0026#34; # Send version 2 with annotation git send-email --annotate -v2 HEAD^ Using --annotate opens your editor, allowing you to add a \u0026ldquo;cover letter\u0026rdquo; or comments under the --- line, like:\nSubject: [PATCH v2] Demonstrate that I can use git send-email --- This fixes the issues raised from the first patch. your-name | 1 + 1 file changed, 1 insertion(+) 5. Advanced Tips # Sending Multiple Patches # To send a series of commits (e.g., the last 3):\ngit send-email HEAD~3 Cover Letters # For complex series, add a cover letter to explain the context:\ngit send-email --cover-letter origin/master This generates a template ([PATCH 0/N]) where you can describe the goal of the series.\nSign-off # Many projects (like Linux) require a \u0026ldquo;Signed-off-by\u0026rdquo; line (DCO).\ngit send-email --signoff # Or configure it globally git config format.signOff yes Always Annotate # To review every email before sending:\ngit config --global sendemail.annotate yes ","date":"2026-01-01","externalUrl":null,"permalink":"/posts/git-email/","section":"Posts","summary":"\u003cp\u003eUsing \u003ccode\u003egit send-email\u003c/code\u003e allows you to send patches directly from the command line, a workflow favored by many open-source projects (like the Linux kernel and SourceHut). This guide walks you through setting up \u003ccode\u003egit send-email\u003c/code\u003e with Gmail and sending your first patch.\u003c/p\u003e","title":"Setting Up Git Send-Email with Gmail","type":"posts"},{"content":"","date":"2025-12-01","externalUrl":null,"permalink":"/tags/firewall/","section":"Tags","summary":"","title":"Firewall","type":"tags"},{"content":"If you\u0026rsquo;re a student or researcher, you\u0026rsquo;ve likely encountered that frustrating \u0026ldquo;Access Denied\u0026rdquo; screen when trying to reach a legitimate website, software repository, or gaming service on campus. University networks often use strict firewalls or transparent proxies to limit bandwidth and enforce security policies, but this can severely hamper your ability to study or relax.\nCloudflare\u0026rsquo;s WARP, built on the free 1.1.1.1 DNS resolver, is an effective tool to bypass these restrictive networks.\n1. Understanding the Problem: Deep Packet Inspection # University networks do not just block websites. They often monitor and filter your traffic using two main methods:\nDNS Filtering # The network forces your device to use their local DNS server. If you try to resolve a blocked domain such as a gaming site or a non-approved software repository, the DNS request fails and you cannot connect.\nDeep Packet Inspection (DPI) # Firewalls inspect your data packets, even those encrypted through standard HTTPS, allowing them to block specific protocols or destinations.\n2. The WARP Solution: Encrypted Tunneling # WARP creates a lightweight, encrypted tunnel from your device to Cloudflare\u0026rsquo;s network.\nEncryption # WARP wraps all your outbound traffic, including DNS and HTTP, in modern encryption.\nProtocol Masking # Your encrypted traffic appears like standard HTTPS. The firewall can only see a connection to a Cloudflare IP address, not the actual destination.\nBypassing the Proxy # Because the traffic is encrypted end to end, the university proxy or firewall cannot inspect its contents or destination and must allow it.\n3. How to Install and Connect WARP on Linux # For Linux users, the warp-cli command line interface is the most stable way to use WARP.\nStep 3.1: Install the WARP Client # On Ubuntu:\n# Add cloudflare gpg key curl -fsSL https://pkg.cloudflareclient.com/pubkey.gpg | sudo gpg --yes --dearmor --output /usr/share/keyrings/cloudflare-warp-archive-keyring.gpg # Add this repo to your apt repositories echo \u0026#34;deb [signed-by=/usr/share/keyrings/cloudflare-warp-archive-keyring.gpg] https://pkg.cloudflareclient.com/ $(lsb_release -cs) main\u0026#34; | sudo tee /etc/apt/sources.list.d/cloudflare-client.list # Install sudo apt-get update \u0026amp;\u0026amp; sudo apt-get install cloudflare-warp Step 3.2: Register and Connect # Register the device:\nwarp-cli registration new Connect:\nwarp-cli connect Step 3.3: Verify the Connection # To confirm that it is working correctly, verify that warp=on.\ncurl https://www.cloudflare.com/cdn-cgi/trace/ 4. Troubleshooting: warp=off Appearing # If the trace output still shows warp=off, try:\nCheck status:\nwarp-cli status Restart the connection:\nwarp-cli disconnect warp-cli connect Using Cloudflare WARP allows you to take control of your internet traffic, ensuring unrestricted access for academic and personal use while connected to a university network.\n5. WARP vs. Traditional VPNs: Why WARP Often Wins on Campus # Traditional VPNs: Primarily designed for anonymity, privacy, and geo-unblocking. They usually connect you to a specific server location (e.g., \u0026ldquo;connect to New York\u0026rdquo;) and often focus on hiding your real IP address from the websites you visit. They are designed to make it look like you\u0026rsquo;re browsing from a different country.\nCloudflare WARP: Primarily designed for security, performance, and bypassing basic network restrictions. It routes your traffic through Cloudflare\u0026rsquo;s global network to encrypt it and potentially speed it up, without necessarily trying to mask your geographical location or assign you a dedicated exit IP. It\u0026rsquo;s designed to make it harder to block your traffic, rather than to make it look like you\u0026rsquo;re somewhere else.\nFull Tunneling: warp-cli establishes a system-wide VPN tunnel. This means all your internet traffic, regardless of the application (browser, terminal, game client, email, etc.), goes through the WARP tunnel. This is crucial for bypassing firewalls that might target specific applications or protocols.\nTraditional VPNs: Performance can vary wildly. Connecting to a server far away will introduce latency. The encryption overhead and server load can also slow things down.\nCloudflare WARP: Optimized for Speed, which leverages Cloudflare\u0026rsquo;s vast global network, routing your traffic through the closest server.\n","date":"2025-12-01","externalUrl":null,"permalink":"/posts/202512-warp-cli/","section":"Posts","summary":"\u003cp\u003eIf you\u0026rsquo;re a student or researcher, you\u0026rsquo;ve likely encountered that\nfrustrating \u0026ldquo;Access Denied\u0026rdquo; screen when trying to reach a legitimate\nwebsite, software repository, or gaming service on campus. University\nnetworks often use strict firewalls or transparent proxies to limit\nbandwidth and enforce security policies, but this can severely hamper\nyour ability to study or relax.\u003c/p\u003e","title":"How to Bypass Restrictive Firewalls and Proxies with Cloudflare WARP (1.1.1.1)","type":"posts"},{"content":"","date":"2025-12-01","externalUrl":null,"permalink":"/categories/linux/","section":"Categories","summary":"","title":"Linux","type":"categories"},{"content":"","date":"2025-12-01","externalUrl":null,"permalink":"/categories/proxy/","section":"Categories","summary":"","title":"Proxy","type":"categories"},{"content":"","date":"2025-12-01","externalUrl":null,"permalink":"/tags/vpn/","section":"Tags","summary":"","title":"VPN","type":"tags"},{"content":"","date":"2025-11-26","externalUrl":null,"permalink":"/categories/container/","section":"Categories","summary":"","title":"Container","type":"categories"},{"content":"Docker has become one of the most essential tools for developers. It allows you to package applications with all their dependencies into portable containers. In this blog post, you will build your first Docker image using the simplest possible example.\nWhat Is a Docker Image? # A Docker image is a read-only template that contains everything needed to run an application: - Source code - Runtime - Dependencies - System tools\nWhen you run an image, Docker creates a container, which is a small isolated environment.\nStep 1 - Create a Project Folder # Start by creating a folder for your project:\nmkdir myapp cd myapp Step 2 - Add a Simple Python Script # Inside your myapp folder, create a file named app.py:\nprint(\u0026#34;Hello from my Docker image!\u0026#34;) This small script will be what your container runs.\nStep 3 - Create Your Dockerfile # The Dockerfile tells Docker how to build your image. Create a file named Dockerfile:\n# Use a small official Python image FROM python:3.10-slim # Copy script into image COPY app.py /app.py # Run script on container start CMD [\u0026#34;python\u0026#34;, \u0026#34;app.py\u0026#34;] Step 4 - Build the Docker Image # Run this from inside your project folder:\ndocker build -t my-first-image . Docker will: 1. Download the base Python image 2. Add app.py into the image 3. Set the startup command\nIf everything works correctly, you will have your first image.\nStep 5 - Run Your Docker Image # Start a container by running:\ndocker run my-first-image You should see:\nHello from my Docker image! Congratulations. You have built and run your first Docker image.\nWhat\u0026rsquo;s Next? # Now that you understand the basic process, you can try: - Building images for web servers - Using docker-compose - Optimizing images with multi-stage builds - Publishing your image to Docker Hub\nDocker is a powerful tool, and this is your starting point.\n","date":"2025-11-26","externalUrl":null,"permalink":"/posts/202411-docker-images/","section":"Posts","summary":"\u003cp\u003eDocker has become one of the most essential tools for developers. It\nallows you to package applications with all their dependencies into\nportable containers. In this blog post, you will build your first Docker\nimage using the simplest possible example.\u003c/p\u003e","title":"Creating Your First Docker Image: A Beginner-Friendly Guide","type":"posts"},{"content":"","date":"2025-11-26","externalUrl":null,"permalink":"/categories/docker/","section":"Categories","summary":"","title":"Docker","type":"categories"},{"content":"","date":"2025-11-26","externalUrl":null,"permalink":"/tags/images/","section":"Tags","summary":"","title":"Images","type":"tags"},{"content":"","date":"2025-11-13","externalUrl":null,"permalink":"/tags/kernel/","section":"Tags","summary":"","title":"Kernel","type":"tags"},{"content":"","date":"2025-11-13","externalUrl":null,"permalink":"/categories/lfx/","section":"Categories","summary":"","title":"LFX","type":"categories"},{"content":" Understanding the Linux Kernel Development Process # The Linux kernel is one of the most influential and widely used open source projects in the world. It powers everything from smartphones and embedded devices to servers, supercomputers, and cloud infrastructure. For developers interested in contributing or simply understanding how the kernel evolves, it is important to know how the development process works. The Linux Foundation\u0026rsquo;s Beginner\u0026rsquo;s Guide to Linux Kernel Development (LFD103) outlines the essential concepts involved in maintaining, updating, and releasing the kernel. This article presents a clear overview of the core components of that process.\nAbout the Linux Kernel # The Linux kernel is the core component of the Linux operating system. It serves as the interface between hardware and user-level software, handling tasks such as memory management, process scheduling, device control, and system security. Linux is developed collaboratively by thousands of contributors around the world, including individuals, hardware vendors, companies, and open source enthusiasts.\nKernel development is built on transparency, peer review, and iterative improvement. Every change, whether it is a bug fix or a major subsystem update, goes through discussion and review on public mailing lists. This open development model allows Linux to adapt quickly, support a wide range of hardware, and remain reliable across diverse environments.\nWhat Does the Release Cycle Look Like? # The Linux kernel follows a predictable release cycle. A new major kernel version is released approximately every nine to ten weeks. The cycle begins when Linus Torvalds announces the opening of the merge window. During this two week period, subsystem maintainers submit the patches they have been preparing for inclusion. Once the merge window closes, no major new features are accepted, and the kernel enters a stabilization phase.\nAfter the merge window, a series of release candidates (rc1, rc2, and so on) are published weekly. These releases focus on testing, bug fixing, and performance tuning. Developers and users test these builds on real hardware and report regressions. When the kernel is sufficiently stable, the final release is published and work begins on the next iteration.\nActive Kernel Releases # Several kernel versions remain active at any given time, including:\nMainline kernel. The current development version that receives new features and major changes. Stable kernels. After a mainline release, important fixes are backported into stable versions, identified as 6.x.y. Long Term Support (LTS) kernels. Selected versions that receive bug and security fixes for several years. These kernels are widely used in production systems that require long term reliability. Different users choose different release types depending on their stability and feature requirements.\nKernel Trees: What Are They? # Kernel trees are a fundamental part of the development structure. The Linux kernel is not maintained as a single repository that everyone edits directly. Instead, code moves through multiple Git trees maintained by various individuals.\nKey kernel tree types include:\nMainline tree. Maintained by Linus Torvalds and considered the authoritative source of the kernel. Subsystem maintainers submit patches directly here. Subsystem trees. Each subsystem such as networking, memory management, filesystems, or drivers has its own tree. Contributors send patches to the subsystem maintainer for review and integration. Integration trees. Larger trees used to test interactions among subsystems and identify conflicts early. This distributed model helps maintain quality and scalability in a project that receives thousands of patches each release cycle.\nSubsystem Maintainers # Subsystem maintainers play a central role in kernel development. They act as stewards of specific parts of the codebase and handle tasks such as:\nReviewing incoming patches for correctness and design Communicating with contributors on mailing lists Testing and validating changes Managing a Git tree with accepted patches Forwarding approved changes to Linus Torvalds during the merge window Maintainers ensure that contributions do not introduce regressions and that the kernel remains stable.\nFor new contributors, working with maintainers is an essential part of the process. Following coding standards, preparing high quality patches, and responding to feedback help increase the chances of successful contributions.\nConclusion # The Linux kernel development process is a well organized system that has evolved over decades of open source collaboration. From the structured release cycle to the distributed architecture of kernel trees and the essential work of subsystem maintainers, each component helps ensure that the kernel remains robust, secure, and adaptable. Understanding this workflow is a valuable first step for anyone interested in contributing to one of the most impactful software projects in the world.\n","date":"2025-11-13","externalUrl":null,"permalink":"/posts/202511-linux_kernel_development/","section":"Posts","summary":"\u003ch1 class=\"relative group\"\u003eUnderstanding the Linux Kernel Development Process\n    \u003cdiv id=\"understanding-the-linux-kernel-development-process\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none\"\u003e\n        \u003ca class=\"text-primary-300 dark:text-neutral-700 !no-underline\" href=\"#understanding-the-linux-kernel-development-process\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e\n    \n\u003c/h1\u003e\n\u003cp\u003eThe Linux kernel is one of the most influential and widely used open source projects in the world. It powers everything from smartphones and embedded devices to servers, supercomputers, and cloud infrastructure. For developers interested in contributing or simply understanding how the kernel evolves, it is important to know how the development process works. The Linux Foundation\u0026rsquo;s Beginner\u0026rsquo;s Guide to Linux Kernel Development (LFD103) outlines the essential concepts involved in maintaining, updating, and releasing the kernel. This article presents a clear overview of the core components of that process.\u003c/p\u003e","title":"Understanding the Linux Kernel Development Process","type":"posts"},{"content":"","date":"2025-09-17","externalUrl":null,"permalink":"/tags/audio/","section":"Tags","summary":"","title":"Audio","type":"tags"},{"content":" Fixing PipeWire Lock Issues on Arch Linux: Why Video \u0026amp; Audio Playback Broke # The other day, I ran into a frustrating issue on my Arch Linux setup:\nno video would play anywhere , not in Chrome, not in Firefox, and not even locally with mpv. The files loaded, but playback simply wouldn’t start.\nDigging deeper revealed that the culprit wasn’t the browser or the media player at all, but PipeWire, the modern Linux audio and video server.\nDiagnosing the Problem # First stop: checking the PipeWire service.\nsystemctl --user status pipewire Output:\n× pipewire.service - PipeWire Multimedia Service Loaded: loaded (/usr/lib/systemd/user/pipewire.service; enabled) Active: failed (Result: exit-code) Main PID: 9386 (code=exited, status=245/KSM) Sep 17 23:12:53 archlinux systemd[762]: pipewire.service: Failed with result \u0026#39;exit-code\u0026#39;. Sep 17 23:12:53 archlinux systemd[762]: Failed to start PipeWire Multimedia Service. So PipeWire wasn’t starting. To get more detail, I ran:\npipewire -v This showed the key error:\n[E] unable to lock lockfile \u0026#39;/run/user/1000/pipewire-0.lock\u0026#39;: Resource temporarily unavailable [E] failed to create context: Resource temporarily unavailable Translation: PipeWire thought it was already running because the lock file was still in place, even though the process was broken.\nThis happens if PipeWire crashes, hangs during suspend, or leaves behind a stale lock file.\nThe Quick Fix # To recover, I killed all PipeWire-related processes:\nkillall -9 pipewire killall -9 pipewire-pulse killall -9 wireplumber Then restarted the services:\nsystemctl --user restart pipewire pipewire-pulse wireplumber Instantly, video and audio playback started working again.\nWhy the -9 Flag? # Normally, killall sends SIGTERM (15), which asks a process to exit cleanly. But when a process is stuck, it can ignore this signal.\nkillall -9 sends SIGKILL (9), which forces the kernel to immediately terminate the process. It skips all cleanup, but it guarantees the process is gone.\nIn my case, this was necessary because PipeWire was in a bad state and wouldn’t shut down otherwise.\nPreventing the Issue # If you run into this again, here’s a safe recovery sequence:\n# First try a graceful stop killall pipewire pipewire-pulse wireplumber # If that fails, force it killall -9 pipewire pipewire-pulse wireplumber # Clean up stale lock files (if any remain) rm -f /run/user/1000/pipewire-*.lock # Restart services systemctl --user restart pipewire pipewire-pulse wireplumber Also, make sure you don’t have PulseAudio installed alongside PipeWire, as they can conflict:\npacman -Qs pulseaudio Remove if needed:\nsudo pacman -Rns pulseaudio Takeaway # When video or audio playback suddenly stops working on Linux, the problem isn’t always your browser or media player, it might be PipeWire itself.\nThe root cause in this case was a stale lock file that tricked PipeWire into thinking it was already running. The fix was as simple as killing the stuck processes and restarting the services.\nNow I’ve got a little one-liner script handy in case it ever happens again, but hopefully, PipeWire behaves better going forward!\n","date":"2025-09-17","externalUrl":null,"permalink":"/posts/pipewire/","section":"Posts","summary":"\u003ch1 class=\"relative group\"\u003eFixing PipeWire Lock Issues on Arch Linux: Why Video \u0026amp; Audio Playback Broke\n    \u003cdiv id=\"fixing-pipewire-lock-issues-on-arch-linux-why-video--audio-playback-broke\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none\"\u003e\n        \u003ca class=\"text-primary-300 dark:text-neutral-700 !no-underline\" href=\"#fixing-pipewire-lock-issues-on-arch-linux-why-video--audio-playback-broke\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e\n    \n\u003c/h1\u003e\n\u003cp\u003eThe other day, I ran into a frustrating issue on my Arch Linux setup:\u003cbr\u003e\n\u003cstrong\u003eno video would play anywhere\u003c/strong\u003e , not in Chrome, not in Firefox, and not even locally with \u003ccode\u003empv\u003c/code\u003e. The files loaded, but playback simply wouldn’t start.\u003c/p\u003e","title":"Fixing PipeWire Lock Issues on Arch Linux: Why Video \u0026 Audio Playback Broke","type":"posts"},{"content":"","date":"2025-09-17","externalUrl":null,"permalink":"/tags/pipewire/","section":"Tags","summary":"","title":"Pipewire","type":"tags"},{"content":"","date":"2025-08-14","externalUrl":null,"permalink":"/categories/local-host/","section":"Categories","summary":"","title":"Local Host","type":"categories"},{"content":" 1. Introduction # Sometimes you need to share a local application with the outside world, maybe to demo your project, test a webhook, or allow a teammate to access your development server.\nNormally, you’d need a public IP, port forwarding, or a cloud server. ngrok removes all that complexity by creating a secure tunnel from the internet directly to your machine, giving you a public URL instantly.\n2. Prerequisites # Before we begin, make sure you have:\nA terminal A free ngrok account (for authentication token) A running local service (e.g., a Python HTTP server, web app, or API) 3. Installing ngrok on Linux # We’ll cover installation for Arch Linux, Debian/Ubuntu, and Fedora.\n3.1 Arch Linux # This package is not in the official repos, install it from the AUR:\nyay -S ngrok 3.2 Debian / Ubuntu # sudo apt update sudo apt install snapd sudo snap install ngrok Alternatively, download the binary from the ngrok downloads page.\n3.3 Fedora # sudo dnf install snapd sudo ln -s /var/lib/snapd/snap /snap sudo snap install ngrok 4. Authenticating ngrok # Once installed, you need to connect it to your account so you can use custom domains, longer session times, and access the dashboard.\nSign in to ngrok dashboard. -\u0026gt; Your AuthToken Copy your AuthToken. Run: ngrok config add-authtoken \u0026lt;YOUR_TOKEN\u0026gt; You will see: Authtoken saved to configuration file: ~/.config/ngrok/ngrok.yml 5. Exposing a Local Service # For example, if your local web server is running on port 8080:\nngrok http 8080 You’ll see output like:\nNow you can share the HTTPS URL with anyone. It wil be similar to: https://random.string.ngrok-free.app\n6. Adding Basic Security # You can protect your tunnel with a simple username and password:\nngrok http --basic-auth=\u0026#34;user:password\u0026#34; 8080 Anyone visiting the public link will need credentials.\n7. The Inspector # One of ngrok\u0026rsquo;s most powerful features is its built-in web interface, accessible at http://127.0.0.1:4040. This interface lets you inspect every single request that comes through your tunnel in real-time. You can see headers, request bodies, and response details, and even replay requests with a single click—an absolute lifesaver for debugging webhooks.\n8. Common Use Cases # Webhook testing — Connect services like GitHub, Stripe, or Twilio to your local environment. Temporary demos — Share work-in-progress with clients without deployment. Remote device access — SSH into a Raspberry Pi without changing router settings. 9. Conclusion # In just a few commands, you’ve learned how to:\nInstall ngrok on popular Linux distros Authenticate your installation Share a local service securely From here, you can explore ngrok’s advanced features like static domains, IP allowlists, and traffic inspection.\n","date":"2025-08-14","externalUrl":null,"permalink":"/posts/ngrok/","section":"Posts","summary":"\u003ch2 class=\"relative group\"\u003e1. Introduction\n    \u003cdiv id=\"1-introduction\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none\"\u003e\n        \u003ca class=\"text-primary-300 dark:text-neutral-700 !no-underline\" href=\"#1-introduction\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e\n    \n\u003c/h2\u003e\n\u003cp\u003eSometimes you need to share a local application with the outside world, maybe to demo your project, test a webhook, or allow a teammate to access your development server.\u003c/p\u003e","title":"Ngrok: Expose Localhost to the Internet","type":"posts"},{"content":"","date":"2025-08-14","externalUrl":null,"permalink":"/tags/tunneling/","section":"Tags","summary":"","title":"Tunneling","type":"tags"},{"content":" Introduction # A memory leak occurs when a program allocates memory dynamically (e.g., using malloc) and fails to release it using free. This leftover allocation can lead to wasted memory resources, eventually causing slowdowns or system crashes in long-running programs.\nValgrind is a powerful command-line tool available on Linux systems. It helps developers detect:\nMemory leaks Invalid memory access Uninitialized memory usage Mismatched memory management In this guide, we\u0026rsquo;ll walk through examples in C to learn how to detect and fix memory leaks using Valgrind.\nInstalling Valgrind # On Arch Linux # sudo pacman -S valgrind On Ubuntu/Debian # sudo apt install valgrind On Fedora # sudo dnf install valgrind Troubleshooting: Valgrind \u0026ldquo;cannot find mandatory redirection\u0026rdquo; on Arch Linux # If you run Valgrind and get an error like:\nvalgrind: Fatal error at startup: a function redirection\nvalgrind: which is mandatory for this platform-tool combination\nvalgrind: cannot be set up.\n…you might be running a 32-bit executable on a 64-bit Arch Linux system.\nWhy this happens # Valgrind needs to hook into low-level glibc functions from your binary’s architecture.\nIf your binary is 32-bit, Arch requires the 32-bit glibc runtime (lib32-glibc).\nWithout it, Valgrind can’t find the right function symbols and quits.\nFix # Install the 32-bit glibc package:\nsudo pacman -S lib32-glibc After installation, re-run:\nvalgrind ./your-binary and it should work.\nUbuntu/Debian equivalent: sudo apt install libc6-dbg:i386\nBasic Example: Hello World # Code # #include \u0026lt;stdio.h\u0026gt; int main() { printf(\u0026#34;Hello World\\n\u0026#34;); return 0; } Compile and Run # gcc main.c -o main.out ./main.out Run with Valgrind # valgrind ./main.out You should see no errors or memory leaks in the output.\nIntroducing a Memory Leak # Static Allocation (Safe) # #include \u0026lt;stdio.h\u0026gt; int main() { char str[20] = \u0026#34;Hello\u0026#34;; printf(\u0026#34;%s\\n\u0026#34;, str); return 0; } This uses stack memory, so Valgrind will report no leaks.\nDynamic Allocation (With Leak) # #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; int main() { char *str = malloc(20); strcpy(str, \u0026#34;Hello\u0026#34;); printf(\u0026#34;%s\\n\u0026#34;, str); return 0; // Forgot to free memory } Valgrind Output # valgrind ./main.out You should see:\ndefinitely lost: 20 bytes in 1 blocks\nFixing the Memory Leak # Add free(str); before returning:\nfree(str); Fixed Code # #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; int main() { char *str = malloc(20); strcpy(str, \u0026#34;Hello\u0026#34;); printf(\u0026#34;%s\\n\u0026#34;, str); free(str); return 0; } Detailed Valgrind Options # Use for deeper analysis:\nvalgrind --leak-check=full ./main.out Or even more detailed:\nvalgrind --leak-check=full --show-leak-kinds=all --track-origins=yes ./main.out Explanation:\n--leak-check=full: Display detailed leak info --show-leak-kinds=all: Show all kinds of leaks (definitely, indirectly lost, etc.) --track-origins=yes: Show where uninitialized values originate Summary # Always free() memory allocated with malloc(), calloc(), or realloc(). Close all file streams with fclose(). Use Valgrind to identify and fix: Memory leaks Invalid memory writes Use-after-free bugs Recommended command: valgrind --leak-check=full --track-origins=yes ./your_program Valgrind is a critical tool for writing safe, efficient, and bug-free C programs.\n","date":"2025-08-01","externalUrl":null,"permalink":"/posts/valgrind/","section":"Posts","summary":"\u003ch2 class=\"relative group\"\u003eIntroduction\n    \u003cdiv id=\"introduction\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none\"\u003e\n        \u003ca class=\"text-primary-300 dark:text-neutral-700 !no-underline\" href=\"#introduction\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e\n    \n\u003c/h2\u003e\n\u003cp\u003eA \u003cstrong\u003ememory leak\u003c/strong\u003e occurs when a program allocates memory dynamically (e.g., using \u003ccode\u003emalloc\u003c/code\u003e) and fails to release it using \u003ccode\u003efree\u003c/code\u003e. This leftover allocation can lead to wasted memory resources, eventually causing slowdowns or system crashes in long-running programs.\u003c/p\u003e","title":"Detecting and Fixing Memory Leaks with Valgrind","type":"posts"},{"content":"","date":"2025-08-01","externalUrl":null,"permalink":"/tags/memory/","section":"Tags","summary":"","title":"Memory","type":"tags"},{"content":"","date":"2025-05-11","externalUrl":null,"permalink":"/categories/hpervisors/","section":"Categories","summary":"","title":"HperVisors","type":"categories"},{"content":" QEMU-KVM on Arch Linux: Running Tiny Core Linux in a Lightweight VM # Virtualization is a powerful tool for developers, sysadmins, and tinkerers alike. On Linux, QEMU-KVM stands out as a robust, high-performance virtualization stack. In this blog, well walk through setting up QEMU-KVM on Arch Linux and using it to run Tiny Core Linuxa super-lightweight distro perfect for testing and experimentation.\nWhat is QEMU-KVM # QEMU (Quick Emulator) is a generic and open-source machine emulator. On its own, it can emulate various hardware systems. However, when paired with **KVM (Kernel-based Virtual Machine)**a Linux kernel module for virtualizationit can run virtual machines with near-native performance.\nQEMU provides device emulation and user-space management. KVM integrates with the Linux kernel and handles hardware-level virtualization. Together, they effectively form a Type 1 hypervisor because the Linux kernel (with KVM) handles core virtualization tasks directly on hardware.\nStep-by-Step: Installing QEMU-KVM on Arch Linux # Step 1: Install Required Packages # sudo pacman -Syu sudo pacman -S qemu virt-manager virt-viewer dnsmasq vde2 bridge-utils openbsd-netcat libvirt edk2-ovmf edk2-ovmf is for UEFI firmware support in VMs.\nStep 2: Enable and Start libvirtd # sudo systemctl enable --now libvirtd.service Step 3: Add Your User to the libvirt Group # sudo usermod -aG libvirt (whoami) newgrp libvirt Step 4: Verify KVM Support # lsmod grep kvm And check CPU virtualization support:\negrep -c (vmxsvm) /proc/cpuinfo A value of 1 or more indicates virtualization support.\nExample: Running Tiny Core Linux on QEMU-KVM # Now that your system is ready, lets run Tiny Core Linux, a minimalist Linux distro thats only 16MB\nStep 1: Download Tiny Core ISO # wget http://tinycorelinux.net/14.x/x86/release/Core-current.iso Or visit http://tinycorelinux.net for the latest release.\nStep 2: Create a Virtual Disk (Optional) # qemu-img create -f qcow2 tinycore.qcow2 512M This creates a 512MB disk image. Optional for RAM-only usage.\nStep 3: Launch the VM with KVM Acceleration # qemu-system-x86_64 -enable-kvm -m 512 -cpu host -smp 1 -cdrom Core-current.iso -hda tinycore.qcow2 -boot d -net nic -net user -vga virtio -display sdl Key Flags Explained:\n-enable-kvm: Enables KVM hardware acceleration -m 512: Allocates 512MB RAM -cpu host: Uses the host CPU features -cdrom: Points to the Tiny Core ISO -hda: Uses a QCOW2 disk image -boot d: Boots from CD first -net user: Enables simple user-mode networking (e.g., for internet access) -display sdl: Uses SDL window for graphics (you can replace with gtk or virt-manager) Alternate: Boot Tiny Core in RAM Without Disk # qemu-system-x86_64 -enable-kvm -m 256 -cdrom Core-current.iso -boot d -net nic -net user -vga std Conclusion # With QEMU-KVM, Arch Linux becomes a full-featured Type 1 hypervisor. By combining kernel-level virtualization (KVM) with the flexibility of QEMU, you get a fast, customizable virtualization platform. Running Tiny Core Linux showcases just how lightweight and efficient this setup can be.\nWhether youre building VMs for testing, learning Linux internals, or experimenting with custom environments, QEMU-KVM on Arch is a powerful combination.\nHappy virtualizing\n","date":"2025-05-11","externalUrl":null,"permalink":"/posts/qemu/","section":"Posts","summary":"\u003ch1 class=\"relative group\"\u003eQEMU-KVM on Arch Linux: Running Tiny Core Linux in a Lightweight VM\n    \u003cdiv id=\"qemu-kvm-on-arch-linux-running-tiny-core-linux-in-a-lightweight-vm\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none\"\u003e\n        \u003ca class=\"text-primary-300 dark:text-neutral-700 !no-underline\" href=\"#qemu-kvm-on-arch-linux-running-tiny-core-linux-in-a-lightweight-vm\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e\n    \n\u003c/h1\u003e\n\u003cp\u003eVirtualization is a powerful tool for developers, sysadmins, and tinkerers alike. On Linux, \u003cstrong\u003eQEMU-KVM\u003c/strong\u003e stands out as a robust, high-performance virtualization stack. In this blog, well walk through setting up QEMU-KVM on \u003cstrong\u003eArch Linux\u003c/strong\u003e and using it to run \u003cstrong\u003eTiny Core Linux\u003c/strong\u003ea super-lightweight distro perfect for testing and experimentation.\u003c/p\u003e","title":"QEMU-KVM on Arch Linux: Running Tiny Core Linux in a Lightweight VM","type":"posts"},{"content":"","date":"2025-05-11","externalUrl":null,"permalink":"/tags/vms/","section":"Tags","summary":"","title":"VMs","type":"tags"},{"content":" Building the Linux Kernel # Compiling the Linux Kernel involves multiple steps and can take some time depending on your hardware specifications.\nStep 1: Download the Kernel Source Code # Start by visiting the Official Linux Kernel Website and downloading the latest available kernel source code. The downloaded file will be a compressed archive containing all necessary source files.\nStep 2: Extract the Source Code # Once the download completes, extract the contents of the compressed archive using the tar command:\ntar xvf linux-6.13.tar.xz If the tar utility is not installed on your system, you can install it using:\nsudo pacman -S tar Note: Always ensure you are using the correct version number in the file name.\nStep 3: Install Required Dependencies # To compile the kernel, you need to install various development tools and libraries. Install them using the following command:\nsudo pacman -S git fakeroot ncurses xz bc flex bison base-devel kmod cpio perl binutils util-linux jfsutils e2fsprogs xfsprogs squashfs-tools quota-tools Step 4: Configure the Kernel # Navigate into the kernel source directory: cd linux-6.13 Use your current system’s configuration as a base:\nIf zcat is available, run:\nzcat /proc/config.gz \u0026gt; .config Otherwise, use this alternative method:\ncp /proc/config.gz ./ gunzip config.gz mv config .config Customize the kernel using a menu-driven interface:\nmake menuconfig make xconfig make oldconfig Modify the .config file directly:\nOpen it with a text editor:\nsudo vim .config Search for the line:\nCONFIG_EXT4_FS=m And change it to:\nCONFIG_EXT4_FS=y Step 5: Compile the Kernel # Determine the number of CPU cores available to speed up compilation: nproc Compile the kernel using the number of cores found above. Replace n with that number: make -j\u0026lt;n\u0026gt; If you encounter any errors during or after this step, back up your .config file and reset the source tree with:\nmake mrproper This command cleans the build environment and restores the source tree to its original state.\nStep 6: Install Kernel Modules # Kernel modules are essential for extending the kernel’s functionality and ensuring compatibility with various hardware. Install them with:\nsudo make modules_install Step 7: Install the Kernel # You can install the compiled kernel using one of the two methods below:\nAutomatic installation: sudo make install Manual installation (if the above doesn\u0026rsquo;t work):\nCopy the kernel image:\nsudo cp arch/x86/boot/bzImage /boot/vmlinuz-linux-custom Copy the System.map file:\nsudo cp System.map /boot/System.map-linux-custom Copy the kernel configuration file:\nsudo cp .config /boot/config-linux-custom Step 8: Update the Bootloader # If you use GRUB, follow these steps to add an entry for your custom kernel:\nFind the UUID of your root partition: lsblk -f Open the custom GRUB configuration file: sudo nvim /etc/grub.d/40_custom Add the following entry (replace paste-your-root-partition-uuid-here with the actual UUID): menuentry \u0026#39;Custom Linux Kernel\u0026#39; { linux /boot/vmlinuz-linux-custom root=UUID=paste-your-root-partition-uuid-here initrd /boot/initramfs-linux.img } Step 9: Generate Initramfs # As you\u0026rsquo;ve compiled a new kernel, installed modules, and modified boot entries, generating a new initramfs is necessary. Run:\nsudo mkinitcpio -k 6.13-custom -c /etc/mkinitcpio.conf -g /boot/initramfs-linux-custom.img Make sure the version (6.13-custom) matches your compiled kernel.\nStep 10: Update GRUB Configuration # Finally, update the GRUB configuration so that it includes your new kernel entry:\nsudo grub-mkconfig -o /boot/grub/grub.cfg Done! # Congratulations! You’ve successfully compiled and installed your custom Linux Kernel. Enjoy your personalized system!\n","date":"2025-05-08","externalUrl":null,"permalink":"/posts/kernalcompile/","section":"Posts","summary":"\u003ch1 class=\"relative group\"\u003eBuilding the Linux Kernel\n    \u003cdiv id=\"building-the-linux-kernel\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none\"\u003e\n        \u003ca class=\"text-primary-300 dark:text-neutral-700 !no-underline\" href=\"#building-the-linux-kernel\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e\n    \n\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003eCompiling the Linux Kernel involves multiple steps and can take some time depending on your hardware specifications.\u003c/strong\u003e\u003c/p\u003e","title":"How to build Linux Kernal: Step by Step Guide","type":"posts"},{"content":" Introduction # So, you’ve built a sleek website with Hugo and deployed it to GitHub Pages. Now, you want to give it a professional touch with a custom domain like yourdomain.tech instead of the default username.github.io URL. This guide walks you through the process step-by-step.\nPrerequisites # A Hugo website hosted on GitHub Pages (public repository). A custom domain (e.g., yourdomain.tech) purchased from a registrar like Namecheap, Google Domains, etc. Basic familiarity with DNS settings and GitHub repository configurations. Step 1: Configure Your GitHub Repository # First, ensure your GitHub Pages site is set up correctly:\nYour repository should be named \u0026lt;username\u0026gt;.github.io (for user/organization sites) or \u0026lt;repo-name\u0026gt; (for project sites). The gh-pages branch (or the /docs folder) should contain your Hugo-generated static files. Step 2: Configure DNS Settings for Your Domain # Option 1: Use an Apex Domain (e.g., yourdomain.tech) # If you want your site to live at the root domain (e.g., yourdomain.tech), configure A records in your DNS settings:\nGo to your domain registrar’s DNS management page. Create four A records pointing to GitHub’s IP addresses: Host: @ Type: A Value: 185.199.108.153 TTL: Automatic ","date":"2025-02-28","externalUrl":null,"permalink":"/posts/202409-customdomain/","section":"Posts","summary":"\u003ch1 class=\"relative group\"\u003eIntroduction\n    \u003cdiv id=\"introduction\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none\"\u003e\n        \u003ca class=\"text-primary-300 dark:text-neutral-700 !no-underline\" href=\"#introduction\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e\n    \n\u003c/h1\u003e\n\u003cp\u003eSo, you’ve built a sleek website with Hugo and deployed it to GitHub Pages. Now, you want to give it a professional touch with a custom domain like \u003ccode\u003eyourdomain.tech\u003c/code\u003e instead of the default \u003ccode\u003eusername.github.io\u003c/code\u003e URL. This guide walks you through the process step-by-step.\u003c/p\u003e","title":"How to up custom domain for GitHub Pages","type":"posts"},{"content":"Exception handling is a crucial aspect of writing robust and reliable Python code. Whether you\u0026rsquo;re a beginner or an experienced developer, getting an error, or exception, in your Python program means the entire program will crash. You don’t want this to happen in real-world programs. Instead, you want the program to detect errors, handle them, and then continue to run. In this blog, we\u0026rsquo;ll explore the fundamentals of exception handling in Python, including syntax, best practices, and advanced techniques.\nWhat Are Exceptions? # Exceptions are runtime errors that disrupt the normal flow of a program. For example, trying to open a non-existent file, dividing by zero, or accessing an invalid index in a list will raise exceptions. If unhandled, these exceptions cause your program to crash.\nBasic Syntax: try and except # The primary mechanism for handling exceptions in Python is the try-except block. Errors can be handled with with this. The code that could potentially have an error is put in a try clause. The program execution moves to the start of a following except clause if an error happens.\nHere\u0026rsquo;s the basic structure:\ndef cal(value): try: return 10 / value except ZeroDivisionError: print(\u0026#34;Cannot divide by zero!\u0026#34;) print(cal(0)) print(cal(2)) print(cal(3)) How It Works: # The code inside the try block is executed. If an exception occurs, Python checks the except blocks for a matching exception type. If a match is found, the corresponding except block runs. Catching Specific Exceptions # Always catch specific exceptions to avoid silencing unexpected errors. Python has many built-in exceptions (e.g., ValueError, TypeError, FileNotFoundError).\nimport math x = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) try: print(f\u0026#39;Square Root of {x} is {math.sqrt(x)}\u0026#39;) except ValueError: print(\u0026#39;Number is less than 0\u0026#39;) Output\nThe else Clause # The else block runs only if no exceptions were raised in the try block. Use it to separate \u0026ldquo;happy path\u0026rdquo; code from error handling.\nimport math def sqr(value): try: x = math.sqrt(value) except ValueError: print(\u0026#39;Number is less than 0\u0026#39;) else: print(f\u0026#39;The Answer is: {x}\u0026#39;) value = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) sqr(value) Output The finally Clause # The finally block runs regardless of whether an exception occurred. It’s ideal for cleanup tasks (e.g., closing files or releasing resources).\nimport math def sqr(value): try: x = math.sqrt(value) except ValueError: print(\u0026#39;Error\u0026#39;) else: print(f\u0026#39;The Answer is: {x}\u0026#39;) finally: print(\u0026#39;Program Ends\u0026#39;) value = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) sqr(value) Output # Raising Exceptions Manually # Use the raise keyword to trigger exceptions intentionally. This is useful for enforcing constraints.\ndef validate_age(age): if age \u0026lt; 0: raise ValueError(\u0026#34;Age cannot be negative!\u0026#34;) return age try: validate_age(-5) except ValueError as e: print(e) Creating Custom Exceptions # Define custom exceptions by subclassing Python’s built-in Exception class. This makes your code more readable and errors more descriptive. (note: I have used RegEx, for that blog will be out soon :) )\nimport re class InvalidEmailError(Exception): \u0026#34;\u0026#34;\u0026#34;Raised when an email format is invalid.\u0026#34;\u0026#34;\u0026#34; pass def send_email(valid,email): if not valid: raise InvalidEmailError(f\u0026#34;Invalid email: {email}\u0026#34;) email = input(\u0026#39;Please enter your email: \u0026#39;) valid = re.match(r\u0026#39;^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\u0026#39;, email) try: send_email(valid, email) except InvalidEmailError as e: print(e) Output Logging a Python Error # We can Log an exception in Python with an error. This can be done in the logging.exception() method. This function logs a message with level ERROR on this logger.\nimport math import logging def sqr(value): try: x = math.sqrt(value) except ValueError: logging.exception(\u0026#34;Error\u0026#34;) else: print(f\u0026#39;The Answer is: {x}\u0026#39;) finally: print(\u0026#39;Program Ends\u0026#39;) value = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) sqr(value) Output Best Practices for Exception Handling # Catch specific exceptions: Avoid broad except: clauses that hide bugs. Keep try blocks minimal: Only wrap code that might raise an exception. Use finally for cleanup: Ensure resources are released (e.g., closing files). Log exceptions: Use logging.error() instead of print() for production code. Provide meaningful messages: Help debug issues faster with clear error descriptions. Avoid empty except blocks: Silent failures make debugging harder. Conclusion # Exception handling is essential for writing better Python applications. By using try-except blocks effectively, catching specific errors, and with else/finally clauses, you can create programs that handle unexpected scenarios.\nNow go forth and write bulletproof Python code!\n","date":"2025-02-09","externalUrl":null,"permalink":"/posts/202502-exception_handling_in_python/","section":"Posts","summary":"\u003cp\u003eException handling is a crucial aspect of writing robust and reliable Python code. Whether you\u0026rsquo;re a beginner or an experienced developer, getting an error, or exception, in your Python program means the entire program will crash. You don’t want this to happen in real-world programs. Instead, you want the program to detect errors, handle them, and then continue to run. In this blog, we\u0026rsquo;ll explore the fundamentals of exception handling in Python, including syntax, best practices, and advanced techniques.\u003c/p\u003e","title":"Exception Handling in Python: A Comprehensive Guide","type":"posts"},{"content":"Have you ever wanted your Python program to do multiple things at once? For example, downloading files while updating the UI, or processing data while listening for user input? That’s where multithreading comes in.\nIn this post, we’ll explore multithreading in Python — what it is, when to use it, and how to use it with simple examples.\n🧠 What is Multithreading? # Multithreading is a way to run multiple threads (smaller units of a process) at the same time. It helps make your program more responsive or perform tasks in parallel, especially when tasks are I/O-bound (e.g., network calls, file reading, etc.).\nPython has a built-in module called threading that makes it easy to create and manage threads.\n⚠️ But Wait — Python\u0026rsquo;s GIL # Before you jump in, it\u0026rsquo;s important to understand the Global Interpreter Lock (GIL). In CPython (the standard Python implementation), the GIL allows only one thread to execute Python bytecode at a time.\nThis means multithreading in Python is best suited for I/O-bound tasks, not CPU-bound tasks like heavy computations. For CPU-bound tasks, consider multiprocessing instead.\n🛠️ Using the threading Module # Here\u0026rsquo;s a basic example to demonstrate multithreading:\nimport threading import time def print_numbers(): for i in range(5): print(f\u0026#34;Number: {i}\u0026#34;) time.sleep(1) def print_letters(): for letter in \u0026#39;abcde\u0026#39;: print(f\u0026#34;Letter: {letter}\u0026#34;) time.sleep(1) # Creating threads t1 = threading.Thread(target=print_numbers) t2 = threading.Thread(target=print_letters) # Starting threads t1.start() t2.start() # Wait for both threads to complete t1.join() t2.join() print(\u0026#34;Both threads have finished.\u0026#34;) 🔍 Output (interleaved): # Number: 0 Letter: a Number: 1 Letter: b ... Both functions run at the same time, and you can see their output interleave. That’s multithreading in action!\n📦 Real-World Use Cases # Downloading multiple files at once Handling multiple client connections on a server Running background tasks like logging or monitoring Keeping your GUI app responsive while doing other work 🧰 Extra Tools # For more advanced usage:\nconcurrent.futures.ThreadPoolExecutor — easier thread management queue.Queue — safe way to share data between threads threading.Lock — prevents race conditions 🧪 Example with ThreadPoolExecutor # from concurrent.futures import ThreadPoolExecutor import time def task(name): print(f\u0026#34;{name} starting\u0026#34;) time.sleep(2) print(f\u0026#34;{name} done\u0026#34;) with ThreadPoolExecutor(max_workers=2) as executor: executor.submit(task, \u0026#34;Task 1\u0026#34;) executor.submit(task, \u0026#34;Task 2\u0026#34;) ✅ Final Thoughts # Multithreading in Python is a powerful tool when used correctly — especially for I/O-bound programs. Just remember the GIL limitation and use the right tool (like multiprocessing) when working with CPU-heavy tasks.\nThanks for reading! Happy threading 🧵🐍\n","date":"2025-02-05","externalUrl":null,"permalink":"/posts/multithreading/","section":"Posts","summary":"\u003cp\u003eHave you ever wanted your Python program to do multiple things at once? For example, downloading files while updating the UI, or processing data while listening for user input? That’s where \u003cstrong\u003emultithreading\u003c/strong\u003e comes in.\u003c/p\u003e","title":"Multithreading in Python","type":"posts"},{"content":" Running a Local LLM on Mobile: Testing PocketPal on iPhone 12 # With the increasing accessibility of large language models (LLMs), running them locally on mobile devices is an exciting prospect. I recently tested PocketPal, a mobile LLM interface, on my iPhone 12, using a distilled 4-bit quantized model. Here’s a breakdown of my experience, covering installation, performance, and overall usability.\nWhy Run an LLM on Mobile? # Running an LLM locally on a mobile device comes with several advantages:\nPrivacy: No data is sent to external servers. Offline Access: Works without an internet connection. Lower Cost: Avoids API costs associated with cloud-based models. What is Quantization? # Quantization is a technique used to reduce the memory and computational requirements of machine learning models by representing their weights with lower precision numbers. Instead of using 32-bit floating-point numbers, models can be compressed into 8-bit or even 4-bit integers while maintaining reasonable accuracy.\nFor LLMs on mobile, 4-bit quantization significantly reduces the model size, making it feasible to run on devices with limited resources. However, this compression can lead to:\nSlightly reduced accuracy due to loss of precision. Faster inference times, as lower-bit computations require less processing power. Lower memory usage, allowing larger models to fit within mobile device constraints. Setting Up and Running PocketPal on iPhone 12 # 1. Download and Install PocketPal # Open the App Store and search for PocketPal AI by Asghar Ghorbani. Download and install the app. Open the app and allow necessary permissions. 2. Adding a Model # Navigate to the Models section in the PocketPal app. Click the + button to add a new model. You will see two options: Add from Hugging Face Add Local Model Select Add from Hugging Face to browse available models. 3. Selecting and Downloading a Model # Search for DeepSeek-R1-Distill-Qwen-1.5B-Q4_0. Select the model and start downloading it (size: 1.06GB, 1.78B parameters). Once downloaded, the model will appear under the Ready to Use section. 4. Running Benchmarks # I ran benchmarks on my iPhone 12 using the DeepSeek-R1-Distill-Qwen-1.5B-Q4_0 model. Here are the key results:\nModel Size: 1.06 GB with 1.78 billion parameters. Benchmark Configuration: Prompt Processing: 512 Token Generation: 128 Pipeline Length: 1 Repetitions: 3 Model Settings: Context Length: 1024 tokens Batch Size: 512 CPU Threads: 4 GPU Layers: 0 (fully CPU-based execution) Flash Attention: Disabled Performance Metrics: Prompt Processing Speed: 26.93 tokens/sec (±2.37) Token Generation Speed: 18.05 tokens/sec (±0.75) Total Execution Time: 1 minute 18 seconds Peak Memory Usage: 35.0% (1GB / 4GB) Live Demo: Running PocketPal on iPhone 12 # Watch a live demonstration of PocketPal running a distilled 4-bit quantized model on an iPhone 12: Image: Video demonstration is available here: Video\nAnalysis of Results # Decent Processing Speed: With a distilled 4-bit quantized model, the 18.05 t/s token generation rate is quite reasonable for mobile inference. Low Memory Footprint: The 1GB RAM usage means this can run on even mid-range smartphones. CPU-Based Execution: Since 0 GPU layers were used, this proves mobile CPUs are capable of running quantized LLMs efficiently. Flash Attention Disabled: If supported, enabling it might further optimize speed and reduce lag. Final Thoughts # Running an LLM locally on an iPhone 12 with PocketPal is feasible but comes with trade-offs. It’s a promising step toward self-hosted AI assistants, though optimization and hardware improvements will be crucial for broader adoption. If you’re privacy-conscious or need offline AI capabilities, it’s definitely worth exploring!\nFuture Improvements I\u0026rsquo;d Like to See: # Better memory efficiency to reduce battery drain. Enhanced speed for real-time interaction. More user-friendly model importing and switching. ","date":"2025-02-05","externalUrl":null,"permalink":"/posts/llmonmobile/","section":"Posts","summary":"\u003ch1 class=\"relative group\"\u003eRunning a Local LLM on Mobile: Testing PocketPal on iPhone 12\n    \u003cdiv id=\"running-a-local-llm-on-mobile-testing-pocketpal-on-iphone-12\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none\"\u003e\n        \u003ca class=\"text-primary-300 dark:text-neutral-700 !no-underline\" href=\"#running-a-local-llm-on-mobile-testing-pocketpal-on-iphone-12\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e\n    \n\u003c/h1\u003e\n\u003cp\u003eWith the increasing accessibility of large language models (LLMs), running them locally on mobile devices is an exciting prospect. I recently tested \u003cstrong\u003ePocketPal\u003c/strong\u003e, a mobile LLM interface, on my \u003cstrong\u003eiPhone 12\u003c/strong\u003e, using a \u003cstrong\u003edistilled 4-bit quantized model\u003c/strong\u003e. Here’s a breakdown of my experience, covering installation, performance, and overall usability.\u003c/p\u003e","title":"Running Large Language Models on Mobile: DeepSeek R1 on iPhone 12","type":"posts"},{"content":" Running DeepSeek-R1 1.5B on Raspberry Pi 5 (CPU-Only) # Technical Insights # Why Can We Run This on Raspberry Pi 5? # Thanks to open-source advancements, we can now run large-scale AI models on small devices like the Raspberry Pi 5. Key factors enabling this include:\nOptimized lightweight models: DeepSeek-R1 1.5B is built efficiently to run on limited hardware. ARM64 Support: Modern AI frameworks support ARM-based architectures, enabling their use on RPi5. Open-source software: Platforms like Ollama make AI deployment accessible to all. Performance Considerations # Running this model on an RPi5 without a GPU will be CPU-intensive. Consider reducing active processes to free up memory. If performance lags, use a lighter model or external processing (cloud inference). No GPU acceleration was used in this setup, meaning all computations rely solely on the CPU, which may affect inference speeds. This guide covers the installation and execution of DeepSeek-R1 1.5B on a Raspberry Pi 5, following the steps demonstrated in your images.\nPrerequisites # Raspberry Pi 5 (ARM64 architecture, more powerful than previous versions) Debian-based Linux installed An internet connection At least 4GB RAM recommended for smooth operation Step 1: Log in to Your Raspberry Pi # Upon booting, log in using your credentials:\nraspberrypi login: hisam Password: ****** Example login screen: Step 2: Install Curl # Curl is required to fetch the installation script. Run:\nsudo apt install curl If it\u0026rsquo;s already installed, you\u0026rsquo;ll see:\ncurl is already the newest version... Example output: Step 3: Install Ollama # Ollama is the runtime needed to execute DeepSeek models.\ncurl -fsSL https://ollama.com/install.sh | sh This will download and install Ollama.\nExample installation screen: Step 4: Enable and Start Ollama Service # After installation, Ollama sets up a system service.\nollama The output will indicate success:\n\u0026gt;\u0026gt;\u0026gt; Creating ollama user... \u0026gt;\u0026gt;\u0026gt; Enabling and starting ollama service... \u0026gt;\u0026gt;\u0026gt; The Ollama API is now available at 127.0.0.1:11434. Example setup screen: Step 5: Pull and Run DeepSeek-R1 1.5B # Now, pull and run the model:\nollama run deepseek-r1:1.5b This will download the model, which is about 1.1 GB in size.\nExample download screen: Once downloaded, the model is ready to run.\nStep 6: Execute DeepSeek-R1 1.5B # Run the model and start interacting:\nollama run deepseek-r1:1.5b You should see a prompt where you can start typing queries:\n\u0026gt;\u0026gt;\u0026gt; Hey! Hello! How can I assist you today? 😊 Example interaction: Final Setup Image # Video Demonstration # Watch Video\nConclusion # You have successfully installed and executed DeepSeek-R1 1.5B on your Raspberry Pi 5. This demonstrates the power of open-source AI, making it possible to run advanced models on small-scale devices. If you encounter performance issues, consider optimizing your setup or offloading computations.\nHappy coding!\n","date":"2025-02-03","externalUrl":null,"permalink":"/posts/202410-deepseek/","section":"Posts","summary":"\u003ch1 class=\"relative group\"\u003eRunning DeepSeek-R1 1.5B on Raspberry Pi 5 (CPU-Only)\n    \u003cdiv id=\"running-deepseek-r1-15b-on-raspberry-pi-5-cpu-only\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none\"\u003e\n        \u003ca class=\"text-primary-300 dark:text-neutral-700 !no-underline\" href=\"#running-deepseek-r1-15b-on-raspberry-pi-5-cpu-only\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e\n    \n\u003c/h1\u003e\n\n\u003ch2 class=\"relative group\"\u003eTechnical Insights\n    \u003cdiv id=\"technical-insights\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none\"\u003e\n        \u003ca class=\"text-primary-300 dark:text-neutral-700 !no-underline\" href=\"#technical-insights\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e\n    \n\u003c/h2\u003e\n\n\u003ch3 class=\"relative group\"\u003eWhy Can We Run This on Raspberry Pi 5?\n    \u003cdiv id=\"why-can-we-run-this-on-raspberry-pi-5\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none\"\u003e\n        \u003ca class=\"text-primary-300 dark:text-neutral-700 !no-underline\" href=\"#why-can-we-run-this-on-raspberry-pi-5\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e\n    \n\u003c/h3\u003e\n\u003cp\u003eThanks to open-source advancements, we can now run large-scale AI models on small devices like the Raspberry Pi 5. Key factors enabling this include:\u003c/p\u003e","title":"DeepSeek-R1 on Raspberry Pi 5: Open-Source AI Without a GPU","type":"posts"},{"content":"","date":"2025-02-03","externalUrl":null,"permalink":"/categories/embedded/","section":"Categories","summary":"","title":"Embedded","type":"categories"},{"content":"","date":"2025-02-03","externalUrl":null,"permalink":"/categories/llms/","section":"Categories","summary":"","title":"LLMs","type":"categories"},{"content":"","date":"2025-02-03","externalUrl":null,"permalink":"/tags/rpi/","section":"Tags","summary":"","title":"RPI","type":"tags"},{"content":" Setting Up Neovim: An Easy and Beginner\u0026rsquo;s Guide # Neovim is a modern and extensible text editor that enhances Vim’s capabilities. If you\u0026rsquo;re using Linux, setting up Neovim can be a rewarding experience, allowing you to customize it for an efficient workflow. In this guide, we\u0026rsquo;ll cover installing Neovim, setting up a basic configuration, and enhancing it with essential plugins to turn it into a full-fledged IDE.\n1. Installing Neovim # sudo pacman -S neovim 2. Setting Up Neovim Configuration # Neovim’s configuration is stored in ~/.config/nvim/. Create the directory and initialize a basic configuration:\nmkdir -p ~/.config/nvim nvim ~/.config/nvim/init.lua Minimal Configuration (init.lua) # Add the following settings to your init.lua file:\n-- Enable line numbers vim.opt.number = true vim.opt.relativenumber = true -- Set tab size vim.opt.expandtab = true vim.opt.shiftwidth = 4 vim.opt.tabstop = 4 -- Enable mouse support vim.opt.mouse = \u0026#34;a\u0026#34; -- Set clipboard to system clipboard vim.opt.clipboard = \u0026#34;unnamedplus\u0026#34; Save and exit Neovim.\n3. Installing a Plugin Manager # The best plugin manager for Neovim is lazy.nvim. Install it by running:\ngit clone --depth 1 https://github.com/folke/lazy.nvim.git \\ ~/.local/share/nvim/lazy/lazy.nvim Then, update your init.lua to load it:\nlocal lazypath = vim.fn.stdpath(\u0026#34;data\u0026#34;) .. \u0026#34;/lazy/lazy.nvim\u0026#34; if not vim.loop.fs_stat(lazypath) then vim.fn.system({ \u0026#34;git\u0026#34;, \u0026#34;clone\u0026#34;, \u0026#34;--filter=blob:none\u0026#34;, \u0026#34;https://github.com/folke/lazy.nvim.git\u0026#34;, lazypath }) end vim.opt.rtp:prepend(lazypath) 4. Installing Essential Plugins # With lazy.nvim installed, you can add plugins in init.lua:\nrequire(\u0026#34;lazy\u0026#34;).setup({ \u0026#34;nvim-treesitter/nvim-treesitter\u0026#34;, -- Syntax highlighting \u0026#34;nvim-telescope/telescope.nvim\u0026#34;, -- Fuzzy finder \u0026#34;neovim/nvim-lspconfig\u0026#34;, -- LSP support \u0026#34;hrsh7th/nvim-cmp\u0026#34;, -- Auto-completion \u0026#34;hrsh7th/cmp-nvim-lsp\u0026#34;, -- LSP completion source \u0026#34;hrsh7th/cmp-buffer\u0026#34;, -- Buffer completion \u0026#34;hrsh7th/cmp-path\u0026#34;, -- Path completion \u0026#34;hrsh7th/cmp-nvim-lua\u0026#34;, -- Neovim Lua API completion \u0026#34;L3MON4D3/LuaSnip\u0026#34;, -- Snippet engine \u0026#34;saadparwaiz1/cmp_luasnip\u0026#34;, -- Snippet completion \u0026#34;nvim-lualine/lualine.nvim\u0026#34;, -- Status line \u0026#34;nvim-tree/nvim-tree.lua\u0026#34;, -- File explorer \u0026#34;tpope/vim-surround\u0026#34;, -- Surround text objects \u0026#34;tpope/vim-commentary\u0026#34;, -- Commenting shortcuts \u0026#34;lewis6991/gitsigns.nvim\u0026#34;, -- Git integration \u0026#34;akinsho/toggleterm.nvim\u0026#34;, -- Terminal management }) Save and exit Neovim, then open it and run:\n:Lazy sync This will install the plugins automatically.\n5. Setting Up Treesitter # Treesitter provides better syntax highlighting and code parsing. Install it by adding the following to your init.lua:\nrequire\u0026#39;nvim-treesitter.configs\u0026#39;.setup { ensure_installed = \u0026#34;all\u0026#34;, highlight = { enable = true, }, indent = { enable = true, }, } Then, update Treesitter by running:\n:TSUpdate 6. Setting Up LSP (Language Server Protocol) # LSP enables features like code completion and linting. Install LSP servers for your language:\n# Python sudo pacman -S python-lsp-server # C++ sudo pacman -S clang # JavaScript/TypeScript npm install -g typescript-language-server Then, enable LSP support in Neovim:\nlocal lspconfig = require(\u0026#34;lspconfig\u0026#34;) lspconfig.pyright.setup({}) -- Python lspconfig.ts_ls.setup({}) -- JavaScript/TypeScript lspconfig.clangd.setup({}) -- C++ Restart Neovim and check LSP status:\n:LspInfo 7. Enhancing Auto-Completion with nvim-cmp # To enable code auto-completion, update your init.lua:\nlocal cmp = require\u0026#39;cmp\u0026#39; cmp.setup({ mapping = { [\u0026#39;\u0026lt;C-Space\u0026gt;\u0026#39;] = cmp.mapping.complete(), [\u0026#39;\u0026lt;CR\u0026gt;\u0026#39;] = cmp.mapping.confirm({ select = true }), }, sources = { { name = \u0026#39;nvim_lsp\u0026#39; }, { name = \u0026#39;buffer\u0026#39; }, { name = \u0026#39;path\u0026#39; }, { name = \u0026#39;luasnip\u0026#39; }, { name = \u0026#39;nvim_lua\u0026#39; }, } }) 9. Final Thoughts # Congratulations! You now have a powerful, customized Neovim setup that functions as a full-fledged IDE. With features like Treesitter, LSP support, auto-completion, syntax highlighting, Git integration, and a file explorer, your development workflow will be much smoother.\nIf you’d like to further improve your Neovim experience, explore more plugins and tweak your settings. Good luck with that!\nFurther Reading # Neovim Documentation Awesome Neovim Plugins Arch Wiki: Neovim ","date":"2025-02-01","externalUrl":null,"permalink":"/posts/neovim/","section":"Posts","summary":"\u003ch1 class=\"relative group\"\u003eSetting Up Neovim: An Easy and Beginner\u0026rsquo;s Guide\n    \u003cdiv id=\"setting-up-neovim-an-easy-and-beginners-guide\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none\"\u003e\n        \u003ca class=\"text-primary-300 dark:text-neutral-700 !no-underline\" href=\"#setting-up-neovim-an-easy-and-beginners-guide\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e\n    \n\u003c/h1\u003e\n\u003cp\u003eNeovim is a modern and extensible text editor that enhances Vim’s capabilities. If you\u0026rsquo;re using Linux, setting up Neovim can be a rewarding experience, allowing you to customize it for an efficient workflow. In this guide, we\u0026rsquo;ll cover installing Neovim, setting up a basic configuration, and enhancing it with essential plugins to turn it into a full-fledged IDE.\u003c/p\u003e","title":"Setting Up Neovim: A Beginner's Guide","type":"posts"},{"content":" Linux Kernal # The majority of the kernel\u0026rsquo;s code is written in C, leveraging extensions provided by the GNU Compiler Collection (GCC) beyond standard C. Additionally, it includes assembly code for architecture-specific functions, such as optimizing memory usage and task execution. Architecturally, the Linux kernel is monolithic, meaning the entire OS operates within kernel space. However, it features a modular design, allowing software components to be integrated as modules, including dynamic loading.\nWhat Is A Kernel Module? # A Linux kernel module is precisely defined as a code segment capable of dynamic loading and unloading within the kernel as needed. These modules enhance kernel capabilities without necessitating a system reboot. A notable example is seen in the device driver module, which facilitates kernel interaction with hardware components linked to the system.\nWriting a Custom Linux Kernel Module # Linux kernel modules (LKMs) allow developers to extend the functionality of the Linux kernel without modifying its source code. This guide walks through writing a simple kernel module from scratch. Kernel modules are pieces of code that can be dynamically loaded and unloaded from the Linux kernel at runtime. They enable functionality such as device drivers, file system support, and system call extensions without requiring a kernel recompilation. LKMs are particularly useful for developing hardware drivers and testing new kernel features without rebooting the system.\nPrerequisites # Ensure you have the necessary development tools installed. On an Arch Linux system, install them with:\nsudo pacman -Syu linux-headers base-devel Creating a Simple Kernel Module # 1. Writing the Module Source Code # Create a file named hello_module.c:\n#include \u0026lt;linux/module.h\u0026gt; #include \u0026lt;linux/kernel.h\u0026gt; #include \u0026lt;linux/init.h\u0026gt; MODULE_LICENSE(\u0026#34;GPL\u0026#34;); MODULE_AUTHOR(\u0026#34;Your Name\u0026#34;); MODULE_DESCRIPTION(\u0026#34;A simple Hello World kernel module\u0026#34;); static int __init hello_init(void) { printk(KERN_INFO \u0026#34;Hello, Kernel!\\n\u0026#34;); return 0; } static void __exit hello_exit(void) { printk(KERN_INFO \u0026#34;Goodbye, Kernel!\\n\u0026#34;); } module_init(hello_init); module_exit(hello_exit); Understanding the Kernel Module Code # #include \u0026lt;linux/module.h\u0026gt;: Includes the necessary module macros and functions. #include \u0026lt;linux/kernel.h\u0026gt;: Provides kernel logging functions. #include \u0026lt;linux/init.h\u0026gt;: Defines initialization and cleanup macros. MODULE_LICENSE(\u0026quot;GPL\u0026quot;): Specifies the module\u0026rsquo;s license. MODULE_AUTHOR(\u0026quot;Your Name\u0026quot;): Specifies the author of the module. MODULE_DESCRIPTION(\u0026quot;A simple Hello World kernel module\u0026quot;): Provides a brief description. static int __init hello_init(void): The function executed when the module is loaded. static void __exit hello_exit(void): The function executed when the module is unloaded. module_init(hello_init): Registers hello_init as the module\u0026rsquo;s initialization function. module_exit(hello_exit): Registers hello_exit as the module\u0026rsquo;s cleanup function. 2. Writing the Makefile # Create a Makefile in the same directory:\nobj-m += hello_module.o all: make -C /lib/modules/$(shell uname -r)/build M=$(PWD) modules clean: make -C /lib/modules/$(shell uname -r)/build M=$(PWD) clean Understanding the Makefile # obj-m += hello_module.o: Specifies that hello_module.o is the object to be built as a module. all:: Defines the build target. make -C /lib/modules/$(shell uname -r)/build M=$(PWD) modules: Directs the kernel build system to compile the module. clean:: Cleans up the generated files. make -C /lib/modules/$(shell uname -r)/build M=$(PWD) clean: Cleans the build artifacts. 3. Compiling the Module # Run:\nmake 4. Loading and Unloading the Module # To insert the module into the kernel:\nsudo insmod hello_module.ko Check the kernel log:\ndmesg | tail To remove the module:\nsudo rmmod hello_module 5. Verifying the Module # List loaded modules:\nlsmod | grep hello_module Understanding the Generated Files # After building the module, several files are generated:\nhello_module.c: The source code of the module. hello_module.ko: The compiled kernel module file, ready to be loaded into the kernel. hello_module.o: An intermediate object file generated during compilation. hello_module.mod.c: An automatically generated file containing module metadata. hello_module.mod.o: An object file containing metadata compiled from hello_module.mod.c. hello_module.mod: Another metadata file required for module loading. Makefile: Contains instructions for building the module. Module.symvers: Stores information about exported symbols, useful for module dependencies. modules.order: Lists the order in which modules should be loaded. Conclusion # This simple kernel module demonstrates the basics of module development. You can expand upon this by adding functionality such as handling parameters or interacting with hardware.\nHappy kernel hacking!\n","date":"2025-01-23","externalUrl":null,"permalink":"/posts/custom-kernal/","section":"Posts","summary":"\u003ch1 class=\"relative group\"\u003eLinux Kernal\n    \u003cdiv id=\"linux-kernal\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none\"\u003e\n        \u003ca class=\"text-primary-300 dark:text-neutral-700 !no-underline\" href=\"#linux-kernal\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e\n    \n\u003c/h1\u003e\n\u003cp\u003eThe majority of the kernel\u0026rsquo;s code is written in C, leveraging extensions provided by the GNU Compiler Collection (GCC) beyond standard C. Additionally, it includes assembly code for architecture-specific functions, such as optimizing memory usage and task execution. Architecturally, the Linux kernel is monolithic, meaning the entire OS operates within kernel space. However, it features a modular design, allowing software components to be integrated as modules, including dynamic loading.\u003c/p\u003e","title":"How to Write a Custom Kernel Module","type":"posts"},{"content":" What is it? # gh is GitHub\u0026rsquo;s official command-line tool designed to extend Git\u0026rsquo;s functionality with GitHub-specific features.\nPurpose: # Simplifies interaction with GitHub\u0026rsquo;s ecosystem directly from the terminal. Allows you to manage repositories and use GitHub features like issues, pull requests, and workflows.\nKey Features: # GitHub-specific tasks:\nAuthentication: Easier login (gh auth login) without dealing with tokens manually. Repository Management: Create, fork, or clone repositories. Issues \u0026amp; Pull Requests: Manage issues, PRs, and comments directly. Actions: Manage and view GitHub Actions workflows. Works alongside Git for basic version control tasks. Use Case: # Best for developers heavily using GitHub and its features (for example: pull requests, issues, and actions).\nHow it works # Install gh:\n\u0026gt; yay -S github-cli Verify the installation:\n\u0026gt; gh --version Login with GitHub CLI (gh)\n\u0026gt; gh auth login Follow the interactive prompts to log in:\nChoose HTTPS or SSH for connection. Log in via a browser using a one-time code or SSH keys. Verify authentication:\n\u0026gt; gh auth status What\u0026rsquo;s best about it that you can install and use both Git and gh (GitHub CLI) seamlessly. Here\u0026rsquo;s how to set them up:\nInstall Git\n\u0026gt;sudo pacman -S git Check the installation:\n\u0026gt; git --version Using Git and gh Together # You can now: Use Git for version control:\n\u0026gt; git clone https://github.com/username/repo.git \u0026gt; git add . \u0026gt; git commit -m \u0026quot;message\u0026quot; \u0026gt; git push ","date":"2025-01-23","externalUrl":null,"permalink":"/posts/202501-github-cli-githubs-official-command-line-tools/","section":"Posts","summary":"\u003ch2 class=\"relative group\"\u003eWhat is it?\n    \u003cdiv id=\"what-is-it\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none\"\u003e\n        \u003ca class=\"text-primary-300 dark:text-neutral-700 !no-underline\" href=\"#what-is-it\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e\n    \n\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003egh\u003c/strong\u003e is GitHub\u0026rsquo;s official command-line tool designed to extend Git\u0026rsquo;s functionality with GitHub-specific features.\u003c/p\u003e","title":"GitHub CLI: GitHub's Official Command Line Tools","type":"posts"},{"content":"Connecting a Raspberry Pi 5 to a USB TTY cable is a common way to interact with it through a serial connection, especially for debugging or setting up the device without using a display.\nPrerequists\nRaspberry Pi 5. USB TTY (serial) cable. Computer with a terminal emulator (minicom/screen). GPIO pinout diagram of Raspberry Pi 5 (for reference). Power source for Raspberry Pi (optional if USB TTY can power it, though not recommended). Before Starting! # Issuse with firmware # UART does NOT work on the RPI5 from the factory. We will need a firmware update to fix this that prevents the dtoverlays for UARTs from working.\nInstall rpi-update with the following commands:\n\u0026gt; sudo curl -L --output /usr/bin/rpi-update https://raw.githubusercontent.com/Hexxeh/rpi-update/master/rpi-update \u0026amp;\u0026amp; sudo chmod +x /usr/bin/rpi-update Then update the firmware on your RPI5 with:\n\u0026gt; sudo rpi-update Enable UART # To manually configure UART, you can edit the config.txt file.\nEdit /boot/firmware/config.txt and add:\n\u0026gt; enable_uart=1 How to Connect # Locate the GPIO Pins Find the GPIO header on the Raspberry Pi 5. Identify the following pins: GND (Ground): Usually black wire on the USB TTY cable. TX (Transmit): Sends data from the Pi to the computer. RX (Receive): Receives data from the computer to the Pi.\nUse a GPIO pinout chart to locate these pins. For Raspberry Pi 5, it will likely be similar to previous models. Making connections # You will need to connect:\nGND with Ground - Pin# 06 TX with GPIO14 - Pin# 08 RX with GPIO15 - Pin# 10 Plug the USB TTY Cable into the Computer\nInsert the USB end of the TTY cable into your computer. The cable will create a virtual COM port (e.g /dev/ttyUSB0). Configure and Access Serial Console\nOpen a terminal.\nIdentify the port with:\n\u0026gt; ls /dev/ttyUSB* Use a terminal emulator like screen or minicom to connect:\n\u0026gt; screen /dev/ttyUSB0 115200 *Replace /dev/ttyUSB0 with the actual port name.\nTurn on the Raspberry Pi. If everything is set up correctly, you should see boot messages in the terminal. Log in to the Pi using the default username (pi) and password (raspberry), or your custom credentials. You should see something similar to this.\nThis is it! You have done it. Congrats!\n","date":"2025-01-20","externalUrl":null,"permalink":"/posts/202501-how-to-connect-a-raspberry-pi-5-to-usb-tty-cable/","section":"Posts","summary":"\u003cp\u003eConnecting a Raspberry Pi 5 to a USB TTY cable is a common way to interact with it through a serial connection, especially for debugging or setting up the device without using a display.\u003c/p\u003e","title":"How to Connect a Raspberry PI 5 to USB TTY Cable","type":"posts"},{"content":"Hosting a website on GitHub Pages with Hugo involves the following steps:\nCreating a website # 1. Install Hugo and git\n\u0026gt; sudo pacman -S Hugo 2. Create a new Hugo site\n\u0026gt; hugo new site your-website 3. Add a Theme\nNavigate to your website directory and add a theme. You can choose one from the Hugo Themes .\n\u0026gt; cd your-website \u0026gt; git init \u0026gt; git submodule add https://github.com/adityatelange/hugo-PaperMod.git themes/hugo-PaperMod Now you will need to update the hugo.toml file for them to take effect. To do so you can either echo or addd it in the file.\n\u0026gt; echo \u0026quot;theme = 'hugo-PaperMod'\u0026quot; \u0026gt;\u0026gt; hugo.toml To view the website you can run it locally using Hugo\u0026rsquo;s development server to view the site. You can add -D to see your drafts.\n\u0026gt; hugo server 3. Add Content\nTo add a new page to your site.\n\u0026gt; hugo new content content/posts/yout-first-post.md This is it You have done it. YAY!\nHosting it on GitHub # 1. Create a GitHub repository.\nClick the + icon in the top-right corner of:\u0026gt; [!WARNING] the GitHub interface and select New repository. Enter a repository name: yourusername.github.io Click Create repository. 2. Add Files for Your website\nClone the repository locally using Git:\ngit clone https://github.com//.git\nAdd your static site files (generated by Hugo) to the repository. Commit and push the changes:\n\u0026gt; git add -A \u0026gt; git commit -s -m \u0026quot;Initial commit\u0026quot; \u0026gt; git push origin main 3. Configure the Repository for GitHub Pages\nGo to the Settings tab of your new repository. Scroll down to the Pages section. Settings \u0026gt; Pages. In the center of your screen you will see this: Build and development Change the Source to GitHub Actions. 4. Create a file named hugo.yaml in a directory named .github/workflows.\n\u0026gt; mkdir -p .github/workflows \u0026gt; cd ./github/workflows touch hugo.yaml 5. Add content in the YAML file.\n# Sample workflow for building and deploying a Hugo site to GitHub Pages name: Deploy Hugo site to Pages on: # Runs on pushes targeting the default branch push: branches: - main # Allows you to run this workflow manually from the Actions tab workflow_dispatch: # Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages permissions: contents: read pages: write id-token: write # Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued. # However, do NOT cancel in-progress runs as we want to allow these production deployments to complete. concurrency: group: \u0026#34;pages\u0026#34; cancel-in-progress: false # Default to bash defaults: run: shell: bash jobs: # Build job build: runs-on: ubuntu-latest env: HUGO_VERSION: 0.141.0 steps: - name: Install Hugo CLI run: | wget -O ${{ runner.temp }}/hugo.deb https://github.com/gohugoio/hugo/releases/download/v${HUGO_VERSION}/hugo_extended_${HUGO_VERSION}_linux-amd64.deb \\ \u0026amp;\u0026amp; sudo dpkg -i ${{ runner.temp }}/hugo.deb - name: Install Dart Sass run: sudo snap install dart-sass - name: Checkout uses: actions/checkout@v4 with: submodules: recursive fetch-depth: 0 - name: Setup Pages id: pages uses: actions/configure-pages@v5 - name: Install Node.js dependencies run: \u0026#34;[[ -f package-lock.json || -f npm-shrinkwrap.json ]] \u0026amp;\u0026amp; npm ci || true\u0026#34; - name: Build with Hugo env: HUGO_CACHEDIR: ${{ runner.temp }}/hugo_cache HUGO_ENVIRONMENT: production TZ: America/Los_Angeles run: | hugo \\ --gc \\ --minify \\ --baseURL \u0026#34;${{ steps.pages.outputs.base_url }}/\u0026#34; - name: Upload artifact uses: actions/upload-pages-artifact@v3 with: path: ./public # Deployment job deploy: environment: name: github-pages url: ${{ steps.deployment.outputs.page_url }} runs-on: ubuntu-latest needs: build steps: - name: Deploy to GitHub Pages id: deployment uses: actions/deploy-pages@v4 5. Commit and push your GitHub repository.\n\u0026gt;git add -A \u0026gt;git commit -m \u0026quot;Create hugo.yaml\u0026quot; \u0026gt;git push 6. Deployment status From GitHub’s main menu, choose Actions. When GitHub has finished building and deploying your site, the color of the status indicator will change to green.\nStep 5: Verify Your GitHub Pages Site\nThe site will be live at https://yourusername.github.io.\n","date":"2025-01-20","externalUrl":null,"permalink":"/posts/hosting-a-website-on-github-pages-with-hugo./","section":"Posts","summary":"\u003cp\u003eHosting a website on GitHub Pages with Hugo involves the following steps:\u003c/p\u003e\n\n\u003ch1 class=\"relative group\"\u003eCreating a website\n    \u003cdiv id=\"creating-a-website\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none\"\u003e\n        \u003ca class=\"text-primary-300 dark:text-neutral-700 !no-underline\" href=\"#creating-a-website\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e\n    \n\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e1. Install Hugo and git\u003c/strong\u003e\u003c/p\u003e","title":"Hosting a Website on Github Pages With Hugo","type":"posts"},{"content":"","date":"2024-08-09","externalUrl":null,"permalink":"/categories/ai/","section":"Categories","summary":"","title":"AI","type":"categories"},{"content":"","date":"2024-08-09","externalUrl":null,"permalink":"/tags/api/","section":"Tags","summary":"","title":"API","type":"tags"},{"content":"","date":"2024-08-09","externalUrl":null,"permalink":"/categories/automation/","section":"Categories","summary":"","title":"Automation","type":"categories"},{"content":"Build your own AI-powered WhatsApp chatbot using n8n, WhatsApp Business Cloud API, and OpenAI. This guide walks you through every step—from setup to testing—with real-world error handling and solutions.\nTable of Contents # Introduction Prerequisites Registering Your WhatsApp Business App Configuring Your Webhook in n8n Processing Incoming Messages Integrating OpenAI for Responses Sending Replies via WhatsApp Common Errors \u0026amp; Fixes Going Live Conclusion \u0026amp; Next Steps 1. Introduction # Want to chat with an AI on WhatsApp? In this tutorial, you\u0026rsquo;ll learn how to build a WhatsApp AI Assistant using:\nn8n (automation tool) WhatsApp Business Cloud API OpenAI (for generating intelligent replies) By the end, you\u0026rsquo;ll have a working chatbot and gain hands-on experience with APIs, webhooks, and automation.\n2. Prerequisites # n8n account (Cloud or self-hosted) Meta Developer account with WhatsApp Business Cloud API access OpenAI API key Basic understanding of APIs and webhook workflows 3. Registering Your WhatsApp Business App # A. Create WhatsApp App in Meta Developer # Visit Meta for Developers Create a new app: choose Business → WhatsApp Link or create a WhatsApp Business Account B. Obtain Testing Credentials # Your app dashboard will show:\nTest phone number Phone Number ID Temporary access token (valid for only 24 hours) Tip: For long-term use, generate a 60-day system-user token later.\nC. Add Recipients to Test List # By default, only approved numbers can receive messages:\nNavigate to WhatsApp → API Setup Add numbers in E.164 format (e.g., +923001234567) Users must accept the invite via WhatsApp to become valid recipients 4. Configuring Your Webhook in n8n # A. Create a Webhook Node # Method: GET (for initial verification) Endpoint example: https://yourname.app.n8n.cloud/webhook/your-unique-id/webhook B. Verify the Webhook with Meta # In your app’s Webhook section:\nCallback URL: your n8n webhook URL Verify Token: any secret string you choose (e.g., mySecret2025) C. Echo Back Meta’s Challenge # Configure n8n\u0026rsquo;s Webhook node response:\nField Value Response Mode On Received Response Body {{$json[\u0026quot;query\u0026quot;][\u0026quot;hub.challenge\u0026quot;]}} This ensures Meta can verify your endpoint successfully.\n5. Processing Incoming Messages # WhatsApp sends JSON data with structure like:\n{ \u0026#34;entry\u0026#34;: [ { \u0026#34;changes\u0026#34;: [ { \u0026#34;value\u0026#34;: { \u0026#34;messages\u0026#34;: [ { \u0026#34;from\u0026#34;: \u0026#34;923001234567\u0026#34;, \u0026#34;text\u0026#34;: { \u0026#34;body\u0026#34;: \u0026#34;Hello bot!\u0026#34; } } ], \u0026#34;metadata\u0026#34;: { \u0026#34;phone_number_id\u0026#34;: \u0026#34;698352170035199\u0026#34; } } } ] } ] } Extract:\nfrom: user’s number text.body: user’s text metadata.phone_number_id: correct sender ID 6. Integrating OpenAI for Responses # Use an HTTP Request node to call OpenAI:\nPOST https://api.openai.com/v1/chat/completions Authorization: Bearer YOUR_OPENAI_API_KEY Content-Type: application/json { \u0026#34;model\u0026#34;: \u0026#34;gpt-4o-mini\u0026#34;, \u0026#34;messages\u0026#34;: [ { \u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;You are a helpful WhatsApp AI assistant.\u0026#34; }, { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;{{ $json[...] }}\u0026#34; } ] } Replace {{ $json[...] }} with the actual path to the user\u0026rsquo;s message text from the Webhook node.\n7. Sending Replies via WhatsApp # Use another HTTP Request node to respond:\nPOST https://graph.facebook.com/v21.0/{{ $json[...] }}/messages Authorization: Bearer YOUR_LONG_LIVED_TOKEN Content-Type: application/json { \u0026#34;messaging_product\u0026#34;: \u0026#34;whatsapp\u0026#34;, \u0026#34;to\u0026#34;: \u0026#34;{{ $json[...] }}\u0026#34;, \u0026#34;text\u0026#34;: { \u0026#34;body\u0026#34;: \u0026#34;{{ $node[\u0026#39;OpenAI Response\u0026#39;].json.choices[0].message.content }}\u0026#34; } } Use the metadata’s phone_number_id for the endpoint and from for the recipient. This avoids hardcoding and ensures proper routing.\n8. Common Errors \u0026amp; Fixes # Recipient phone number not in allowed list\n→ Add as test number or switch to Live mode\n401 – Session expired\n→ Refresh token via Graph API:\nGET https://graph.facebook.com/v21.0/oauth/access_token ?grant_type=fb_exchange_token \u0026amp;client_id=YOUR_APP_ID \u0026amp;client_secret=YOUR_APP_SECRET \u0026amp;fb_exchange_token=YOUR_CURRENT_TOKEN Webhook verification failed\n→ Ensure verify token matches between Meta and n8n and echo hub.challenge\nNo execution data available\n→ Trigger workflow via actual WhatsApp message, not manual run\n9. Going Live # Add a Privacy Policy URL in Meta App → Settings → Basic (required for live access) Switch app to Live mode once all compliance items are met Remove restricted recipient list Use WhatsApp message templates for messages sent after 24 hours of user interaction 10. Conclusion \u0026amp; Next Steps # Congrats! You now have a WhatsApp AI Assistant built with n8n and OpenAI.\nWhere to go from here: # Wire up custom knowledge (PDFs, documents) Implement memory for conversation context Launch multilingual support Export n8n workflow as JSON for reuse Need help? Join the n8n Community Forum or OpenAI Discord to connect with fellow builders.\nHappy automating!\n","date":"2024-08-09","externalUrl":null,"permalink":"/posts/202408-creating-whatsapp-ai-assistant-using-n8n/","section":"Posts","summary":"\u003cp\u003eBuild your own AI-powered WhatsApp chatbot using \u003cstrong\u003en8n\u003c/strong\u003e, \u003cstrong\u003eWhatsApp Business Cloud API\u003c/strong\u003e, and \u003cstrong\u003eOpenAI\u003c/strong\u003e. This guide walks you through every step—from setup to testing—with real-world error handling and solutions.\u003c/p\u003e\n\u003chr\u003e\n\n\u003ch2 class=\"relative group\"\u003eTable of Contents\n    \u003cdiv id=\"table-of-contents\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none\"\u003e\n        \u003ca class=\"text-primary-300 dark:text-neutral-700 !no-underline\" href=\"#table-of-contents\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e\n    \n\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca\n  href=\"#introduction\"\u003eIntroduction\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\n  href=\"#prerequisites\"\u003ePrerequisites\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\n  href=\"#registering-your-whatsapp-business-app\"\u003eRegistering Your WhatsApp Business App\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\n  href=\"#configuring-your-webhook-in-n8n\"\u003eConfiguring Your Webhook in n8n\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\n  href=\"#processing-incoming-messages\"\u003eProcessing Incoming Messages\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\n  href=\"#integrating-openai-for-responses\"\u003eIntegrating OpenAI for Responses\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\n  href=\"#sending-replies-via-whatsapp\"\u003eSending Replies via WhatsApp\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\n  href=\"#common-errors--fixes\"\u003eCommon Errors \u0026amp; Fixes\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\n  href=\"#going-live\"\u003eGoing Live\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca\n  href=\"#conclusion--next-steps\"\u003eConclusion \u0026amp; Next Steps\u003c/a\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003chr\u003e\n\n\u003ch2 class=\"relative group\"\u003e1. Introduction\n    \u003cdiv id=\"1-introduction\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none\"\u003e\n        \u003ca class=\"text-primary-300 dark:text-neutral-700 !no-underline\" href=\"#1-introduction\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e\n    \n\u003c/h2\u003e\n\u003cp\u003eWant to chat with an AI on WhatsApp? In this tutorial, you\u0026rsquo;ll learn how to build a \u003cstrong\u003eWhatsApp AI Assistant\u003c/strong\u003e using:\u003c/p\u003e","title":"Creating a WhatsApp AI Assistant Using n8n: A Step-by-Step Guide","type":"posts"},{"content":"","date":"2024-08-09","externalUrl":null,"permalink":"/tags/n8n/","section":"Tags","summary":"","title":"N8n","type":"tags"},{"content":" Experience Company Link Role Dates Location COLAB NU Teir III Member Oct 2024 - Present Fast National University Peshawar Communities Work Company Link Role Dates Location AWS Club FAST NUCES Co-Lead Teachnical Team Sep. 2025 - Present Fast National University Peshawar SOS Children's Village Tutor Sep. 2025 - Dec. 2025 SOS Children's Village Book Club FAST NUCES Member Nov. 2024 - Present Fast National University Peshawar Education School Link Degree Date National University of Computer and Emerging Sciences Bachelor of Science in Computer Science; CGPA: 3.50 Aug. 2024 - Present ","date":"2022-06-13","externalUrl":null,"permalink":"/resume/","section":"","summary":"\u003ch2 class=\"relative group\"\u003eExperience\n    \u003cdiv id=\"experience\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n\u003c/h2\u003e\n\u003ctable\u003e\n    \u003cthead\u003e\n        \u003ctr\u003e\n            \u003cth\u003eCompany\u003c/th\u003e\n            \u003cth\u003eLink\u003c/th\u003e\n            \u003cth\u003eRole\u003c/th\u003e\n            \u003cth\u003eDates\u003c/th\u003e\n            \u003cth\u003eLocation\u003c/th\u003e\n        \u003c/tr\u003e\n    \u003c/thead\u003e\n    \u003ctbody\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u003cimg class=\"customEntitityLogo\" style=\"background-color:transparent\" src=\"colab_nu_logo.png\"/\u003e\u003c/td\u003e\n            \u003ctd\u003e\u003ca href=\"#\" target=\"_blank\"\u003eCOLAB NU\u003c/a\u003e\u003c/td\u003e\n            \u003ctd\u003eTeir III Member\u003c/td\u003e\n            \u003ctd\u003eOct 2024 - Present\u003c/td\u003e\n            \u003ctd\u003eFast National University Peshawar\u003c/td\u003e\n        \u003c/tr\u003e\n    \u003c/tbody\u003e\n\u003c/table\u003e\n\u003chr\u003e\n\n\u003ch2 class=\"relative group\"\u003eCommunities Work\n    \u003cdiv id=\"communities-work\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n\u003c/h2\u003e\n\u003ctable\u003e\n    \u003cthead\u003e\n        \u003ctr\u003e\n            \u003cth\u003eCompany\u003c/th\u003e\n            \u003cth\u003eLink\u003c/th\u003e\n            \u003cth\u003eRole\u003c/th\u003e\n            \u003cth\u003eDates\u003c/th\u003e\n            \u003cth\u003eLocation\u003c/th\u003e\n        \u003c/tr\u003e\n    \u003c/thead\u003e\n    \u003ctbody\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u003cimg class=\"customEntitityLogo\"  style=\"background-color:transparent\" src=\"aws_fast_logo.png\"/\u003e\u003c/td\u003e\n            \u003ctd\u003e\u003ca href=\"#\" target=\"_blank\"\u003eAWS Club FAST NUCES\u003c/a\u003e\u003c/td\u003e\n            \u003ctd\u003eCo-Lead Teachnical Team\u003c/td\u003e\n            \u003ctd\u003eSep. 2025 - Present\u003c/td\u003e\n            \u003ctd\u003eFast National University Peshawar\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u003cimg class=\"customEntitityLogo\" style=\"background-color:transparent\" src=\"sos_logo.png\"/\u003e\u003c/td\u003e\n            \u003ctd\u003e\u003ca href=\"#\" target=\"_blank\"\u003eSOS Children's Village\u003c/a\u003e\u003c/td\u003e\n            \u003ctd\u003eTutor\u003c/td\u003e\n            \u003ctd\u003eSep. 2025 - Dec. 2025 \u003c/td\u003e\n            \u003ctd\u003eSOS Children's Village\u003c/td\u003e\n        \u003c/tr\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u003cimg class=\"customEntitityLogo\" style=\"background-color:transparent\" src=\"book_club_fast_logo.png\"/\u003e\u003c/td\u003e\n            \u003ctd\u003e\u003ca href=\"#\" target=\"_blank\"\u003eBook Club FAST NUCES\u003c/a\u003e\u003c/td\u003e\n            \u003ctd\u003eMember\u003c/td\u003e\n            \u003ctd\u003eNov. 2024 - Present\u003c/td\u003e\n            \u003ctd\u003eFast National University Peshawar\u003c/td\u003e\n        \u003c/tr\u003e\n    \u003c/tbody\u003e\n\u003c/table\u003e\n\u003chr\u003e\n\n\u003ch2 class=\"relative group\"\u003eEducation\n    \u003cdiv id=\"education\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n\u003c/h2\u003e\n\u003ctable\u003e\n    \u003cthead\u003e\n        \u003ctr\u003e\n            \u003cth\u003eSchool\u003c/th\u003e\n            \u003cth\u003eLink\u003c/th\u003e\n            \u003cth\u003eDegree\u003c/th\u003e\n            \u003cth\u003eDate\u003c/th\u003e\n        \u003c/tr\u003e\n    \u003c/thead\u003e\n    \u003ctbody\u003e\n        \u003ctr\u003e\n            \u003ctd\u003e\u003cimg class=\"customEntitityLogo\" style=\"background-color:transparent\"  src=\"nuces_logo.png\"/\u003e\u003c/td\u003e\n            \u003ctd\u003e\u003ca href=\"#\" target=\"_blank\"\u003eNational University of Computer and Emerging Sciences\u003c/a\u003e\u003c/td\u003e\n            \u003ctd\u003eBachelor of Science in Computer Science; CGPA: 3.50\u003c/td\u003e\n            \u003ctd\u003eAug. 2024 - Present\u003c/td\u003e\n        \u003c/tr\u003e\n    \u003c/tbody\u003e\n\u003c/table\u003e","title":"Resume","type":"page"},{"content":"I’m a Computer Science student at FAST NUCES with a growing focus on systems, tooling, and developer experience. Through my work at COLAB NU as a Tier III member, I’ve built static sites with Hugo, written custom Linux kernel modules, experimented with Raspberry Pi based embedded systems, and configured virtualization stacks using KVM/QEMU with libvirt and virt-manager.\nOutside of classes, I like building things from the ground up: a minimal text editor and POSIX shell in C, a ray tracer in C++, and a full computer system via Nand2Tetris, from logic gates to a working compiler. I’m active in communities like AWS, and my university book club, where I learn, share, and collaborate. I enjoy writing, tinkering with low-level tools, and helping others get closer to how computers really work.\n","date":"2022-06-13","externalUrl":null,"permalink":"/about/","section":"","summary":"\u003cp\u003eI’m a Computer Science student at FAST NUCES with a growing focus on systems, tooling, and developer experience. Through my work at COLAB NU as a Tier III member, I’ve built static sites with Hugo, written custom Linux kernel modules, experimented with Raspberry Pi based embedded systems, and configured virtualization stacks using KVM/QEMU with libvirt and virt-manager.\u003c/p\u003e","title":"About","type":"page"},{"content":"","date":"2022-06-13","externalUrl":null,"permalink":"/music/","section":"","summary":"","title":"Music","type":"page"},{"content":"","date":"2022-06-13","externalUrl":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":"I consistently seek out opportunities to learn and build through new projects. Although many of these personal initiatives don\u0026rsquo;t always reach a public release, they are instrumental in allowing me to experiment, grow, and apply new skills in practical scenarios.\nLogo Title Description References TextEditor Coded in C/C++ with no dependencies, implementing all basic text editor features. [cite: 13] github POSIX-Shell\nBuilt a Portable Operating System Interface compliant shell using C language. [cite: 14] github RayTracing\nImplemented a ray tracer from scratch using C++ to gain experience in rendering algorithms, 3D graphics, and computational geometry. [cite: 15] github Nand2Tetris\nBuilt a complete modern computer system from the ground up, designing hardware (logic gates to CPU) and software (assembler, VM, compiler) layers. [cite: 16] github ","date":"2022-06-13","externalUrl":null,"permalink":"/projects/","section":"","summary":"\u003cp\u003eI consistently seek out opportunities to learn and build through new projects. Although many of these personal initiatives don\u0026rsquo;t always reach a public release, they are instrumental in allowing me to experiment, grow, and apply new skills in practical scenarios.\u003c/p\u003e","title":"Projects","type":"page"},{"content":"","date":"2021-09-09","externalUrl":null,"permalink":"/categories/arch-linux/","section":"Categories","summary":"","title":"Arch Linux","type":"categories"},{"content":"Kernel-based Virtual Machine is a free and open-source virtualization module in the Linux kernel that allows the kernel to function as a hypervisor.\nInstallation # For updates, run the following command:\n$ sudo pacman -Syu QEMU/KVM installation: # We\u0026rsquo;ll install qemu and all the utils required:\n$ sudo pacman -S qemu vde2 ebtables iptables-nft nftables dms masq bridge-utils ovmf swptm Virtual Machine Manager installation: # The virt-manager application is a graphical user interface for managing virtual machines through libvirt. It primarily targets KVM VMs.\n$ sudo pacman -S virt-manager Now everything is set to work. We can move towards downloading archlinux .iso file.\nDownload .iso file: # Head towards: https://archlinux.org/download/ Scroll through and look for the server closest to you. Download archlinux-2024.10.01-x86_64.iso file. Setting up: # Open terminal and run the following command:\n$ virt-manager You will see an interface similar to this:\nClick on \u0026lsquo;create a new virtual machine\u0026rsquo; (option with star). Select \u0026lsquo;Local install media\u0026rsquo;. Browse to your \u0026lsquo;archlinux-2024.10.01-x86_64.iso\u0026rsquo;. Add your desired VM configuration and create a disk image. Boot Menu: # You will be prompted to a boot menu.\nSelect the topmost option to start the installation process. Archlinux Installer: # You will be prompted to a terminal. The first step is to check if you are connected to the internet.\nRun:\n# ip addr show If it shows an IP address and says \u0026lsquo;UP\u0026rsquo;, that means you are good to go.\nIf not: # You will need to connect to the internet using the \u0026lsquo;iwctl\u0026rsquo; method for Wi-Fi.\n# iwctl To search networks in your vicinity:\n[iwd]# station [your_wifi_interface] get-networks Get the name of the network you want to connect to. Exit from this prompt using \u0026rsquo;exit\u0026rsquo;.\nTo connect to the desired Wi-Fi network, run:\n# iwctl --passphrase \u0026#34;[wifi_password]\u0026#34; station [your_wifi_interface] connect [wifi_name] You can again run ip addr show to check if you are connected to the network.\nNow you can run the installation command. We\u0026rsquo;ll be using the archinstall method.\n# archinstall You will be prompted to an interface similar to this:\nWe will install Arch using this interface. Go through each option:\nArchinstall language: Choose your preferred language. Mirrors: Select the mirror region closest to you. Use \u0026lsquo;/\u0026rsquo; to search. Locales: Set language and keyboard layout. Disk configuration: Choose Best-effort default partition to format the system. Bootloader: Use the default \u0026lsquo;Grub\u0026rsquo; option. Swap: Select Swap on zram (default). Hostname: Leave as it is. Root password: Set the password for sudo/root privileges. User account: Set up a user account. Profile: Select Desktop. It includes essential packages. Others include Minimal, Server, and Xorg. In Desktop, select your desktop environment. We\u0026rsquo;ll use Gnome for simplicity.\nAudio: Use PipeWire (default) or PulseAudio. Kernels: Use the linux kernel. Additional packages: Install any required packages. Network Configuration: Use NetworkManager for a GUI in Gnome. Timezone: Set the timezone closest to you and enable time sync. Press Install. Congratulations! You\u0026rsquo;ve successfully installed Arch Linux.\n","date":"2021-09-09","externalUrl":null,"permalink":"/posts/202109-arch-linux-qemu-kvm/","section":"Posts","summary":"\u003cp\u003eKernel-based Virtual Machine is a free and open-source virtualization module in the Linux kernel that allows the kernel to function as a hypervisor.\u003c/p\u003e\n\n\u003ch2 class=\"relative group\"\u003eInstallation\n    \u003cdiv id=\"installation\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none\"\u003e\n        \u003ca class=\"text-primary-300 dark:text-neutral-700 !no-underline\" href=\"#installation\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e\n    \n\u003c/h2\u003e\n\u003cp\u003eFor updates, run the following command:\u003c/p\u003e","title":"Arch Linux installation in hypervisor through QEMU/KVM","type":"posts"},{"content":"","date":"2021-09-09","externalUrl":null,"permalink":"/tags/hypervisor/","section":"Tags","summary":"","title":"HyperVisor","type":"tags"},{"content":"","date":"2021-09-09","externalUrl":null,"permalink":"/tags/linux/","section":"Tags","summary":"","title":"Linux","type":"tags"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":" Aspiring SoftDev ","externalUrl":null,"permalink":"/authors/hisamshar/","section":"Authors","summary":"\u003cdiv class=\"flex mt-4\"\u003e\n  \u003cimg class=\"!mt-0 !mb-0 h-24 w-24 rounded-full ltr:mr-4 rtl:ml-4\" width=\"96\" height=\"96\"\n    src=\"avatar.jpg\" /\u003e\n  \u003cdiv class=\"place-self-center\"\u003e\n    \u003cdiv class=\"text-sm text-neutral-700 dark:text-neutral-400\"\u003eAspiring SoftDev\u003c/div\u003e\n    \u003cdiv class=\"text-2xl sm:text-lg\"\u003e\n      \u003cdiv class=\"flex flex-wrap text-neutral-400 dark:text-neutral-500\"\u003e\n        \u003ca class=\"px-1 hover:text-primary-700 dark:hover:text-primary-400\" href=\"https://linkedin.com/in/nunocoracao\" target=\"_blank\"\n          aria-label=\"{{ $name | title }}\" rel=\"me noopener noreferrer\"\u003e\u003cspan class=\"relative inline-block align-text-bottom icon\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 448 512\"\u003e\u003cpath fill=\"currentColor\" d=\"M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z\"/\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/a\u003e\n        \u003ca class=\"px-1 hover:text-primary-700 dark:hover:text-primary-400\" href=\"https://twitter.com/nunocoracao\" target=\"_blank\"\n          aria-label=\"{{ $name | title }}\" rel=\"me noopener noreferrer\"\u003e\u003cspan class=\"relative inline-block align-text-bottom icon\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\"\u003e\u003cpath fill=\"currentColor\" d=\"M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z\"/\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/a\u003e\n        \u003ca class=\"px-1 hover:text-primary-700 dark:hover:text-primary-400\" href=\"https://instagram.com/nunocoracao\" target=\"_blank\"\n          aria-label=\"{{ $name | title }}\" rel=\"me noopener noreferrer\"\u003e\u003cspan class=\"relative inline-block align-text-bottom icon\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 448 512\"\u003e\u003cpath fill=\"currentColor\" d=\"M224.1 141c-63.6 0-114.9 51.3-114.9 114.9s51.3 114.9 114.9 114.9S339 319.5 339 255.9 287.7 141 224.1 141zm0 189.6c-41.1 0-74.7-33.5-74.7-74.7s33.5-74.7 74.7-74.7 74.7 33.5 74.7 74.7-33.6 74.7-74.7 74.7zm146.4-194.3c0 14.9-12 26.8-26.8 26.8-14.9 0-26.8-12-26.8-26.8s12-26.8 26.8-26.8 26.8 12 26.8 26.8zm76.1 27.2c-1.7-35.9-9.9-67.7-36.2-93.9-26.2-26.2-58-34.4-93.9-36.2-37-2.1-147.9-2.1-184.9 0-35.8 1.7-67.6 9.9-93.9 36.1s-34.4 58-36.2 93.9c-2.1 37-2.1 147.9 0 184.9 1.7 35.9 9.9 67.7 36.2 93.9s58 34.4 93.9 36.2c37 2.1 147.9 2.1 184.9 0 35.9-1.7 67.7-9.9 93.9-36.2 26.2-26.2 34.4-58 36.2-93.9 2.1-37 2.1-147.8 0-184.8zM398.8 388c-7.8 19.6-22.9 34.7-42.6 42.6-29.5 11.7-99.5 9-132.1 9s-102.7 2.6-132.1-9c-19.6-7.8-34.7-22.9-42.6-42.6-11.7-29.5-9-99.5-9-132.1s-2.6-102.7 9-132.1c7.8-19.6 22.9-34.7 42.6-42.6 29.5-11.7 99.5-9 132.1-9s102.7-2.6 132.1 9c19.6 7.8 34.7 22.9 42.6 42.6 11.7 29.5 9 99.5 9 132.1s2.7 102.7-9 132.1z\"/\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/a\u003e\n        \u003ca class=\"px-1 hover:text-primary-700 dark:hover:text-primary-400\" href=\"https://medium.com/@nunocoracao\" target=\"_blank\"\n          aria-label=\"{{ $name | title }}\" rel=\"me noopener noreferrer\"\u003e\u003cspan class=\"relative inline-block align-text-bottom icon\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 640 512\"\u003e\u003cpath fill=\"currentColor\" d=\"M180.5,74.262C80.813,74.262,0,155.633,0,256S80.819,437.738,180.5,437.738,361,356.373,361,256,280.191,74.262,180.5,74.262Zm288.25,10.646c-49.845,0-90.245,76.619-90.245,171.095s40.406,171.1,90.251,171.1,90.251-76.619,90.251-171.1H559C559,161.5,518.6,84.908,468.752,84.908Zm139.506,17.821c-17.526,0-31.735,68.628-31.735,153.274s14.2,153.274,31.735,153.274S640,340.631,640,256C640,171.351,625.785,102.729,608.258,102.729Z\"/\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/a\u003e\n        \u003ca class=\"px-1 hover:text-primary-700 dark:hover:text-primary-400\" href=\"https://github.com/nunocoracao\" target=\"_blank\"\n          aria-label=\"{{ $name | title }}\" rel=\"me noopener noreferrer\"\u003e\u003cspan class=\"relative inline-block align-text-bottom icon\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 496 512\"\u003e\u003cpath fill=\"currentColor\" d=\"M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z\"/\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/a\u003e\n        \u003ca class=\"px-1 hover:text-primary-700 dark:hover:text-primary-400\" href=\"http://goodreads.com/nunocoracao\" target=\"_blank\"\n          aria-label=\"{{ $name | title }}\" rel=\"me noopener noreferrer\"\u003e\u003cspan class=\"relative inline-block align-text-bottom icon\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 448 512\"\u003e\u003cpath fill=\"currentColor\" d=\"M299.9 191.2c5.1 37.3-4.7 79-35.9 100.7-22.3 15.5-52.8 14.1-70.8 5.7-37.1-17.3-49.5-58.6-46.8-97.2 4.3-60.9 40.9-87.9 75.3-87.5 46.9-.2 71.8 31.8 78.2 78.3zM448 88v336c0 30.9-25.1 56-56 56H56c-30.9 0-56-25.1-56-56V88c0-30.9 25.1-56 56-56h336c30.9 0 56 25.1 56 56zM330 313.2s-.1-34-.1-217.3h-29v40.3c-.8.3-1.2-.5-1.6-1.2-9.6-20.7-35.9-46.3-76-46-51.9.4-87.2 31.2-100.6 77.8-4.3 14.9-5.8 30.1-5.5 45.6 1.7 77.9 45.1 117.8 112.4 115.2 28.9-1.1 54.5-17 69-45.2.5-1 1.1-1.9 1.7-2.9.2.1.4.1.6.2.3 3.8.2 30.7.1 34.5-.2 14.8-2 29.5-7.2 43.5-7.8 21-22.3 34.7-44.5 39.5-17.8 3.9-35.6 3.8-53.2-1.2-21.5-6.1-36.5-19-41.1-41.8-.3-1.6-1.3-1.3-2.3-1.3h-26.8c.8 10.6 3.2 20.3 8.5 29.2 24.2 40.5 82.7 48.5 128.2 37.4 49.9-12.3 67.3-54.9 67.4-106.3z\"/\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/a\u003e\n        \u003ca class=\"px-1 hover:text-primary-700 dark:hover:text-primary-400\" href=\"https://reddit.com/user/nunoheart\" target=\"_blank\"\n          aria-label=\"{{ $name | title }}\" rel=\"me noopener noreferrer\"\u003e\u003cspan class=\"relative inline-block align-text-bottom icon\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\"\u003e\u003cpath fill=\"currentColor\" d=\"M201.5 305.5c-13.8 0-24.9-11.1-24.9-24.6 0-13.8 11.1-24.9 24.9-24.9 13.6 0 24.6 11.1 24.6 24.9 0 13.6-11.1 24.6-24.6 24.6zM504 256c0 137-111 248-248 248S8 393 8 256 119 8 256 8s248 111 248 248zm-132.3-41.2c-9.4 0-17.7 3.9-23.8 10-22.4-15.5-52.6-25.5-86.1-26.6l17.4-78.3 55.4 12.5c0 13.6 11.1 24.6 24.6 24.6 13.8 0 24.9-11.3 24.9-24.9s-11.1-24.9-24.9-24.9c-9.7 0-18 5.8-22.1 13.8l-61.2-13.6c-3-.8-6.1 1.4-6.9 4.4l-19.1 86.4c-33.2 1.4-63.1 11.3-85.5 26.8-6.1-6.4-14.7-10.2-24.1-10.2-34.9 0-46.3 46.9-14.4 62.8-1.1 5-1.7 10.2-1.7 15.5 0 52.6 59.2 95.2 132 95.2 73.1 0 132.3-42.6 132.3-95.2 0-5.3-.6-10.8-1.9-15.8 31.3-16 19.8-62.5-14.9-62.5zM302.8 331c-18.2 18.2-76.1 17.9-93.6 0-2.2-2.2-6.1-2.2-8.3 0-2.5 2.5-2.5 6.4 0 8.6 22.8 22.8 87.3 22.8 110.2 0 2.5-2.2 2.5-6.1 0-8.6-2.2-2.2-6.1-2.2-8.3 0zm7.7-75c-13.6 0-24.6 11.1-24.6 24.9 0 13.6 11.1 24.6 24.6 24.6 13.8 0 24.9-11.1 24.9-24.6 0-13.8-11-24.9-24.9-24.9z\"/\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/a\u003e                \n      \u003c/div\u003e\n    \u003c/div\u003e\n  \u003c/div\u003e\n\u003c/div\u003e","title":"Hisam Mehboob","type":"authors"},{"content":"","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"}]