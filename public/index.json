[{"content":"Building the Linux Kernel Compiling the Linux Kernel involves multiple steps and can take some time depending on your hardware specifications.\nStep 1: Download the Kernel Source Code Start by visiting the Official Linux Kernel Website and downloading the latest available kernel source code. The downloaded file will be a compressed archive containing all necessary source files.\nStep 2: Extract the Source Code Once the download completes, extract the contents of the compressed archive using the tar command:\ntar xvf linux-6.13.tar.xz If the tar utility is not installed on your system, you can install it using:\nsudo pacman -S tar Note: Always ensure you are using the correct version number in the file name.\nStep 3: Install Required Dependencies To compile the kernel, you need to install various development tools and libraries. Install them using the following command:\nsudo pacman -S git fakeroot ncurses xz bc flex bison base-devel kmod cpio perl binutils util-linux jfsutils e2fsprogs xfsprogs squashfs-tools quota-tools Step 4: Configure the Kernel Navigate into the kernel source directory: cd linux-6.13 Use your current system’s configuration as a base:\nIf zcat is available, run:\nzcat /proc/config.gz \u0026gt; .config Otherwise, use this alternative method:\ncp /proc/config.gz ./ gunzip config.gz mv config .config Customize the kernel using a menu-driven interface:\nmake menuconfig make xconfig make oldconfig Modify the .config file directly:\nOpen it with a text editor:\nsudo vim .config Search for the line:\nCONFIG_EXT4_FS=m And change it to:\nCONFIG_EXT4_FS=y Step 5: Compile the Kernel Determine the number of CPU cores available to speed up compilation: nproc Compile the kernel using the number of cores found above. Replace n with that number: make -j\u0026lt;n\u0026gt; If you encounter any errors during or after this step, back up your .config file and reset the source tree with:\nmake mrproper This command cleans the build environment and restores the source tree to its original state.\nStep 6: Install Kernel Modules Kernel modules are essential for extending the kernel’s functionality and ensuring compatibility with various hardware. Install them with:\nsudo make modules_install Step 7: Install the Kernel You can install the compiled kernel using one of the two methods below:\nAutomatic installation: sudo make install Manual installation (if the above doesn\u0026rsquo;t work):\nCopy the kernel image:\nsudo cp arch/x86/boot/bzImage /boot/vmlinuz-linux-custom Copy the System.map file:\nsudo cp System.map /boot/System.map-linux-custom Copy the kernel configuration file:\nsudo cp .config /boot/config-linux-custom Step 8: Update the Bootloader If you use GRUB, follow these steps to add an entry for your custom kernel:\nFind the UUID of your root partition: lsblk -f Open the custom GRUB configuration file: sudo nvim /etc/grub.d/40_custom Add the following entry (replace paste-your-root-partition-uuid-here with the actual UUID): menuentry \u0026#39;Custom Linux Kernel\u0026#39; { linux /boot/vmlinuz-linux-custom root=UUID=paste-your-root-partition-uuid-here initrd /boot/initramfs-linux.img } Step 9: Generate Initramfs As you\u0026rsquo;ve compiled a new kernel, installed modules, and modified boot entries, generating a new initramfs is necessary. Run:\nsudo mkinitcpio -k 6.13-custom -c /etc/mkinitcpio.conf -g /boot/initramfs-linux-custom.img Make sure the version (6.13-custom) matches your compiled kernel.\nStep 10: Update GRUB Configuration Finally, update the GRUB configuration so that it includes your new kernel entry:\nsudo grub-mkconfig -o /boot/grub/grub.cfg Done! Congratulations! You’ve successfully compiled and installed your custom Linux Kernel. Enjoy your personalized system!\n","permalink":"http://localhost:1313/posts/kernal_compilation/","summary":"\u003ch1 id=\"building-the-linux-kernel\"\u003eBuilding the Linux Kernel\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003eCompiling the Linux Kernel involves multiple steps and can take some time depending on your hardware specifications.\u003c/strong\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"step-1-download-the-kernel-source-code\"\u003eStep 1: Download the Kernel Source Code\u003c/h3\u003e\n\u003cp\u003eStart by visiting the \u003ca href=\"https://www.kernel.org/\"\u003eOfficial Linux Kernel Website\u003c/a\u003e and downloading the latest available kernel source code. The downloaded file will be a compressed archive containing all necessary source files.\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"step-2-extract-the-source-code\"\u003eStep 2: Extract the Source Code\u003c/h3\u003e\n\u003cp\u003eOnce the download completes, extract the contents of the compressed archive using the \u003ccode\u003etar\u003c/code\u003e command:\u003c/p\u003e","title":"How to build Linux Kernal: Step by Step Guide"},{"content":"Introduction So, you’ve built a sleek website with Hugo and deployed it to GitHub Pages. Now, you want to give it a professional touch with a custom domain like yourdomain.tech instead of the default username.github.io URL. This guide walks you through the process step-by-step.\nPrerequisites A Hugo website hosted on GitHub Pages (public repository). A custom domain (e.g., yourdomain.tech) purchased from a registrar like Namecheap, Google Domains, etc. Basic familiarity with DNS settings and GitHub repository configurations. Step 1: Configure Your GitHub Repository First, ensure your GitHub Pages site is set up correctly:\nYour repository should be named \u0026lt;username\u0026gt;.github.io (for user/organization sites) or \u0026lt;repo-name\u0026gt; (for project sites). The gh-pages branch (or the /docs folder) should contain your Hugo-generated static files. Step 2: Configure DNS Settings for Your Domain Option 1: Use an Apex Domain (e.g., yourdomain.tech) If you want your site to live at the root domain (e.g., yourdomain.tech), configure A records in your DNS settings:\nGo to your domain registrar’s DNS management page. Create four A records pointing to GitHub’s IP addresses: Host: @ Type: A Value: 185.199.108.153 TTL: Automatic ","permalink":"http://localhost:1313/posts/customdomain/","summary":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003eSo, you’ve built a sleek website with Hugo and deployed it to GitHub Pages. Now, you want to give it a professional touch with a custom domain like \u003ccode\u003eyourdomain.tech\u003c/code\u003e instead of the default \u003ccode\u003eusername.github.io\u003c/code\u003e URL. This guide walks you through the process step-by-step.\u003c/p\u003e\n\u003ch2 id=\"prerequisites\"\u003ePrerequisites\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003eA Hugo website hosted on GitHub Pages (public repository).\u003c/li\u003e\n\u003cli\u003eA custom domain (e.g., \u003ccode\u003eyourdomain.tech\u003c/code\u003e) purchased from a registrar like Namecheap, Google Domains, etc.\u003c/li\u003e\n\u003cli\u003eBasic familiarity with DNS settings and GitHub repository configurations.\u003c/li\u003e\n\u003c/ol\u003e\n\u003chr\u003e\n\u003ch2 id=\"step-1-configure-your-github-repository\"\u003eStep 1: Configure Your GitHub Repository\u003c/h2\u003e\n\u003cp\u003eFirst, ensure your GitHub Pages site is set up correctly:\u003c/p\u003e","title":"How to up custom domain for GitHub Pages"},{"content":"Exception handling is a crucial aspect of writing robust and reliable Python code. Whether you\u0026rsquo;re a beginner or an experienced developer, getting an error, or exception, in your Python program means the entire program will crash. You don’t want this to happen in real-world programs. Instead, you want the program to detect errors, handle them, and then continue to run. In this blog, we\u0026rsquo;ll explore the fundamentals of exception handling in Python, including syntax, best practices, and advanced techniques.\nWhat Are Exceptions? Exceptions are runtime errors that disrupt the normal flow of a program. For example, trying to open a non-existent file, dividing by zero, or accessing an invalid index in a list will raise exceptions. If unhandled, these exceptions cause your program to crash.\nBasic Syntax: try and except The primary mechanism for handling exceptions in Python is the try-except block. Errors can be handled with with this. The code that could potentially have an error is put in a try clause. The program execution moves to the start of a following except clause if an error happens.\nHere\u0026rsquo;s the basic structure:\ndef cal(value): try: return 10 / value except ZeroDivisionError: print(\u0026#34;Cannot divide by zero!\u0026#34;) print(cal(0)) print(cal(2)) print(cal(3)) How It Works: The code inside the try block is executed. If an exception occurs, Python checks the except blocks for a matching exception type. If a match is found, the corresponding except block runs. Catching Specific Exceptions Always catch specific exceptions to avoid silencing unexpected errors. Python has many built-in exceptions (e.g., ValueError, TypeError, FileNotFoundError).\nimport math x = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) try: print(f\u0026#39;Square Root of {x} is {math.sqrt(x)}\u0026#39;) except ValueError: print(\u0026#39;Number is less than 0\u0026#39;) Output\nThe else Clause The else block runs only if no exceptions were raised in the try block. Use it to separate \u0026ldquo;happy path\u0026rdquo; code from error handling.\nimport math def sqr(value): try: x = math.sqrt(value) except ValueError: print(\u0026#39;Number is less than 0\u0026#39;) else: print(f\u0026#39;The Answer is: {x}\u0026#39;) value = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) sqr(value) Output The finally Clause The finally block runs regardless of whether an exception occurred. It’s ideal for cleanup tasks (e.g., closing files or releasing resources).\nimport math def sqr(value): try: x = math.sqrt(value) except ValueError: print(\u0026#39;Error\u0026#39;) else: print(f\u0026#39;The Answer is: {x}\u0026#39;) finally: print(\u0026#39;Program Ends\u0026#39;) value = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) sqr(value) Output Raising Exceptions Manually Use the raise keyword to trigger exceptions intentionally. This is useful for enforcing constraints.\ndef validate_age(age): if age \u0026lt; 0: raise ValueError(\u0026#34;Age cannot be negative!\u0026#34;) return age try: validate_age(-5) except ValueError as e: print(e) Creating Custom Exceptions Define custom exceptions by subclassing Python’s built-in Exception class. This makes your code more readable and errors more descriptive. (note: I have used RegEx, for that blog will be out soon :) )\nimport re class InvalidEmailError(Exception): \u0026#34;\u0026#34;\u0026#34;Raised when an email format is invalid.\u0026#34;\u0026#34;\u0026#34; pass def send_email(valid,email): if not valid: raise InvalidEmailError(f\u0026#34;Invalid email: {email}\u0026#34;) email = input(\u0026#39;Please enter your email: \u0026#39;) valid = re.match(r\u0026#39;^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\u0026#39;, email) try: send_email(valid, email) except InvalidEmailError as e: print(e) Output Logging a Python Error We can Log an exception in Python with an error. This can be done in the logging.exception() method. This function logs a message with level ERROR on this logger.\nimport math import logging def sqr(value): try: x = math.sqrt(value) except ValueError: logging.exception(\u0026#34;Error\u0026#34;) else: print(f\u0026#39;The Answer is: {x}\u0026#39;) finally: print(\u0026#39;Program Ends\u0026#39;) value = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) sqr(value) Output Best Practices for Exception Handling Catch specific exceptions: Avoid broad except: clauses that hide bugs. Keep try blocks minimal: Only wrap code that might raise an exception. Use finally for cleanup: Ensure resources are released (e.g., closing files). Log exceptions: Use logging.error() instead of print() for production code. Provide meaningful messages: Help debug issues faster with clear error descriptions. Avoid empty except blocks: Silent failures make debugging harder. Conclusion Exception handling is essential for writing better Python applications. By using try-except blocks effectively, catching specific errors, and with else/finally clauses, you can create programs that handle unexpected scenarios.\nNow go forth and write bulletproof Python code!\n","permalink":"http://localhost:1313/posts/exception_handling_in_python/","summary":"\u003cp\u003eException handling is a crucial aspect of writing robust and reliable Python code. Whether you\u0026rsquo;re a beginner or an experienced developer, getting an error, or exception, in your Python program means the entire program will crash. You don’t want this to happen in real-world programs. Instead, you want the program to detect errors, handle them, and then continue to run. In this blog, we\u0026rsquo;ll explore the fundamentals of exception handling in Python, including syntax, best practices, and advanced techniques.\u003c/p\u003e","title":"Exception Handling in Python: A Comprehensive Guide"},{"content":"Running a Local LLM on Mobile: Testing PocketPal on iPhone 12 With the increasing accessibility of large language models (LLMs), running them locally on mobile devices is an exciting prospect. I recently tested PocketPal, a mobile LLM interface, on my iPhone 12, using a distilled 4-bit quantized model. Here’s a breakdown of my experience, covering installation, performance, and overall usability.\nWhy Run an LLM on Mobile? Running an LLM locally on a mobile device comes with several advantages:\nPrivacy: No data is sent to external servers. Offline Access: Works without an internet connection. Lower Cost: Avoids API costs associated with cloud-based models. What is Quantization? Quantization is a technique used to reduce the memory and computational requirements of machine learning models by representing their weights with lower precision numbers. Instead of using 32-bit floating-point numbers, models can be compressed into 8-bit or even 4-bit integers while maintaining reasonable accuracy.\nFor LLMs on mobile, 4-bit quantization significantly reduces the model size, making it feasible to run on devices with limited resources. However, this compression can lead to:\nSlightly reduced accuracy due to loss of precision. Faster inference times, as lower-bit computations require less processing power. Lower memory usage, allowing larger models to fit within mobile device constraints. Setting Up and Running PocketPal on iPhone 12 1. Download and Install PocketPal Open the App Store and search for PocketPal AI by Asghar Ghorbani. Download and install the app. Open the app and allow necessary permissions. 2. Adding a Model Navigate to the Models section in the PocketPal app. Click the + button to add a new model. You will see two options: Add from Hugging Face Add Local Model Select Add from Hugging Face to browse available models. 3. Selecting and Downloading a Model Search for DeepSeek-R1-Distill-Qwen-1.5B-Q4_0. Select the model and start downloading it (size: 1.06GB, 1.78B parameters). Once downloaded, the model will appear under the Ready to Use section. 4. Running Benchmarks I ran benchmarks on my iPhone 12 using the DeepSeek-R1-Distill-Qwen-1.5B-Q4_0 model. Here are the key results:\nModel Size: 1.06 GB with 1.78 billion parameters. Benchmark Configuration: Prompt Processing: 512 Token Generation: 128 Pipeline Length: 1 Repetitions: 3 Model Settings: Context Length: 1024 tokens Batch Size: 512 CPU Threads: 4 GPU Layers: 0 (fully CPU-based execution) Flash Attention: Disabled Performance Metrics: Prompt Processing Speed: 26.93 tokens/sec (±2.37) Token Generation Speed: 18.05 tokens/sec (±0.75) Total Execution Time: 1 minute 18 seconds Peak Memory Usage: 35.0% (1GB / 4GB) Live Demo: Running PocketPal on iPhone 12 Watch a live demonstration of PocketPal running a distilled 4-bit quantized model on an iPhone 12: Image: Video demonstration is available here: Video\nAnalysis of Results Decent Processing Speed: With a distilled 4-bit quantized model, the 18.05 t/s token generation rate is quite reasonable for mobile inference. Low Memory Footprint: The 1GB RAM usage means this can run on even mid-range smartphones. CPU-Based Execution: Since 0 GPU layers were used, this proves mobile CPUs are capable of running quantized LLMs efficiently. Flash Attention Disabled: If supported, enabling it might further optimize speed and reduce lag. Final Thoughts Running an LLM locally on an iPhone 12 with PocketPal is feasible but comes with trade-offs. It’s a promising step toward self-hosted AI assistants, though optimization and hardware improvements will be crucial for broader adoption. If you’re privacy-conscious or need offline AI capabilities, it’s definitely worth exploring!\nFuture Improvements I\u0026rsquo;d Like to See: Better memory efficiency to reduce battery drain. Enhanced speed for real-time interaction. More user-friendly model importing and switching. ","permalink":"http://localhost:1313/posts/llmonmobile/","summary":"\u003ch1 id=\"running-a-local-llm-on-mobile-testing-pocketpal-on-iphone-12\"\u003eRunning a Local LLM on Mobile: Testing PocketPal on iPhone 12\u003c/h1\u003e\n\u003cp\u003eWith the increasing accessibility of large language models (LLMs), running them locally on mobile devices is an exciting prospect. I recently tested \u003cstrong\u003ePocketPal\u003c/strong\u003e, a mobile LLM interface, on my \u003cstrong\u003eiPhone 12\u003c/strong\u003e, using a \u003cstrong\u003edistilled 4-bit quantized model\u003c/strong\u003e. Here’s a breakdown of my experience, covering installation, performance, and overall usability.\u003c/p\u003e\n\u003ch2 id=\"why-run-an-llm-on-mobile\"\u003eWhy Run an LLM on Mobile?\u003c/h2\u003e\n\u003cp\u003eRunning an LLM locally on a mobile device comes with several advantages:\u003c/p\u003e","title":"Running Large Language Models on Mobile: DeepSeek R1 on iPhone 12"},{"content":"Running DeepSeek-R1 1.5B on Raspberry Pi 5 (CPU-Only) Technical Insights Why Can We Run This on Raspberry Pi 5? Thanks to open-source advancements, we can now run large-scale AI models on small devices like the Raspberry Pi 5. Key factors enabling this include:\nOptimized lightweight models: DeepSeek-R1 1.5B is built efficiently to run on limited hardware. ARM64 Support: Modern AI frameworks support ARM-based architectures, enabling their use on RPi5. Open-source software: Platforms like Ollama make AI deployment accessible to all. Performance Considerations Running this model on an RPi5 without a GPU will be CPU-intensive. Consider reducing active processes to free up memory. If performance lags, use a lighter model or external processing (cloud inference). No GPU acceleration was used in this setup, meaning all computations rely solely on the CPU, which may affect inference speeds. This guide covers the installation and execution of DeepSeek-R1 1.5B on a Raspberry Pi 5, following the steps demonstrated in your images.\nPrerequisites Raspberry Pi 5 (ARM64 architecture, more powerful than previous versions) Debian-based Linux installed An internet connection At least 4GB RAM recommended for smooth operation Step 1: Log in to Your Raspberry Pi Upon booting, log in using your credentials:\nraspberrypi login: hisam Password: ****** Example login screen: Step 2: Install Curl Curl is required to fetch the installation script. Run:\nsudo apt install curl If it\u0026rsquo;s already installed, you\u0026rsquo;ll see:\ncurl is already the newest version... Example output: Step 3: Install Ollama Ollama is the runtime needed to execute DeepSeek models.\ncurl -fsSL https://ollama.com/install.sh | sh This will download and install Ollama.\nExample installation screen: Step 4: Enable and Start Ollama Service After installation, Ollama sets up a system service.\nollama The output will indicate success:\n\u0026gt;\u0026gt;\u0026gt; Creating ollama user... \u0026gt;\u0026gt;\u0026gt; Enabling and starting ollama service... \u0026gt;\u0026gt;\u0026gt; The Ollama API is now available at 127.0.0.1:11434. Example setup screen: Step 5: Pull and Run DeepSeek-R1 1.5B Now, pull and run the model:\nollama run deepseek-r1:1.5b This will download the model, which is about 1.1 GB in size.\nExample download screen: Once downloaded, the model is ready to run.\nStep 6: Execute DeepSeek-R1 1.5B Run the model and start interacting:\nollama run deepseek-r1:1.5b You should see a prompt where you can start typing queries:\n\u0026gt;\u0026gt;\u0026gt; Hey! Hello! How can I assist you today? 😊 Example interaction: Final Setup Image Video Demonstration Watch Video\nConclusion You have successfully installed and executed DeepSeek-R1 1.5B on your Raspberry Pi 5. This demonstrates the power of open-source AI, making it possible to run advanced models on small-scale devices. If you encounter performance issues, consider optimizing your setup or offloading computations.\nHappy coding!\n","permalink":"http://localhost:1313/posts/deepseek/","summary":"\u003ch1 id=\"running-deepseek-r1-15b-on-raspberry-pi-5-cpu-only\"\u003eRunning DeepSeek-R1 1.5B on Raspberry Pi 5 (CPU-Only)\u003c/h1\u003e\n\u003ch2 id=\"technical-insights\"\u003eTechnical Insights\u003c/h2\u003e\n\u003ch3 id=\"why-can-we-run-this-on-raspberry-pi-5\"\u003eWhy Can We Run This on Raspberry Pi 5?\u003c/h3\u003e\n\u003cp\u003eThanks to open-source advancements, we can now run large-scale AI models on small devices like the Raspberry Pi 5. Key factors enabling this include:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eOptimized lightweight models\u003c/strong\u003e: DeepSeek-R1 1.5B is built efficiently to run on limited hardware.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eARM64 Support\u003c/strong\u003e: Modern AI frameworks support ARM-based architectures, enabling their use on RPi5.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eOpen-source software\u003c/strong\u003e: Platforms like Ollama make AI deployment accessible to all.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"performance-considerations\"\u003ePerformance Considerations\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eRunning this model on an RPi5 \u003cstrong\u003ewithout a GPU\u003c/strong\u003e will be CPU-intensive.\u003c/li\u003e\n\u003cli\u003eConsider \u003cstrong\u003ereducing active processes\u003c/strong\u003e to free up memory.\u003c/li\u003e\n\u003cli\u003eIf performance lags, use a \u003cstrong\u003elighter model\u003c/strong\u003e or \u003cstrong\u003eexternal processing (cloud inference).\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eNo GPU acceleration was used\u003c/strong\u003e in this setup, meaning all computations rely solely on the CPU, which may affect inference speeds.\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003cp\u003eThis guide covers the installation and execution of DeepSeek-R1 1.5B on a Raspberry Pi 5, following the steps demonstrated in your images.\u003c/p\u003e","title":"DeepSeek-R1 on Raspberry Pi 5: Open-Source AI Without a GPU"},{"content":"Setting Up Neovim: An Easy and Beginner\u0026rsquo;s Guide Neovim is a modern and extensible text editor that enhances Vim’s capabilities. If you\u0026rsquo;re using Linux, setting up Neovim can be a rewarding experience, allowing you to customize it for an efficient workflow. In this guide, we\u0026rsquo;ll cover installing Neovim, setting up a basic configuration, and enhancing it with essential plugins to turn it into a full-fledged IDE.\n1. Installing Neovim sudo pacman -S neovim 2. Setting Up Neovim Configuration Neovim’s configuration is stored in ~/.config/nvim/. Create the directory and initialize a basic configuration:\nmkdir -p ~/.config/nvim nvim ~/.config/nvim/init.lua Minimal Configuration (init.lua) Add the following settings to your init.lua file:\n-- Enable line numbers vim.opt.number = true vim.opt.relativenumber = true -- Set tab size vim.opt.expandtab = true vim.opt.shiftwidth = 4 vim.opt.tabstop = 4 -- Enable mouse support vim.opt.mouse = \u0026#34;a\u0026#34; -- Set clipboard to system clipboard vim.opt.clipboard = \u0026#34;unnamedplus\u0026#34; Save and exit Neovim.\n3. Installing a Plugin Manager The best plugin manager for Neovim is lazy.nvim. Install it by running:\ngit clone --depth 1 https://github.com/folke/lazy.nvim.git \\ ~/.local/share/nvim/lazy/lazy.nvim Then, update your init.lua to load it:\nlocal lazypath = vim.fn.stdpath(\u0026#34;data\u0026#34;) .. \u0026#34;/lazy/lazy.nvim\u0026#34; if not vim.loop.fs_stat(lazypath) then vim.fn.system({ \u0026#34;git\u0026#34;, \u0026#34;clone\u0026#34;, \u0026#34;--filter=blob:none\u0026#34;, \u0026#34;https://github.com/folke/lazy.nvim.git\u0026#34;, lazypath }) end vim.opt.rtp:prepend(lazypath) 4. Installing Essential Plugins With lazy.nvim installed, you can add plugins in init.lua:\nrequire(\u0026#34;lazy\u0026#34;).setup({ \u0026#34;nvim-treesitter/nvim-treesitter\u0026#34;, -- Syntax highlighting \u0026#34;nvim-telescope/telescope.nvim\u0026#34;, -- Fuzzy finder \u0026#34;neovim/nvim-lspconfig\u0026#34;, -- LSP support \u0026#34;hrsh7th/nvim-cmp\u0026#34;, -- Auto-completion \u0026#34;hrsh7th/cmp-nvim-lsp\u0026#34;, -- LSP completion source \u0026#34;hrsh7th/cmp-buffer\u0026#34;, -- Buffer completion \u0026#34;hrsh7th/cmp-path\u0026#34;, -- Path completion \u0026#34;hrsh7th/cmp-nvim-lua\u0026#34;, -- Neovim Lua API completion \u0026#34;L3MON4D3/LuaSnip\u0026#34;, -- Snippet engine \u0026#34;saadparwaiz1/cmp_luasnip\u0026#34;, -- Snippet completion \u0026#34;nvim-lualine/lualine.nvim\u0026#34;, -- Status line \u0026#34;nvim-tree/nvim-tree.lua\u0026#34;, -- File explorer \u0026#34;tpope/vim-surround\u0026#34;, -- Surround text objects \u0026#34;tpope/vim-commentary\u0026#34;, -- Commenting shortcuts \u0026#34;lewis6991/gitsigns.nvim\u0026#34;, -- Git integration \u0026#34;akinsho/toggleterm.nvim\u0026#34;, -- Terminal management }) Save and exit Neovim, then open it and run:\n:Lazy sync This will install the plugins automatically.\n5. Setting Up Treesitter Treesitter provides better syntax highlighting and code parsing. Install it by adding the following to your init.lua:\nrequire\u0026#39;nvim-treesitter.configs\u0026#39;.setup { ensure_installed = \u0026#34;all\u0026#34;, highlight = { enable = true, }, indent = { enable = true, }, } Then, update Treesitter by running:\n:TSUpdate 6. Setting Up LSP (Language Server Protocol) LSP enables features like code completion and linting. Install LSP servers for your language:\n# Python sudo pacman -S python-lsp-server # C++ sudo pacman -S clang # JavaScript/TypeScript npm install -g typescript-language-server Then, enable LSP support in Neovim:\nlocal lspconfig = require(\u0026#34;lspconfig\u0026#34;) lspconfig.pyright.setup({}) -- Python lspconfig.ts_ls.setup({}) -- JavaScript/TypeScript lspconfig.clangd.setup({}) -- C++ Restart Neovim and check LSP status:\n:LspInfo 7. Enhancing Auto-Completion with nvim-cmp To enable code auto-completion, update your init.lua:\nlocal cmp = require\u0026#39;cmp\u0026#39; cmp.setup({ mapping = { [\u0026#39;\u0026lt;C-Space\u0026gt;\u0026#39;] = cmp.mapping.complete(), [\u0026#39;\u0026lt;CR\u0026gt;\u0026#39;] = cmp.mapping.confirm({ select = true }), }, sources = { { name = \u0026#39;nvim_lsp\u0026#39; }, { name = \u0026#39;buffer\u0026#39; }, { name = \u0026#39;path\u0026#39; }, { name = \u0026#39;luasnip\u0026#39; }, { name = \u0026#39;nvim_lua\u0026#39; }, } }) 9. Final Thoughts Congratulations! You now have a powerful, customized Neovim setup that functions as a full-fledged IDE. With features like Treesitter, LSP support, auto-completion, syntax highlighting, Git integration, and a file explorer, your development workflow will be much smoother.\nIf you’d like to further improve your Neovim experience, explore more plugins and tweak your settings. Good luck with that!\nFurther Reading Neovim Documentation Awesome Neovim Plugins Arch Wiki: Neovim ","permalink":"http://localhost:1313/posts/setting-up-neovim-on-arch-linux-a-beginners-guide/","summary":"\u003ch1 id=\"setting-up-neovim-an-easy-and-beginners-guide\"\u003eSetting Up Neovim: An Easy and Beginner\u0026rsquo;s Guide\u003c/h1\u003e\n\u003cp\u003eNeovim is a modern and extensible text editor that enhances Vim’s capabilities. If you\u0026rsquo;re using Linux, setting up Neovim can be a rewarding experience, allowing you to customize it for an efficient workflow. In this guide, we\u0026rsquo;ll cover installing Neovim, setting up a basic configuration, and enhancing it with essential plugins to turn it into a full-fledged IDE.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"1-installing-neovim\"\u003e\u003cstrong\u003e1. Installing Neovim\u003c/strong\u003e\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003esudo pacman -S neovim\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003chr\u003e\n\u003ch2 id=\"2-setting-up-neovim-configuration\"\u003e\u003cstrong\u003e2. Setting Up Neovim Configuration\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003eNeovim’s configuration is stored in \u003ccode\u003e~/.config/nvim/\u003c/code\u003e. Create the directory and initialize a basic configuration:\u003c/p\u003e","title":"Setting Up Neovim: A Beginner's Guide"},{"content":"Linux Kernal The majority of the kernel\u0026rsquo;s code is written in C, leveraging extensions provided by the GNU Compiler Collection (GCC) beyond standard C. Additionally, it includes assembly code for architecture-specific functions, such as optimizing memory usage and task execution. Architecturally, the Linux kernel is monolithic, meaning the entire OS operates within kernel space. However, it features a modular design, allowing software components to be integrated as modules, including dynamic loading.\nWhat Is A Kernel Module? A Linux kernel module is precisely defined as a code segment capable of dynamic loading and unloading within the kernel as needed. These modules enhance kernel capabilities without necessitating a system reboot. A notable example is seen in the device driver module, which facilitates kernel interaction with hardware components linked to the system.\nWriting a Custom Linux Kernel Module Linux kernel modules (LKMs) allow developers to extend the functionality of the Linux kernel without modifying its source code. This guide walks through writing a simple kernel module from scratch. Kernel modules are pieces of code that can be dynamically loaded and unloaded from the Linux kernel at runtime. They enable functionality such as device drivers, file system support, and system call extensions without requiring a kernel recompilation. LKMs are particularly useful for developing hardware drivers and testing new kernel features without rebooting the system.\nPrerequisites Ensure you have the necessary development tools installed. On an Arch Linux system, install them with:\nsudo pacman -Syu linux-headers base-devel Creating a Simple Kernel Module 1. Writing the Module Source Code Create a file named hello_module.c:\n#include \u0026lt;linux/module.h\u0026gt; #include \u0026lt;linux/kernel.h\u0026gt; #include \u0026lt;linux/init.h\u0026gt; MODULE_LICENSE(\u0026#34;GPL\u0026#34;); MODULE_AUTHOR(\u0026#34;Your Name\u0026#34;); MODULE_DESCRIPTION(\u0026#34;A simple Hello World kernel module\u0026#34;); static int __init hello_init(void) { printk(KERN_INFO \u0026#34;Hello, Kernel!\\n\u0026#34;); return 0; } static void __exit hello_exit(void) { printk(KERN_INFO \u0026#34;Goodbye, Kernel!\\n\u0026#34;); } module_init(hello_init); module_exit(hello_exit); Understanding the Kernel Module Code #include \u0026lt;linux/module.h\u0026gt;: Includes the necessary module macros and functions. #include \u0026lt;linux/kernel.h\u0026gt;: Provides kernel logging functions. #include \u0026lt;linux/init.h\u0026gt;: Defines initialization and cleanup macros. MODULE_LICENSE(\u0026quot;GPL\u0026quot;): Specifies the module\u0026rsquo;s license. MODULE_AUTHOR(\u0026quot;Your Name\u0026quot;): Specifies the author of the module. MODULE_DESCRIPTION(\u0026quot;A simple Hello World kernel module\u0026quot;): Provides a brief description. static int __init hello_init(void): The function executed when the module is loaded. static void __exit hello_exit(void): The function executed when the module is unloaded. module_init(hello_init): Registers hello_init as the module\u0026rsquo;s initialization function. module_exit(hello_exit): Registers hello_exit as the module\u0026rsquo;s cleanup function. 2. Writing the Makefile Create a Makefile in the same directory:\nobj-m += hello_module.o all: make -C /lib/modules/$(shell uname -r)/build M=$(PWD) modules clean: make -C /lib/modules/$(shell uname -r)/build M=$(PWD) clean Understanding the Makefile obj-m += hello_module.o: Specifies that hello_module.o is the object to be built as a module. all:: Defines the build target. make -C /lib/modules/$(shell uname -r)/build M=$(PWD) modules: Directs the kernel build system to compile the module. clean:: Cleans up the generated files. make -C /lib/modules/$(shell uname -r)/build M=$(PWD) clean: Cleans the build artifacts. 3. Compiling the Module Run:\nmake 4. Loading and Unloading the Module To insert the module into the kernel:\nsudo insmod hello_module.ko Check the kernel log:\ndmesg | tail To remove the module:\nsudo rmmod hello_module 5. Verifying the Module List loaded modules:\nlsmod | grep hello_module Understanding the Generated Files After building the module, several files are generated:\nhello_module.c: The source code of the module. hello_module.ko: The compiled kernel module file, ready to be loaded into the kernel. hello_module.o: An intermediate object file generated during compilation. hello_module.mod.c: An automatically generated file containing module metadata. hello_module.mod.o: An object file containing metadata compiled from hello_module.mod.c. hello_module.mod: Another metadata file required for module loading. Makefile: Contains instructions for building the module. Module.symvers: Stores information about exported symbols, useful for module dependencies. modules.order: Lists the order in which modules should be loaded. Conclusion This simple kernel module demonstrates the basics of module development. You can expand upon this by adding functionality such as handling parameters or interacting with hardware.\nHappy kernel hacking!\n","permalink":"http://localhost:1313/posts/how-to-write-a-custom-kernel-module/","summary":"\u003ch1 id=\"linux-kernal\"\u003eLinux Kernal\u003c/h1\u003e\n\u003cp\u003eThe majority of the kernel\u0026rsquo;s code is written in C, leveraging extensions provided by the GNU Compiler Collection (GCC) beyond standard C. Additionally, it includes assembly code for architecture-specific functions, such as optimizing memory usage and task execution. Architecturally, the Linux kernel is monolithic, meaning the entire OS operates within kernel space. However, it features a modular design, allowing software components to be integrated as modules, including dynamic loading.\u003c/p\u003e","title":"How to Write a Custom Kernel Module"},{"content":"What is it? gh is GitHub\u0026rsquo;s official command-line tool designed to extend Git\u0026rsquo;s functionality with GitHub-specific features.\nPurpose: Simplifies interaction with GitHub\u0026rsquo;s ecosystem directly from the terminal. Allows you to manage repositories and use GitHub features like issues, pull requests, and workflows.\nKey Features: GitHub-specific tasks:\nAuthentication: Easier login (gh auth login) without dealing with tokens manually. Repository Management: Create, fork, or clone repositories. Issues \u0026amp; Pull Requests: Manage issues, PRs, and comments directly. Actions: Manage and view GitHub Actions workflows. Works alongside Git for basic version control tasks. Use Case: Best for developers heavily using GitHub and its features (for example: pull requests, issues, and actions).\nHow it works Install gh:\n\u0026gt; yay -S github-cli Verify the installation:\n\u0026gt; gh --version Login with GitHub CLI (gh)\n\u0026gt; gh auth login Follow the interactive prompts to log in:\nChoose HTTPS or SSH for connection. Log in via a browser using a one-time code or SSH keys. Verify authentication:\n\u0026gt; gh auth status What\u0026rsquo;s best about it that you can install and use both Git and gh (GitHub CLI) seamlessly. Here\u0026rsquo;s how to set them up:\nInstall Git\n\u0026gt;sudo pacman -S git Check the installation:\n\u0026gt; git --version Using Git and gh Together You can now: Use Git for version control:\n\u0026gt; git clone https://github.com/username/repo.git \u0026gt; git add . \u0026gt; git commit -m \u0026quot;message\u0026quot; \u0026gt; git push ","permalink":"http://localhost:1313/posts/github-cli-githubs-official-command-line-tools/","summary":"\u003ch2 id=\"what-is-it\"\u003eWhat is it?\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003egh\u003c/strong\u003e is GitHub\u0026rsquo;s official command-line tool designed to extend Git\u0026rsquo;s functionality with GitHub-specific features.\u003c/p\u003e\n\u003ch2 id=\"purpose\"\u003ePurpose:\u003c/h2\u003e\n\u003cp\u003eSimplifies interaction with GitHub\u0026rsquo;s ecosystem directly from the terminal. Allows you to manage repositories and use GitHub features like issues, pull requests, and workflows.\u003c/p\u003e\n\u003ch2 id=\"key-features\"\u003eKey Features:\u003c/h2\u003e\n\u003cp\u003eGitHub-specific tasks:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAuthentication: Easier login (gh auth login) without dealing with tokens manually.\u003c/li\u003e\n\u003cli\u003eRepository Management: Create, fork, or clone repositories.\u003c/li\u003e\n\u003cli\u003eIssues \u0026amp; Pull Requests: Manage issues, PRs, and comments directly.\u003c/li\u003e\n\u003cli\u003eActions: Manage and view GitHub Actions workflows.\u003c/li\u003e\n\u003cli\u003eWorks alongside Git for basic version control tasks.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"use-case\"\u003eUse Case:\u003c/h2\u003e\n\u003cp\u003eBest for developers heavily using GitHub and its features (for example: pull requests, issues, and actions).\u003c/p\u003e","title":"GitHub CLI: GitHub's Official Command Line Tools"},{"content":"Connecting a Raspberry Pi 5 to a USB TTY cable is a common way to interact with it through a serial connection, especially for debugging or setting up the device without using a display.\nPrerequists\nRaspberry Pi 5. USB TTY (serial) cable. Computer with a terminal emulator (minicom/screen). GPIO pinout diagram of Raspberry Pi 5 (for reference). Power source for Raspberry Pi (optional if USB TTY can power it, though not recommended). Before Starting! Issuse with firmware UART does NOT work on the RPI5 from the factory. We will need a firmware update to fix this that prevents the dtoverlays for UARTs from working.\nInstall rpi-update with the following commands:\n\u0026gt; sudo curl -L --output /usr/bin/rpi-update https://raw.githubusercontent.com/Hexxeh/rpi-update/master/rpi-update \u0026amp;\u0026amp; sudo chmod +x /usr/bin/rpi-update Then update the firmware on your RPI5 with:\n\u0026gt; sudo rpi-update Enable UART To manually configure UART, you can edit the config.txt file.\nEdit /boot/firmware/config.txt and add:\n\u0026gt; enable_uart=1 How to Connect Locate the GPIO Pins Find the GPIO header on the Raspberry Pi 5. Identify the following pins: GND (Ground): Usually black wire on the USB TTY cable. TX (Transmit): Sends data from the Pi to the computer. RX (Receive): Receives data from the computer to the Pi.\nUse a GPIO pinout chart to locate these pins. For Raspberry Pi 5, it will likely be similar to previous models. Making connections You will need to connect:\nGND with Ground - Pin# 06 TX with GPIO14 - Pin# 08 RX with GPIO15 - Pin# 10 Plug the USB TTY Cable into the Computer\nInsert the USB end of the TTY cable into your computer. The cable will create a virtual COM port (e.g /dev/ttyUSB0). Configure and Access Serial Console\nOpen a terminal.\nIdentify the port with:\n\u0026gt; ls /dev/ttyUSB* Use a terminal emulator like screen or minicom to connect:\n\u0026gt; screen /dev/ttyUSB0 115200 *Replace /dev/ttyUSB0 with the actual port name.\nTurn on the Raspberry Pi. If everything is set up correctly, you should see boot messages in the terminal. Log in to the Pi using the default username (pi) and password (raspberry), or your custom credentials. You should see something similar to this.\nThis is it! You have done it. Congrats!\n","permalink":"http://localhost:1313/posts/how-to-connect-a-raspberry-pi-5-to-usb-tty-cable/","summary":"\u003cp\u003eConnecting a Raspberry Pi 5 to a USB TTY cable is a common way to interact with it through a serial connection, especially for debugging or setting up the device without using a display.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003ePrerequists\u003c/strong\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eRaspberry Pi 5.\u003c/li\u003e\n\u003cli\u003eUSB TTY (serial) cable.\u003c/li\u003e\n\u003cli\u003eComputer with a terminal emulator (minicom/screen).\u003c/li\u003e\n\u003cli\u003eGPIO pinout diagram of Raspberry Pi 5 (for reference).\u003c/li\u003e\n\u003cli\u003ePower source for Raspberry Pi (optional if USB TTY can power it, though not recommended).\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"before-starting\"\u003e\u003cstrong\u003eBefore Starting!\u003c/strong\u003e\u003c/h3\u003e\n\u003ch3 id=\"issuse-with-firmware\"\u003e\u003cstrong\u003e\u003ca href=\"https://forums.raspberrypi.com/viewtopic.php?t=361397#p2171244\"\u003eIssuse with firmware\u003c/a\u003e\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003eUART does NOT work on the RPI5 from the factory. We will need a firmware update to fix this that prevents the dtoverlays for UARTs from working.\u003c/p\u003e","title":"How to Connect a Raspberry PI 5 to USB TTY Cable"},{"content":"Hosting a website on GitHub Pages with Hugo involves the following steps:\nCreating a website 1. Install Hugo and git\n\u0026gt; sudo pacman -S Hugo 2. Create a new Hugo site\n\u0026gt; hugo new site your-website 3. Add a Theme\nNavigate to your website directory and add a theme. You can choose one from the Hugo Themes .\n\u0026gt; cd your-website \u0026gt; git init \u0026gt; git submodule add https://github.com/adityatelange/hugo-PaperMod.git themes/hugo-PaperMod Now you will need to update the hugo.toml file for them to take effect. To do so you can either echo or addd it in the file.\n\u0026gt; echo \u0026quot;theme = 'hugo-PaperMod'\u0026quot; \u0026gt;\u0026gt; hugo.toml To view the website you can run it locally using Hugo\u0026rsquo;s development server to view the site. You can add -D to see your drafts.\n\u0026gt; hugo server 3. Add Content\nTo add a new page to your site.\n\u0026gt; hugo new content content/posts/yout-first-post.md This is it You have done it. YAY!\nHosting it on GitHub 1. Create a GitHub repository.\nClick the + icon in the top-right corner of:\u0026gt; [!WARNING] the GitHub interface and select New repository. Enter a repository name: yourusername.github.io Click Create repository. 2. Add Files for Your website\nClone the repository locally using Git:\ngit clone https://github.com//.git\nAdd your static site files (generated by Hugo) to the repository. Commit and push the changes:\n\u0026gt; git add -A \u0026gt; git commit -s -m \u0026quot;Initial commit\u0026quot; \u0026gt; git push origin main 3. Configure the Repository for GitHub Pages\nGo to the Settings tab of your new repository. Scroll down to the Pages section. Settings \u0026gt; Pages. In the center of your screen you will see this: Build and development Change the Source to GitHub Actions. 4. Create a file named hugo.yaml in a directory named .github/workflows.\n\u0026gt; mkdir -p .github/workflows \u0026gt; cd ./github/workflows touch hugo.yaml 5. Add content in the YAML file.\n# Sample workflow for building and deploying a Hugo site to GitHub Pages name: Deploy Hugo site to Pages on: # Runs on pushes targeting the default branch push: branches: - main # Allows you to run this workflow manually from the Actions tab workflow_dispatch: # Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages permissions: contents: read pages: write id-token: write # Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued. # However, do NOT cancel in-progress runs as we want to allow these production deployments to complete. concurrency: group: \u0026#34;pages\u0026#34; cancel-in-progress: false # Default to bash defaults: run: shell: bash jobs: # Build job build: runs-on: ubuntu-latest env: HUGO_VERSION: 0.141.0 steps: - name: Install Hugo CLI run: | wget -O ${{ runner.temp }}/hugo.deb https://github.com/gohugoio/hugo/releases/download/v${HUGO_VERSION}/hugo_extended_${HUGO_VERSION}_linux-amd64.deb \\ \u0026amp;\u0026amp; sudo dpkg -i ${{ runner.temp }}/hugo.deb - name: Install Dart Sass run: sudo snap install dart-sass - name: Checkout uses: actions/checkout@v4 with: submodules: recursive fetch-depth: 0 - name: Setup Pages id: pages uses: actions/configure-pages@v5 - name: Install Node.js dependencies run: \u0026#34;[[ -f package-lock.json || -f npm-shrinkwrap.json ]] \u0026amp;\u0026amp; npm ci || true\u0026#34; - name: Build with Hugo env: HUGO_CACHEDIR: ${{ runner.temp }}/hugo_cache HUGO_ENVIRONMENT: production TZ: America/Los_Angeles run: | hugo \\ --gc \\ --minify \\ --baseURL \u0026#34;${{ steps.pages.outputs.base_url }}/\u0026#34; - name: Upload artifact uses: actions/upload-pages-artifact@v3 with: path: ./public # Deployment job deploy: environment: name: github-pages url: ${{ steps.deployment.outputs.page_url }} runs-on: ubuntu-latest needs: build steps: - name: Deploy to GitHub Pages id: deployment uses: actions/deploy-pages@v4 5. Commit and push your GitHub repository.\n\u0026gt;git add -A \u0026gt;git commit -m \u0026quot;Create hugo.yaml\u0026quot; \u0026gt;git push 6. Deployment status From GitHub’s main menu, choose Actions. When GitHub has finished building and deploying your site, the color of the status indicator will change to green.\nStep 5: Verify Your GitHub Pages Site\nThe site will be live at https://yourusername.github.io.\n","permalink":"http://localhost:1313/posts/hosting-a-website-on-github-pages-with-hugo/","summary":"\u003cp\u003eHosting a website on GitHub Pages with Hugo involves the following steps:\u003c/p\u003e\n\u003ch1 id=\"creating-a-website\"\u003eCreating a website\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e1. Install Hugo and git\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; sudo pacman -S Hugo\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e2. Create a new Hugo site\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; hugo new site your-website\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e3. Add a Theme\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eNavigate to your website directory and add a theme. You can choose one from the \u003ca href=\"https://themes.gohugo.io/\"\u003eHugo Themes\u003c/a\u003e .\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; cd your-website\n\u0026gt; git init \n\u0026gt; git submodule add https://github.com/adityatelange/hugo-PaperMod.git themes/hugo-PaperMod\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow you will need to update the hugo.toml file for them to take effect. To do so you can either \u003cem\u003eecho\u003c/em\u003e or addd it in the file.\u003c/p\u003e","title":"Hosting a Website on Github Pages With Hugo"},{"content":"KVM Kernel-based Virtual Machine is a free and open-source virtualization module in the Linux kernel that allows the kernel to function as a hypervisor.\nInstallation For updates, run the following command:\n$ sudo pacman -Syu QEMU/KVM installation: We\u0026rsquo;ll install qemu and all the utils required:\n$ sudo pacman -S qemu vde2 ebtables iptables-nft nftables dms masq bridge-utils ovmf swptm Virtual Machine Manager installation: The virt-manager application is a graphical user interface for managing virtual machines through libvirt. It primarily targets KVM VMs.\n$ sudo pacman -S virt-manager Now everything is set to work. We can move towards downloading archlinux .iso file.\nDownload .iso file: Head towards: https://archlinux.org/download/ Scroll through and look for the server closest to you. Download archlinux-2024.10.01-x86_64.iso file. Setting up: Open terminal and run the following command:\n$ virt-manager You will see an interface similar to this:\nClick on \u0026lsquo;create a new virtual machine\u0026rsquo; (option with star). Select \u0026lsquo;Local install media\u0026rsquo;. Browse to your \u0026lsquo;archlinux-2024.10.01-x86_64.iso\u0026rsquo;. Add your desired VM configuration and create a disk image. Boot Menu: You will be prompted to a boot menu.\nSelect the topmost option to start the installation process. Archlinux Installer: You will be prompted to a terminal. The first step is to check if you are connected to the internet.\nRun:\n# ip addr show If it shows an IP address and says \u0026lsquo;UP\u0026rsquo;, that means you are good to go.\nIf not: You will need to connect to the internet using the \u0026lsquo;iwctl\u0026rsquo; method for Wi-Fi.\n# iwctl To search networks in your vicinity:\n[iwd]# station [your_wifi_interface] get-networks Get the name of the network you want to connect to. Exit from this prompt using \u0026rsquo;exit\u0026rsquo;.\nTo connect to the desired Wi-Fi network, run:\n# iwctl --passphrase \u0026#34;[wifi_password]\u0026#34; station [your_wifi_interface] connect [wifi_name] You can again run ip addr show to check if you are connected to the network.\nNow you can run the installation command. We\u0026rsquo;ll be using the archinstall method.\n# archinstall You will be prompted to an interface similar to this:\nWe will install Arch using this interface. Go through each option:\nArchinstall language: Choose your preferred language. Mirrors: Select the mirror region closest to you. Use \u0026lsquo;/\u0026rsquo; to search. Locales: Set language and keyboard layout. Disk configuration: Choose Best-effort default partition to format the system. Bootloader: Use the default \u0026lsquo;Grub\u0026rsquo; option. Swap: Select Swap on zram (default). Hostname: Leave as it is. Root password: Set the password for sudo/root privileges. User account: Set up a user account. Profile: Select Desktop. It includes essential packages. Others include Minimal, Server, and Xorg. In Desktop, select your desktop environment. We\u0026rsquo;ll use Gnome for simplicity.\nAudio: Use PipeWire (default) or PulseAudio. Kernels: Use the linux kernel. Additional packages: Install any required packages. Network Configuration: Use NetworkManager for a GUI in Gnome. Timezone: Set the timezone closest to you and enable time sync. Press Install. Congratulations! You\u0026rsquo;ve successfully installed Arch Linux.\n","permalink":"http://localhost:1313/posts/arch_kvm/","summary":"\u003ch1 id=\"kvm\"\u003eKVM\u003c/h1\u003e\n\u003cp\u003eKernel-based Virtual Machine is a free and open-source virtualization module in the Linux kernel that allows the kernel to function as a hypervisor.\u003c/p\u003e\n\u003ch2 id=\"installation\"\u003eInstallation\u003c/h2\u003e\n\u003cp\u003eFor updates, run the following command:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ sudo pacman -Syu\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"qemukvm-installation\"\u003eQEMU/KVM installation:\u003c/h3\u003e\n\u003cp\u003eWe\u0026rsquo;ll install qemu and all the utils required:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ sudo pacman -S qemu vde2 ebtables iptables-nft nftables dms masq bridge-utils ovmf swptm\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"virtual-machine-manager-installation\"\u003eVirtual Machine Manager installation:\u003c/h3\u003e\n\u003cp\u003eThe virt-manager application is a graphical user interface for managing virtual machines through libvirt. It primarily targets KVM VMs.\u003c/p\u003e","title":"archlinux installation in hypervisor through QEMU/KVM"},{"content":"","permalink":"http://localhost:1313/posts/github-cli-githubs-official-command-line-tool/","summary":"","title":""}]