[{"content":"1. Introduction Sometimes you need to share a local application with the outside world — maybe to demo your project, test a webhook, or allow a teammate to access your development server.\nNormally, you’d need a public IP, port forwarding, or a cloud server. ngrok removes all that complexity by creating a secure tunnel from the internet directly to your machine, giving you a public URL instantly.\nIn this guide, we’ll walk through:\nInstalling ngrok on popular Linux distributions Authenticating your installation Exposing a local service to the internet Adding basic security Practical examples for real-world usage 2. Prerequisites Before we begin, make sure you have:\nA terminal A free ngrok account (for authentication token) A running local service (e.g., a Python HTTP server, web app, or API) 3. Installing ngrok on Linux We’ll cover installation for Arch Linux, Debian/Ubuntu, and Fedora.\n3.1 Arch Linux This package is not in the official repos, install it from the AUR:\nyay -S ngrok 3.2 Debian / Ubuntu sudo apt update sudo apt install snapd sudo snap install ngrok Alternatively, download the binary from the ngrok downloads page.\n3.3 Fedora sudo dnf install snapd sudo ln -s /var/lib/snapd/snap /snap sudo snap install ngrok 4. Authenticating ngrok Once installed, you need to connect it to your account so you can use custom domains, longer session times, and access the dashboard.\nSign in to ngrok dashboard. Copy your AuthToken. Run: ngrok config add-authtoken \u0026lt;YOUR_TOKEN\u0026gt; 5. Exposing a Local Service For example, if your local web server is running on port 8080:\nngrok http 8080 You’ll see output like:\nForwarding https://random-id.ngrok-free.app -\u0026gt; http://localhost:8080 Now you can share the HTTPS URL with anyone.\n6. Adding Basic Security You can protect your tunnel with a simple username and password:\nngrok http --basic-auth=\u0026#34;user:password\u0026#34; 8080 Anyone visiting the public link will need credentials.\n7. Common Use Cases Webhook testing — Connect services like GitHub, Stripe, or Twilio to your local environment. Temporary demos — Share work-in-progress with clients without deployment. Remote device access — SSH into a Raspberry Pi without changing router settings. 8. Conclusion In just a few commands, you’ve learned how to:\nInstall ngrok on popular Linux distros Authenticate your installation Share a local service securely From here, you can explore ngrok’s advanced features like static domains, IP allowlists, and traffic inspection.\n","permalink":"http://localhost:1313/posts/ngrok/","summary":"\u003ch2 id=\"1-introduction\"\u003e1. Introduction\u003c/h2\u003e\n\u003cp\u003eSometimes you need to share a local application with the outside world — maybe to demo your project, test a webhook, or allow a teammate to access your development server.\u003c/p\u003e\n\u003cp\u003eNormally, you’d need a public IP, port forwarding, or a cloud server. \u003cstrong\u003engrok\u003c/strong\u003e removes all that complexity by creating a \u003cstrong\u003esecure tunnel\u003c/strong\u003e from the internet directly to your machine, giving you a public URL instantly.\u003c/p\u003e\n\u003cp\u003eIn this guide, we’ll walk through:\u003c/p\u003e","title":"Ngrok: Expose Localhost to the Internet"},{"content":"Creating a WhatsApp AI Assistant Using n8n: A Step-by-Step Guide Build your own AI-powered WhatsApp chatbot using n8n, WhatsApp Business Cloud API, and OpenAI. This guide walks you through every step—from setup to testing—with real-world error handling, solutions, and an example production-ready workflow.\n1. Introduction Want to chat with an AI on WhatsApp? In this tutorial, you\u0026rsquo;ll learn how to build a WhatsApp AI Assistant using:\nn8n (automation tool) WhatsApp Business Cloud API OpenAI (for generating intelligent replies) By the end, you\u0026rsquo;ll have a working chatbot and gain hands-on experience with APIs, webhooks, and automation.\n2. Prerequisites n8n account (Cloud or self-hosted) Meta Developer account with WhatsApp Business Cloud API access OpenAI API key Basic understanding of APIs and webhook workflows 3. Registering Your WhatsApp Business App A. Create WhatsApp App in Meta Developer Visit Meta for Developers Create a new app: choose Business → WhatsApp Link or create a WhatsApp Business Account B. Obtain Testing Credentials Your app dashboard will show:\nTest phone number Phone Number ID Temporary access token (valid for only 24 hours) Tip: For long-term use, generate a 60-day system-user token later.\nC. Add Recipients to Test List By default, only approved numbers can receive messages:\nNavigate to WhatsApp → API Setup Add numbers in E.164 format (e.g., +923001234567) Users must accept the invite via WhatsApp to become valid recipients 4. Configuring Your Webhook in n8n A. Create a Webhook Node Method: GET (for initial verification) Endpoint example: https://yourname.app.n8n.cloud/webhook/your-unique-id/webhook B. Verify the Webhook with Meta In your app’s Webhook section:\nCallback URL: your n8n webhook URL Verify Token: any secret string you choose (e.g., mySecret2025) C. Echo Back Meta’s Challenge Configure n8n\u0026rsquo;s Webhook node response:\nField Value Response Mode On Received Response Body {{$json[\u0026quot;query\u0026quot;][\u0026quot;hub.challenge\u0026quot;]}} This ensures Meta can verify your endpoint successfully.\n5. Processing Incoming Messages WhatsApp sends JSON data with structure like:\n{ \u0026#34;entry\u0026#34;: [ { \u0026#34;changes\u0026#34;: [ { \u0026#34;value\u0026#34;: { \u0026#34;messages\u0026#34;: [ { \u0026#34;from\u0026#34;: \u0026#34;923001234567\u0026#34;, \u0026#34;text\u0026#34;: { \u0026#34;body\u0026#34;: \u0026#34;Hello bot!\u0026#34; } } ], \u0026#34;metadata\u0026#34;: { \u0026#34;phone_number_id\u0026#34;: \u0026#34;698352170035199\u0026#34; } } } ] } ] } Extract:\nfrom: user’s number text.body: user’s text metadata.phone_number_id: correct sender ID 6. Integrating OpenAI for Responses Obtaining Your OpenAI API Key Before integrating OpenAI into your n8n workflow, you’ll need to get an API key from OpenAI.\nStep-by-Step: Sign up or log in to OpenAI. Navigate to your API Keys page. Click \u0026ldquo;Create new secret key\u0026rdquo;. Optionally name your key, then copy it immediately (you won’t be able to view it again). In n8n: Go to Credentials → Add New → choose OpenAI or HTTP Request. Paste your API key into the key field. Save the credentials. Security Tip: Keep your key private. Do not share it or commit it to public repositories.\nUse an HTTP Request node to call OpenAI:\nPOST https://api.openai.com/v1/chat/completions Authorization: Bearer YOUR_OPENAI_API_KEY Content-Type: application/json { \u0026#34;model\u0026#34;: \u0026#34;gpt-4o-mini\u0026#34;, \u0026#34;messages\u0026#34;: [ { \u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;You are a helpful WhatsApp AI assistant.\u0026#34; }, { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;{{ $json[...] }}\u0026#34; } ] } Replace {{ $json[...] }} with the actual path to the user\u0026rsquo;s message text from the Webhook node.\n7. Sending Replies via WhatsApp Use another HTTP Request node to respond:\nPOST https://graph.facebook.com/v21.0/{{ $json[...] }}/messages Authorization: Bearer YOUR_LONG_LIVED_TOKEN Content-Type: application/json { \u0026#34;messaging_product\u0026#34;: \u0026#34;whatsapp\u0026#34;, \u0026#34;to\u0026#34;: \u0026#34;{{ $json[...] }}\u0026#34;, \u0026#34;text\u0026#34;: { \u0026#34;body\u0026#34;: \u0026#34;{{ $node[\u0026#39;OpenAI Response\u0026#39;].json.choices[0].message.content }}\u0026#34; } } Use the metadata’s phone_number_id for the endpoint and from for the recipient. This avoids hardcoding and ensures proper routing.\n8. Example n8n Workflow Here’s the actual n8n workflow I used for my WhatsApp AI assistant. It integrates a product brochure PDF into a vector store for AI-powered Q\u0026amp;A, and handles WhatsApp message flow.\nStep-by-Step Breakdown: 1. Download Product Brochure PDF Downloads the brochure from a given URL. Extracts text from the PDF. 2. Create Product Brochure Vector Store Splits large text into chunks. Generates embeddings using OpenAI. Saves them in a vector store for fast semantic search. 3. Use the WhatsApp Trigger Listens for incoming WhatsApp messages. Routes them to supported or unsupported handlers. 3a. Handle Unsupported Messages Replies with a friendly error if the message type is not text. 4. Sales AI Agent Responds Uses OpenAI with memory + vector store retrieval to answer based on brochure content. 5. Reply to WhatsApp User Sends the AI-generated message back to the sender. Why this is effective:\nContext-aware answers via buffer memory. Reduced hallucinations thanks to vector store grounding. Smooth error handling for unsupported message types. 9. Common Errors \u0026amp; Fixes Recipient phone number not in allowed list\n→ Add as test number or switch to Live mode\n401 – Session expired\n→ Refresh token via Graph API:\nGET https://graph.facebook.com/v21.0/oauth/access_token ?grant_type=fb_exchange_token \u0026amp;client_id=YOUR_APP_ID \u0026amp;client_secret=YOUR_APP_SECRET \u0026amp;fb_exchange_token=YOUR_CURRENT_TOKEN Webhook verification failed\n→ Ensure verify token matches between Meta and n8n and echo hub.challenge\nNo execution data available\n→ Trigger workflow via actual WhatsApp message, not manual run\n10. Going Live Add a Privacy Policy URL in Meta App → Settings → Basic (required for live access) Switch app to Live mode once all compliance items are met Remove restricted recipient list Use WhatsApp message templates for messages sent after 24 hours of user interaction 11. Conclusion \u0026amp; Next Steps Congrats! You now have a WhatsApp AI Assistant built with n8n and OpenAI.\nWhere to go from here: Wire up custom knowledge (PDFs, documents) Implement memory for conversation context Launch multilingual support Export n8n workflow as JSON for reuse Need help? Join the n8n Community Forum or OpenAI Discord to connect with fellow builders.\nHappy automating!\n","permalink":"http://localhost:1313/posts/creating-whatsapp-ai-assistant-using-n8n2/","summary":"\u003ch1 id=\"creating-a-whatsapp-ai-assistant-using-n8n-a-step-by-step-guide\"\u003eCreating a WhatsApp AI Assistant Using n8n: A Step-by-Step Guide\u003c/h1\u003e\n\u003cp\u003eBuild your own AI-powered WhatsApp chatbot using \u003cstrong\u003en8n\u003c/strong\u003e, \u003cstrong\u003eWhatsApp Business Cloud API\u003c/strong\u003e, and \u003cstrong\u003eOpenAI\u003c/strong\u003e. This guide walks you through every step—from setup to testing—with real-world error handling, solutions, and an example production-ready workflow.\u003c/p\u003e\n\u003ch2 id=\"1-introduction\"\u003e1. Introduction\u003c/h2\u003e\n\u003cp\u003eWant to chat with an AI on WhatsApp? In this tutorial, you\u0026rsquo;ll learn how to build a \u003cstrong\u003eWhatsApp AI Assistant\u003c/strong\u003e using:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003en8n\u003c/strong\u003e (automation tool)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eWhatsApp Business Cloud API\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eOpenAI\u003c/strong\u003e (for generating intelligent replies)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eBy the end, you\u0026rsquo;ll have a working chatbot and gain hands-on experience with APIs, webhooks, and automation.\u003c/p\u003e","title":"Creating Whatsapp Ai Assistant Using N8n"},{"content":"Introduction A memory leak occurs when a program allocates memory dynamically (e.g., using malloc) and fails to release it using free. This leftover allocation can lead to wasted memory resources, eventually causing slowdowns or system crashes in long-running programs.\nValgrind is a powerful command-line tool available on Linux systems. It helps developers detect:\nMemory leaks Invalid memory access Uninitialized memory usage Mismatched memory management In this guide, we\u0026rsquo;ll walk through examples in C to learn how to detect and fix memory leaks using Valgrind.\nInstalling Valgrind On Arch Linux sudo pacman -S valgrind On Ubuntu/Debian sudo apt install valgrind On Fedora sudo dnf install valgrind Troubleshooting: Valgrind \u0026ldquo;cannot find mandatory redirection\u0026rdquo; on Arch Linux If you run Valgrind and get an error like:\nvalgrind: Fatal error at startup: a function redirection\nvalgrind: which is mandatory for this platform-tool combination\nvalgrind: cannot be set up.\n…you might be running a 32-bit executable on a 64-bit Arch Linux system.\nWhy this happens Valgrind needs to hook into low-level glibc functions from your binary’s architecture.\nIf your binary is 32-bit, Arch requires the 32-bit glibc runtime (lib32-glibc).\nWithout it, Valgrind can’t find the right function symbols and quits.\nFix Install the 32-bit glibc package:\nsudo pacman -S lib32-glibc After installation, re-run:\nvalgrind ./your-binary and it should work.\nUbuntu/Debian equivalent: sudo apt install libc6-dbg:i386\nBasic Example: Hello World Code #include \u0026lt;stdio.h\u0026gt; int main() { printf(\u0026#34;Hello World\\n\u0026#34;); return 0; } Compile and Run gcc main.c -o main.out ./main.out Run with Valgrind valgrind ./main.out You should see no errors or memory leaks in the output.\nIntroducing a Memory Leak Static Allocation (Safe) #include \u0026lt;stdio.h\u0026gt; int main() { char str[20] = \u0026#34;Hello\u0026#34;; printf(\u0026#34;%s\\n\u0026#34;, str); return 0; } This uses stack memory, so Valgrind will report no leaks.\nDynamic Allocation (With Leak) #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; int main() { char *str = malloc(20); strcpy(str, \u0026#34;Hello\u0026#34;); printf(\u0026#34;%s\\n\u0026#34;, str); return 0; // Forgot to free memory } Valgrind Output valgrind ./main.out You should see:\ndefinitely lost: 20 bytes in 1 blocks\nFixing the Memory Leak Add free(str); before returning:\nfree(str); Fixed Code #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; int main() { char *str = malloc(20); strcpy(str, \u0026#34;Hello\u0026#34;); printf(\u0026#34;%s\\n\u0026#34;, str); free(str); return 0; } Detailed Valgrind Options Use for deeper analysis:\nvalgrind --leak-check=full ./main.out Or even more detailed:\nvalgrind --leak-check=full --show-leak-kinds=all --track-origins=yes ./main.out Explanation:\n--leak-check=full: Display detailed leak info --show-leak-kinds=all: Show all kinds of leaks (definitely, indirectly lost, etc.) --track-origins=yes: Show where uninitialized values originate Summary Always free() memory allocated with malloc(), calloc(), or realloc(). Close all file streams with fclose(). Use Valgrind to identify and fix: Memory leaks Invalid memory writes Use-after-free bugs Recommended command: valgrind --leak-check=full --track-origins=yes ./your_program Valgrind is a critical tool for writing safe, efficient, and bug-free C programs.\n","permalink":"http://localhost:1313/posts/introductiontovalgrind/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eA \u003cstrong\u003ememory leak\u003c/strong\u003e occurs when a program allocates memory dynamically (e.g., using \u003ccode\u003emalloc\u003c/code\u003e) and fails to release it using \u003ccode\u003efree\u003c/code\u003e. This leftover allocation can lead to wasted memory resources, eventually causing slowdowns or system crashes in long-running programs.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eValgrind\u003c/strong\u003e is a powerful command-line tool available on Linux systems. It helps developers detect:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eMemory leaks\u003c/li\u003e\n\u003cli\u003eInvalid memory access\u003c/li\u003e\n\u003cli\u003eUninitialized memory usage\u003c/li\u003e\n\u003cli\u003eMismatched memory management\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIn this guide, we\u0026rsquo;ll walk through examples in C to learn how to detect and fix memory leaks using Valgrind.\u003c/p\u003e","title":"Detecting and Fixing Memory Leaks with Valgrind"},{"content":"QEMU-KVM on Arch Linux: Running Tiny Core Linux in a Lightweight VM Virtualization is a powerful tool for developers, sysadmins, and tinkerers alike. On Linux, QEMU-KVM stands out as a robust, high-performance virtualization stack. In this blog, well walk through setting up QEMU-KVM on Arch Linux and using it to run Tiny Core Linuxa super-lightweight distro perfect for testing and experimentation.\nWhat is QEMU-KVM QEMU (Quick Emulator) is a generic and open-source machine emulator. On its own, it can emulate various hardware systems. However, when paired with **KVM (Kernel-based Virtual Machine)**a Linux kernel module for virtualizationit can run virtual machines with near-native performance.\nQEMU provides device emulation and user-space management. KVM integrates with the Linux kernel and handles hardware-level virtualization. Together, they effectively form a Type 1 hypervisor because the Linux kernel (with KVM) handles core virtualization tasks directly on hardware.\nStep-by-Step: Installing QEMU-KVM on Arch Linux Step 1: Install Required Packages sudo pacman -Syu sudo pacman -S qemu virt-manager virt-viewer dnsmasq vde2 bridge-utils openbsd-netcat libvirt edk2-ovmf edk2-ovmf is for UEFI firmware support in VMs.\nStep 2: Enable and Start libvirtd sudo systemctl enable --now libvirtd.service Step 3: Add Your User to the libvirt Group sudo usermod -aG libvirt (whoami) newgrp libvirt Step 4: Verify KVM Support lsmod grep kvm And check CPU virtualization support:\negrep -c (vmxsvm) /proc/cpuinfo A value of 1 or more indicates virtualization support.\nExample: Running Tiny Core Linux on QEMU-KVM Now that your system is ready, lets run Tiny Core Linux, a minimalist Linux distro thats only 16MB\nStep 1: Download Tiny Core ISO wget http://tinycorelinux.net/14.x/x86/release/Core-current.iso Or visit http://tinycorelinux.net for the latest release.\nStep 2: Create a Virtual Disk (Optional) qemu-img create -f qcow2 tinycore.qcow2 512M This creates a 512MB disk image. Optional for RAM-only usage.\nStep 3: Launch the VM with KVM Acceleration qemu-system-x86_64 -enable-kvm -m 512 -cpu host -smp 1 -cdrom Core-current.iso -hda tinycore.qcow2 -boot d -net nic -net user -vga virtio -display sdl Key Flags Explained:\n-enable-kvm: Enables KVM hardware acceleration -m 512: Allocates 512MB RAM -cpu host: Uses the host CPU features -cdrom: Points to the Tiny Core ISO -hda: Uses a QCOW2 disk image -boot d: Boots from CD first -net user: Enables simple user-mode networking (e.g., for internet access) -display sdl: Uses SDL window for graphics (you can replace with gtk or virt-manager) Alternate: Boot Tiny Core in RAM Without Disk qemu-system-x86_64 -enable-kvm -m 256 -cdrom Core-current.iso -boot d -net nic -net user -vga std Conclusion With QEMU-KVM, Arch Linux becomes a full-featured Type 1 hypervisor. By combining kernel-level virtualization (KVM) with the flexibility of QEMU, you get a fast, customizable virtualization platform. Running Tiny Core Linux showcases just how lightweight and efficient this setup can be.\nWhether youre building VMs for testing, learning Linux internals, or experimenting with custom environments, QEMU-KVM on Arch is a powerful combination.\nHappy virtualizing\n","permalink":"http://localhost:1313/posts/qemu/","summary":"\u003ch1 id=\"qemu-kvm-on-arch-linux-running-tiny-core-linux-in-a-lightweight-vm\"\u003eQEMU-KVM on Arch Linux: Running Tiny Core Linux in a Lightweight VM\u003c/h1\u003e\n\u003cp\u003eVirtualization is a powerful tool for developers, sysadmins, and tinkerers alike. On Linux, \u003cstrong\u003eQEMU-KVM\u003c/strong\u003e stands out as a robust, high-performance virtualization stack. In this blog, well walk through setting up QEMU-KVM on \u003cstrong\u003eArch Linux\u003c/strong\u003e and using it to run \u003cstrong\u003eTiny Core Linux\u003c/strong\u003ea super-lightweight distro perfect for testing and experimentation.\u003c/p\u003e\n\u003ch2 id=\"what-is-qemu-kvm\"\u003eWhat is QEMU-KVM\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eQEMU (Quick Emulator)\u003c/strong\u003e is a generic and open-source machine emulator. On its own, it can emulate various hardware systems. However, when paired with **KVM (Kernel-based Virtual Machine)**a Linux kernel module for virtualizationit can run virtual machines with near-native performance.\u003c/p\u003e","title":"QEMU-KVM on Arch Linux: Running Tiny Core Linux in a Lightweight VM"},{"content":"Building the Linux Kernel Compiling the Linux Kernel involves multiple steps and can take some time depending on your hardware specifications.\nStep 1: Download the Kernel Source Code Start by visiting the Official Linux Kernel Website and downloading the latest available kernel source code. The downloaded file will be a compressed archive containing all necessary source files.\nStep 2: Extract the Source Code Once the download completes, extract the contents of the compressed archive using the tar command:\ntar xvf linux-6.13.tar.xz If the tar utility is not installed on your system, you can install it using:\nsudo pacman -S tar Note: Always ensure you are using the correct version number in the file name.\nStep 3: Install Required Dependencies To compile the kernel, you need to install various development tools and libraries. Install them using the following command:\nsudo pacman -S git fakeroot ncurses xz bc flex bison base-devel kmod cpio perl binutils util-linux jfsutils e2fsprogs xfsprogs squashfs-tools quota-tools Step 4: Configure the Kernel Navigate into the kernel source directory: cd linux-6.13 Use your current system’s configuration as a base:\nIf zcat is available, run:\nzcat /proc/config.gz \u0026gt; .config Otherwise, use this alternative method:\ncp /proc/config.gz ./ gunzip config.gz mv config .config Customize the kernel using a menu-driven interface:\nmake menuconfig make xconfig make oldconfig Modify the .config file directly:\nOpen it with a text editor:\nsudo vim .config Search for the line:\nCONFIG_EXT4_FS=m And change it to:\nCONFIG_EXT4_FS=y Step 5: Compile the Kernel Determine the number of CPU cores available to speed up compilation: nproc Compile the kernel using the number of cores found above. Replace n with that number: make -j\u0026lt;n\u0026gt; If you encounter any errors during or after this step, back up your .config file and reset the source tree with:\nmake mrproper This command cleans the build environment and restores the source tree to its original state.\nStep 6: Install Kernel Modules Kernel modules are essential for extending the kernel’s functionality and ensuring compatibility with various hardware. Install them with:\nsudo make modules_install Step 7: Install the Kernel You can install the compiled kernel using one of the two methods below:\nAutomatic installation: sudo make install Manual installation (if the above doesn\u0026rsquo;t work):\nCopy the kernel image:\nsudo cp arch/x86/boot/bzImage /boot/vmlinuz-linux-custom Copy the System.map file:\nsudo cp System.map /boot/System.map-linux-custom Copy the kernel configuration file:\nsudo cp .config /boot/config-linux-custom Step 8: Update the Bootloader If you use GRUB, follow these steps to add an entry for your custom kernel:\nFind the UUID of your root partition: lsblk -f Open the custom GRUB configuration file: sudo nvim /etc/grub.d/40_custom Add the following entry (replace paste-your-root-partition-uuid-here with the actual UUID): menuentry \u0026#39;Custom Linux Kernel\u0026#39; { linux /boot/vmlinuz-linux-custom root=UUID=paste-your-root-partition-uuid-here initrd /boot/initramfs-linux.img } Step 9: Generate Initramfs As you\u0026rsquo;ve compiled a new kernel, installed modules, and modified boot entries, generating a new initramfs is necessary. Run:\nsudo mkinitcpio -k 6.13-custom -c /etc/mkinitcpio.conf -g /boot/initramfs-linux-custom.img Make sure the version (6.13-custom) matches your compiled kernel.\nStep 10: Update GRUB Configuration Finally, update the GRUB configuration so that it includes your new kernel entry:\nsudo grub-mkconfig -o /boot/grub/grub.cfg Done! Congratulations! You’ve successfully compiled and installed your custom Linux Kernel. Enjoy your personalized system!\n","permalink":"http://localhost:1313/posts/kernal_compilation/","summary":"\u003ch1 id=\"building-the-linux-kernel\"\u003eBuilding the Linux Kernel\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003eCompiling the Linux Kernel involves multiple steps and can take some time depending on your hardware specifications.\u003c/strong\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"step-1-download-the-kernel-source-code\"\u003eStep 1: Download the Kernel Source Code\u003c/h3\u003e\n\u003cp\u003eStart by visiting the \u003ca href=\"https://www.kernel.org/\"\u003eOfficial Linux Kernel Website\u003c/a\u003e and downloading the latest available kernel source code. The downloaded file will be a compressed archive containing all necessary source files.\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"step-2-extract-the-source-code\"\u003eStep 2: Extract the Source Code\u003c/h3\u003e\n\u003cp\u003eOnce the download completes, extract the contents of the compressed archive using the \u003ccode\u003etar\u003c/code\u003e command:\u003c/p\u003e","title":"How to build Linux Kernal: Step by Step Guide"},{"content":"Introduction So, you’ve built a sleek website with Hugo and deployed it to GitHub Pages. Now, you want to give it a professional touch with a custom domain like yourdomain.tech instead of the default username.github.io URL. This guide walks you through the process step-by-step.\nPrerequisites A Hugo website hosted on GitHub Pages (public repository). A custom domain (e.g., yourdomain.tech) purchased from a registrar like Namecheap, Google Domains, etc. Basic familiarity with DNS settings and GitHub repository configurations. Step 1: Configure Your GitHub Repository First, ensure your GitHub Pages site is set up correctly:\nYour repository should be named \u0026lt;username\u0026gt;.github.io (for user/organization sites) or \u0026lt;repo-name\u0026gt; (for project sites). The gh-pages branch (or the /docs folder) should contain your Hugo-generated static files. Step 2: Configure DNS Settings for Your Domain Option 1: Use an Apex Domain (e.g., yourdomain.tech) If you want your site to live at the root domain (e.g., yourdomain.tech), configure A records in your DNS settings:\nGo to your domain registrar’s DNS management page. Create four A records pointing to GitHub’s IP addresses: Host: @ Type: A Value: 185.199.108.153 TTL: Automatic ","permalink":"http://localhost:1313/posts/customdomain/","summary":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003eSo, you’ve built a sleek website with Hugo and deployed it to GitHub Pages. Now, you want to give it a professional touch with a custom domain like \u003ccode\u003eyourdomain.tech\u003c/code\u003e instead of the default \u003ccode\u003eusername.github.io\u003c/code\u003e URL. This guide walks you through the process step-by-step.\u003c/p\u003e\n\u003ch2 id=\"prerequisites\"\u003ePrerequisites\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003eA Hugo website hosted on GitHub Pages (public repository).\u003c/li\u003e\n\u003cli\u003eA custom domain (e.g., \u003ccode\u003eyourdomain.tech\u003c/code\u003e) purchased from a registrar like Namecheap, Google Domains, etc.\u003c/li\u003e\n\u003cli\u003eBasic familiarity with DNS settings and GitHub repository configurations.\u003c/li\u003e\n\u003c/ol\u003e\n\u003chr\u003e\n\u003ch2 id=\"step-1-configure-your-github-repository\"\u003eStep 1: Configure Your GitHub Repository\u003c/h2\u003e\n\u003cp\u003eFirst, ensure your GitHub Pages site is set up correctly:\u003c/p\u003e","title":"How to up custom domain for GitHub Pages"},{"content":"Exception handling is a crucial aspect of writing robust and reliable Python code. Whether you\u0026rsquo;re a beginner or an experienced developer, getting an error, or exception, in your Python program means the entire program will crash. You don’t want this to happen in real-world programs. Instead, you want the program to detect errors, handle them, and then continue to run. In this blog, we\u0026rsquo;ll explore the fundamentals of exception handling in Python, including syntax, best practices, and advanced techniques.\nWhat Are Exceptions? Exceptions are runtime errors that disrupt the normal flow of a program. For example, trying to open a non-existent file, dividing by zero, or accessing an invalid index in a list will raise exceptions. If unhandled, these exceptions cause your program to crash.\nBasic Syntax: try and except The primary mechanism for handling exceptions in Python is the try-except block. Errors can be handled with with this. The code that could potentially have an error is put in a try clause. The program execution moves to the start of a following except clause if an error happens.\nHere\u0026rsquo;s the basic structure:\ndef cal(value): try: return 10 / value except ZeroDivisionError: print(\u0026#34;Cannot divide by zero!\u0026#34;) print(cal(0)) print(cal(2)) print(cal(3)) How It Works: The code inside the try block is executed. If an exception occurs, Python checks the except blocks for a matching exception type. If a match is found, the corresponding except block runs. Catching Specific Exceptions Always catch specific exceptions to avoid silencing unexpected errors. Python has many built-in exceptions (e.g., ValueError, TypeError, FileNotFoundError).\nimport math x = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) try: print(f\u0026#39;Square Root of {x} is {math.sqrt(x)}\u0026#39;) except ValueError: print(\u0026#39;Number is less than 0\u0026#39;) Output\nThe else Clause The else block runs only if no exceptions were raised in the try block. Use it to separate \u0026ldquo;happy path\u0026rdquo; code from error handling.\nimport math def sqr(value): try: x = math.sqrt(value) except ValueError: print(\u0026#39;Number is less than 0\u0026#39;) else: print(f\u0026#39;The Answer is: {x}\u0026#39;) value = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) sqr(value) Output The finally Clause The finally block runs regardless of whether an exception occurred. It’s ideal for cleanup tasks (e.g., closing files or releasing resources).\nimport math def sqr(value): try: x = math.sqrt(value) except ValueError: print(\u0026#39;Error\u0026#39;) else: print(f\u0026#39;The Answer is: {x}\u0026#39;) finally: print(\u0026#39;Program Ends\u0026#39;) value = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) sqr(value) Output Raising Exceptions Manually Use the raise keyword to trigger exceptions intentionally. This is useful for enforcing constraints.\ndef validate_age(age): if age \u0026lt; 0: raise ValueError(\u0026#34;Age cannot be negative!\u0026#34;) return age try: validate_age(-5) except ValueError as e: print(e) Creating Custom Exceptions Define custom exceptions by subclassing Python’s built-in Exception class. This makes your code more readable and errors more descriptive. (note: I have used RegEx, for that blog will be out soon :) )\nimport re class InvalidEmailError(Exception): \u0026#34;\u0026#34;\u0026#34;Raised when an email format is invalid.\u0026#34;\u0026#34;\u0026#34; pass def send_email(valid,email): if not valid: raise InvalidEmailError(f\u0026#34;Invalid email: {email}\u0026#34;) email = input(\u0026#39;Please enter your email: \u0026#39;) valid = re.match(r\u0026#39;^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\u0026#39;, email) try: send_email(valid, email) except InvalidEmailError as e: print(e) Output Logging a Python Error We can Log an exception in Python with an error. This can be done in the logging.exception() method. This function logs a message with level ERROR on this logger.\nimport math import logging def sqr(value): try: x = math.sqrt(value) except ValueError: logging.exception(\u0026#34;Error\u0026#34;) else: print(f\u0026#39;The Answer is: {x}\u0026#39;) finally: print(\u0026#39;Program Ends\u0026#39;) value = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) sqr(value) Output Best Practices for Exception Handling Catch specific exceptions: Avoid broad except: clauses that hide bugs. Keep try blocks minimal: Only wrap code that might raise an exception. Use finally for cleanup: Ensure resources are released (e.g., closing files). Log exceptions: Use logging.error() instead of print() for production code. Provide meaningful messages: Help debug issues faster with clear error descriptions. Avoid empty except blocks: Silent failures make debugging harder. Conclusion Exception handling is essential for writing better Python applications. By using try-except blocks effectively, catching specific errors, and with else/finally clauses, you can create programs that handle unexpected scenarios.\nNow go forth and write bulletproof Python code!\n","permalink":"http://localhost:1313/posts/exception_handling_in_python/","summary":"\u003cp\u003eException handling is a crucial aspect of writing robust and reliable Python code. Whether you\u0026rsquo;re a beginner or an experienced developer, getting an error, or exception, in your Python program means the entire program will crash. You don’t want this to happen in real-world programs. Instead, you want the program to detect errors, handle them, and then continue to run. In this blog, we\u0026rsquo;ll explore the fundamentals of exception handling in Python, including syntax, best practices, and advanced techniques.\u003c/p\u003e","title":"Exception Handling in Python: A Comprehensive Guide"},{"content":"Have you ever wanted your Python program to do multiple things at once? For example, downloading files while updating the UI, or processing data while listening for user input? That’s where multithreading comes in.\nIn this post, we’ll explore multithreading in Python — what it is, when to use it, and how to use it with simple examples.\n🧠 What is Multithreading? Multithreading is a way to run multiple threads (smaller units of a process) at the same time. It helps make your program more responsive or perform tasks in parallel, especially when tasks are I/O-bound (e.g., network calls, file reading, etc.).\nPython has a built-in module called threading that makes it easy to create and manage threads.\n⚠️ But Wait — Python\u0026rsquo;s GIL Before you jump in, it\u0026rsquo;s important to understand the Global Interpreter Lock (GIL). In CPython (the standard Python implementation), the GIL allows only one thread to execute Python bytecode at a time.\nThis means multithreading in Python is best suited for I/O-bound tasks, not CPU-bound tasks like heavy computations. For CPU-bound tasks, consider multiprocessing instead.\n🛠️ Using the threading Module Here\u0026rsquo;s a basic example to demonstrate multithreading:\nimport threading import time def print_numbers(): for i in range(5): print(f\u0026#34;Number: {i}\u0026#34;) time.sleep(1) def print_letters(): for letter in \u0026#39;abcde\u0026#39;: print(f\u0026#34;Letter: {letter}\u0026#34;) time.sleep(1) # Creating threads t1 = threading.Thread(target=print_numbers) t2 = threading.Thread(target=print_letters) # Starting threads t1.start() t2.start() # Wait for both threads to complete t1.join() t2.join() print(\u0026#34;Both threads have finished.\u0026#34;) 🔍 Output (interleaved): Number: 0 Letter: a Number: 1 Letter: b ... Both functions run at the same time, and you can see their output interleave. That’s multithreading in action!\n📦 Real-World Use Cases Downloading multiple files at once Handling multiple client connections on a server Running background tasks like logging or monitoring Keeping your GUI app responsive while doing other work 🧰 Extra Tools For more advanced usage:\nconcurrent.futures.ThreadPoolExecutor — easier thread management queue.Queue — safe way to share data between threads threading.Lock — prevents race conditions 🧪 Example with ThreadPoolExecutor from concurrent.futures import ThreadPoolExecutor import time def task(name): print(f\u0026#34;{name} starting\u0026#34;) time.sleep(2) print(f\u0026#34;{name} done\u0026#34;) with ThreadPoolExecutor(max_workers=2) as executor: executor.submit(task, \u0026#34;Task 1\u0026#34;) executor.submit(task, \u0026#34;Task 2\u0026#34;) ✅ Final Thoughts Multithreading in Python is a powerful tool when used correctly — especially for I/O-bound programs. Just remember the GIL limitation and use the right tool (like multiprocessing) when working with CPU-heavy tasks.\nThanks for reading! Happy threading 🧵🐍\n","permalink":"http://localhost:1313/posts/multithreading/","summary":"\u003cp\u003eHave you ever wanted your Python program to do multiple things at once? For example, downloading files while updating the UI, or processing data while listening for user input? That’s where \u003cstrong\u003emultithreading\u003c/strong\u003e comes in.\u003c/p\u003e\n\u003cp\u003eIn this post, we’ll explore multithreading in Python — what it is, when to use it, and how to use it with simple examples.\u003c/p\u003e\n\u003ch2 id=\"-what-is-multithreading\"\u003e🧠 What is Multithreading?\u003c/h2\u003e\n\u003cp\u003eMultithreading is a way to run multiple threads (smaller units of a process) at the same time. It helps make your program more responsive or perform tasks in parallel, especially when tasks are I/O-bound (e.g., network calls, file reading, etc.).\u003c/p\u003e","title":"Multithreading in Python"},{"content":"Running a Local LLM on Mobile: Testing PocketPal on iPhone 12 With the increasing accessibility of large language models (LLMs), running them locally on mobile devices is an exciting prospect. I recently tested PocketPal, a mobile LLM interface, on my iPhone 12, using a distilled 4-bit quantized model. Here’s a breakdown of my experience, covering installation, performance, and overall usability.\nWhy Run an LLM on Mobile? Running an LLM locally on a mobile device comes with several advantages:\nPrivacy: No data is sent to external servers. Offline Access: Works without an internet connection. Lower Cost: Avoids API costs associated with cloud-based models. What is Quantization? Quantization is a technique used to reduce the memory and computational requirements of machine learning models by representing their weights with lower precision numbers. Instead of using 32-bit floating-point numbers, models can be compressed into 8-bit or even 4-bit integers while maintaining reasonable accuracy.\nFor LLMs on mobile, 4-bit quantization significantly reduces the model size, making it feasible to run on devices with limited resources. However, this compression can lead to:\nSlightly reduced accuracy due to loss of precision. Faster inference times, as lower-bit computations require less processing power. Lower memory usage, allowing larger models to fit within mobile device constraints. Setting Up and Running PocketPal on iPhone 12 1. Download and Install PocketPal Open the App Store and search for PocketPal AI by Asghar Ghorbani. Download and install the app. Open the app and allow necessary permissions. 2. Adding a Model Navigate to the Models section in the PocketPal app. Click the + button to add a new model. You will see two options: Add from Hugging Face Add Local Model Select Add from Hugging Face to browse available models. 3. Selecting and Downloading a Model Search for DeepSeek-R1-Distill-Qwen-1.5B-Q4_0. Select the model and start downloading it (size: 1.06GB, 1.78B parameters). Once downloaded, the model will appear under the Ready to Use section. 4. Running Benchmarks I ran benchmarks on my iPhone 12 using the DeepSeek-R1-Distill-Qwen-1.5B-Q4_0 model. Here are the key results:\nModel Size: 1.06 GB with 1.78 billion parameters. Benchmark Configuration: Prompt Processing: 512 Token Generation: 128 Pipeline Length: 1 Repetitions: 3 Model Settings: Context Length: 1024 tokens Batch Size: 512 CPU Threads: 4 GPU Layers: 0 (fully CPU-based execution) Flash Attention: Disabled Performance Metrics: Prompt Processing Speed: 26.93 tokens/sec (±2.37) Token Generation Speed: 18.05 tokens/sec (±0.75) Total Execution Time: 1 minute 18 seconds Peak Memory Usage: 35.0% (1GB / 4GB) Live Demo: Running PocketPal on iPhone 12 Watch a live demonstration of PocketPal running a distilled 4-bit quantized model on an iPhone 12: Image: Video demonstration is available here: Video\nAnalysis of Results Decent Processing Speed: With a distilled 4-bit quantized model, the 18.05 t/s token generation rate is quite reasonable for mobile inference. Low Memory Footprint: The 1GB RAM usage means this can run on even mid-range smartphones. CPU-Based Execution: Since 0 GPU layers were used, this proves mobile CPUs are capable of running quantized LLMs efficiently. Flash Attention Disabled: If supported, enabling it might further optimize speed and reduce lag. Final Thoughts Running an LLM locally on an iPhone 12 with PocketPal is feasible but comes with trade-offs. It’s a promising step toward self-hosted AI assistants, though optimization and hardware improvements will be crucial for broader adoption. If you’re privacy-conscious or need offline AI capabilities, it’s definitely worth exploring!\nFuture Improvements I\u0026rsquo;d Like to See: Better memory efficiency to reduce battery drain. Enhanced speed for real-time interaction. More user-friendly model importing and switching. ","permalink":"http://localhost:1313/posts/llmonmobile/","summary":"\u003ch1 id=\"running-a-local-llm-on-mobile-testing-pocketpal-on-iphone-12\"\u003eRunning a Local LLM on Mobile: Testing PocketPal on iPhone 12\u003c/h1\u003e\n\u003cp\u003eWith the increasing accessibility of large language models (LLMs), running them locally on mobile devices is an exciting prospect. I recently tested \u003cstrong\u003ePocketPal\u003c/strong\u003e, a mobile LLM interface, on my \u003cstrong\u003eiPhone 12\u003c/strong\u003e, using a \u003cstrong\u003edistilled 4-bit quantized model\u003c/strong\u003e. Here’s a breakdown of my experience, covering installation, performance, and overall usability.\u003c/p\u003e\n\u003ch2 id=\"why-run-an-llm-on-mobile\"\u003eWhy Run an LLM on Mobile?\u003c/h2\u003e\n\u003cp\u003eRunning an LLM locally on a mobile device comes with several advantages:\u003c/p\u003e","title":"Running Large Language Models on Mobile: DeepSeek R1 on iPhone 12"},{"content":"Running DeepSeek-R1 1.5B on Raspberry Pi 5 (CPU-Only) Technical Insights Why Can We Run This on Raspberry Pi 5? Thanks to open-source advancements, we can now run large-scale AI models on small devices like the Raspberry Pi 5. Key factors enabling this include:\nOptimized lightweight models: DeepSeek-R1 1.5B is built efficiently to run on limited hardware. ARM64 Support: Modern AI frameworks support ARM-based architectures, enabling their use on RPi5. Open-source software: Platforms like Ollama make AI deployment accessible to all. Performance Considerations Running this model on an RPi5 without a GPU will be CPU-intensive. Consider reducing active processes to free up memory. If performance lags, use a lighter model or external processing (cloud inference). No GPU acceleration was used in this setup, meaning all computations rely solely on the CPU, which may affect inference speeds. This guide covers the installation and execution of DeepSeek-R1 1.5B on a Raspberry Pi 5, following the steps demonstrated in your images.\nPrerequisites Raspberry Pi 5 (ARM64 architecture, more powerful than previous versions) Debian-based Linux installed An internet connection At least 4GB RAM recommended for smooth operation Step 1: Log in to Your Raspberry Pi Upon booting, log in using your credentials:\nraspberrypi login: hisam Password: ****** Example login screen: Step 2: Install Curl Curl is required to fetch the installation script. Run:\nsudo apt install curl If it\u0026rsquo;s already installed, you\u0026rsquo;ll see:\ncurl is already the newest version... Example output: Step 3: Install Ollama Ollama is the runtime needed to execute DeepSeek models.\ncurl -fsSL https://ollama.com/install.sh | sh This will download and install Ollama.\nExample installation screen: Step 4: Enable and Start Ollama Service After installation, Ollama sets up a system service.\nollama The output will indicate success:\n\u0026gt;\u0026gt;\u0026gt; Creating ollama user... \u0026gt;\u0026gt;\u0026gt; Enabling and starting ollama service... \u0026gt;\u0026gt;\u0026gt; The Ollama API is now available at 127.0.0.1:11434. Example setup screen: Step 5: Pull and Run DeepSeek-R1 1.5B Now, pull and run the model:\nollama run deepseek-r1:1.5b This will download the model, which is about 1.1 GB in size.\nExample download screen: Once downloaded, the model is ready to run.\nStep 6: Execute DeepSeek-R1 1.5B Run the model and start interacting:\nollama run deepseek-r1:1.5b You should see a prompt where you can start typing queries:\n\u0026gt;\u0026gt;\u0026gt; Hey! Hello! How can I assist you today? 😊 Example interaction: Final Setup Image Video Demonstration Watch Video\nConclusion You have successfully installed and executed DeepSeek-R1 1.5B on your Raspberry Pi 5. This demonstrates the power of open-source AI, making it possible to run advanced models on small-scale devices. If you encounter performance issues, consider optimizing your setup or offloading computations.\nHappy coding!\n","permalink":"http://localhost:1313/posts/deepseek/","summary":"\u003ch1 id=\"running-deepseek-r1-15b-on-raspberry-pi-5-cpu-only\"\u003eRunning DeepSeek-R1 1.5B on Raspberry Pi 5 (CPU-Only)\u003c/h1\u003e\n\u003ch2 id=\"technical-insights\"\u003eTechnical Insights\u003c/h2\u003e\n\u003ch3 id=\"why-can-we-run-this-on-raspberry-pi-5\"\u003eWhy Can We Run This on Raspberry Pi 5?\u003c/h3\u003e\n\u003cp\u003eThanks to open-source advancements, we can now run large-scale AI models on small devices like the Raspberry Pi 5. Key factors enabling this include:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eOptimized lightweight models\u003c/strong\u003e: DeepSeek-R1 1.5B is built efficiently to run on limited hardware.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eARM64 Support\u003c/strong\u003e: Modern AI frameworks support ARM-based architectures, enabling their use on RPi5.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eOpen-source software\u003c/strong\u003e: Platforms like Ollama make AI deployment accessible to all.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"performance-considerations\"\u003ePerformance Considerations\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eRunning this model on an RPi5 \u003cstrong\u003ewithout a GPU\u003c/strong\u003e will be CPU-intensive.\u003c/li\u003e\n\u003cli\u003eConsider \u003cstrong\u003ereducing active processes\u003c/strong\u003e to free up memory.\u003c/li\u003e\n\u003cli\u003eIf performance lags, use a \u003cstrong\u003elighter model\u003c/strong\u003e or \u003cstrong\u003eexternal processing (cloud inference).\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eNo GPU acceleration was used\u003c/strong\u003e in this setup, meaning all computations rely solely on the CPU, which may affect inference speeds.\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003cp\u003eThis guide covers the installation and execution of DeepSeek-R1 1.5B on a Raspberry Pi 5, following the steps demonstrated in your images.\u003c/p\u003e","title":"DeepSeek-R1 on Raspberry Pi 5: Open-Source AI Without a GPU"},{"content":"Setting Up Neovim: An Easy and Beginner\u0026rsquo;s Guide Neovim is a modern and extensible text editor that enhances Vim’s capabilities. If you\u0026rsquo;re using Linux, setting up Neovim can be a rewarding experience, allowing you to customize it for an efficient workflow. In this guide, we\u0026rsquo;ll cover installing Neovim, setting up a basic configuration, and enhancing it with essential plugins to turn it into a full-fledged IDE.\n1. Installing Neovim sudo pacman -S neovim 2. Setting Up Neovim Configuration Neovim’s configuration is stored in ~/.config/nvim/. Create the directory and initialize a basic configuration:\nmkdir -p ~/.config/nvim nvim ~/.config/nvim/init.lua Minimal Configuration (init.lua) Add the following settings to your init.lua file:\n-- Enable line numbers vim.opt.number = true vim.opt.relativenumber = true -- Set tab size vim.opt.expandtab = true vim.opt.shiftwidth = 4 vim.opt.tabstop = 4 -- Enable mouse support vim.opt.mouse = \u0026#34;a\u0026#34; -- Set clipboard to system clipboard vim.opt.clipboard = \u0026#34;unnamedplus\u0026#34; Save and exit Neovim.\n3. Installing a Plugin Manager The best plugin manager for Neovim is lazy.nvim. Install it by running:\ngit clone --depth 1 https://github.com/folke/lazy.nvim.git \\ ~/.local/share/nvim/lazy/lazy.nvim Then, update your init.lua to load it:\nlocal lazypath = vim.fn.stdpath(\u0026#34;data\u0026#34;) .. \u0026#34;/lazy/lazy.nvim\u0026#34; if not vim.loop.fs_stat(lazypath) then vim.fn.system({ \u0026#34;git\u0026#34;, \u0026#34;clone\u0026#34;, \u0026#34;--filter=blob:none\u0026#34;, \u0026#34;https://github.com/folke/lazy.nvim.git\u0026#34;, lazypath }) end vim.opt.rtp:prepend(lazypath) 4. Installing Essential Plugins With lazy.nvim installed, you can add plugins in init.lua:\nrequire(\u0026#34;lazy\u0026#34;).setup({ \u0026#34;nvim-treesitter/nvim-treesitter\u0026#34;, -- Syntax highlighting \u0026#34;nvim-telescope/telescope.nvim\u0026#34;, -- Fuzzy finder \u0026#34;neovim/nvim-lspconfig\u0026#34;, -- LSP support \u0026#34;hrsh7th/nvim-cmp\u0026#34;, -- Auto-completion \u0026#34;hrsh7th/cmp-nvim-lsp\u0026#34;, -- LSP completion source \u0026#34;hrsh7th/cmp-buffer\u0026#34;, -- Buffer completion \u0026#34;hrsh7th/cmp-path\u0026#34;, -- Path completion \u0026#34;hrsh7th/cmp-nvim-lua\u0026#34;, -- Neovim Lua API completion \u0026#34;L3MON4D3/LuaSnip\u0026#34;, -- Snippet engine \u0026#34;saadparwaiz1/cmp_luasnip\u0026#34;, -- Snippet completion \u0026#34;nvim-lualine/lualine.nvim\u0026#34;, -- Status line \u0026#34;nvim-tree/nvim-tree.lua\u0026#34;, -- File explorer \u0026#34;tpope/vim-surround\u0026#34;, -- Surround text objects \u0026#34;tpope/vim-commentary\u0026#34;, -- Commenting shortcuts \u0026#34;lewis6991/gitsigns.nvim\u0026#34;, -- Git integration \u0026#34;akinsho/toggleterm.nvim\u0026#34;, -- Terminal management }) Save and exit Neovim, then open it and run:\n:Lazy sync This will install the plugins automatically.\n5. Setting Up Treesitter Treesitter provides better syntax highlighting and code parsing. Install it by adding the following to your init.lua:\nrequire\u0026#39;nvim-treesitter.configs\u0026#39;.setup { ensure_installed = \u0026#34;all\u0026#34;, highlight = { enable = true, }, indent = { enable = true, }, } Then, update Treesitter by running:\n:TSUpdate 6. Setting Up LSP (Language Server Protocol) LSP enables features like code completion and linting. Install LSP servers for your language:\n# Python sudo pacman -S python-lsp-server # C++ sudo pacman -S clang # JavaScript/TypeScript npm install -g typescript-language-server Then, enable LSP support in Neovim:\nlocal lspconfig = require(\u0026#34;lspconfig\u0026#34;) lspconfig.pyright.setup({}) -- Python lspconfig.ts_ls.setup({}) -- JavaScript/TypeScript lspconfig.clangd.setup({}) -- C++ Restart Neovim and check LSP status:\n:LspInfo 7. Enhancing Auto-Completion with nvim-cmp To enable code auto-completion, update your init.lua:\nlocal cmp = require\u0026#39;cmp\u0026#39; cmp.setup({ mapping = { [\u0026#39;\u0026lt;C-Space\u0026gt;\u0026#39;] = cmp.mapping.complete(), [\u0026#39;\u0026lt;CR\u0026gt;\u0026#39;] = cmp.mapping.confirm({ select = true }), }, sources = { { name = \u0026#39;nvim_lsp\u0026#39; }, { name = \u0026#39;buffer\u0026#39; }, { name = \u0026#39;path\u0026#39; }, { name = \u0026#39;luasnip\u0026#39; }, { name = \u0026#39;nvim_lua\u0026#39; }, } }) 9. Final Thoughts Congratulations! You now have a powerful, customized Neovim setup that functions as a full-fledged IDE. With features like Treesitter, LSP support, auto-completion, syntax highlighting, Git integration, and a file explorer, your development workflow will be much smoother.\nIf you’d like to further improve your Neovim experience, explore more plugins and tweak your settings. Good luck with that!\nFurther Reading Neovim Documentation Awesome Neovim Plugins Arch Wiki: Neovim ","permalink":"http://localhost:1313/posts/setting-up-neovim-on-arch-linux-a-beginners-guide/","summary":"\u003ch1 id=\"setting-up-neovim-an-easy-and-beginners-guide\"\u003eSetting Up Neovim: An Easy and Beginner\u0026rsquo;s Guide\u003c/h1\u003e\n\u003cp\u003eNeovim is a modern and extensible text editor that enhances Vim’s capabilities. If you\u0026rsquo;re using Linux, setting up Neovim can be a rewarding experience, allowing you to customize it for an efficient workflow. In this guide, we\u0026rsquo;ll cover installing Neovim, setting up a basic configuration, and enhancing it with essential plugins to turn it into a full-fledged IDE.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"1-installing-neovim\"\u003e\u003cstrong\u003e1. Installing Neovim\u003c/strong\u003e\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003esudo pacman -S neovim\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003chr\u003e\n\u003ch2 id=\"2-setting-up-neovim-configuration\"\u003e\u003cstrong\u003e2. Setting Up Neovim Configuration\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003eNeovim’s configuration is stored in \u003ccode\u003e~/.config/nvim/\u003c/code\u003e. Create the directory and initialize a basic configuration:\u003c/p\u003e","title":"Setting Up Neovim: A Beginner's Guide"},{"content":"Linux Kernal The majority of the kernel\u0026rsquo;s code is written in C, leveraging extensions provided by the GNU Compiler Collection (GCC) beyond standard C. Additionally, it includes assembly code for architecture-specific functions, such as optimizing memory usage and task execution. Architecturally, the Linux kernel is monolithic, meaning the entire OS operates within kernel space. However, it features a modular design, allowing software components to be integrated as modules, including dynamic loading.\nWhat Is A Kernel Module? A Linux kernel module is precisely defined as a code segment capable of dynamic loading and unloading within the kernel as needed. These modules enhance kernel capabilities without necessitating a system reboot. A notable example is seen in the device driver module, which facilitates kernel interaction with hardware components linked to the system.\nWriting a Custom Linux Kernel Module Linux kernel modules (LKMs) allow developers to extend the functionality of the Linux kernel without modifying its source code. This guide walks through writing a simple kernel module from scratch. Kernel modules are pieces of code that can be dynamically loaded and unloaded from the Linux kernel at runtime. They enable functionality such as device drivers, file system support, and system call extensions without requiring a kernel recompilation. LKMs are particularly useful for developing hardware drivers and testing new kernel features without rebooting the system.\nPrerequisites Ensure you have the necessary development tools installed. On an Arch Linux system, install them with:\nsudo pacman -Syu linux-headers base-devel Creating a Simple Kernel Module 1. Writing the Module Source Code Create a file named hello_module.c:\n#include \u0026lt;linux/module.h\u0026gt; #include \u0026lt;linux/kernel.h\u0026gt; #include \u0026lt;linux/init.h\u0026gt; MODULE_LICENSE(\u0026#34;GPL\u0026#34;); MODULE_AUTHOR(\u0026#34;Your Name\u0026#34;); MODULE_DESCRIPTION(\u0026#34;A simple Hello World kernel module\u0026#34;); static int __init hello_init(void) { printk(KERN_INFO \u0026#34;Hello, Kernel!\\n\u0026#34;); return 0; } static void __exit hello_exit(void) { printk(KERN_INFO \u0026#34;Goodbye, Kernel!\\n\u0026#34;); } module_init(hello_init); module_exit(hello_exit); Understanding the Kernel Module Code #include \u0026lt;linux/module.h\u0026gt;: Includes the necessary module macros and functions. #include \u0026lt;linux/kernel.h\u0026gt;: Provides kernel logging functions. #include \u0026lt;linux/init.h\u0026gt;: Defines initialization and cleanup macros. MODULE_LICENSE(\u0026quot;GPL\u0026quot;): Specifies the module\u0026rsquo;s license. MODULE_AUTHOR(\u0026quot;Your Name\u0026quot;): Specifies the author of the module. MODULE_DESCRIPTION(\u0026quot;A simple Hello World kernel module\u0026quot;): Provides a brief description. static int __init hello_init(void): The function executed when the module is loaded. static void __exit hello_exit(void): The function executed when the module is unloaded. module_init(hello_init): Registers hello_init as the module\u0026rsquo;s initialization function. module_exit(hello_exit): Registers hello_exit as the module\u0026rsquo;s cleanup function. 2. Writing the Makefile Create a Makefile in the same directory:\nobj-m += hello_module.o all: make -C /lib/modules/$(shell uname -r)/build M=$(PWD) modules clean: make -C /lib/modules/$(shell uname -r)/build M=$(PWD) clean Understanding the Makefile obj-m += hello_module.o: Specifies that hello_module.o is the object to be built as a module. all:: Defines the build target. make -C /lib/modules/$(shell uname -r)/build M=$(PWD) modules: Directs the kernel build system to compile the module. clean:: Cleans up the generated files. make -C /lib/modules/$(shell uname -r)/build M=$(PWD) clean: Cleans the build artifacts. 3. Compiling the Module Run:\nmake 4. Loading and Unloading the Module To insert the module into the kernel:\nsudo insmod hello_module.ko Check the kernel log:\ndmesg | tail To remove the module:\nsudo rmmod hello_module 5. Verifying the Module List loaded modules:\nlsmod | grep hello_module Understanding the Generated Files After building the module, several files are generated:\nhello_module.c: The source code of the module. hello_module.ko: The compiled kernel module file, ready to be loaded into the kernel. hello_module.o: An intermediate object file generated during compilation. hello_module.mod.c: An automatically generated file containing module metadata. hello_module.mod.o: An object file containing metadata compiled from hello_module.mod.c. hello_module.mod: Another metadata file required for module loading. Makefile: Contains instructions for building the module. Module.symvers: Stores information about exported symbols, useful for module dependencies. modules.order: Lists the order in which modules should be loaded. Conclusion This simple kernel module demonstrates the basics of module development. You can expand upon this by adding functionality such as handling parameters or interacting with hardware.\nHappy kernel hacking!\n","permalink":"http://localhost:1313/posts/how-to-write-a-custom-kernel-module/","summary":"\u003ch1 id=\"linux-kernal\"\u003eLinux Kernal\u003c/h1\u003e\n\u003cp\u003eThe majority of the kernel\u0026rsquo;s code is written in C, leveraging extensions provided by the GNU Compiler Collection (GCC) beyond standard C. Additionally, it includes assembly code for architecture-specific functions, such as optimizing memory usage and task execution. Architecturally, the Linux kernel is monolithic, meaning the entire OS operates within kernel space. However, it features a modular design, allowing software components to be integrated as modules, including dynamic loading.\u003c/p\u003e","title":"How to Write a Custom Kernel Module"},{"content":"What is it? gh is GitHub\u0026rsquo;s official command-line tool designed to extend Git\u0026rsquo;s functionality with GitHub-specific features.\nPurpose: Simplifies interaction with GitHub\u0026rsquo;s ecosystem directly from the terminal. Allows you to manage repositories and use GitHub features like issues, pull requests, and workflows.\nKey Features: GitHub-specific tasks:\nAuthentication: Easier login (gh auth login) without dealing with tokens manually. Repository Management: Create, fork, or clone repositories. Issues \u0026amp; Pull Requests: Manage issues, PRs, and comments directly. Actions: Manage and view GitHub Actions workflows. Works alongside Git for basic version control tasks. Use Case: Best for developers heavily using GitHub and its features (for example: pull requests, issues, and actions).\nHow it works Install gh:\n\u0026gt; yay -S github-cli Verify the installation:\n\u0026gt; gh --version Login with GitHub CLI (gh)\n\u0026gt; gh auth login Follow the interactive prompts to log in:\nChoose HTTPS or SSH for connection. Log in via a browser using a one-time code or SSH keys. Verify authentication:\n\u0026gt; gh auth status What\u0026rsquo;s best about it that you can install and use both Git and gh (GitHub CLI) seamlessly. Here\u0026rsquo;s how to set them up:\nInstall Git\n\u0026gt;sudo pacman -S git Check the installation:\n\u0026gt; git --version Using Git and gh Together You can now: Use Git for version control:\n\u0026gt; git clone https://github.com/username/repo.git \u0026gt; git add . \u0026gt; git commit -m \u0026quot;message\u0026quot; \u0026gt; git push ","permalink":"http://localhost:1313/posts/github-cli-githubs-official-command-line-tools/","summary":"\u003ch2 id=\"what-is-it\"\u003eWhat is it?\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003egh\u003c/strong\u003e is GitHub\u0026rsquo;s official command-line tool designed to extend Git\u0026rsquo;s functionality with GitHub-specific features.\u003c/p\u003e\n\u003ch2 id=\"purpose\"\u003ePurpose:\u003c/h2\u003e\n\u003cp\u003eSimplifies interaction with GitHub\u0026rsquo;s ecosystem directly from the terminal. Allows you to manage repositories and use GitHub features like issues, pull requests, and workflows.\u003c/p\u003e\n\u003ch2 id=\"key-features\"\u003eKey Features:\u003c/h2\u003e\n\u003cp\u003eGitHub-specific tasks:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAuthentication: Easier login (gh auth login) without dealing with tokens manually.\u003c/li\u003e\n\u003cli\u003eRepository Management: Create, fork, or clone repositories.\u003c/li\u003e\n\u003cli\u003eIssues \u0026amp; Pull Requests: Manage issues, PRs, and comments directly.\u003c/li\u003e\n\u003cli\u003eActions: Manage and view GitHub Actions workflows.\u003c/li\u003e\n\u003cli\u003eWorks alongside Git for basic version control tasks.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"use-case\"\u003eUse Case:\u003c/h2\u003e\n\u003cp\u003eBest for developers heavily using GitHub and its features (for example: pull requests, issues, and actions).\u003c/p\u003e","title":"GitHub CLI: GitHub's Official Command Line Tools"},{"content":"Connecting a Raspberry Pi 5 to a USB TTY cable is a common way to interact with it through a serial connection, especially for debugging or setting up the device without using a display.\nPrerequists\nRaspberry Pi 5. USB TTY (serial) cable. Computer with a terminal emulator (minicom/screen). GPIO pinout diagram of Raspberry Pi 5 (for reference). Power source for Raspberry Pi (optional if USB TTY can power it, though not recommended). Before Starting! Issuse with firmware UART does NOT work on the RPI5 from the factory. We will need a firmware update to fix this that prevents the dtoverlays for UARTs from working.\nInstall rpi-update with the following commands:\n\u0026gt; sudo curl -L --output /usr/bin/rpi-update https://raw.githubusercontent.com/Hexxeh/rpi-update/master/rpi-update \u0026amp;\u0026amp; sudo chmod +x /usr/bin/rpi-update Then update the firmware on your RPI5 with:\n\u0026gt; sudo rpi-update Enable UART To manually configure UART, you can edit the config.txt file.\nEdit /boot/firmware/config.txt and add:\n\u0026gt; enable_uart=1 How to Connect Locate the GPIO Pins Find the GPIO header on the Raspberry Pi 5. Identify the following pins: GND (Ground): Usually black wire on the USB TTY cable. TX (Transmit): Sends data from the Pi to the computer. RX (Receive): Receives data from the computer to the Pi.\nUse a GPIO pinout chart to locate these pins. For Raspberry Pi 5, it will likely be similar to previous models. Making connections You will need to connect:\nGND with Ground - Pin# 06 TX with GPIO14 - Pin# 08 RX with GPIO15 - Pin# 10 Plug the USB TTY Cable into the Computer\nInsert the USB end of the TTY cable into your computer. The cable will create a virtual COM port (e.g /dev/ttyUSB0). Configure and Access Serial Console\nOpen a terminal.\nIdentify the port with:\n\u0026gt; ls /dev/ttyUSB* Use a terminal emulator like screen or minicom to connect:\n\u0026gt; screen /dev/ttyUSB0 115200 *Replace /dev/ttyUSB0 with the actual port name.\nTurn on the Raspberry Pi. If everything is set up correctly, you should see boot messages in the terminal. Log in to the Pi using the default username (pi) and password (raspberry), or your custom credentials. You should see something similar to this.\nThis is it! You have done it. Congrats!\n","permalink":"http://localhost:1313/posts/how-to-connect-a-raspberry-pi-5-to-usb-tty-cable/","summary":"\u003cp\u003eConnecting a Raspberry Pi 5 to a USB TTY cable is a common way to interact with it through a serial connection, especially for debugging or setting up the device without using a display.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003ePrerequists\u003c/strong\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eRaspberry Pi 5.\u003c/li\u003e\n\u003cli\u003eUSB TTY (serial) cable.\u003c/li\u003e\n\u003cli\u003eComputer with a terminal emulator (minicom/screen).\u003c/li\u003e\n\u003cli\u003eGPIO pinout diagram of Raspberry Pi 5 (for reference).\u003c/li\u003e\n\u003cli\u003ePower source for Raspberry Pi (optional if USB TTY can power it, though not recommended).\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"before-starting\"\u003e\u003cstrong\u003eBefore Starting!\u003c/strong\u003e\u003c/h3\u003e\n\u003ch3 id=\"issuse-with-firmware\"\u003e\u003cstrong\u003e\u003ca href=\"https://forums.raspberrypi.com/viewtopic.php?t=361397#p2171244\"\u003eIssuse with firmware\u003c/a\u003e\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003eUART does NOT work on the RPI5 from the factory. We will need a firmware update to fix this that prevents the dtoverlays for UARTs from working.\u003c/p\u003e","title":"How to Connect a Raspberry PI 5 to USB TTY Cable"},{"content":"Hosting a website on GitHub Pages with Hugo involves the following steps:\nCreating a website 1. Install Hugo and git\n\u0026gt; sudo pacman -S Hugo 2. Create a new Hugo site\n\u0026gt; hugo new site your-website 3. Add a Theme\nNavigate to your website directory and add a theme. You can choose one from the Hugo Themes .\n\u0026gt; cd your-website \u0026gt; git init \u0026gt; git submodule add https://github.com/adityatelange/hugo-PaperMod.git themes/hugo-PaperMod Now you will need to update the hugo.toml file for them to take effect. To do so you can either echo or addd it in the file.\n\u0026gt; echo \u0026quot;theme = 'hugo-PaperMod'\u0026quot; \u0026gt;\u0026gt; hugo.toml To view the website you can run it locally using Hugo\u0026rsquo;s development server to view the site. You can add -D to see your drafts.\n\u0026gt; hugo server 3. Add Content\nTo add a new page to your site.\n\u0026gt; hugo new content content/posts/yout-first-post.md This is it You have done it. YAY!\nHosting it on GitHub 1. Create a GitHub repository.\nClick the + icon in the top-right corner of:\u0026gt; [!WARNING] the GitHub interface and select New repository. Enter a repository name: yourusername.github.io Click Create repository. 2. Add Files for Your website\nClone the repository locally using Git:\ngit clone https://github.com//.git\nAdd your static site files (generated by Hugo) to the repository. Commit and push the changes:\n\u0026gt; git add -A \u0026gt; git commit -s -m \u0026quot;Initial commit\u0026quot; \u0026gt; git push origin main 3. Configure the Repository for GitHub Pages\nGo to the Settings tab of your new repository. Scroll down to the Pages section. Settings \u0026gt; Pages. In the center of your screen you will see this: Build and development Change the Source to GitHub Actions. 4. Create a file named hugo.yaml in a directory named .github/workflows.\n\u0026gt; mkdir -p .github/workflows \u0026gt; cd ./github/workflows touch hugo.yaml 5. Add content in the YAML file.\n# Sample workflow for building and deploying a Hugo site to GitHub Pages name: Deploy Hugo site to Pages on: # Runs on pushes targeting the default branch push: branches: - main # Allows you to run this workflow manually from the Actions tab workflow_dispatch: # Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages permissions: contents: read pages: write id-token: write # Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued. # However, do NOT cancel in-progress runs as we want to allow these production deployments to complete. concurrency: group: \u0026#34;pages\u0026#34; cancel-in-progress: false # Default to bash defaults: run: shell: bash jobs: # Build job build: runs-on: ubuntu-latest env: HUGO_VERSION: 0.141.0 steps: - name: Install Hugo CLI run: | wget -O ${{ runner.temp }}/hugo.deb https://github.com/gohugoio/hugo/releases/download/v${HUGO_VERSION}/hugo_extended_${HUGO_VERSION}_linux-amd64.deb \\ \u0026amp;\u0026amp; sudo dpkg -i ${{ runner.temp }}/hugo.deb - name: Install Dart Sass run: sudo snap install dart-sass - name: Checkout uses: actions/checkout@v4 with: submodules: recursive fetch-depth: 0 - name: Setup Pages id: pages uses: actions/configure-pages@v5 - name: Install Node.js dependencies run: \u0026#34;[[ -f package-lock.json || -f npm-shrinkwrap.json ]] \u0026amp;\u0026amp; npm ci || true\u0026#34; - name: Build with Hugo env: HUGO_CACHEDIR: ${{ runner.temp }}/hugo_cache HUGO_ENVIRONMENT: production TZ: America/Los_Angeles run: | hugo \\ --gc \\ --minify \\ --baseURL \u0026#34;${{ steps.pages.outputs.base_url }}/\u0026#34; - name: Upload artifact uses: actions/upload-pages-artifact@v3 with: path: ./public # Deployment job deploy: environment: name: github-pages url: ${{ steps.deployment.outputs.page_url }} runs-on: ubuntu-latest needs: build steps: - name: Deploy to GitHub Pages id: deployment uses: actions/deploy-pages@v4 5. Commit and push your GitHub repository.\n\u0026gt;git add -A \u0026gt;git commit -m \u0026quot;Create hugo.yaml\u0026quot; \u0026gt;git push 6. Deployment status From GitHub’s main menu, choose Actions. When GitHub has finished building and deploying your site, the color of the status indicator will change to green.\nStep 5: Verify Your GitHub Pages Site\nThe site will be live at https://yourusername.github.io.\n","permalink":"http://localhost:1313/posts/hosting-a-website-on-github-pages-with-hugo/","summary":"\u003cp\u003eHosting a website on GitHub Pages with Hugo involves the following steps:\u003c/p\u003e\n\u003ch1 id=\"creating-a-website\"\u003eCreating a website\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e1. Install Hugo and git\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; sudo pacman -S Hugo\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e2. Create a new Hugo site\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; hugo new site your-website\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e3. Add a Theme\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eNavigate to your website directory and add a theme. You can choose one from the \u003ca href=\"https://themes.gohugo.io/\"\u003eHugo Themes\u003c/a\u003e .\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; cd your-website\n\u0026gt; git init \n\u0026gt; git submodule add https://github.com/adityatelange/hugo-PaperMod.git themes/hugo-PaperMod\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow you will need to update the hugo.toml file for them to take effect. To do so you can either \u003cem\u003eecho\u003c/em\u003e or addd it in the file.\u003c/p\u003e","title":"Hosting a Website on Github Pages With Hugo"},{"content":"KVM Kernel-based Virtual Machine is a free and open-source virtualization module in the Linux kernel that allows the kernel to function as a hypervisor.\nInstallation For updates, run the following command:\n$ sudo pacman -Syu QEMU/KVM installation: We\u0026rsquo;ll install qemu and all the utils required:\n$ sudo pacman -S qemu vde2 ebtables iptables-nft nftables dms masq bridge-utils ovmf swptm Virtual Machine Manager installation: The virt-manager application is a graphical user interface for managing virtual machines through libvirt. It primarily targets KVM VMs.\n$ sudo pacman -S virt-manager Now everything is set to work. We can move towards downloading archlinux .iso file.\nDownload .iso file: Head towards: https://archlinux.org/download/ Scroll through and look for the server closest to you. Download archlinux-2024.10.01-x86_64.iso file. Setting up: Open terminal and run the following command:\n$ virt-manager You will see an interface similar to this:\nClick on \u0026lsquo;create a new virtual machine\u0026rsquo; (option with star). Select \u0026lsquo;Local install media\u0026rsquo;. Browse to your \u0026lsquo;archlinux-2024.10.01-x86_64.iso\u0026rsquo;. Add your desired VM configuration and create a disk image. Boot Menu: You will be prompted to a boot menu.\nSelect the topmost option to start the installation process. Archlinux Installer: You will be prompted to a terminal. The first step is to check if you are connected to the internet.\nRun:\n# ip addr show If it shows an IP address and says \u0026lsquo;UP\u0026rsquo;, that means you are good to go.\nIf not: You will need to connect to the internet using the \u0026lsquo;iwctl\u0026rsquo; method for Wi-Fi.\n# iwctl To search networks in your vicinity:\n[iwd]# station [your_wifi_interface] get-networks Get the name of the network you want to connect to. Exit from this prompt using \u0026rsquo;exit\u0026rsquo;.\nTo connect to the desired Wi-Fi network, run:\n# iwctl --passphrase \u0026#34;[wifi_password]\u0026#34; station [your_wifi_interface] connect [wifi_name] You can again run ip addr show to check if you are connected to the network.\nNow you can run the installation command. We\u0026rsquo;ll be using the archinstall method.\n# archinstall You will be prompted to an interface similar to this:\nWe will install Arch using this interface. Go through each option:\nArchinstall language: Choose your preferred language. Mirrors: Select the mirror region closest to you. Use \u0026lsquo;/\u0026rsquo; to search. Locales: Set language and keyboard layout. Disk configuration: Choose Best-effort default partition to format the system. Bootloader: Use the default \u0026lsquo;Grub\u0026rsquo; option. Swap: Select Swap on zram (default). Hostname: Leave as it is. Root password: Set the password for sudo/root privileges. User account: Set up a user account. Profile: Select Desktop. It includes essential packages. Others include Minimal, Server, and Xorg. In Desktop, select your desktop environment. We\u0026rsquo;ll use Gnome for simplicity.\nAudio: Use PipeWire (default) or PulseAudio. Kernels: Use the linux kernel. Additional packages: Install any required packages. Network Configuration: Use NetworkManager for a GUI in Gnome. Timezone: Set the timezone closest to you and enable time sync. Press Install. Congratulations! You\u0026rsquo;ve successfully installed Arch Linux.\n","permalink":"http://localhost:1313/posts/arch_kvm/","summary":"\u003ch1 id=\"kvm\"\u003eKVM\u003c/h1\u003e\n\u003cp\u003eKernel-based Virtual Machine is a free and open-source virtualization module in the Linux kernel that allows the kernel to function as a hypervisor.\u003c/p\u003e\n\u003ch2 id=\"installation\"\u003eInstallation\u003c/h2\u003e\n\u003cp\u003eFor updates, run the following command:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ sudo pacman -Syu\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"qemukvm-installation\"\u003eQEMU/KVM installation:\u003c/h3\u003e\n\u003cp\u003eWe\u0026rsquo;ll install qemu and all the utils required:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ sudo pacman -S qemu vde2 ebtables iptables-nft nftables dms masq bridge-utils ovmf swptm\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"virtual-machine-manager-installation\"\u003eVirtual Machine Manager installation:\u003c/h3\u003e\n\u003cp\u003eThe virt-manager application is a graphical user interface for managing virtual machines through libvirt. It primarily targets KVM VMs.\u003c/p\u003e","title":"archlinux installation in hypervisor through QEMU/KVM"},{"content":"","permalink":"http://localhost:1313/posts/github-cli-githubs-official-command-line-tool/","summary":"","title":""},{"content":"1. Introduction Sometimes you need to share a local application with the outside world — maybe to demo your project, test a webhook, or allow a teammate to access your development server.\nNormally, you’d need a public IP, port forwarding, or a cloud server. ngrok removes all that complexity by creating a secure tunnel from the internet directly to your machine, giving you a public URL instantly.\nIn this guide, we’ll walk through:\nInstalling ngrok on popular Linux distributions Authenticating your installation Exposing a local service to the internet Adding basic security Practical examples for real-world usage 2. Prerequisites Before we begin, make sure you have:\nA terminal A free ngrok account (for authentication token) A running local service (e.g., a Python HTTP server, web app, or API) 3. Installing ngrok on Linux We’ll cover installation for Arch Linux, Debian/Ubuntu, and Fedora.\n3.1 Arch Linux This package is not in the official repos, install it from the AUR:\nyay -S ngrok 3.2 Debian / Ubuntu sudo apt update sudo apt install snapd sudo snap install ngrok Alternatively, download the binary from the ngrok downloads page.\n3.3 Fedora sudo dnf install snapd sudo ln -s /var/lib/snapd/snap /snap sudo snap install ngrok 4. Authenticating ngrok Once installed, you need to connect it to your account so you can use custom domains, longer session times, and access the dashboard.\nSign in to ngrok dashboard. -\u0026gt; Your AuthToken Copy your AuthToken. Run: ngrok config add-authtoken \u0026lt;YOUR_TOKEN\u0026gt; You will see: Authtoken saved to configuration file: ~/.config/ngrok/ngrok.yml 5. Exposing a Local Service For example, if your local web server is running on port 8080:\nngrok http 8080 You’ll see output like:\nNow you can share the HTTPS URL with anyone.\n6. Adding Basic Security You can protect your tunnel with a simple username and password:\nngrok http --basic-auth=\u0026#34;user:password\u0026#34; 8080 Anyone visiting the public link will need credentials.\n7. Common Use Cases Webhook testing — Connect services like GitHub, Stripe, or Twilio to your local environment. Temporary demos — Share work-in-progress with clients without deployment. Remote device access — SSH into a Raspberry Pi without changing router settings. 8. Conclusion In just a few commands, you’ve learned how to:\nInstall ngrok on popular Linux distros Authenticate your installation Share a local service securely From here, you can explore ngrok’s advanced features like static domains, IP allowlists, and traffic inspection.\n","permalink":"http://localhost:1313/posts/ngrok/","summary":"\u003ch2 id=\"1-introduction\"\u003e1. Introduction\u003c/h2\u003e\n\u003cp\u003eSometimes you need to share a local application with the outside world — maybe to demo your project, test a webhook, or allow a teammate to access your development server.\u003c/p\u003e\n\u003cp\u003eNormally, you’d need a public IP, port forwarding, or a cloud server. \u003cstrong\u003engrok\u003c/strong\u003e removes all that complexity by creating a \u003cstrong\u003esecure tunnel\u003c/strong\u003e from the internet directly to your machine, giving you a public URL instantly.\u003c/p\u003e\n\u003cp\u003eIn this guide, we’ll walk through:\u003c/p\u003e","title":"Ngrok: Expose Localhost to the Internet"},{"content":"Creating a WhatsApp AI Assistant Using n8n: A Step-by-Step Guide Build your own AI-powered WhatsApp chatbot using n8n, WhatsApp Business Cloud API, and OpenAI. This guide walks you through every step—from setup to testing—with real-world error handling, solutions, and an example production-ready workflow.\n1. Introduction Want to chat with an AI on WhatsApp? In this tutorial, you\u0026rsquo;ll learn how to build a WhatsApp AI Assistant using:\nn8n (automation tool) WhatsApp Business Cloud API OpenAI (for generating intelligent replies) By the end, you\u0026rsquo;ll have a working chatbot and gain hands-on experience with APIs, webhooks, and automation.\n2. Prerequisites n8n account (Cloud or self-hosted) Meta Developer account with WhatsApp Business Cloud API access OpenAI API key Basic understanding of APIs and webhook workflows 3. Registering Your WhatsApp Business App A. Create WhatsApp App in Meta Developer Visit Meta for Developers Create a new app: choose Business → WhatsApp Link or create a WhatsApp Business Account B. Obtain Testing Credentials Your app dashboard will show:\nTest phone number Phone Number ID Temporary access token (valid for only 24 hours) Tip: For long-term use, generate a 60-day system-user token later.\nC. Add Recipients to Test List By default, only approved numbers can receive messages:\nNavigate to WhatsApp → API Setup Add numbers in E.164 format (e.g., +923001234567) Users must accept the invite via WhatsApp to become valid recipients 4. Configuring Your Webhook in n8n A. Create a Webhook Node Method: GET (for initial verification) Endpoint example: https://yourname.app.n8n.cloud/webhook/your-unique-id/webhook B. Verify the Webhook with Meta In your app’s Webhook section:\nCallback URL: your n8n webhook URL Verify Token: any secret string you choose (e.g., mySecret2025) C. Echo Back Meta’s Challenge Configure n8n\u0026rsquo;s Webhook node response:\nField Value Response Mode On Received Response Body {{$json[\u0026quot;query\u0026quot;][\u0026quot;hub.challenge\u0026quot;]}} This ensures Meta can verify your endpoint successfully.\n5. Processing Incoming Messages WhatsApp sends JSON data with structure like:\n{ \u0026#34;entry\u0026#34;: [ { \u0026#34;changes\u0026#34;: [ { \u0026#34;value\u0026#34;: { \u0026#34;messages\u0026#34;: [ { \u0026#34;from\u0026#34;: \u0026#34;923001234567\u0026#34;, \u0026#34;text\u0026#34;: { \u0026#34;body\u0026#34;: \u0026#34;Hello bot!\u0026#34; } } ], \u0026#34;metadata\u0026#34;: { \u0026#34;phone_number_id\u0026#34;: \u0026#34;698352170035199\u0026#34; } } } ] } ] } Extract:\nfrom: user’s number text.body: user’s text metadata.phone_number_id: correct sender ID 6. Integrating OpenAI for Responses Obtaining Your OpenAI API Key Before integrating OpenAI into your n8n workflow, you’ll need to get an API key from OpenAI.\nStep-by-Step: Sign up or log in to OpenAI. Navigate to your API Keys page. Click \u0026ldquo;Create new secret key\u0026rdquo;. Optionally name your key, then copy it immediately (you won’t be able to view it again). In n8n: Go to Credentials → Add New → choose OpenAI or HTTP Request. Paste your API key into the key field. Save the credentials. Security Tip: Keep your key private. Do not share it or commit it to public repositories.\nUse an HTTP Request node to call OpenAI:\nPOST https://api.openai.com/v1/chat/completions Authorization: Bearer YOUR_OPENAI_API_KEY Content-Type: application/json { \u0026#34;model\u0026#34;: \u0026#34;gpt-4o-mini\u0026#34;, \u0026#34;messages\u0026#34;: [ { \u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;You are a helpful WhatsApp AI assistant.\u0026#34; }, { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;{{ $json[...] }}\u0026#34; } ] } Replace {{ $json[...] }} with the actual path to the user\u0026rsquo;s message text from the Webhook node.\n7. Sending Replies via WhatsApp Use another HTTP Request node to respond:\nPOST https://graph.facebook.com/v21.0/{{ $json[...] }}/messages Authorization: Bearer YOUR_LONG_LIVED_TOKEN Content-Type: application/json { \u0026#34;messaging_product\u0026#34;: \u0026#34;whatsapp\u0026#34;, \u0026#34;to\u0026#34;: \u0026#34;{{ $json[...] }}\u0026#34;, \u0026#34;text\u0026#34;: { \u0026#34;body\u0026#34;: \u0026#34;{{ $node[\u0026#39;OpenAI Response\u0026#39;].json.choices[0].message.content }}\u0026#34; } } Use the metadata’s phone_number_id for the endpoint and from for the recipient. This avoids hardcoding and ensures proper routing.\n8. Example n8n Workflow Here’s the actual n8n workflow I used for my WhatsApp AI assistant. It integrates a product brochure PDF into a vector store for AI-powered Q\u0026amp;A, and handles WhatsApp message flow.\nStep-by-Step Breakdown: 1. Download Product Brochure PDF Downloads the brochure from a given URL. Extracts text from the PDF. 2. Create Product Brochure Vector Store Splits large text into chunks. Generates embeddings using OpenAI. Saves them in a vector store for fast semantic search. 3. Use the WhatsApp Trigger Listens for incoming WhatsApp messages. Routes them to supported or unsupported handlers. 3a. Handle Unsupported Messages Replies with a friendly error if the message type is not text. 4. Sales AI Agent Responds Uses OpenAI with memory + vector store retrieval to answer based on brochure content. 5. Reply to WhatsApp User Sends the AI-generated message back to the sender. Why this is effective:\nContext-aware answers via buffer memory. Reduced hallucinations thanks to vector store grounding. Smooth error handling for unsupported message types. 9. Common Errors \u0026amp; Fixes Recipient phone number not in allowed list\n→ Add as test number or switch to Live mode\n401 – Session expired\n→ Refresh token via Graph API:\nGET https://graph.facebook.com/v21.0/oauth/access_token ?grant_type=fb_exchange_token \u0026amp;client_id=YOUR_APP_ID \u0026amp;client_secret=YOUR_APP_SECRET \u0026amp;fb_exchange_token=YOUR_CURRENT_TOKEN Webhook verification failed\n→ Ensure verify token matches between Meta and n8n and echo hub.challenge\nNo execution data available\n→ Trigger workflow via actual WhatsApp message, not manual run\n10. Going Live Add a Privacy Policy URL in Meta App → Settings → Basic (required for live access) Switch app to Live mode once all compliance items are met Remove restricted recipient list Use WhatsApp message templates for messages sent after 24 hours of user interaction 11. Conclusion \u0026amp; Next Steps Congrats! You now have a WhatsApp AI Assistant built with n8n and OpenAI.\nWhere to go from here: Wire up custom knowledge (PDFs, documents) Implement memory for conversation context Launch multilingual support Export n8n workflow as JSON for reuse Need help? Join the n8n Community Forum or OpenAI Discord to connect with fellow builders.\nHappy automating!\n","permalink":"http://localhost:1313/posts/creating-whatsapp-ai-assistant-using-n8n2/","summary":"\u003ch1 id=\"creating-a-whatsapp-ai-assistant-using-n8n-a-step-by-step-guide\"\u003eCreating a WhatsApp AI Assistant Using n8n: A Step-by-Step Guide\u003c/h1\u003e\n\u003cp\u003eBuild your own AI-powered WhatsApp chatbot using \u003cstrong\u003en8n\u003c/strong\u003e, \u003cstrong\u003eWhatsApp Business Cloud API\u003c/strong\u003e, and \u003cstrong\u003eOpenAI\u003c/strong\u003e. This guide walks you through every step—from setup to testing—with real-world error handling, solutions, and an example production-ready workflow.\u003c/p\u003e\n\u003ch2 id=\"1-introduction\"\u003e1. Introduction\u003c/h2\u003e\n\u003cp\u003eWant to chat with an AI on WhatsApp? In this tutorial, you\u0026rsquo;ll learn how to build a \u003cstrong\u003eWhatsApp AI Assistant\u003c/strong\u003e using:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003en8n\u003c/strong\u003e (automation tool)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eWhatsApp Business Cloud API\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eOpenAI\u003c/strong\u003e (for generating intelligent replies)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eBy the end, you\u0026rsquo;ll have a working chatbot and gain hands-on experience with APIs, webhooks, and automation.\u003c/p\u003e","title":"Creating Whatsapp Ai Assistant Using N8n"},{"content":"Introduction A memory leak occurs when a program allocates memory dynamically (e.g., using malloc) and fails to release it using free. This leftover allocation can lead to wasted memory resources, eventually causing slowdowns or system crashes in long-running programs.\nValgrind is a powerful command-line tool available on Linux systems. It helps developers detect:\nMemory leaks Invalid memory access Uninitialized memory usage Mismatched memory management In this guide, we\u0026rsquo;ll walk through examples in C to learn how to detect and fix memory leaks using Valgrind.\nInstalling Valgrind On Arch Linux sudo pacman -S valgrind On Ubuntu/Debian sudo apt install valgrind On Fedora sudo dnf install valgrind Troubleshooting: Valgrind \u0026ldquo;cannot find mandatory redirection\u0026rdquo; on Arch Linux If you run Valgrind and get an error like:\nvalgrind: Fatal error at startup: a function redirection\nvalgrind: which is mandatory for this platform-tool combination\nvalgrind: cannot be set up.\n…you might be running a 32-bit executable on a 64-bit Arch Linux system.\nWhy this happens Valgrind needs to hook into low-level glibc functions from your binary’s architecture.\nIf your binary is 32-bit, Arch requires the 32-bit glibc runtime (lib32-glibc).\nWithout it, Valgrind can’t find the right function symbols and quits.\nFix Install the 32-bit glibc package:\nsudo pacman -S lib32-glibc After installation, re-run:\nvalgrind ./your-binary and it should work.\nUbuntu/Debian equivalent: sudo apt install libc6-dbg:i386\nBasic Example: Hello World Code #include \u0026lt;stdio.h\u0026gt; int main() { printf(\u0026#34;Hello World\\n\u0026#34;); return 0; } Compile and Run gcc main.c -o main.out ./main.out Run with Valgrind valgrind ./main.out You should see no errors or memory leaks in the output.\nIntroducing a Memory Leak Static Allocation (Safe) #include \u0026lt;stdio.h\u0026gt; int main() { char str[20] = \u0026#34;Hello\u0026#34;; printf(\u0026#34;%s\\n\u0026#34;, str); return 0; } This uses stack memory, so Valgrind will report no leaks.\nDynamic Allocation (With Leak) #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; int main() { char *str = malloc(20); strcpy(str, \u0026#34;Hello\u0026#34;); printf(\u0026#34;%s\\n\u0026#34;, str); return 0; // Forgot to free memory } Valgrind Output valgrind ./main.out You should see:\ndefinitely lost: 20 bytes in 1 blocks\nFixing the Memory Leak Add free(str); before returning:\nfree(str); Fixed Code #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; int main() { char *str = malloc(20); strcpy(str, \u0026#34;Hello\u0026#34;); printf(\u0026#34;%s\\n\u0026#34;, str); free(str); return 0; } Detailed Valgrind Options Use for deeper analysis:\nvalgrind --leak-check=full ./main.out Or even more detailed:\nvalgrind --leak-check=full --show-leak-kinds=all --track-origins=yes ./main.out Explanation:\n--leak-check=full: Display detailed leak info --show-leak-kinds=all: Show all kinds of leaks (definitely, indirectly lost, etc.) --track-origins=yes: Show where uninitialized values originate Summary Always free() memory allocated with malloc(), calloc(), or realloc(). Close all file streams with fclose(). Use Valgrind to identify and fix: Memory leaks Invalid memory writes Use-after-free bugs Recommended command: valgrind --leak-check=full --track-origins=yes ./your_program Valgrind is a critical tool for writing safe, efficient, and bug-free C programs.\n","permalink":"http://localhost:1313/posts/introductiontovalgrind/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eA \u003cstrong\u003ememory leak\u003c/strong\u003e occurs when a program allocates memory dynamically (e.g., using \u003ccode\u003emalloc\u003c/code\u003e) and fails to release it using \u003ccode\u003efree\u003c/code\u003e. This leftover allocation can lead to wasted memory resources, eventually causing slowdowns or system crashes in long-running programs.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eValgrind\u003c/strong\u003e is a powerful command-line tool available on Linux systems. It helps developers detect:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eMemory leaks\u003c/li\u003e\n\u003cli\u003eInvalid memory access\u003c/li\u003e\n\u003cli\u003eUninitialized memory usage\u003c/li\u003e\n\u003cli\u003eMismatched memory management\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIn this guide, we\u0026rsquo;ll walk through examples in C to learn how to detect and fix memory leaks using Valgrind.\u003c/p\u003e","title":"Detecting and Fixing Memory Leaks with Valgrind"},{"content":"QEMU-KVM on Arch Linux: Running Tiny Core Linux in a Lightweight VM Virtualization is a powerful tool for developers, sysadmins, and tinkerers alike. On Linux, QEMU-KVM stands out as a robust, high-performance virtualization stack. In this blog, well walk through setting up QEMU-KVM on Arch Linux and using it to run Tiny Core Linuxa super-lightweight distro perfect for testing and experimentation.\nWhat is QEMU-KVM QEMU (Quick Emulator) is a generic and open-source machine emulator. On its own, it can emulate various hardware systems. However, when paired with **KVM (Kernel-based Virtual Machine)**a Linux kernel module for virtualizationit can run virtual machines with near-native performance.\nQEMU provides device emulation and user-space management. KVM integrates with the Linux kernel and handles hardware-level virtualization. Together, they effectively form a Type 1 hypervisor because the Linux kernel (with KVM) handles core virtualization tasks directly on hardware.\nStep-by-Step: Installing QEMU-KVM on Arch Linux Step 1: Install Required Packages sudo pacman -Syu sudo pacman -S qemu virt-manager virt-viewer dnsmasq vde2 bridge-utils openbsd-netcat libvirt edk2-ovmf edk2-ovmf is for UEFI firmware support in VMs.\nStep 2: Enable and Start libvirtd sudo systemctl enable --now libvirtd.service Step 3: Add Your User to the libvirt Group sudo usermod -aG libvirt (whoami) newgrp libvirt Step 4: Verify KVM Support lsmod grep kvm And check CPU virtualization support:\negrep -c (vmxsvm) /proc/cpuinfo A value of 1 or more indicates virtualization support.\nExample: Running Tiny Core Linux on QEMU-KVM Now that your system is ready, lets run Tiny Core Linux, a minimalist Linux distro thats only 16MB\nStep 1: Download Tiny Core ISO wget http://tinycorelinux.net/14.x/x86/release/Core-current.iso Or visit http://tinycorelinux.net for the latest release.\nStep 2: Create a Virtual Disk (Optional) qemu-img create -f qcow2 tinycore.qcow2 512M This creates a 512MB disk image. Optional for RAM-only usage.\nStep 3: Launch the VM with KVM Acceleration qemu-system-x86_64 -enable-kvm -m 512 -cpu host -smp 1 -cdrom Core-current.iso -hda tinycore.qcow2 -boot d -net nic -net user -vga virtio -display sdl Key Flags Explained:\n-enable-kvm: Enables KVM hardware acceleration -m 512: Allocates 512MB RAM -cpu host: Uses the host CPU features -cdrom: Points to the Tiny Core ISO -hda: Uses a QCOW2 disk image -boot d: Boots from CD first -net user: Enables simple user-mode networking (e.g., for internet access) -display sdl: Uses SDL window for graphics (you can replace with gtk or virt-manager) Alternate: Boot Tiny Core in RAM Without Disk qemu-system-x86_64 -enable-kvm -m 256 -cdrom Core-current.iso -boot d -net nic -net user -vga std Conclusion With QEMU-KVM, Arch Linux becomes a full-featured Type 1 hypervisor. By combining kernel-level virtualization (KVM) with the flexibility of QEMU, you get a fast, customizable virtualization platform. Running Tiny Core Linux showcases just how lightweight and efficient this setup can be.\nWhether youre building VMs for testing, learning Linux internals, or experimenting with custom environments, QEMU-KVM on Arch is a powerful combination.\nHappy virtualizing\n","permalink":"http://localhost:1313/posts/qemu/","summary":"\u003ch1 id=\"qemu-kvm-on-arch-linux-running-tiny-core-linux-in-a-lightweight-vm\"\u003eQEMU-KVM on Arch Linux: Running Tiny Core Linux in a Lightweight VM\u003c/h1\u003e\n\u003cp\u003eVirtualization is a powerful tool for developers, sysadmins, and tinkerers alike. On Linux, \u003cstrong\u003eQEMU-KVM\u003c/strong\u003e stands out as a robust, high-performance virtualization stack. In this blog, well walk through setting up QEMU-KVM on \u003cstrong\u003eArch Linux\u003c/strong\u003e and using it to run \u003cstrong\u003eTiny Core Linux\u003c/strong\u003ea super-lightweight distro perfect for testing and experimentation.\u003c/p\u003e\n\u003ch2 id=\"what-is-qemu-kvm\"\u003eWhat is QEMU-KVM\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eQEMU (Quick Emulator)\u003c/strong\u003e is a generic and open-source machine emulator. On its own, it can emulate various hardware systems. However, when paired with **KVM (Kernel-based Virtual Machine)**a Linux kernel module for virtualizationit can run virtual machines with near-native performance.\u003c/p\u003e","title":"QEMU-KVM on Arch Linux: Running Tiny Core Linux in a Lightweight VM"},{"content":"Building the Linux Kernel Compiling the Linux Kernel involves multiple steps and can take some time depending on your hardware specifications.\nStep 1: Download the Kernel Source Code Start by visiting the Official Linux Kernel Website and downloading the latest available kernel source code. The downloaded file will be a compressed archive containing all necessary source files.\nStep 2: Extract the Source Code Once the download completes, extract the contents of the compressed archive using the tar command:\ntar xvf linux-6.13.tar.xz If the tar utility is not installed on your system, you can install it using:\nsudo pacman -S tar Note: Always ensure you are using the correct version number in the file name.\nStep 3: Install Required Dependencies To compile the kernel, you need to install various development tools and libraries. Install them using the following command:\nsudo pacman -S git fakeroot ncurses xz bc flex bison base-devel kmod cpio perl binutils util-linux jfsutils e2fsprogs xfsprogs squashfs-tools quota-tools Step 4: Configure the Kernel Navigate into the kernel source directory: cd linux-6.13 Use your current system’s configuration as a base:\nIf zcat is available, run:\nzcat /proc/config.gz \u0026gt; .config Otherwise, use this alternative method:\ncp /proc/config.gz ./ gunzip config.gz mv config .config Customize the kernel using a menu-driven interface:\nmake menuconfig make xconfig make oldconfig Modify the .config file directly:\nOpen it with a text editor:\nsudo vim .config Search for the line:\nCONFIG_EXT4_FS=m And change it to:\nCONFIG_EXT4_FS=y Step 5: Compile the Kernel Determine the number of CPU cores available to speed up compilation: nproc Compile the kernel using the number of cores found above. Replace n with that number: make -j\u0026lt;n\u0026gt; If you encounter any errors during or after this step, back up your .config file and reset the source tree with:\nmake mrproper This command cleans the build environment and restores the source tree to its original state.\nStep 6: Install Kernel Modules Kernel modules are essential for extending the kernel’s functionality and ensuring compatibility with various hardware. Install them with:\nsudo make modules_install Step 7: Install the Kernel You can install the compiled kernel using one of the two methods below:\nAutomatic installation: sudo make install Manual installation (if the above doesn\u0026rsquo;t work):\nCopy the kernel image:\nsudo cp arch/x86/boot/bzImage /boot/vmlinuz-linux-custom Copy the System.map file:\nsudo cp System.map /boot/System.map-linux-custom Copy the kernel configuration file:\nsudo cp .config /boot/config-linux-custom Step 8: Update the Bootloader If you use GRUB, follow these steps to add an entry for your custom kernel:\nFind the UUID of your root partition: lsblk -f Open the custom GRUB configuration file: sudo nvim /etc/grub.d/40_custom Add the following entry (replace paste-your-root-partition-uuid-here with the actual UUID): menuentry \u0026#39;Custom Linux Kernel\u0026#39; { linux /boot/vmlinuz-linux-custom root=UUID=paste-your-root-partition-uuid-here initrd /boot/initramfs-linux.img } Step 9: Generate Initramfs As you\u0026rsquo;ve compiled a new kernel, installed modules, and modified boot entries, generating a new initramfs is necessary. Run:\nsudo mkinitcpio -k 6.13-custom -c /etc/mkinitcpio.conf -g /boot/initramfs-linux-custom.img Make sure the version (6.13-custom) matches your compiled kernel.\nStep 10: Update GRUB Configuration Finally, update the GRUB configuration so that it includes your new kernel entry:\nsudo grub-mkconfig -o /boot/grub/grub.cfg Done! Congratulations! You’ve successfully compiled and installed your custom Linux Kernel. Enjoy your personalized system!\n","permalink":"http://localhost:1313/posts/kernal_compilation/","summary":"\u003ch1 id=\"building-the-linux-kernel\"\u003eBuilding the Linux Kernel\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003eCompiling the Linux Kernel involves multiple steps and can take some time depending on your hardware specifications.\u003c/strong\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"step-1-download-the-kernel-source-code\"\u003eStep 1: Download the Kernel Source Code\u003c/h3\u003e\n\u003cp\u003eStart by visiting the \u003ca href=\"https://www.kernel.org/\"\u003eOfficial Linux Kernel Website\u003c/a\u003e and downloading the latest available kernel source code. The downloaded file will be a compressed archive containing all necessary source files.\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"step-2-extract-the-source-code\"\u003eStep 2: Extract the Source Code\u003c/h3\u003e\n\u003cp\u003eOnce the download completes, extract the contents of the compressed archive using the \u003ccode\u003etar\u003c/code\u003e command:\u003c/p\u003e","title":"How to build Linux Kernal: Step by Step Guide"},{"content":"Introduction So, you’ve built a sleek website with Hugo and deployed it to GitHub Pages. Now, you want to give it a professional touch with a custom domain like yourdomain.tech instead of the default username.github.io URL. This guide walks you through the process step-by-step.\nPrerequisites A Hugo website hosted on GitHub Pages (public repository). A custom domain (e.g., yourdomain.tech) purchased from a registrar like Namecheap, Google Domains, etc. Basic familiarity with DNS settings and GitHub repository configurations. Step 1: Configure Your GitHub Repository First, ensure your GitHub Pages site is set up correctly:\nYour repository should be named \u0026lt;username\u0026gt;.github.io (for user/organization sites) or \u0026lt;repo-name\u0026gt; (for project sites). The gh-pages branch (or the /docs folder) should contain your Hugo-generated static files. Step 2: Configure DNS Settings for Your Domain Option 1: Use an Apex Domain (e.g., yourdomain.tech) If you want your site to live at the root domain (e.g., yourdomain.tech), configure A records in your DNS settings:\nGo to your domain registrar’s DNS management page. Create four A records pointing to GitHub’s IP addresses: Host: @ Type: A Value: 185.199.108.153 TTL: Automatic ","permalink":"http://localhost:1313/posts/customdomain/","summary":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003eSo, you’ve built a sleek website with Hugo and deployed it to GitHub Pages. Now, you want to give it a professional touch with a custom domain like \u003ccode\u003eyourdomain.tech\u003c/code\u003e instead of the default \u003ccode\u003eusername.github.io\u003c/code\u003e URL. This guide walks you through the process step-by-step.\u003c/p\u003e\n\u003ch2 id=\"prerequisites\"\u003ePrerequisites\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003eA Hugo website hosted on GitHub Pages (public repository).\u003c/li\u003e\n\u003cli\u003eA custom domain (e.g., \u003ccode\u003eyourdomain.tech\u003c/code\u003e) purchased from a registrar like Namecheap, Google Domains, etc.\u003c/li\u003e\n\u003cli\u003eBasic familiarity with DNS settings and GitHub repository configurations.\u003c/li\u003e\n\u003c/ol\u003e\n\u003chr\u003e\n\u003ch2 id=\"step-1-configure-your-github-repository\"\u003eStep 1: Configure Your GitHub Repository\u003c/h2\u003e\n\u003cp\u003eFirst, ensure your GitHub Pages site is set up correctly:\u003c/p\u003e","title":"How to up custom domain for GitHub Pages"},{"content":"Exception handling is a crucial aspect of writing robust and reliable Python code. Whether you\u0026rsquo;re a beginner or an experienced developer, getting an error, or exception, in your Python program means the entire program will crash. You don’t want this to happen in real-world programs. Instead, you want the program to detect errors, handle them, and then continue to run. In this blog, we\u0026rsquo;ll explore the fundamentals of exception handling in Python, including syntax, best practices, and advanced techniques.\nWhat Are Exceptions? Exceptions are runtime errors that disrupt the normal flow of a program. For example, trying to open a non-existent file, dividing by zero, or accessing an invalid index in a list will raise exceptions. If unhandled, these exceptions cause your program to crash.\nBasic Syntax: try and except The primary mechanism for handling exceptions in Python is the try-except block. Errors can be handled with with this. The code that could potentially have an error is put in a try clause. The program execution moves to the start of a following except clause if an error happens.\nHere\u0026rsquo;s the basic structure:\ndef cal(value): try: return 10 / value except ZeroDivisionError: print(\u0026#34;Cannot divide by zero!\u0026#34;) print(cal(0)) print(cal(2)) print(cal(3)) How It Works: The code inside the try block is executed. If an exception occurs, Python checks the except blocks for a matching exception type. If a match is found, the corresponding except block runs. Catching Specific Exceptions Always catch specific exceptions to avoid silencing unexpected errors. Python has many built-in exceptions (e.g., ValueError, TypeError, FileNotFoundError).\nimport math x = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) try: print(f\u0026#39;Square Root of {x} is {math.sqrt(x)}\u0026#39;) except ValueError: print(\u0026#39;Number is less than 0\u0026#39;) Output\nThe else Clause The else block runs only if no exceptions were raised in the try block. Use it to separate \u0026ldquo;happy path\u0026rdquo; code from error handling.\nimport math def sqr(value): try: x = math.sqrt(value) except ValueError: print(\u0026#39;Number is less than 0\u0026#39;) else: print(f\u0026#39;The Answer is: {x}\u0026#39;) value = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) sqr(value) Output The finally Clause The finally block runs regardless of whether an exception occurred. It’s ideal for cleanup tasks (e.g., closing files or releasing resources).\nimport math def sqr(value): try: x = math.sqrt(value) except ValueError: print(\u0026#39;Error\u0026#39;) else: print(f\u0026#39;The Answer is: {x}\u0026#39;) finally: print(\u0026#39;Program Ends\u0026#39;) value = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) sqr(value) Output Raising Exceptions Manually Use the raise keyword to trigger exceptions intentionally. This is useful for enforcing constraints.\ndef validate_age(age): if age \u0026lt; 0: raise ValueError(\u0026#34;Age cannot be negative!\u0026#34;) return age try: validate_age(-5) except ValueError as e: print(e) Creating Custom Exceptions Define custom exceptions by subclassing Python’s built-in Exception class. This makes your code more readable and errors more descriptive. (note: I have used RegEx, for that blog will be out soon :) )\nimport re class InvalidEmailError(Exception): \u0026#34;\u0026#34;\u0026#34;Raised when an email format is invalid.\u0026#34;\u0026#34;\u0026#34; pass def send_email(valid,email): if not valid: raise InvalidEmailError(f\u0026#34;Invalid email: {email}\u0026#34;) email = input(\u0026#39;Please enter your email: \u0026#39;) valid = re.match(r\u0026#39;^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\u0026#39;, email) try: send_email(valid, email) except InvalidEmailError as e: print(e) Output Logging a Python Error We can Log an exception in Python with an error. This can be done in the logging.exception() method. This function logs a message with level ERROR on this logger.\nimport math import logging def sqr(value): try: x = math.sqrt(value) except ValueError: logging.exception(\u0026#34;Error\u0026#34;) else: print(f\u0026#39;The Answer is: {x}\u0026#39;) finally: print(\u0026#39;Program Ends\u0026#39;) value = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) sqr(value) Output Best Practices for Exception Handling Catch specific exceptions: Avoid broad except: clauses that hide bugs. Keep try blocks minimal: Only wrap code that might raise an exception. Use finally for cleanup: Ensure resources are released (e.g., closing files). Log exceptions: Use logging.error() instead of print() for production code. Provide meaningful messages: Help debug issues faster with clear error descriptions. Avoid empty except blocks: Silent failures make debugging harder. Conclusion Exception handling is essential for writing better Python applications. By using try-except blocks effectively, catching specific errors, and with else/finally clauses, you can create programs that handle unexpected scenarios.\nNow go forth and write bulletproof Python code!\n","permalink":"http://localhost:1313/posts/exception_handling_in_python/","summary":"\u003cp\u003eException handling is a crucial aspect of writing robust and reliable Python code. Whether you\u0026rsquo;re a beginner or an experienced developer, getting an error, or exception, in your Python program means the entire program will crash. You don’t want this to happen in real-world programs. Instead, you want the program to detect errors, handle them, and then continue to run. In this blog, we\u0026rsquo;ll explore the fundamentals of exception handling in Python, including syntax, best practices, and advanced techniques.\u003c/p\u003e","title":"Exception Handling in Python: A Comprehensive Guide"},{"content":"Have you ever wanted your Python program to do multiple things at once? For example, downloading files while updating the UI, or processing data while listening for user input? That’s where multithreading comes in.\nIn this post, we’ll explore multithreading in Python — what it is, when to use it, and how to use it with simple examples.\n🧠 What is Multithreading? Multithreading is a way to run multiple threads (smaller units of a process) at the same time. It helps make your program more responsive or perform tasks in parallel, especially when tasks are I/O-bound (e.g., network calls, file reading, etc.).\nPython has a built-in module called threading that makes it easy to create and manage threads.\n⚠️ But Wait — Python\u0026rsquo;s GIL Before you jump in, it\u0026rsquo;s important to understand the Global Interpreter Lock (GIL). In CPython (the standard Python implementation), the GIL allows only one thread to execute Python bytecode at a time.\nThis means multithreading in Python is best suited for I/O-bound tasks, not CPU-bound tasks like heavy computations. For CPU-bound tasks, consider multiprocessing instead.\n🛠️ Using the threading Module Here\u0026rsquo;s a basic example to demonstrate multithreading:\nimport threading import time def print_numbers(): for i in range(5): print(f\u0026#34;Number: {i}\u0026#34;) time.sleep(1) def print_letters(): for letter in \u0026#39;abcde\u0026#39;: print(f\u0026#34;Letter: {letter}\u0026#34;) time.sleep(1) # Creating threads t1 = threading.Thread(target=print_numbers) t2 = threading.Thread(target=print_letters) # Starting threads t1.start() t2.start() # Wait for both threads to complete t1.join() t2.join() print(\u0026#34;Both threads have finished.\u0026#34;) 🔍 Output (interleaved): Number: 0 Letter: a Number: 1 Letter: b ... Both functions run at the same time, and you can see their output interleave. That’s multithreading in action!\n📦 Real-World Use Cases Downloading multiple files at once Handling multiple client connections on a server Running background tasks like logging or monitoring Keeping your GUI app responsive while doing other work 🧰 Extra Tools For more advanced usage:\nconcurrent.futures.ThreadPoolExecutor — easier thread management queue.Queue — safe way to share data between threads threading.Lock — prevents race conditions 🧪 Example with ThreadPoolExecutor from concurrent.futures import ThreadPoolExecutor import time def task(name): print(f\u0026#34;{name} starting\u0026#34;) time.sleep(2) print(f\u0026#34;{name} done\u0026#34;) with ThreadPoolExecutor(max_workers=2) as executor: executor.submit(task, \u0026#34;Task 1\u0026#34;) executor.submit(task, \u0026#34;Task 2\u0026#34;) ✅ Final Thoughts Multithreading in Python is a powerful tool when used correctly — especially for I/O-bound programs. Just remember the GIL limitation and use the right tool (like multiprocessing) when working with CPU-heavy tasks.\nThanks for reading! Happy threading 🧵🐍\n","permalink":"http://localhost:1313/posts/multithreading/","summary":"\u003cp\u003eHave you ever wanted your Python program to do multiple things at once? For example, downloading files while updating the UI, or processing data while listening for user input? That’s where \u003cstrong\u003emultithreading\u003c/strong\u003e comes in.\u003c/p\u003e\n\u003cp\u003eIn this post, we’ll explore multithreading in Python — what it is, when to use it, and how to use it with simple examples.\u003c/p\u003e\n\u003ch2 id=\"-what-is-multithreading\"\u003e🧠 What is Multithreading?\u003c/h2\u003e\n\u003cp\u003eMultithreading is a way to run multiple threads (smaller units of a process) at the same time. It helps make your program more responsive or perform tasks in parallel, especially when tasks are I/O-bound (e.g., network calls, file reading, etc.).\u003c/p\u003e","title":"Multithreading in Python"},{"content":"Running a Local LLM on Mobile: Testing PocketPal on iPhone 12 With the increasing accessibility of large language models (LLMs), running them locally on mobile devices is an exciting prospect. I recently tested PocketPal, a mobile LLM interface, on my iPhone 12, using a distilled 4-bit quantized model. Here’s a breakdown of my experience, covering installation, performance, and overall usability.\nWhy Run an LLM on Mobile? Running an LLM locally on a mobile device comes with several advantages:\nPrivacy: No data is sent to external servers. Offline Access: Works without an internet connection. Lower Cost: Avoids API costs associated with cloud-based models. What is Quantization? Quantization is a technique used to reduce the memory and computational requirements of machine learning models by representing their weights with lower precision numbers. Instead of using 32-bit floating-point numbers, models can be compressed into 8-bit or even 4-bit integers while maintaining reasonable accuracy.\nFor LLMs on mobile, 4-bit quantization significantly reduces the model size, making it feasible to run on devices with limited resources. However, this compression can lead to:\nSlightly reduced accuracy due to loss of precision. Faster inference times, as lower-bit computations require less processing power. Lower memory usage, allowing larger models to fit within mobile device constraints. Setting Up and Running PocketPal on iPhone 12 1. Download and Install PocketPal Open the App Store and search for PocketPal AI by Asghar Ghorbani. Download and install the app. Open the app and allow necessary permissions. 2. Adding a Model Navigate to the Models section in the PocketPal app. Click the + button to add a new model. You will see two options: Add from Hugging Face Add Local Model Select Add from Hugging Face to browse available models. 3. Selecting and Downloading a Model Search for DeepSeek-R1-Distill-Qwen-1.5B-Q4_0. Select the model and start downloading it (size: 1.06GB, 1.78B parameters). Once downloaded, the model will appear under the Ready to Use section. 4. Running Benchmarks I ran benchmarks on my iPhone 12 using the DeepSeek-R1-Distill-Qwen-1.5B-Q4_0 model. Here are the key results:\nModel Size: 1.06 GB with 1.78 billion parameters. Benchmark Configuration: Prompt Processing: 512 Token Generation: 128 Pipeline Length: 1 Repetitions: 3 Model Settings: Context Length: 1024 tokens Batch Size: 512 CPU Threads: 4 GPU Layers: 0 (fully CPU-based execution) Flash Attention: Disabled Performance Metrics: Prompt Processing Speed: 26.93 tokens/sec (±2.37) Token Generation Speed: 18.05 tokens/sec (±0.75) Total Execution Time: 1 minute 18 seconds Peak Memory Usage: 35.0% (1GB / 4GB) Live Demo: Running PocketPal on iPhone 12 Watch a live demonstration of PocketPal running a distilled 4-bit quantized model on an iPhone 12: Image: Video demonstration is available here: Video\nAnalysis of Results Decent Processing Speed: With a distilled 4-bit quantized model, the 18.05 t/s token generation rate is quite reasonable for mobile inference. Low Memory Footprint: The 1GB RAM usage means this can run on even mid-range smartphones. CPU-Based Execution: Since 0 GPU layers were used, this proves mobile CPUs are capable of running quantized LLMs efficiently. Flash Attention Disabled: If supported, enabling it might further optimize speed and reduce lag. Final Thoughts Running an LLM locally on an iPhone 12 with PocketPal is feasible but comes with trade-offs. It’s a promising step toward self-hosted AI assistants, though optimization and hardware improvements will be crucial for broader adoption. If you’re privacy-conscious or need offline AI capabilities, it’s definitely worth exploring!\nFuture Improvements I\u0026rsquo;d Like to See: Better memory efficiency to reduce battery drain. Enhanced speed for real-time interaction. More user-friendly model importing and switching. ","permalink":"http://localhost:1313/posts/llmonmobile/","summary":"\u003ch1 id=\"running-a-local-llm-on-mobile-testing-pocketpal-on-iphone-12\"\u003eRunning a Local LLM on Mobile: Testing PocketPal on iPhone 12\u003c/h1\u003e\n\u003cp\u003eWith the increasing accessibility of large language models (LLMs), running them locally on mobile devices is an exciting prospect. I recently tested \u003cstrong\u003ePocketPal\u003c/strong\u003e, a mobile LLM interface, on my \u003cstrong\u003eiPhone 12\u003c/strong\u003e, using a \u003cstrong\u003edistilled 4-bit quantized model\u003c/strong\u003e. Here’s a breakdown of my experience, covering installation, performance, and overall usability.\u003c/p\u003e\n\u003ch2 id=\"why-run-an-llm-on-mobile\"\u003eWhy Run an LLM on Mobile?\u003c/h2\u003e\n\u003cp\u003eRunning an LLM locally on a mobile device comes with several advantages:\u003c/p\u003e","title":"Running Large Language Models on Mobile: DeepSeek R1 on iPhone 12"},{"content":"Running DeepSeek-R1 1.5B on Raspberry Pi 5 (CPU-Only) Technical Insights Why Can We Run This on Raspberry Pi 5? Thanks to open-source advancements, we can now run large-scale AI models on small devices like the Raspberry Pi 5. Key factors enabling this include:\nOptimized lightweight models: DeepSeek-R1 1.5B is built efficiently to run on limited hardware. ARM64 Support: Modern AI frameworks support ARM-based architectures, enabling their use on RPi5. Open-source software: Platforms like Ollama make AI deployment accessible to all. Performance Considerations Running this model on an RPi5 without a GPU will be CPU-intensive. Consider reducing active processes to free up memory. If performance lags, use a lighter model or external processing (cloud inference). No GPU acceleration was used in this setup, meaning all computations rely solely on the CPU, which may affect inference speeds. This guide covers the installation and execution of DeepSeek-R1 1.5B on a Raspberry Pi 5, following the steps demonstrated in your images.\nPrerequisites Raspberry Pi 5 (ARM64 architecture, more powerful than previous versions) Debian-based Linux installed An internet connection At least 4GB RAM recommended for smooth operation Step 1: Log in to Your Raspberry Pi Upon booting, log in using your credentials:\nraspberrypi login: hisam Password: ****** Example login screen: Step 2: Install Curl Curl is required to fetch the installation script. Run:\nsudo apt install curl If it\u0026rsquo;s already installed, you\u0026rsquo;ll see:\ncurl is already the newest version... Example output: Step 3: Install Ollama Ollama is the runtime needed to execute DeepSeek models.\ncurl -fsSL https://ollama.com/install.sh | sh This will download and install Ollama.\nExample installation screen: Step 4: Enable and Start Ollama Service After installation, Ollama sets up a system service.\nollama The output will indicate success:\n\u0026gt;\u0026gt;\u0026gt; Creating ollama user... \u0026gt;\u0026gt;\u0026gt; Enabling and starting ollama service... \u0026gt;\u0026gt;\u0026gt; The Ollama API is now available at 127.0.0.1:11434. Example setup screen: Step 5: Pull and Run DeepSeek-R1 1.5B Now, pull and run the model:\nollama run deepseek-r1:1.5b This will download the model, which is about 1.1 GB in size.\nExample download screen: Once downloaded, the model is ready to run.\nStep 6: Execute DeepSeek-R1 1.5B Run the model and start interacting:\nollama run deepseek-r1:1.5b You should see a prompt where you can start typing queries:\n\u0026gt;\u0026gt;\u0026gt; Hey! Hello! How can I assist you today? 😊 Example interaction: Final Setup Image Video Demonstration Watch Video\nConclusion You have successfully installed and executed DeepSeek-R1 1.5B on your Raspberry Pi 5. This demonstrates the power of open-source AI, making it possible to run advanced models on small-scale devices. If you encounter performance issues, consider optimizing your setup or offloading computations.\nHappy coding!\n","permalink":"http://localhost:1313/posts/deepseek/","summary":"\u003ch1 id=\"running-deepseek-r1-15b-on-raspberry-pi-5-cpu-only\"\u003eRunning DeepSeek-R1 1.5B on Raspberry Pi 5 (CPU-Only)\u003c/h1\u003e\n\u003ch2 id=\"technical-insights\"\u003eTechnical Insights\u003c/h2\u003e\n\u003ch3 id=\"why-can-we-run-this-on-raspberry-pi-5\"\u003eWhy Can We Run This on Raspberry Pi 5?\u003c/h3\u003e\n\u003cp\u003eThanks to open-source advancements, we can now run large-scale AI models on small devices like the Raspberry Pi 5. Key factors enabling this include:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eOptimized lightweight models\u003c/strong\u003e: DeepSeek-R1 1.5B is built efficiently to run on limited hardware.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eARM64 Support\u003c/strong\u003e: Modern AI frameworks support ARM-based architectures, enabling their use on RPi5.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eOpen-source software\u003c/strong\u003e: Platforms like Ollama make AI deployment accessible to all.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"performance-considerations\"\u003ePerformance Considerations\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eRunning this model on an RPi5 \u003cstrong\u003ewithout a GPU\u003c/strong\u003e will be CPU-intensive.\u003c/li\u003e\n\u003cli\u003eConsider \u003cstrong\u003ereducing active processes\u003c/strong\u003e to free up memory.\u003c/li\u003e\n\u003cli\u003eIf performance lags, use a \u003cstrong\u003elighter model\u003c/strong\u003e or \u003cstrong\u003eexternal processing (cloud inference).\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eNo GPU acceleration was used\u003c/strong\u003e in this setup, meaning all computations rely solely on the CPU, which may affect inference speeds.\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003cp\u003eThis guide covers the installation and execution of DeepSeek-R1 1.5B on a Raspberry Pi 5, following the steps demonstrated in your images.\u003c/p\u003e","title":"DeepSeek-R1 on Raspberry Pi 5: Open-Source AI Without a GPU"},{"content":"Setting Up Neovim: An Easy and Beginner\u0026rsquo;s Guide Neovim is a modern and extensible text editor that enhances Vim’s capabilities. If you\u0026rsquo;re using Linux, setting up Neovim can be a rewarding experience, allowing you to customize it for an efficient workflow. In this guide, we\u0026rsquo;ll cover installing Neovim, setting up a basic configuration, and enhancing it with essential plugins to turn it into a full-fledged IDE.\n1. Installing Neovim sudo pacman -S neovim 2. Setting Up Neovim Configuration Neovim’s configuration is stored in ~/.config/nvim/. Create the directory and initialize a basic configuration:\nmkdir -p ~/.config/nvim nvim ~/.config/nvim/init.lua Minimal Configuration (init.lua) Add the following settings to your init.lua file:\n-- Enable line numbers vim.opt.number = true vim.opt.relativenumber = true -- Set tab size vim.opt.expandtab = true vim.opt.shiftwidth = 4 vim.opt.tabstop = 4 -- Enable mouse support vim.opt.mouse = \u0026#34;a\u0026#34; -- Set clipboard to system clipboard vim.opt.clipboard = \u0026#34;unnamedplus\u0026#34; Save and exit Neovim.\n3. Installing a Plugin Manager The best plugin manager for Neovim is lazy.nvim. Install it by running:\ngit clone --depth 1 https://github.com/folke/lazy.nvim.git \\ ~/.local/share/nvim/lazy/lazy.nvim Then, update your init.lua to load it:\nlocal lazypath = vim.fn.stdpath(\u0026#34;data\u0026#34;) .. \u0026#34;/lazy/lazy.nvim\u0026#34; if not vim.loop.fs_stat(lazypath) then vim.fn.system({ \u0026#34;git\u0026#34;, \u0026#34;clone\u0026#34;, \u0026#34;--filter=blob:none\u0026#34;, \u0026#34;https://github.com/folke/lazy.nvim.git\u0026#34;, lazypath }) end vim.opt.rtp:prepend(lazypath) 4. Installing Essential Plugins With lazy.nvim installed, you can add plugins in init.lua:\nrequire(\u0026#34;lazy\u0026#34;).setup({ \u0026#34;nvim-treesitter/nvim-treesitter\u0026#34;, -- Syntax highlighting \u0026#34;nvim-telescope/telescope.nvim\u0026#34;, -- Fuzzy finder \u0026#34;neovim/nvim-lspconfig\u0026#34;, -- LSP support \u0026#34;hrsh7th/nvim-cmp\u0026#34;, -- Auto-completion \u0026#34;hrsh7th/cmp-nvim-lsp\u0026#34;, -- LSP completion source \u0026#34;hrsh7th/cmp-buffer\u0026#34;, -- Buffer completion \u0026#34;hrsh7th/cmp-path\u0026#34;, -- Path completion \u0026#34;hrsh7th/cmp-nvim-lua\u0026#34;, -- Neovim Lua API completion \u0026#34;L3MON4D3/LuaSnip\u0026#34;, -- Snippet engine \u0026#34;saadparwaiz1/cmp_luasnip\u0026#34;, -- Snippet completion \u0026#34;nvim-lualine/lualine.nvim\u0026#34;, -- Status line \u0026#34;nvim-tree/nvim-tree.lua\u0026#34;, -- File explorer \u0026#34;tpope/vim-surround\u0026#34;, -- Surround text objects \u0026#34;tpope/vim-commentary\u0026#34;, -- Commenting shortcuts \u0026#34;lewis6991/gitsigns.nvim\u0026#34;, -- Git integration \u0026#34;akinsho/toggleterm.nvim\u0026#34;, -- Terminal management }) Save and exit Neovim, then open it and run:\n:Lazy sync This will install the plugins automatically.\n5. Setting Up Treesitter Treesitter provides better syntax highlighting and code parsing. Install it by adding the following to your init.lua:\nrequire\u0026#39;nvim-treesitter.configs\u0026#39;.setup { ensure_installed = \u0026#34;all\u0026#34;, highlight = { enable = true, }, indent = { enable = true, }, } Then, update Treesitter by running:\n:TSUpdate 6. Setting Up LSP (Language Server Protocol) LSP enables features like code completion and linting. Install LSP servers for your language:\n# Python sudo pacman -S python-lsp-server # C++ sudo pacman -S clang # JavaScript/TypeScript npm install -g typescript-language-server Then, enable LSP support in Neovim:\nlocal lspconfig = require(\u0026#34;lspconfig\u0026#34;) lspconfig.pyright.setup({}) -- Python lspconfig.ts_ls.setup({}) -- JavaScript/TypeScript lspconfig.clangd.setup({}) -- C++ Restart Neovim and check LSP status:\n:LspInfo 7. Enhancing Auto-Completion with nvim-cmp To enable code auto-completion, update your init.lua:\nlocal cmp = require\u0026#39;cmp\u0026#39; cmp.setup({ mapping = { [\u0026#39;\u0026lt;C-Space\u0026gt;\u0026#39;] = cmp.mapping.complete(), [\u0026#39;\u0026lt;CR\u0026gt;\u0026#39;] = cmp.mapping.confirm({ select = true }), }, sources = { { name = \u0026#39;nvim_lsp\u0026#39; }, { name = \u0026#39;buffer\u0026#39; }, { name = \u0026#39;path\u0026#39; }, { name = \u0026#39;luasnip\u0026#39; }, { name = \u0026#39;nvim_lua\u0026#39; }, } }) 9. Final Thoughts Congratulations! You now have a powerful, customized Neovim setup that functions as a full-fledged IDE. With features like Treesitter, LSP support, auto-completion, syntax highlighting, Git integration, and a file explorer, your development workflow will be much smoother.\nIf you’d like to further improve your Neovim experience, explore more plugins and tweak your settings. Good luck with that!\nFurther Reading Neovim Documentation Awesome Neovim Plugins Arch Wiki: Neovim ","permalink":"http://localhost:1313/posts/setting-up-neovim-on-arch-linux-a-beginners-guide/","summary":"\u003ch1 id=\"setting-up-neovim-an-easy-and-beginners-guide\"\u003eSetting Up Neovim: An Easy and Beginner\u0026rsquo;s Guide\u003c/h1\u003e\n\u003cp\u003eNeovim is a modern and extensible text editor that enhances Vim’s capabilities. If you\u0026rsquo;re using Linux, setting up Neovim can be a rewarding experience, allowing you to customize it for an efficient workflow. In this guide, we\u0026rsquo;ll cover installing Neovim, setting up a basic configuration, and enhancing it with essential plugins to turn it into a full-fledged IDE.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"1-installing-neovim\"\u003e\u003cstrong\u003e1. Installing Neovim\u003c/strong\u003e\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003esudo pacman -S neovim\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003chr\u003e\n\u003ch2 id=\"2-setting-up-neovim-configuration\"\u003e\u003cstrong\u003e2. Setting Up Neovim Configuration\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003eNeovim’s configuration is stored in \u003ccode\u003e~/.config/nvim/\u003c/code\u003e. Create the directory and initialize a basic configuration:\u003c/p\u003e","title":"Setting Up Neovim: A Beginner's Guide"},{"content":"Linux Kernal The majority of the kernel\u0026rsquo;s code is written in C, leveraging extensions provided by the GNU Compiler Collection (GCC) beyond standard C. Additionally, it includes assembly code for architecture-specific functions, such as optimizing memory usage and task execution. Architecturally, the Linux kernel is monolithic, meaning the entire OS operates within kernel space. However, it features a modular design, allowing software components to be integrated as modules, including dynamic loading.\nWhat Is A Kernel Module? A Linux kernel module is precisely defined as a code segment capable of dynamic loading and unloading within the kernel as needed. These modules enhance kernel capabilities without necessitating a system reboot. A notable example is seen in the device driver module, which facilitates kernel interaction with hardware components linked to the system.\nWriting a Custom Linux Kernel Module Linux kernel modules (LKMs) allow developers to extend the functionality of the Linux kernel without modifying its source code. This guide walks through writing a simple kernel module from scratch. Kernel modules are pieces of code that can be dynamically loaded and unloaded from the Linux kernel at runtime. They enable functionality such as device drivers, file system support, and system call extensions without requiring a kernel recompilation. LKMs are particularly useful for developing hardware drivers and testing new kernel features without rebooting the system.\nPrerequisites Ensure you have the necessary development tools installed. On an Arch Linux system, install them with:\nsudo pacman -Syu linux-headers base-devel Creating a Simple Kernel Module 1. Writing the Module Source Code Create a file named hello_module.c:\n#include \u0026lt;linux/module.h\u0026gt; #include \u0026lt;linux/kernel.h\u0026gt; #include \u0026lt;linux/init.h\u0026gt; MODULE_LICENSE(\u0026#34;GPL\u0026#34;); MODULE_AUTHOR(\u0026#34;Your Name\u0026#34;); MODULE_DESCRIPTION(\u0026#34;A simple Hello World kernel module\u0026#34;); static int __init hello_init(void) { printk(KERN_INFO \u0026#34;Hello, Kernel!\\n\u0026#34;); return 0; } static void __exit hello_exit(void) { printk(KERN_INFO \u0026#34;Goodbye, Kernel!\\n\u0026#34;); } module_init(hello_init); module_exit(hello_exit); Understanding the Kernel Module Code #include \u0026lt;linux/module.h\u0026gt;: Includes the necessary module macros and functions. #include \u0026lt;linux/kernel.h\u0026gt;: Provides kernel logging functions. #include \u0026lt;linux/init.h\u0026gt;: Defines initialization and cleanup macros. MODULE_LICENSE(\u0026quot;GPL\u0026quot;): Specifies the module\u0026rsquo;s license. MODULE_AUTHOR(\u0026quot;Your Name\u0026quot;): Specifies the author of the module. MODULE_DESCRIPTION(\u0026quot;A simple Hello World kernel module\u0026quot;): Provides a brief description. static int __init hello_init(void): The function executed when the module is loaded. static void __exit hello_exit(void): The function executed when the module is unloaded. module_init(hello_init): Registers hello_init as the module\u0026rsquo;s initialization function. module_exit(hello_exit): Registers hello_exit as the module\u0026rsquo;s cleanup function. 2. Writing the Makefile Create a Makefile in the same directory:\nobj-m += hello_module.o all: make -C /lib/modules/$(shell uname -r)/build M=$(PWD) modules clean: make -C /lib/modules/$(shell uname -r)/build M=$(PWD) clean Understanding the Makefile obj-m += hello_module.o: Specifies that hello_module.o is the object to be built as a module. all:: Defines the build target. make -C /lib/modules/$(shell uname -r)/build M=$(PWD) modules: Directs the kernel build system to compile the module. clean:: Cleans up the generated files. make -C /lib/modules/$(shell uname -r)/build M=$(PWD) clean: Cleans the build artifacts. 3. Compiling the Module Run:\nmake 4. Loading and Unloading the Module To insert the module into the kernel:\nsudo insmod hello_module.ko Check the kernel log:\ndmesg | tail To remove the module:\nsudo rmmod hello_module 5. Verifying the Module List loaded modules:\nlsmod | grep hello_module Understanding the Generated Files After building the module, several files are generated:\nhello_module.c: The source code of the module. hello_module.ko: The compiled kernel module file, ready to be loaded into the kernel. hello_module.o: An intermediate object file generated during compilation. hello_module.mod.c: An automatically generated file containing module metadata. hello_module.mod.o: An object file containing metadata compiled from hello_module.mod.c. hello_module.mod: Another metadata file required for module loading. Makefile: Contains instructions for building the module. Module.symvers: Stores information about exported symbols, useful for module dependencies. modules.order: Lists the order in which modules should be loaded. Conclusion This simple kernel module demonstrates the basics of module development. You can expand upon this by adding functionality such as handling parameters or interacting with hardware.\nHappy kernel hacking!\n","permalink":"http://localhost:1313/posts/how-to-write-a-custom-kernel-module/","summary":"\u003ch1 id=\"linux-kernal\"\u003eLinux Kernal\u003c/h1\u003e\n\u003cp\u003eThe majority of the kernel\u0026rsquo;s code is written in C, leveraging extensions provided by the GNU Compiler Collection (GCC) beyond standard C. Additionally, it includes assembly code for architecture-specific functions, such as optimizing memory usage and task execution. Architecturally, the Linux kernel is monolithic, meaning the entire OS operates within kernel space. However, it features a modular design, allowing software components to be integrated as modules, including dynamic loading.\u003c/p\u003e","title":"How to Write a Custom Kernel Module"},{"content":"What is it? gh is GitHub\u0026rsquo;s official command-line tool designed to extend Git\u0026rsquo;s functionality with GitHub-specific features.\nPurpose: Simplifies interaction with GitHub\u0026rsquo;s ecosystem directly from the terminal. Allows you to manage repositories and use GitHub features like issues, pull requests, and workflows.\nKey Features: GitHub-specific tasks:\nAuthentication: Easier login (gh auth login) without dealing with tokens manually. Repository Management: Create, fork, or clone repositories. Issues \u0026amp; Pull Requests: Manage issues, PRs, and comments directly. Actions: Manage and view GitHub Actions workflows. Works alongside Git for basic version control tasks. Use Case: Best for developers heavily using GitHub and its features (for example: pull requests, issues, and actions).\nHow it works Install gh:\n\u0026gt; yay -S github-cli Verify the installation:\n\u0026gt; gh --version Login with GitHub CLI (gh)\n\u0026gt; gh auth login Follow the interactive prompts to log in:\nChoose HTTPS or SSH for connection. Log in via a browser using a one-time code or SSH keys. Verify authentication:\n\u0026gt; gh auth status What\u0026rsquo;s best about it that you can install and use both Git and gh (GitHub CLI) seamlessly. Here\u0026rsquo;s how to set them up:\nInstall Git\n\u0026gt;sudo pacman -S git Check the installation:\n\u0026gt; git --version Using Git and gh Together You can now: Use Git for version control:\n\u0026gt; git clone https://github.com/username/repo.git \u0026gt; git add . \u0026gt; git commit -m \u0026quot;message\u0026quot; \u0026gt; git push ","permalink":"http://localhost:1313/posts/github-cli-githubs-official-command-line-tools/","summary":"\u003ch2 id=\"what-is-it\"\u003eWhat is it?\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003egh\u003c/strong\u003e is GitHub\u0026rsquo;s official command-line tool designed to extend Git\u0026rsquo;s functionality with GitHub-specific features.\u003c/p\u003e\n\u003ch2 id=\"purpose\"\u003ePurpose:\u003c/h2\u003e\n\u003cp\u003eSimplifies interaction with GitHub\u0026rsquo;s ecosystem directly from the terminal. Allows you to manage repositories and use GitHub features like issues, pull requests, and workflows.\u003c/p\u003e\n\u003ch2 id=\"key-features\"\u003eKey Features:\u003c/h2\u003e\n\u003cp\u003eGitHub-specific tasks:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAuthentication: Easier login (gh auth login) without dealing with tokens manually.\u003c/li\u003e\n\u003cli\u003eRepository Management: Create, fork, or clone repositories.\u003c/li\u003e\n\u003cli\u003eIssues \u0026amp; Pull Requests: Manage issues, PRs, and comments directly.\u003c/li\u003e\n\u003cli\u003eActions: Manage and view GitHub Actions workflows.\u003c/li\u003e\n\u003cli\u003eWorks alongside Git for basic version control tasks.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"use-case\"\u003eUse Case:\u003c/h2\u003e\n\u003cp\u003eBest for developers heavily using GitHub and its features (for example: pull requests, issues, and actions).\u003c/p\u003e","title":"GitHub CLI: GitHub's Official Command Line Tools"},{"content":"Connecting a Raspberry Pi 5 to a USB TTY cable is a common way to interact with it through a serial connection, especially for debugging or setting up the device without using a display.\nPrerequists\nRaspberry Pi 5. USB TTY (serial) cable. Computer with a terminal emulator (minicom/screen). GPIO pinout diagram of Raspberry Pi 5 (for reference). Power source for Raspberry Pi (optional if USB TTY can power it, though not recommended). Before Starting! Issuse with firmware UART does NOT work on the RPI5 from the factory. We will need a firmware update to fix this that prevents the dtoverlays for UARTs from working.\nInstall rpi-update with the following commands:\n\u0026gt; sudo curl -L --output /usr/bin/rpi-update https://raw.githubusercontent.com/Hexxeh/rpi-update/master/rpi-update \u0026amp;\u0026amp; sudo chmod +x /usr/bin/rpi-update Then update the firmware on your RPI5 with:\n\u0026gt; sudo rpi-update Enable UART To manually configure UART, you can edit the config.txt file.\nEdit /boot/firmware/config.txt and add:\n\u0026gt; enable_uart=1 How to Connect Locate the GPIO Pins Find the GPIO header on the Raspberry Pi 5. Identify the following pins: GND (Ground): Usually black wire on the USB TTY cable. TX (Transmit): Sends data from the Pi to the computer. RX (Receive): Receives data from the computer to the Pi.\nUse a GPIO pinout chart to locate these pins. For Raspberry Pi 5, it will likely be similar to previous models. Making connections You will need to connect:\nGND with Ground - Pin# 06 TX with GPIO14 - Pin# 08 RX with GPIO15 - Pin# 10 Plug the USB TTY Cable into the Computer\nInsert the USB end of the TTY cable into your computer. The cable will create a virtual COM port (e.g /dev/ttyUSB0). Configure and Access Serial Console\nOpen a terminal.\nIdentify the port with:\n\u0026gt; ls /dev/ttyUSB* Use a terminal emulator like screen or minicom to connect:\n\u0026gt; screen /dev/ttyUSB0 115200 *Replace /dev/ttyUSB0 with the actual port name.\nTurn on the Raspberry Pi. If everything is set up correctly, you should see boot messages in the terminal. Log in to the Pi using the default username (pi) and password (raspberry), or your custom credentials. You should see something similar to this.\nThis is it! You have done it. Congrats!\n","permalink":"http://localhost:1313/posts/how-to-connect-a-raspberry-pi-5-to-usb-tty-cable/","summary":"\u003cp\u003eConnecting a Raspberry Pi 5 to a USB TTY cable is a common way to interact with it through a serial connection, especially for debugging or setting up the device without using a display.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003ePrerequists\u003c/strong\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eRaspberry Pi 5.\u003c/li\u003e\n\u003cli\u003eUSB TTY (serial) cable.\u003c/li\u003e\n\u003cli\u003eComputer with a terminal emulator (minicom/screen).\u003c/li\u003e\n\u003cli\u003eGPIO pinout diagram of Raspberry Pi 5 (for reference).\u003c/li\u003e\n\u003cli\u003ePower source for Raspberry Pi (optional if USB TTY can power it, though not recommended).\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"before-starting\"\u003e\u003cstrong\u003eBefore Starting!\u003c/strong\u003e\u003c/h3\u003e\n\u003ch3 id=\"issuse-with-firmware\"\u003e\u003cstrong\u003e\u003ca href=\"https://forums.raspberrypi.com/viewtopic.php?t=361397#p2171244\"\u003eIssuse with firmware\u003c/a\u003e\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003eUART does NOT work on the RPI5 from the factory. We will need a firmware update to fix this that prevents the dtoverlays for UARTs from working.\u003c/p\u003e","title":"How to Connect a Raspberry PI 5 to USB TTY Cable"},{"content":"Hosting a website on GitHub Pages with Hugo involves the following steps:\nCreating a website 1. Install Hugo and git\n\u0026gt; sudo pacman -S Hugo 2. Create a new Hugo site\n\u0026gt; hugo new site your-website 3. Add a Theme\nNavigate to your website directory and add a theme. You can choose one from the Hugo Themes .\n\u0026gt; cd your-website \u0026gt; git init \u0026gt; git submodule add https://github.com/adityatelange/hugo-PaperMod.git themes/hugo-PaperMod Now you will need to update the hugo.toml file for them to take effect. To do so you can either echo or addd it in the file.\n\u0026gt; echo \u0026quot;theme = 'hugo-PaperMod'\u0026quot; \u0026gt;\u0026gt; hugo.toml To view the website you can run it locally using Hugo\u0026rsquo;s development server to view the site. You can add -D to see your drafts.\n\u0026gt; hugo server 3. Add Content\nTo add a new page to your site.\n\u0026gt; hugo new content content/posts/yout-first-post.md This is it You have done it. YAY!\nHosting it on GitHub 1. Create a GitHub repository.\nClick the + icon in the top-right corner of:\u0026gt; [!WARNING] the GitHub interface and select New repository. Enter a repository name: yourusername.github.io Click Create repository. 2. Add Files for Your website\nClone the repository locally using Git:\ngit clone https://github.com//.git\nAdd your static site files (generated by Hugo) to the repository. Commit and push the changes:\n\u0026gt; git add -A \u0026gt; git commit -s -m \u0026quot;Initial commit\u0026quot; \u0026gt; git push origin main 3. Configure the Repository for GitHub Pages\nGo to the Settings tab of your new repository. Scroll down to the Pages section. Settings \u0026gt; Pages. In the center of your screen you will see this: Build and development Change the Source to GitHub Actions. 4. Create a file named hugo.yaml in a directory named .github/workflows.\n\u0026gt; mkdir -p .github/workflows \u0026gt; cd ./github/workflows touch hugo.yaml 5. Add content in the YAML file.\n# Sample workflow for building and deploying a Hugo site to GitHub Pages name: Deploy Hugo site to Pages on: # Runs on pushes targeting the default branch push: branches: - main # Allows you to run this workflow manually from the Actions tab workflow_dispatch: # Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages permissions: contents: read pages: write id-token: write # Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued. # However, do NOT cancel in-progress runs as we want to allow these production deployments to complete. concurrency: group: \u0026#34;pages\u0026#34; cancel-in-progress: false # Default to bash defaults: run: shell: bash jobs: # Build job build: runs-on: ubuntu-latest env: HUGO_VERSION: 0.141.0 steps: - name: Install Hugo CLI run: | wget -O ${{ runner.temp }}/hugo.deb https://github.com/gohugoio/hugo/releases/download/v${HUGO_VERSION}/hugo_extended_${HUGO_VERSION}_linux-amd64.deb \\ \u0026amp;\u0026amp; sudo dpkg -i ${{ runner.temp }}/hugo.deb - name: Install Dart Sass run: sudo snap install dart-sass - name: Checkout uses: actions/checkout@v4 with: submodules: recursive fetch-depth: 0 - name: Setup Pages id: pages uses: actions/configure-pages@v5 - name: Install Node.js dependencies run: \u0026#34;[[ -f package-lock.json || -f npm-shrinkwrap.json ]] \u0026amp;\u0026amp; npm ci || true\u0026#34; - name: Build with Hugo env: HUGO_CACHEDIR: ${{ runner.temp }}/hugo_cache HUGO_ENVIRONMENT: production TZ: America/Los_Angeles run: | hugo \\ --gc \\ --minify \\ --baseURL \u0026#34;${{ steps.pages.outputs.base_url }}/\u0026#34; - name: Upload artifact uses: actions/upload-pages-artifact@v3 with: path: ./public # Deployment job deploy: environment: name: github-pages url: ${{ steps.deployment.outputs.page_url }} runs-on: ubuntu-latest needs: build steps: - name: Deploy to GitHub Pages id: deployment uses: actions/deploy-pages@v4 5. Commit and push your GitHub repository.\n\u0026gt;git add -A \u0026gt;git commit -m \u0026quot;Create hugo.yaml\u0026quot; \u0026gt;git push 6. Deployment status From GitHub’s main menu, choose Actions. When GitHub has finished building and deploying your site, the color of the status indicator will change to green.\nStep 5: Verify Your GitHub Pages Site\nThe site will be live at https://yourusername.github.io.\n","permalink":"http://localhost:1313/posts/hosting-a-website-on-github-pages-with-hugo/","summary":"\u003cp\u003eHosting a website on GitHub Pages with Hugo involves the following steps:\u003c/p\u003e\n\u003ch1 id=\"creating-a-website\"\u003eCreating a website\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e1. Install Hugo and git\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; sudo pacman -S Hugo\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e2. Create a new Hugo site\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; hugo new site your-website\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e3. Add a Theme\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eNavigate to your website directory and add a theme. You can choose one from the \u003ca href=\"https://themes.gohugo.io/\"\u003eHugo Themes\u003c/a\u003e .\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; cd your-website\n\u0026gt; git init \n\u0026gt; git submodule add https://github.com/adityatelange/hugo-PaperMod.git themes/hugo-PaperMod\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow you will need to update the hugo.toml file for them to take effect. To do so you can either \u003cem\u003eecho\u003c/em\u003e or addd it in the file.\u003c/p\u003e","title":"Hosting a Website on Github Pages With Hugo"},{"content":"KVM Kernel-based Virtual Machine is a free and open-source virtualization module in the Linux kernel that allows the kernel to function as a hypervisor.\nInstallation For updates, run the following command:\n$ sudo pacman -Syu QEMU/KVM installation: We\u0026rsquo;ll install qemu and all the utils required:\n$ sudo pacman -S qemu vde2 ebtables iptables-nft nftables dms masq bridge-utils ovmf swptm Virtual Machine Manager installation: The virt-manager application is a graphical user interface for managing virtual machines through libvirt. It primarily targets KVM VMs.\n$ sudo pacman -S virt-manager Now everything is set to work. We can move towards downloading archlinux .iso file.\nDownload .iso file: Head towards: https://archlinux.org/download/ Scroll through and look for the server closest to you. Download archlinux-2024.10.01-x86_64.iso file. Setting up: Open terminal and run the following command:\n$ virt-manager You will see an interface similar to this:\nClick on \u0026lsquo;create a new virtual machine\u0026rsquo; (option with star). Select \u0026lsquo;Local install media\u0026rsquo;. Browse to your \u0026lsquo;archlinux-2024.10.01-x86_64.iso\u0026rsquo;. Add your desired VM configuration and create a disk image. Boot Menu: You will be prompted to a boot menu.\nSelect the topmost option to start the installation process. Archlinux Installer: You will be prompted to a terminal. The first step is to check if you are connected to the internet.\nRun:\n# ip addr show If it shows an IP address and says \u0026lsquo;UP\u0026rsquo;, that means you are good to go.\nIf not: You will need to connect to the internet using the \u0026lsquo;iwctl\u0026rsquo; method for Wi-Fi.\n# iwctl To search networks in your vicinity:\n[iwd]# station [your_wifi_interface] get-networks Get the name of the network you want to connect to. Exit from this prompt using \u0026rsquo;exit\u0026rsquo;.\nTo connect to the desired Wi-Fi network, run:\n# iwctl --passphrase \u0026#34;[wifi_password]\u0026#34; station [your_wifi_interface] connect [wifi_name] You can again run ip addr show to check if you are connected to the network.\nNow you can run the installation command. We\u0026rsquo;ll be using the archinstall method.\n# archinstall You will be prompted to an interface similar to this:\nWe will install Arch using this interface. Go through each option:\nArchinstall language: Choose your preferred language. Mirrors: Select the mirror region closest to you. Use \u0026lsquo;/\u0026rsquo; to search. Locales: Set language and keyboard layout. Disk configuration: Choose Best-effort default partition to format the system. Bootloader: Use the default \u0026lsquo;Grub\u0026rsquo; option. Swap: Select Swap on zram (default). Hostname: Leave as it is. Root password: Set the password for sudo/root privileges. User account: Set up a user account. Profile: Select Desktop. It includes essential packages. Others include Minimal, Server, and Xorg. In Desktop, select your desktop environment. We\u0026rsquo;ll use Gnome for simplicity.\nAudio: Use PipeWire (default) or PulseAudio. Kernels: Use the linux kernel. Additional packages: Install any required packages. Network Configuration: Use NetworkManager for a GUI in Gnome. Timezone: Set the timezone closest to you and enable time sync. Press Install. Congratulations! You\u0026rsquo;ve successfully installed Arch Linux.\n","permalink":"http://localhost:1313/posts/arch_kvm/","summary":"\u003ch1 id=\"kvm\"\u003eKVM\u003c/h1\u003e\n\u003cp\u003eKernel-based Virtual Machine is a free and open-source virtualization module in the Linux kernel that allows the kernel to function as a hypervisor.\u003c/p\u003e\n\u003ch2 id=\"installation\"\u003eInstallation\u003c/h2\u003e\n\u003cp\u003eFor updates, run the following command:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ sudo pacman -Syu\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"qemukvm-installation\"\u003eQEMU/KVM installation:\u003c/h3\u003e\n\u003cp\u003eWe\u0026rsquo;ll install qemu and all the utils required:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ sudo pacman -S qemu vde2 ebtables iptables-nft nftables dms masq bridge-utils ovmf swptm\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"virtual-machine-manager-installation\"\u003eVirtual Machine Manager installation:\u003c/h3\u003e\n\u003cp\u003eThe virt-manager application is a graphical user interface for managing virtual machines through libvirt. It primarily targets KVM VMs.\u003c/p\u003e","title":"archlinux installation in hypervisor through QEMU/KVM"},{"content":"","permalink":"http://localhost:1313/posts/github-cli-githubs-official-command-line-tool/","summary":"","title":""},{"content":"1. Introduction Sometimes you need to share a local application with the outside world — maybe to demo your project, test a webhook, or allow a teammate to access your development server.\nNormally, you’d need a public IP, port forwarding, or a cloud server. ngrok removes all that complexity by creating a secure tunnel from the internet directly to your machine, giving you a public URL instantly.\nIn this guide, we’ll walk through:\nInstalling ngrok on popular Linux distributions Authenticating your installation Exposing a local service to the internet Adding basic security Practical examples for real-world usage 2. Prerequisites Before we begin, make sure you have:\nA terminal A free ngrok account (for authentication token) A running local service (e.g., a Python HTTP server, web app, or API) 3. Installing ngrok on Linux We’ll cover installation for Arch Linux, Debian/Ubuntu, and Fedora.\n3.1 Arch Linux This package is not in the official repos, install it from the AUR:\nyay -S ngrok 3.2 Debian / Ubuntu sudo apt update sudo apt install snapd sudo snap install ngrok Alternatively, download the binary from the ngrok downloads page.\n3.3 Fedora sudo dnf install snapd sudo ln -s /var/lib/snapd/snap /snap sudo snap install ngrok 4. Authenticating ngrok Once installed, you need to connect it to your account so you can use custom domains, longer session times, and access the dashboard.\nSign in to ngrok dashboard. -\u0026gt; Your AuthToken Copy your AuthToken. Run: ngrok config add-authtoken \u0026lt;YOUR_TOKEN\u0026gt; You will see: Authtoken saved to configuration file: ~/.config/ngrok/ngrok.yml 5. Exposing a Local Service For example, if your local web server is running on port 8080:\nngrok http 8080 You’ll see output like:\nNow you can share the HTTPS URL with anyone. It wil be similar to: https://random.string.ngrok-free.app\n6. Adding Basic Security You can protect your tunnel with a simple username and password:\nngrok http --basic-auth=\u0026#34;user:password\u0026#34; 8080 Anyone visiting the public link will need credentials.\n7. Common Use Cases Webhook testing — Connect services like GitHub, Stripe, or Twilio to your local environment. Temporary demos — Share work-in-progress with clients without deployment. Remote device access — SSH into a Raspberry Pi without changing router settings. 8. Conclusion In just a few commands, you’ve learned how to:\nInstall ngrok on popular Linux distros Authenticate your installation Share a local service securely From here, you can explore ngrok’s advanced features like static domains, IP allowlists, and traffic inspection.\n","permalink":"http://localhost:1313/posts/ngrok/","summary":"\u003ch2 id=\"1-introduction\"\u003e1. Introduction\u003c/h2\u003e\n\u003cp\u003eSometimes you need to share a local application with the outside world — maybe to demo your project, test a webhook, or allow a teammate to access your development server.\u003c/p\u003e\n\u003cp\u003eNormally, you’d need a public IP, port forwarding, or a cloud server. \u003cstrong\u003engrok\u003c/strong\u003e removes all that complexity by creating a \u003cstrong\u003esecure tunnel\u003c/strong\u003e from the internet directly to your machine, giving you a public URL instantly.\u003c/p\u003e\n\u003cp\u003eIn this guide, we’ll walk through:\u003c/p\u003e","title":"Ngrok: Expose Localhost to the Internet"},{"content":"Creating a WhatsApp AI Assistant Using n8n: A Step-by-Step Guide Build your own AI-powered WhatsApp chatbot using n8n, WhatsApp Business Cloud API, and OpenAI. This guide walks you through every step—from setup to testing—with real-world error handling, solutions, and an example production-ready workflow.\n1. Introduction Want to chat with an AI on WhatsApp? In this tutorial, you\u0026rsquo;ll learn how to build a WhatsApp AI Assistant using:\nn8n (automation tool) WhatsApp Business Cloud API OpenAI (for generating intelligent replies) By the end, you\u0026rsquo;ll have a working chatbot and gain hands-on experience with APIs, webhooks, and automation.\n2. Prerequisites n8n account (Cloud or self-hosted) Meta Developer account with WhatsApp Business Cloud API access OpenAI API key Basic understanding of APIs and webhook workflows 3. Registering Your WhatsApp Business App A. Create WhatsApp App in Meta Developer Visit Meta for Developers Create a new app: choose Business → WhatsApp Link or create a WhatsApp Business Account B. Obtain Testing Credentials Your app dashboard will show:\nTest phone number Phone Number ID Temporary access token (valid for only 24 hours) Tip: For long-term use, generate a 60-day system-user token later.\nC. Add Recipients to Test List By default, only approved numbers can receive messages:\nNavigate to WhatsApp → API Setup Add numbers in E.164 format (e.g., +923001234567) Users must accept the invite via WhatsApp to become valid recipients 4. Configuring Your Webhook in n8n A. Create a Webhook Node Method: GET (for initial verification) Endpoint example: https://yourname.app.n8n.cloud/webhook/your-unique-id/webhook B. Verify the Webhook with Meta In your app’s Webhook section:\nCallback URL: your n8n webhook URL Verify Token: any secret string you choose (e.g., mySecret2025) C. Echo Back Meta’s Challenge Configure n8n\u0026rsquo;s Webhook node response:\nField Value Response Mode On Received Response Body {{$json[\u0026quot;query\u0026quot;][\u0026quot;hub.challenge\u0026quot;]}} This ensures Meta can verify your endpoint successfully.\n5. Processing Incoming Messages WhatsApp sends JSON data with structure like:\n{ \u0026#34;entry\u0026#34;: [ { \u0026#34;changes\u0026#34;: [ { \u0026#34;value\u0026#34;: { \u0026#34;messages\u0026#34;: [ { \u0026#34;from\u0026#34;: \u0026#34;923001234567\u0026#34;, \u0026#34;text\u0026#34;: { \u0026#34;body\u0026#34;: \u0026#34;Hello bot!\u0026#34; } } ], \u0026#34;metadata\u0026#34;: { \u0026#34;phone_number_id\u0026#34;: \u0026#34;698352170035199\u0026#34; } } } ] } ] } Extract:\nfrom: user’s number text.body: user’s text metadata.phone_number_id: correct sender ID 6. Integrating OpenAI for Responses Obtaining Your OpenAI API Key Before integrating OpenAI into your n8n workflow, you’ll need to get an API key from OpenAI.\nStep-by-Step: Sign up or log in to OpenAI. Navigate to your API Keys page. Click \u0026ldquo;Create new secret key\u0026rdquo;. Optionally name your key, then copy it immediately (you won’t be able to view it again). In n8n: Go to Credentials → Add New → choose OpenAI or HTTP Request. Paste your API key into the key field. Save the credentials. Security Tip: Keep your key private. Do not share it or commit it to public repositories.\nUse an HTTP Request node to call OpenAI:\nPOST https://api.openai.com/v1/chat/completions Authorization: Bearer YOUR_OPENAI_API_KEY Content-Type: application/json { \u0026#34;model\u0026#34;: \u0026#34;gpt-4o-mini\u0026#34;, \u0026#34;messages\u0026#34;: [ { \u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;You are a helpful WhatsApp AI assistant.\u0026#34; }, { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;{{ $json[...] }}\u0026#34; } ] } Replace {{ $json[...] }} with the actual path to the user\u0026rsquo;s message text from the Webhook node.\n7. Sending Replies via WhatsApp Use another HTTP Request node to respond:\nPOST https://graph.facebook.com/v21.0/{{ $json[...] }}/messages Authorization: Bearer YOUR_LONG_LIVED_TOKEN Content-Type: application/json { \u0026#34;messaging_product\u0026#34;: \u0026#34;whatsapp\u0026#34;, \u0026#34;to\u0026#34;: \u0026#34;{{ $json[...] }}\u0026#34;, \u0026#34;text\u0026#34;: { \u0026#34;body\u0026#34;: \u0026#34;{{ $node[\u0026#39;OpenAI Response\u0026#39;].json.choices[0].message.content }}\u0026#34; } } Use the metadata’s phone_number_id for the endpoint and from for the recipient. This avoids hardcoding and ensures proper routing.\n8. Example n8n Workflow Here’s the actual n8n workflow I used for my WhatsApp AI assistant. It integrates a product brochure PDF into a vector store for AI-powered Q\u0026amp;A, and handles WhatsApp message flow.\nStep-by-Step Breakdown: 1. Download Product Brochure PDF Downloads the brochure from a given URL. Extracts text from the PDF. 2. Create Product Brochure Vector Store Splits large text into chunks. Generates embeddings using OpenAI. Saves them in a vector store for fast semantic search. 3. Use the WhatsApp Trigger Listens for incoming WhatsApp messages. Routes them to supported or unsupported handlers. 3a. Handle Unsupported Messages Replies with a friendly error if the message type is not text. 4. Sales AI Agent Responds Uses OpenAI with memory + vector store retrieval to answer based on brochure content. 5. Reply to WhatsApp User Sends the AI-generated message back to the sender. Why this is effective:\nContext-aware answers via buffer memory. Reduced hallucinations thanks to vector store grounding. Smooth error handling for unsupported message types. 9. Common Errors \u0026amp; Fixes Recipient phone number not in allowed list\n→ Add as test number or switch to Live mode\n401 – Session expired\n→ Refresh token via Graph API:\nGET https://graph.facebook.com/v21.0/oauth/access_token ?grant_type=fb_exchange_token \u0026amp;client_id=YOUR_APP_ID \u0026amp;client_secret=YOUR_APP_SECRET \u0026amp;fb_exchange_token=YOUR_CURRENT_TOKEN Webhook verification failed\n→ Ensure verify token matches between Meta and n8n and echo hub.challenge\nNo execution data available\n→ Trigger workflow via actual WhatsApp message, not manual run\n10. Going Live Add a Privacy Policy URL in Meta App → Settings → Basic (required for live access) Switch app to Live mode once all compliance items are met Remove restricted recipient list Use WhatsApp message templates for messages sent after 24 hours of user interaction 11. Conclusion \u0026amp; Next Steps Congrats! You now have a WhatsApp AI Assistant built with n8n and OpenAI.\nWhere to go from here: Wire up custom knowledge (PDFs, documents) Implement memory for conversation context Launch multilingual support Export n8n workflow as JSON for reuse Need help? Join the n8n Community Forum or OpenAI Discord to connect with fellow builders.\nHappy automating!\n","permalink":"http://localhost:1313/posts/creating-whatsapp-ai-assistant-using-n8n2/","summary":"\u003ch1 id=\"creating-a-whatsapp-ai-assistant-using-n8n-a-step-by-step-guide\"\u003eCreating a WhatsApp AI Assistant Using n8n: A Step-by-Step Guide\u003c/h1\u003e\n\u003cp\u003eBuild your own AI-powered WhatsApp chatbot using \u003cstrong\u003en8n\u003c/strong\u003e, \u003cstrong\u003eWhatsApp Business Cloud API\u003c/strong\u003e, and \u003cstrong\u003eOpenAI\u003c/strong\u003e. This guide walks you through every step—from setup to testing—with real-world error handling, solutions, and an example production-ready workflow.\u003c/p\u003e\n\u003ch2 id=\"1-introduction\"\u003e1. Introduction\u003c/h2\u003e\n\u003cp\u003eWant to chat with an AI on WhatsApp? In this tutorial, you\u0026rsquo;ll learn how to build a \u003cstrong\u003eWhatsApp AI Assistant\u003c/strong\u003e using:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003en8n\u003c/strong\u003e (automation tool)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eWhatsApp Business Cloud API\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eOpenAI\u003c/strong\u003e (for generating intelligent replies)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eBy the end, you\u0026rsquo;ll have a working chatbot and gain hands-on experience with APIs, webhooks, and automation.\u003c/p\u003e","title":"Creating Whatsapp Ai Assistant Using N8n"},{"content":"Introduction A memory leak occurs when a program allocates memory dynamically (e.g., using malloc) and fails to release it using free. This leftover allocation can lead to wasted memory resources, eventually causing slowdowns or system crashes in long-running programs.\nValgrind is a powerful command-line tool available on Linux systems. It helps developers detect:\nMemory leaks Invalid memory access Uninitialized memory usage Mismatched memory management In this guide, we\u0026rsquo;ll walk through examples in C to learn how to detect and fix memory leaks using Valgrind.\nInstalling Valgrind On Arch Linux sudo pacman -S valgrind On Ubuntu/Debian sudo apt install valgrind On Fedora sudo dnf install valgrind Troubleshooting: Valgrind \u0026ldquo;cannot find mandatory redirection\u0026rdquo; on Arch Linux If you run Valgrind and get an error like:\nvalgrind: Fatal error at startup: a function redirection\nvalgrind: which is mandatory for this platform-tool combination\nvalgrind: cannot be set up.\n…you might be running a 32-bit executable on a 64-bit Arch Linux system.\nWhy this happens Valgrind needs to hook into low-level glibc functions from your binary’s architecture.\nIf your binary is 32-bit, Arch requires the 32-bit glibc runtime (lib32-glibc).\nWithout it, Valgrind can’t find the right function symbols and quits.\nFix Install the 32-bit glibc package:\nsudo pacman -S lib32-glibc After installation, re-run:\nvalgrind ./your-binary and it should work.\nUbuntu/Debian equivalent: sudo apt install libc6-dbg:i386\nBasic Example: Hello World Code #include \u0026lt;stdio.h\u0026gt; int main() { printf(\u0026#34;Hello World\\n\u0026#34;); return 0; } Compile and Run gcc main.c -o main.out ./main.out Run with Valgrind valgrind ./main.out You should see no errors or memory leaks in the output.\nIntroducing a Memory Leak Static Allocation (Safe) #include \u0026lt;stdio.h\u0026gt; int main() { char str[20] = \u0026#34;Hello\u0026#34;; printf(\u0026#34;%s\\n\u0026#34;, str); return 0; } This uses stack memory, so Valgrind will report no leaks.\nDynamic Allocation (With Leak) #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; int main() { char *str = malloc(20); strcpy(str, \u0026#34;Hello\u0026#34;); printf(\u0026#34;%s\\n\u0026#34;, str); return 0; // Forgot to free memory } Valgrind Output valgrind ./main.out You should see:\ndefinitely lost: 20 bytes in 1 blocks\nFixing the Memory Leak Add free(str); before returning:\nfree(str); Fixed Code #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; int main() { char *str = malloc(20); strcpy(str, \u0026#34;Hello\u0026#34;); printf(\u0026#34;%s\\n\u0026#34;, str); free(str); return 0; } Detailed Valgrind Options Use for deeper analysis:\nvalgrind --leak-check=full ./main.out Or even more detailed:\nvalgrind --leak-check=full --show-leak-kinds=all --track-origins=yes ./main.out Explanation:\n--leak-check=full: Display detailed leak info --show-leak-kinds=all: Show all kinds of leaks (definitely, indirectly lost, etc.) --track-origins=yes: Show where uninitialized values originate Summary Always free() memory allocated with malloc(), calloc(), or realloc(). Close all file streams with fclose(). Use Valgrind to identify and fix: Memory leaks Invalid memory writes Use-after-free bugs Recommended command: valgrind --leak-check=full --track-origins=yes ./your_program Valgrind is a critical tool for writing safe, efficient, and bug-free C programs.\n","permalink":"http://localhost:1313/posts/introductiontovalgrind/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eA \u003cstrong\u003ememory leak\u003c/strong\u003e occurs when a program allocates memory dynamically (e.g., using \u003ccode\u003emalloc\u003c/code\u003e) and fails to release it using \u003ccode\u003efree\u003c/code\u003e. This leftover allocation can lead to wasted memory resources, eventually causing slowdowns or system crashes in long-running programs.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eValgrind\u003c/strong\u003e is a powerful command-line tool available on Linux systems. It helps developers detect:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eMemory leaks\u003c/li\u003e\n\u003cli\u003eInvalid memory access\u003c/li\u003e\n\u003cli\u003eUninitialized memory usage\u003c/li\u003e\n\u003cli\u003eMismatched memory management\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIn this guide, we\u0026rsquo;ll walk through examples in C to learn how to detect and fix memory leaks using Valgrind.\u003c/p\u003e","title":"Detecting and Fixing Memory Leaks with Valgrind"},{"content":"QEMU-KVM on Arch Linux: Running Tiny Core Linux in a Lightweight VM Virtualization is a powerful tool for developers, sysadmins, and tinkerers alike. On Linux, QEMU-KVM stands out as a robust, high-performance virtualization stack. In this blog, well walk through setting up QEMU-KVM on Arch Linux and using it to run Tiny Core Linuxa super-lightweight distro perfect for testing and experimentation.\nWhat is QEMU-KVM QEMU (Quick Emulator) is a generic and open-source machine emulator. On its own, it can emulate various hardware systems. However, when paired with **KVM (Kernel-based Virtual Machine)**a Linux kernel module for virtualizationit can run virtual machines with near-native performance.\nQEMU provides device emulation and user-space management. KVM integrates with the Linux kernel and handles hardware-level virtualization. Together, they effectively form a Type 1 hypervisor because the Linux kernel (with KVM) handles core virtualization tasks directly on hardware.\nStep-by-Step: Installing QEMU-KVM on Arch Linux Step 1: Install Required Packages sudo pacman -Syu sudo pacman -S qemu virt-manager virt-viewer dnsmasq vde2 bridge-utils openbsd-netcat libvirt edk2-ovmf edk2-ovmf is for UEFI firmware support in VMs.\nStep 2: Enable and Start libvirtd sudo systemctl enable --now libvirtd.service Step 3: Add Your User to the libvirt Group sudo usermod -aG libvirt (whoami) newgrp libvirt Step 4: Verify KVM Support lsmod grep kvm And check CPU virtualization support:\negrep -c (vmxsvm) /proc/cpuinfo A value of 1 or more indicates virtualization support.\nExample: Running Tiny Core Linux on QEMU-KVM Now that your system is ready, lets run Tiny Core Linux, a minimalist Linux distro thats only 16MB\nStep 1: Download Tiny Core ISO wget http://tinycorelinux.net/14.x/x86/release/Core-current.iso Or visit http://tinycorelinux.net for the latest release.\nStep 2: Create a Virtual Disk (Optional) qemu-img create -f qcow2 tinycore.qcow2 512M This creates a 512MB disk image. Optional for RAM-only usage.\nStep 3: Launch the VM with KVM Acceleration qemu-system-x86_64 -enable-kvm -m 512 -cpu host -smp 1 -cdrom Core-current.iso -hda tinycore.qcow2 -boot d -net nic -net user -vga virtio -display sdl Key Flags Explained:\n-enable-kvm: Enables KVM hardware acceleration -m 512: Allocates 512MB RAM -cpu host: Uses the host CPU features -cdrom: Points to the Tiny Core ISO -hda: Uses a QCOW2 disk image -boot d: Boots from CD first -net user: Enables simple user-mode networking (e.g., for internet access) -display sdl: Uses SDL window for graphics (you can replace with gtk or virt-manager) Alternate: Boot Tiny Core in RAM Without Disk qemu-system-x86_64 -enable-kvm -m 256 -cdrom Core-current.iso -boot d -net nic -net user -vga std Conclusion With QEMU-KVM, Arch Linux becomes a full-featured Type 1 hypervisor. By combining kernel-level virtualization (KVM) with the flexibility of QEMU, you get a fast, customizable virtualization platform. Running Tiny Core Linux showcases just how lightweight and efficient this setup can be.\nWhether youre building VMs for testing, learning Linux internals, or experimenting with custom environments, QEMU-KVM on Arch is a powerful combination.\nHappy virtualizing\n","permalink":"http://localhost:1313/posts/qemu/","summary":"\u003ch1 id=\"qemu-kvm-on-arch-linux-running-tiny-core-linux-in-a-lightweight-vm\"\u003eQEMU-KVM on Arch Linux: Running Tiny Core Linux in a Lightweight VM\u003c/h1\u003e\n\u003cp\u003eVirtualization is a powerful tool for developers, sysadmins, and tinkerers alike. On Linux, \u003cstrong\u003eQEMU-KVM\u003c/strong\u003e stands out as a robust, high-performance virtualization stack. In this blog, well walk through setting up QEMU-KVM on \u003cstrong\u003eArch Linux\u003c/strong\u003e and using it to run \u003cstrong\u003eTiny Core Linux\u003c/strong\u003ea super-lightweight distro perfect for testing and experimentation.\u003c/p\u003e\n\u003ch2 id=\"what-is-qemu-kvm\"\u003eWhat is QEMU-KVM\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eQEMU (Quick Emulator)\u003c/strong\u003e is a generic and open-source machine emulator. On its own, it can emulate various hardware systems. However, when paired with **KVM (Kernel-based Virtual Machine)**a Linux kernel module for virtualizationit can run virtual machines with near-native performance.\u003c/p\u003e","title":"QEMU-KVM on Arch Linux: Running Tiny Core Linux in a Lightweight VM"},{"content":"Building the Linux Kernel Compiling the Linux Kernel involves multiple steps and can take some time depending on your hardware specifications.\nStep 1: Download the Kernel Source Code Start by visiting the Official Linux Kernel Website and downloading the latest available kernel source code. The downloaded file will be a compressed archive containing all necessary source files.\nStep 2: Extract the Source Code Once the download completes, extract the contents of the compressed archive using the tar command:\ntar xvf linux-6.13.tar.xz If the tar utility is not installed on your system, you can install it using:\nsudo pacman -S tar Note: Always ensure you are using the correct version number in the file name.\nStep 3: Install Required Dependencies To compile the kernel, you need to install various development tools and libraries. Install them using the following command:\nsudo pacman -S git fakeroot ncurses xz bc flex bison base-devel kmod cpio perl binutils util-linux jfsutils e2fsprogs xfsprogs squashfs-tools quota-tools Step 4: Configure the Kernel Navigate into the kernel source directory: cd linux-6.13 Use your current system’s configuration as a base:\nIf zcat is available, run:\nzcat /proc/config.gz \u0026gt; .config Otherwise, use this alternative method:\ncp /proc/config.gz ./ gunzip config.gz mv config .config Customize the kernel using a menu-driven interface:\nmake menuconfig make xconfig make oldconfig Modify the .config file directly:\nOpen it with a text editor:\nsudo vim .config Search for the line:\nCONFIG_EXT4_FS=m And change it to:\nCONFIG_EXT4_FS=y Step 5: Compile the Kernel Determine the number of CPU cores available to speed up compilation: nproc Compile the kernel using the number of cores found above. Replace n with that number: make -j\u0026lt;n\u0026gt; If you encounter any errors during or after this step, back up your .config file and reset the source tree with:\nmake mrproper This command cleans the build environment and restores the source tree to its original state.\nStep 6: Install Kernel Modules Kernel modules are essential for extending the kernel’s functionality and ensuring compatibility with various hardware. Install them with:\nsudo make modules_install Step 7: Install the Kernel You can install the compiled kernel using one of the two methods below:\nAutomatic installation: sudo make install Manual installation (if the above doesn\u0026rsquo;t work):\nCopy the kernel image:\nsudo cp arch/x86/boot/bzImage /boot/vmlinuz-linux-custom Copy the System.map file:\nsudo cp System.map /boot/System.map-linux-custom Copy the kernel configuration file:\nsudo cp .config /boot/config-linux-custom Step 8: Update the Bootloader If you use GRUB, follow these steps to add an entry for your custom kernel:\nFind the UUID of your root partition: lsblk -f Open the custom GRUB configuration file: sudo nvim /etc/grub.d/40_custom Add the following entry (replace paste-your-root-partition-uuid-here with the actual UUID): menuentry \u0026#39;Custom Linux Kernel\u0026#39; { linux /boot/vmlinuz-linux-custom root=UUID=paste-your-root-partition-uuid-here initrd /boot/initramfs-linux.img } Step 9: Generate Initramfs As you\u0026rsquo;ve compiled a new kernel, installed modules, and modified boot entries, generating a new initramfs is necessary. Run:\nsudo mkinitcpio -k 6.13-custom -c /etc/mkinitcpio.conf -g /boot/initramfs-linux-custom.img Make sure the version (6.13-custom) matches your compiled kernel.\nStep 10: Update GRUB Configuration Finally, update the GRUB configuration so that it includes your new kernel entry:\nsudo grub-mkconfig -o /boot/grub/grub.cfg Done! Congratulations! You’ve successfully compiled and installed your custom Linux Kernel. Enjoy your personalized system!\n","permalink":"http://localhost:1313/posts/kernal_compilation/","summary":"\u003ch1 id=\"building-the-linux-kernel\"\u003eBuilding the Linux Kernel\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003eCompiling the Linux Kernel involves multiple steps and can take some time depending on your hardware specifications.\u003c/strong\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"step-1-download-the-kernel-source-code\"\u003eStep 1: Download the Kernel Source Code\u003c/h3\u003e\n\u003cp\u003eStart by visiting the \u003ca href=\"https://www.kernel.org/\"\u003eOfficial Linux Kernel Website\u003c/a\u003e and downloading the latest available kernel source code. The downloaded file will be a compressed archive containing all necessary source files.\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"step-2-extract-the-source-code\"\u003eStep 2: Extract the Source Code\u003c/h3\u003e\n\u003cp\u003eOnce the download completes, extract the contents of the compressed archive using the \u003ccode\u003etar\u003c/code\u003e command:\u003c/p\u003e","title":"How to build Linux Kernal: Step by Step Guide"},{"content":"Introduction So, you’ve built a sleek website with Hugo and deployed it to GitHub Pages. Now, you want to give it a professional touch with a custom domain like yourdomain.tech instead of the default username.github.io URL. This guide walks you through the process step-by-step.\nPrerequisites A Hugo website hosted on GitHub Pages (public repository). A custom domain (e.g., yourdomain.tech) purchased from a registrar like Namecheap, Google Domains, etc. Basic familiarity with DNS settings and GitHub repository configurations. Step 1: Configure Your GitHub Repository First, ensure your GitHub Pages site is set up correctly:\nYour repository should be named \u0026lt;username\u0026gt;.github.io (for user/organization sites) or \u0026lt;repo-name\u0026gt; (for project sites). The gh-pages branch (or the /docs folder) should contain your Hugo-generated static files. Step 2: Configure DNS Settings for Your Domain Option 1: Use an Apex Domain (e.g., yourdomain.tech) If you want your site to live at the root domain (e.g., yourdomain.tech), configure A records in your DNS settings:\nGo to your domain registrar’s DNS management page. Create four A records pointing to GitHub’s IP addresses: Host: @ Type: A Value: 185.199.108.153 TTL: Automatic ","permalink":"http://localhost:1313/posts/customdomain/","summary":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003eSo, you’ve built a sleek website with Hugo and deployed it to GitHub Pages. Now, you want to give it a professional touch with a custom domain like \u003ccode\u003eyourdomain.tech\u003c/code\u003e instead of the default \u003ccode\u003eusername.github.io\u003c/code\u003e URL. This guide walks you through the process step-by-step.\u003c/p\u003e\n\u003ch2 id=\"prerequisites\"\u003ePrerequisites\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003eA Hugo website hosted on GitHub Pages (public repository).\u003c/li\u003e\n\u003cli\u003eA custom domain (e.g., \u003ccode\u003eyourdomain.tech\u003c/code\u003e) purchased from a registrar like Namecheap, Google Domains, etc.\u003c/li\u003e\n\u003cli\u003eBasic familiarity with DNS settings and GitHub repository configurations.\u003c/li\u003e\n\u003c/ol\u003e\n\u003chr\u003e\n\u003ch2 id=\"step-1-configure-your-github-repository\"\u003eStep 1: Configure Your GitHub Repository\u003c/h2\u003e\n\u003cp\u003eFirst, ensure your GitHub Pages site is set up correctly:\u003c/p\u003e","title":"How to up custom domain for GitHub Pages"},{"content":"Exception handling is a crucial aspect of writing robust and reliable Python code. Whether you\u0026rsquo;re a beginner or an experienced developer, getting an error, or exception, in your Python program means the entire program will crash. You don’t want this to happen in real-world programs. Instead, you want the program to detect errors, handle them, and then continue to run. In this blog, we\u0026rsquo;ll explore the fundamentals of exception handling in Python, including syntax, best practices, and advanced techniques.\nWhat Are Exceptions? Exceptions are runtime errors that disrupt the normal flow of a program. For example, trying to open a non-existent file, dividing by zero, or accessing an invalid index in a list will raise exceptions. If unhandled, these exceptions cause your program to crash.\nBasic Syntax: try and except The primary mechanism for handling exceptions in Python is the try-except block. Errors can be handled with with this. The code that could potentially have an error is put in a try clause. The program execution moves to the start of a following except clause if an error happens.\nHere\u0026rsquo;s the basic structure:\ndef cal(value): try: return 10 / value except ZeroDivisionError: print(\u0026#34;Cannot divide by zero!\u0026#34;) print(cal(0)) print(cal(2)) print(cal(3)) How It Works: The code inside the try block is executed. If an exception occurs, Python checks the except blocks for a matching exception type. If a match is found, the corresponding except block runs. Catching Specific Exceptions Always catch specific exceptions to avoid silencing unexpected errors. Python has many built-in exceptions (e.g., ValueError, TypeError, FileNotFoundError).\nimport math x = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) try: print(f\u0026#39;Square Root of {x} is {math.sqrt(x)}\u0026#39;) except ValueError: print(\u0026#39;Number is less than 0\u0026#39;) Output\nThe else Clause The else block runs only if no exceptions were raised in the try block. Use it to separate \u0026ldquo;happy path\u0026rdquo; code from error handling.\nimport math def sqr(value): try: x = math.sqrt(value) except ValueError: print(\u0026#39;Number is less than 0\u0026#39;) else: print(f\u0026#39;The Answer is: {x}\u0026#39;) value = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) sqr(value) Output The finally Clause The finally block runs regardless of whether an exception occurred. It’s ideal for cleanup tasks (e.g., closing files or releasing resources).\nimport math def sqr(value): try: x = math.sqrt(value) except ValueError: print(\u0026#39;Error\u0026#39;) else: print(f\u0026#39;The Answer is: {x}\u0026#39;) finally: print(\u0026#39;Program Ends\u0026#39;) value = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) sqr(value) Output Raising Exceptions Manually Use the raise keyword to trigger exceptions intentionally. This is useful for enforcing constraints.\ndef validate_age(age): if age \u0026lt; 0: raise ValueError(\u0026#34;Age cannot be negative!\u0026#34;) return age try: validate_age(-5) except ValueError as e: print(e) Creating Custom Exceptions Define custom exceptions by subclassing Python’s built-in Exception class. This makes your code more readable and errors more descriptive. (note: I have used RegEx, for that blog will be out soon :) )\nimport re class InvalidEmailError(Exception): \u0026#34;\u0026#34;\u0026#34;Raised when an email format is invalid.\u0026#34;\u0026#34;\u0026#34; pass def send_email(valid,email): if not valid: raise InvalidEmailError(f\u0026#34;Invalid email: {email}\u0026#34;) email = input(\u0026#39;Please enter your email: \u0026#39;) valid = re.match(r\u0026#39;^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\u0026#39;, email) try: send_email(valid, email) except InvalidEmailError as e: print(e) Output Logging a Python Error We can Log an exception in Python with an error. This can be done in the logging.exception() method. This function logs a message with level ERROR on this logger.\nimport math import logging def sqr(value): try: x = math.sqrt(value) except ValueError: logging.exception(\u0026#34;Error\u0026#34;) else: print(f\u0026#39;The Answer is: {x}\u0026#39;) finally: print(\u0026#39;Program Ends\u0026#39;) value = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) sqr(value) Output Best Practices for Exception Handling Catch specific exceptions: Avoid broad except: clauses that hide bugs. Keep try blocks minimal: Only wrap code that might raise an exception. Use finally for cleanup: Ensure resources are released (e.g., closing files). Log exceptions: Use logging.error() instead of print() for production code. Provide meaningful messages: Help debug issues faster with clear error descriptions. Avoid empty except blocks: Silent failures make debugging harder. Conclusion Exception handling is essential for writing better Python applications. By using try-except blocks effectively, catching specific errors, and with else/finally clauses, you can create programs that handle unexpected scenarios.\nNow go forth and write bulletproof Python code!\n","permalink":"http://localhost:1313/posts/exception_handling_in_python/","summary":"\u003cp\u003eException handling is a crucial aspect of writing robust and reliable Python code. Whether you\u0026rsquo;re a beginner or an experienced developer, getting an error, or exception, in your Python program means the entire program will crash. You don’t want this to happen in real-world programs. Instead, you want the program to detect errors, handle them, and then continue to run. In this blog, we\u0026rsquo;ll explore the fundamentals of exception handling in Python, including syntax, best practices, and advanced techniques.\u003c/p\u003e","title":"Exception Handling in Python: A Comprehensive Guide"},{"content":"Have you ever wanted your Python program to do multiple things at once? For example, downloading files while updating the UI, or processing data while listening for user input? That’s where multithreading comes in.\nIn this post, we’ll explore multithreading in Python — what it is, when to use it, and how to use it with simple examples.\n🧠 What is Multithreading? Multithreading is a way to run multiple threads (smaller units of a process) at the same time. It helps make your program more responsive or perform tasks in parallel, especially when tasks are I/O-bound (e.g., network calls, file reading, etc.).\nPython has a built-in module called threading that makes it easy to create and manage threads.\n⚠️ But Wait — Python\u0026rsquo;s GIL Before you jump in, it\u0026rsquo;s important to understand the Global Interpreter Lock (GIL). In CPython (the standard Python implementation), the GIL allows only one thread to execute Python bytecode at a time.\nThis means multithreading in Python is best suited for I/O-bound tasks, not CPU-bound tasks like heavy computations. For CPU-bound tasks, consider multiprocessing instead.\n🛠️ Using the threading Module Here\u0026rsquo;s a basic example to demonstrate multithreading:\nimport threading import time def print_numbers(): for i in range(5): print(f\u0026#34;Number: {i}\u0026#34;) time.sleep(1) def print_letters(): for letter in \u0026#39;abcde\u0026#39;: print(f\u0026#34;Letter: {letter}\u0026#34;) time.sleep(1) # Creating threads t1 = threading.Thread(target=print_numbers) t2 = threading.Thread(target=print_letters) # Starting threads t1.start() t2.start() # Wait for both threads to complete t1.join() t2.join() print(\u0026#34;Both threads have finished.\u0026#34;) 🔍 Output (interleaved): Number: 0 Letter: a Number: 1 Letter: b ... Both functions run at the same time, and you can see their output interleave. That’s multithreading in action!\n📦 Real-World Use Cases Downloading multiple files at once Handling multiple client connections on a server Running background tasks like logging or monitoring Keeping your GUI app responsive while doing other work 🧰 Extra Tools For more advanced usage:\nconcurrent.futures.ThreadPoolExecutor — easier thread management queue.Queue — safe way to share data between threads threading.Lock — prevents race conditions 🧪 Example with ThreadPoolExecutor from concurrent.futures import ThreadPoolExecutor import time def task(name): print(f\u0026#34;{name} starting\u0026#34;) time.sleep(2) print(f\u0026#34;{name} done\u0026#34;) with ThreadPoolExecutor(max_workers=2) as executor: executor.submit(task, \u0026#34;Task 1\u0026#34;) executor.submit(task, \u0026#34;Task 2\u0026#34;) ✅ Final Thoughts Multithreading in Python is a powerful tool when used correctly — especially for I/O-bound programs. Just remember the GIL limitation and use the right tool (like multiprocessing) when working with CPU-heavy tasks.\nThanks for reading! Happy threading 🧵🐍\n","permalink":"http://localhost:1313/posts/multithreading/","summary":"\u003cp\u003eHave you ever wanted your Python program to do multiple things at once? For example, downloading files while updating the UI, or processing data while listening for user input? That’s where \u003cstrong\u003emultithreading\u003c/strong\u003e comes in.\u003c/p\u003e\n\u003cp\u003eIn this post, we’ll explore multithreading in Python — what it is, when to use it, and how to use it with simple examples.\u003c/p\u003e\n\u003ch2 id=\"-what-is-multithreading\"\u003e🧠 What is Multithreading?\u003c/h2\u003e\n\u003cp\u003eMultithreading is a way to run multiple threads (smaller units of a process) at the same time. It helps make your program more responsive or perform tasks in parallel, especially when tasks are I/O-bound (e.g., network calls, file reading, etc.).\u003c/p\u003e","title":"Multithreading in Python"},{"content":"Running a Local LLM on Mobile: Testing PocketPal on iPhone 12 With the increasing accessibility of large language models (LLMs), running them locally on mobile devices is an exciting prospect. I recently tested PocketPal, a mobile LLM interface, on my iPhone 12, using a distilled 4-bit quantized model. Here’s a breakdown of my experience, covering installation, performance, and overall usability.\nWhy Run an LLM on Mobile? Running an LLM locally on a mobile device comes with several advantages:\nPrivacy: No data is sent to external servers. Offline Access: Works without an internet connection. Lower Cost: Avoids API costs associated with cloud-based models. What is Quantization? Quantization is a technique used to reduce the memory and computational requirements of machine learning models by representing their weights with lower precision numbers. Instead of using 32-bit floating-point numbers, models can be compressed into 8-bit or even 4-bit integers while maintaining reasonable accuracy.\nFor LLMs on mobile, 4-bit quantization significantly reduces the model size, making it feasible to run on devices with limited resources. However, this compression can lead to:\nSlightly reduced accuracy due to loss of precision. Faster inference times, as lower-bit computations require less processing power. Lower memory usage, allowing larger models to fit within mobile device constraints. Setting Up and Running PocketPal on iPhone 12 1. Download and Install PocketPal Open the App Store and search for PocketPal AI by Asghar Ghorbani. Download and install the app. Open the app and allow necessary permissions. 2. Adding a Model Navigate to the Models section in the PocketPal app. Click the + button to add a new model. You will see two options: Add from Hugging Face Add Local Model Select Add from Hugging Face to browse available models. 3. Selecting and Downloading a Model Search for DeepSeek-R1-Distill-Qwen-1.5B-Q4_0. Select the model and start downloading it (size: 1.06GB, 1.78B parameters). Once downloaded, the model will appear under the Ready to Use section. 4. Running Benchmarks I ran benchmarks on my iPhone 12 using the DeepSeek-R1-Distill-Qwen-1.5B-Q4_0 model. Here are the key results:\nModel Size: 1.06 GB with 1.78 billion parameters. Benchmark Configuration: Prompt Processing: 512 Token Generation: 128 Pipeline Length: 1 Repetitions: 3 Model Settings: Context Length: 1024 tokens Batch Size: 512 CPU Threads: 4 GPU Layers: 0 (fully CPU-based execution) Flash Attention: Disabled Performance Metrics: Prompt Processing Speed: 26.93 tokens/sec (±2.37) Token Generation Speed: 18.05 tokens/sec (±0.75) Total Execution Time: 1 minute 18 seconds Peak Memory Usage: 35.0% (1GB / 4GB) Live Demo: Running PocketPal on iPhone 12 Watch a live demonstration of PocketPal running a distilled 4-bit quantized model on an iPhone 12: Image: Video demonstration is available here: Video\nAnalysis of Results Decent Processing Speed: With a distilled 4-bit quantized model, the 18.05 t/s token generation rate is quite reasonable for mobile inference. Low Memory Footprint: The 1GB RAM usage means this can run on even mid-range smartphones. CPU-Based Execution: Since 0 GPU layers were used, this proves mobile CPUs are capable of running quantized LLMs efficiently. Flash Attention Disabled: If supported, enabling it might further optimize speed and reduce lag. Final Thoughts Running an LLM locally on an iPhone 12 with PocketPal is feasible but comes with trade-offs. It’s a promising step toward self-hosted AI assistants, though optimization and hardware improvements will be crucial for broader adoption. If you’re privacy-conscious or need offline AI capabilities, it’s definitely worth exploring!\nFuture Improvements I\u0026rsquo;d Like to See: Better memory efficiency to reduce battery drain. Enhanced speed for real-time interaction. More user-friendly model importing and switching. ","permalink":"http://localhost:1313/posts/llmonmobile/","summary":"\u003ch1 id=\"running-a-local-llm-on-mobile-testing-pocketpal-on-iphone-12\"\u003eRunning a Local LLM on Mobile: Testing PocketPal on iPhone 12\u003c/h1\u003e\n\u003cp\u003eWith the increasing accessibility of large language models (LLMs), running them locally on mobile devices is an exciting prospect. I recently tested \u003cstrong\u003ePocketPal\u003c/strong\u003e, a mobile LLM interface, on my \u003cstrong\u003eiPhone 12\u003c/strong\u003e, using a \u003cstrong\u003edistilled 4-bit quantized model\u003c/strong\u003e. Here’s a breakdown of my experience, covering installation, performance, and overall usability.\u003c/p\u003e\n\u003ch2 id=\"why-run-an-llm-on-mobile\"\u003eWhy Run an LLM on Mobile?\u003c/h2\u003e\n\u003cp\u003eRunning an LLM locally on a mobile device comes with several advantages:\u003c/p\u003e","title":"Running Large Language Models on Mobile: DeepSeek R1 on iPhone 12"},{"content":"Running DeepSeek-R1 1.5B on Raspberry Pi 5 (CPU-Only) Technical Insights Why Can We Run This on Raspberry Pi 5? Thanks to open-source advancements, we can now run large-scale AI models on small devices like the Raspberry Pi 5. Key factors enabling this include:\nOptimized lightweight models: DeepSeek-R1 1.5B is built efficiently to run on limited hardware. ARM64 Support: Modern AI frameworks support ARM-based architectures, enabling their use on RPi5. Open-source software: Platforms like Ollama make AI deployment accessible to all. Performance Considerations Running this model on an RPi5 without a GPU will be CPU-intensive. Consider reducing active processes to free up memory. If performance lags, use a lighter model or external processing (cloud inference). No GPU acceleration was used in this setup, meaning all computations rely solely on the CPU, which may affect inference speeds. This guide covers the installation and execution of DeepSeek-R1 1.5B on a Raspberry Pi 5, following the steps demonstrated in your images.\nPrerequisites Raspberry Pi 5 (ARM64 architecture, more powerful than previous versions) Debian-based Linux installed An internet connection At least 4GB RAM recommended for smooth operation Step 1: Log in to Your Raspberry Pi Upon booting, log in using your credentials:\nraspberrypi login: hisam Password: ****** Example login screen: Step 2: Install Curl Curl is required to fetch the installation script. Run:\nsudo apt install curl If it\u0026rsquo;s already installed, you\u0026rsquo;ll see:\ncurl is already the newest version... Example output: Step 3: Install Ollama Ollama is the runtime needed to execute DeepSeek models.\ncurl -fsSL https://ollama.com/install.sh | sh This will download and install Ollama.\nExample installation screen: Step 4: Enable and Start Ollama Service After installation, Ollama sets up a system service.\nollama The output will indicate success:\n\u0026gt;\u0026gt;\u0026gt; Creating ollama user... \u0026gt;\u0026gt;\u0026gt; Enabling and starting ollama service... \u0026gt;\u0026gt;\u0026gt; The Ollama API is now available at 127.0.0.1:11434. Example setup screen: Step 5: Pull and Run DeepSeek-R1 1.5B Now, pull and run the model:\nollama run deepseek-r1:1.5b This will download the model, which is about 1.1 GB in size.\nExample download screen: Once downloaded, the model is ready to run.\nStep 6: Execute DeepSeek-R1 1.5B Run the model and start interacting:\nollama run deepseek-r1:1.5b You should see a prompt where you can start typing queries:\n\u0026gt;\u0026gt;\u0026gt; Hey! Hello! How can I assist you today? 😊 Example interaction: Final Setup Image Video Demonstration Watch Video\nConclusion You have successfully installed and executed DeepSeek-R1 1.5B on your Raspberry Pi 5. This demonstrates the power of open-source AI, making it possible to run advanced models on small-scale devices. If you encounter performance issues, consider optimizing your setup or offloading computations.\nHappy coding!\n","permalink":"http://localhost:1313/posts/deepseek/","summary":"\u003ch1 id=\"running-deepseek-r1-15b-on-raspberry-pi-5-cpu-only\"\u003eRunning DeepSeek-R1 1.5B on Raspberry Pi 5 (CPU-Only)\u003c/h1\u003e\n\u003ch2 id=\"technical-insights\"\u003eTechnical Insights\u003c/h2\u003e\n\u003ch3 id=\"why-can-we-run-this-on-raspberry-pi-5\"\u003eWhy Can We Run This on Raspberry Pi 5?\u003c/h3\u003e\n\u003cp\u003eThanks to open-source advancements, we can now run large-scale AI models on small devices like the Raspberry Pi 5. Key factors enabling this include:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eOptimized lightweight models\u003c/strong\u003e: DeepSeek-R1 1.5B is built efficiently to run on limited hardware.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eARM64 Support\u003c/strong\u003e: Modern AI frameworks support ARM-based architectures, enabling their use on RPi5.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eOpen-source software\u003c/strong\u003e: Platforms like Ollama make AI deployment accessible to all.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"performance-considerations\"\u003ePerformance Considerations\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eRunning this model on an RPi5 \u003cstrong\u003ewithout a GPU\u003c/strong\u003e will be CPU-intensive.\u003c/li\u003e\n\u003cli\u003eConsider \u003cstrong\u003ereducing active processes\u003c/strong\u003e to free up memory.\u003c/li\u003e\n\u003cli\u003eIf performance lags, use a \u003cstrong\u003elighter model\u003c/strong\u003e or \u003cstrong\u003eexternal processing (cloud inference).\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eNo GPU acceleration was used\u003c/strong\u003e in this setup, meaning all computations rely solely on the CPU, which may affect inference speeds.\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003cp\u003eThis guide covers the installation and execution of DeepSeek-R1 1.5B on a Raspberry Pi 5, following the steps demonstrated in your images.\u003c/p\u003e","title":"DeepSeek-R1 on Raspberry Pi 5: Open-Source AI Without a GPU"},{"content":"Setting Up Neovim: An Easy and Beginner\u0026rsquo;s Guide Neovim is a modern and extensible text editor that enhances Vim’s capabilities. If you\u0026rsquo;re using Linux, setting up Neovim can be a rewarding experience, allowing you to customize it for an efficient workflow. In this guide, we\u0026rsquo;ll cover installing Neovim, setting up a basic configuration, and enhancing it with essential plugins to turn it into a full-fledged IDE.\n1. Installing Neovim sudo pacman -S neovim 2. Setting Up Neovim Configuration Neovim’s configuration is stored in ~/.config/nvim/. Create the directory and initialize a basic configuration:\nmkdir -p ~/.config/nvim nvim ~/.config/nvim/init.lua Minimal Configuration (init.lua) Add the following settings to your init.lua file:\n-- Enable line numbers vim.opt.number = true vim.opt.relativenumber = true -- Set tab size vim.opt.expandtab = true vim.opt.shiftwidth = 4 vim.opt.tabstop = 4 -- Enable mouse support vim.opt.mouse = \u0026#34;a\u0026#34; -- Set clipboard to system clipboard vim.opt.clipboard = \u0026#34;unnamedplus\u0026#34; Save and exit Neovim.\n3. Installing a Plugin Manager The best plugin manager for Neovim is lazy.nvim. Install it by running:\ngit clone --depth 1 https://github.com/folke/lazy.nvim.git \\ ~/.local/share/nvim/lazy/lazy.nvim Then, update your init.lua to load it:\nlocal lazypath = vim.fn.stdpath(\u0026#34;data\u0026#34;) .. \u0026#34;/lazy/lazy.nvim\u0026#34; if not vim.loop.fs_stat(lazypath) then vim.fn.system({ \u0026#34;git\u0026#34;, \u0026#34;clone\u0026#34;, \u0026#34;--filter=blob:none\u0026#34;, \u0026#34;https://github.com/folke/lazy.nvim.git\u0026#34;, lazypath }) end vim.opt.rtp:prepend(lazypath) 4. Installing Essential Plugins With lazy.nvim installed, you can add plugins in init.lua:\nrequire(\u0026#34;lazy\u0026#34;).setup({ \u0026#34;nvim-treesitter/nvim-treesitter\u0026#34;, -- Syntax highlighting \u0026#34;nvim-telescope/telescope.nvim\u0026#34;, -- Fuzzy finder \u0026#34;neovim/nvim-lspconfig\u0026#34;, -- LSP support \u0026#34;hrsh7th/nvim-cmp\u0026#34;, -- Auto-completion \u0026#34;hrsh7th/cmp-nvim-lsp\u0026#34;, -- LSP completion source \u0026#34;hrsh7th/cmp-buffer\u0026#34;, -- Buffer completion \u0026#34;hrsh7th/cmp-path\u0026#34;, -- Path completion \u0026#34;hrsh7th/cmp-nvim-lua\u0026#34;, -- Neovim Lua API completion \u0026#34;L3MON4D3/LuaSnip\u0026#34;, -- Snippet engine \u0026#34;saadparwaiz1/cmp_luasnip\u0026#34;, -- Snippet completion \u0026#34;nvim-lualine/lualine.nvim\u0026#34;, -- Status line \u0026#34;nvim-tree/nvim-tree.lua\u0026#34;, -- File explorer \u0026#34;tpope/vim-surround\u0026#34;, -- Surround text objects \u0026#34;tpope/vim-commentary\u0026#34;, -- Commenting shortcuts \u0026#34;lewis6991/gitsigns.nvim\u0026#34;, -- Git integration \u0026#34;akinsho/toggleterm.nvim\u0026#34;, -- Terminal management }) Save and exit Neovim, then open it and run:\n:Lazy sync This will install the plugins automatically.\n5. Setting Up Treesitter Treesitter provides better syntax highlighting and code parsing. Install it by adding the following to your init.lua:\nrequire\u0026#39;nvim-treesitter.configs\u0026#39;.setup { ensure_installed = \u0026#34;all\u0026#34;, highlight = { enable = true, }, indent = { enable = true, }, } Then, update Treesitter by running:\n:TSUpdate 6. Setting Up LSP (Language Server Protocol) LSP enables features like code completion and linting. Install LSP servers for your language:\n# Python sudo pacman -S python-lsp-server # C++ sudo pacman -S clang # JavaScript/TypeScript npm install -g typescript-language-server Then, enable LSP support in Neovim:\nlocal lspconfig = require(\u0026#34;lspconfig\u0026#34;) lspconfig.pyright.setup({}) -- Python lspconfig.ts_ls.setup({}) -- JavaScript/TypeScript lspconfig.clangd.setup({}) -- C++ Restart Neovim and check LSP status:\n:LspInfo 7. Enhancing Auto-Completion with nvim-cmp To enable code auto-completion, update your init.lua:\nlocal cmp = require\u0026#39;cmp\u0026#39; cmp.setup({ mapping = { [\u0026#39;\u0026lt;C-Space\u0026gt;\u0026#39;] = cmp.mapping.complete(), [\u0026#39;\u0026lt;CR\u0026gt;\u0026#39;] = cmp.mapping.confirm({ select = true }), }, sources = { { name = \u0026#39;nvim_lsp\u0026#39; }, { name = \u0026#39;buffer\u0026#39; }, { name = \u0026#39;path\u0026#39; }, { name = \u0026#39;luasnip\u0026#39; }, { name = \u0026#39;nvim_lua\u0026#39; }, } }) 9. Final Thoughts Congratulations! You now have a powerful, customized Neovim setup that functions as a full-fledged IDE. With features like Treesitter, LSP support, auto-completion, syntax highlighting, Git integration, and a file explorer, your development workflow will be much smoother.\nIf you’d like to further improve your Neovim experience, explore more plugins and tweak your settings. Good luck with that!\nFurther Reading Neovim Documentation Awesome Neovim Plugins Arch Wiki: Neovim ","permalink":"http://localhost:1313/posts/setting-up-neovim-on-arch-linux-a-beginners-guide/","summary":"\u003ch1 id=\"setting-up-neovim-an-easy-and-beginners-guide\"\u003eSetting Up Neovim: An Easy and Beginner\u0026rsquo;s Guide\u003c/h1\u003e\n\u003cp\u003eNeovim is a modern and extensible text editor that enhances Vim’s capabilities. If you\u0026rsquo;re using Linux, setting up Neovim can be a rewarding experience, allowing you to customize it for an efficient workflow. In this guide, we\u0026rsquo;ll cover installing Neovim, setting up a basic configuration, and enhancing it with essential plugins to turn it into a full-fledged IDE.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"1-installing-neovim\"\u003e\u003cstrong\u003e1. Installing Neovim\u003c/strong\u003e\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003esudo pacman -S neovim\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003chr\u003e\n\u003ch2 id=\"2-setting-up-neovim-configuration\"\u003e\u003cstrong\u003e2. Setting Up Neovim Configuration\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003eNeovim’s configuration is stored in \u003ccode\u003e~/.config/nvim/\u003c/code\u003e. Create the directory and initialize a basic configuration:\u003c/p\u003e","title":"Setting Up Neovim: A Beginner's Guide"},{"content":"Linux Kernal The majority of the kernel\u0026rsquo;s code is written in C, leveraging extensions provided by the GNU Compiler Collection (GCC) beyond standard C. Additionally, it includes assembly code for architecture-specific functions, such as optimizing memory usage and task execution. Architecturally, the Linux kernel is monolithic, meaning the entire OS operates within kernel space. However, it features a modular design, allowing software components to be integrated as modules, including dynamic loading.\nWhat Is A Kernel Module? A Linux kernel module is precisely defined as a code segment capable of dynamic loading and unloading within the kernel as needed. These modules enhance kernel capabilities without necessitating a system reboot. A notable example is seen in the device driver module, which facilitates kernel interaction with hardware components linked to the system.\nWriting a Custom Linux Kernel Module Linux kernel modules (LKMs) allow developers to extend the functionality of the Linux kernel without modifying its source code. This guide walks through writing a simple kernel module from scratch. Kernel modules are pieces of code that can be dynamically loaded and unloaded from the Linux kernel at runtime. They enable functionality such as device drivers, file system support, and system call extensions without requiring a kernel recompilation. LKMs are particularly useful for developing hardware drivers and testing new kernel features without rebooting the system.\nPrerequisites Ensure you have the necessary development tools installed. On an Arch Linux system, install them with:\nsudo pacman -Syu linux-headers base-devel Creating a Simple Kernel Module 1. Writing the Module Source Code Create a file named hello_module.c:\n#include \u0026lt;linux/module.h\u0026gt; #include \u0026lt;linux/kernel.h\u0026gt; #include \u0026lt;linux/init.h\u0026gt; MODULE_LICENSE(\u0026#34;GPL\u0026#34;); MODULE_AUTHOR(\u0026#34;Your Name\u0026#34;); MODULE_DESCRIPTION(\u0026#34;A simple Hello World kernel module\u0026#34;); static int __init hello_init(void) { printk(KERN_INFO \u0026#34;Hello, Kernel!\\n\u0026#34;); return 0; } static void __exit hello_exit(void) { printk(KERN_INFO \u0026#34;Goodbye, Kernel!\\n\u0026#34;); } module_init(hello_init); module_exit(hello_exit); Understanding the Kernel Module Code #include \u0026lt;linux/module.h\u0026gt;: Includes the necessary module macros and functions. #include \u0026lt;linux/kernel.h\u0026gt;: Provides kernel logging functions. #include \u0026lt;linux/init.h\u0026gt;: Defines initialization and cleanup macros. MODULE_LICENSE(\u0026quot;GPL\u0026quot;): Specifies the module\u0026rsquo;s license. MODULE_AUTHOR(\u0026quot;Your Name\u0026quot;): Specifies the author of the module. MODULE_DESCRIPTION(\u0026quot;A simple Hello World kernel module\u0026quot;): Provides a brief description. static int __init hello_init(void): The function executed when the module is loaded. static void __exit hello_exit(void): The function executed when the module is unloaded. module_init(hello_init): Registers hello_init as the module\u0026rsquo;s initialization function. module_exit(hello_exit): Registers hello_exit as the module\u0026rsquo;s cleanup function. 2. Writing the Makefile Create a Makefile in the same directory:\nobj-m += hello_module.o all: make -C /lib/modules/$(shell uname -r)/build M=$(PWD) modules clean: make -C /lib/modules/$(shell uname -r)/build M=$(PWD) clean Understanding the Makefile obj-m += hello_module.o: Specifies that hello_module.o is the object to be built as a module. all:: Defines the build target. make -C /lib/modules/$(shell uname -r)/build M=$(PWD) modules: Directs the kernel build system to compile the module. clean:: Cleans up the generated files. make -C /lib/modules/$(shell uname -r)/build M=$(PWD) clean: Cleans the build artifacts. 3. Compiling the Module Run:\nmake 4. Loading and Unloading the Module To insert the module into the kernel:\nsudo insmod hello_module.ko Check the kernel log:\ndmesg | tail To remove the module:\nsudo rmmod hello_module 5. Verifying the Module List loaded modules:\nlsmod | grep hello_module Understanding the Generated Files After building the module, several files are generated:\nhello_module.c: The source code of the module. hello_module.ko: The compiled kernel module file, ready to be loaded into the kernel. hello_module.o: An intermediate object file generated during compilation. hello_module.mod.c: An automatically generated file containing module metadata. hello_module.mod.o: An object file containing metadata compiled from hello_module.mod.c. hello_module.mod: Another metadata file required for module loading. Makefile: Contains instructions for building the module. Module.symvers: Stores information about exported symbols, useful for module dependencies. modules.order: Lists the order in which modules should be loaded. Conclusion This simple kernel module demonstrates the basics of module development. You can expand upon this by adding functionality such as handling parameters or interacting with hardware.\nHappy kernel hacking!\n","permalink":"http://localhost:1313/posts/how-to-write-a-custom-kernel-module/","summary":"\u003ch1 id=\"linux-kernal\"\u003eLinux Kernal\u003c/h1\u003e\n\u003cp\u003eThe majority of the kernel\u0026rsquo;s code is written in C, leveraging extensions provided by the GNU Compiler Collection (GCC) beyond standard C. Additionally, it includes assembly code for architecture-specific functions, such as optimizing memory usage and task execution. Architecturally, the Linux kernel is monolithic, meaning the entire OS operates within kernel space. However, it features a modular design, allowing software components to be integrated as modules, including dynamic loading.\u003c/p\u003e","title":"How to Write a Custom Kernel Module"},{"content":"What is it? gh is GitHub\u0026rsquo;s official command-line tool designed to extend Git\u0026rsquo;s functionality with GitHub-specific features.\nPurpose: Simplifies interaction with GitHub\u0026rsquo;s ecosystem directly from the terminal. Allows you to manage repositories and use GitHub features like issues, pull requests, and workflows.\nKey Features: GitHub-specific tasks:\nAuthentication: Easier login (gh auth login) without dealing with tokens manually. Repository Management: Create, fork, or clone repositories. Issues \u0026amp; Pull Requests: Manage issues, PRs, and comments directly. Actions: Manage and view GitHub Actions workflows. Works alongside Git for basic version control tasks. Use Case: Best for developers heavily using GitHub and its features (for example: pull requests, issues, and actions).\nHow it works Install gh:\n\u0026gt; yay -S github-cli Verify the installation:\n\u0026gt; gh --version Login with GitHub CLI (gh)\n\u0026gt; gh auth login Follow the interactive prompts to log in:\nChoose HTTPS or SSH for connection. Log in via a browser using a one-time code or SSH keys. Verify authentication:\n\u0026gt; gh auth status What\u0026rsquo;s best about it that you can install and use both Git and gh (GitHub CLI) seamlessly. Here\u0026rsquo;s how to set them up:\nInstall Git\n\u0026gt;sudo pacman -S git Check the installation:\n\u0026gt; git --version Using Git and gh Together You can now: Use Git for version control:\n\u0026gt; git clone https://github.com/username/repo.git \u0026gt; git add . \u0026gt; git commit -m \u0026quot;message\u0026quot; \u0026gt; git push ","permalink":"http://localhost:1313/posts/github-cli-githubs-official-command-line-tools/","summary":"\u003ch2 id=\"what-is-it\"\u003eWhat is it?\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003egh\u003c/strong\u003e is GitHub\u0026rsquo;s official command-line tool designed to extend Git\u0026rsquo;s functionality with GitHub-specific features.\u003c/p\u003e\n\u003ch2 id=\"purpose\"\u003ePurpose:\u003c/h2\u003e\n\u003cp\u003eSimplifies interaction with GitHub\u0026rsquo;s ecosystem directly from the terminal. Allows you to manage repositories and use GitHub features like issues, pull requests, and workflows.\u003c/p\u003e\n\u003ch2 id=\"key-features\"\u003eKey Features:\u003c/h2\u003e\n\u003cp\u003eGitHub-specific tasks:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAuthentication: Easier login (gh auth login) without dealing with tokens manually.\u003c/li\u003e\n\u003cli\u003eRepository Management: Create, fork, or clone repositories.\u003c/li\u003e\n\u003cli\u003eIssues \u0026amp; Pull Requests: Manage issues, PRs, and comments directly.\u003c/li\u003e\n\u003cli\u003eActions: Manage and view GitHub Actions workflows.\u003c/li\u003e\n\u003cli\u003eWorks alongside Git for basic version control tasks.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"use-case\"\u003eUse Case:\u003c/h2\u003e\n\u003cp\u003eBest for developers heavily using GitHub and its features (for example: pull requests, issues, and actions).\u003c/p\u003e","title":"GitHub CLI: GitHub's Official Command Line Tools"},{"content":"Connecting a Raspberry Pi 5 to a USB TTY cable is a common way to interact with it through a serial connection, especially for debugging or setting up the device without using a display.\nPrerequists\nRaspberry Pi 5. USB TTY (serial) cable. Computer with a terminal emulator (minicom/screen). GPIO pinout diagram of Raspberry Pi 5 (for reference). Power source for Raspberry Pi (optional if USB TTY can power it, though not recommended). Before Starting! Issuse with firmware UART does NOT work on the RPI5 from the factory. We will need a firmware update to fix this that prevents the dtoverlays for UARTs from working.\nInstall rpi-update with the following commands:\n\u0026gt; sudo curl -L --output /usr/bin/rpi-update https://raw.githubusercontent.com/Hexxeh/rpi-update/master/rpi-update \u0026amp;\u0026amp; sudo chmod +x /usr/bin/rpi-update Then update the firmware on your RPI5 with:\n\u0026gt; sudo rpi-update Enable UART To manually configure UART, you can edit the config.txt file.\nEdit /boot/firmware/config.txt and add:\n\u0026gt; enable_uart=1 How to Connect Locate the GPIO Pins Find the GPIO header on the Raspberry Pi 5. Identify the following pins: GND (Ground): Usually black wire on the USB TTY cable. TX (Transmit): Sends data from the Pi to the computer. RX (Receive): Receives data from the computer to the Pi.\nUse a GPIO pinout chart to locate these pins. For Raspberry Pi 5, it will likely be similar to previous models. Making connections You will need to connect:\nGND with Ground - Pin# 06 TX with GPIO14 - Pin# 08 RX with GPIO15 - Pin# 10 Plug the USB TTY Cable into the Computer\nInsert the USB end of the TTY cable into your computer. The cable will create a virtual COM port (e.g /dev/ttyUSB0). Configure and Access Serial Console\nOpen a terminal.\nIdentify the port with:\n\u0026gt; ls /dev/ttyUSB* Use a terminal emulator like screen or minicom to connect:\n\u0026gt; screen /dev/ttyUSB0 115200 *Replace /dev/ttyUSB0 with the actual port name.\nTurn on the Raspberry Pi. If everything is set up correctly, you should see boot messages in the terminal. Log in to the Pi using the default username (pi) and password (raspberry), or your custom credentials. You should see something similar to this.\nThis is it! You have done it. Congrats!\n","permalink":"http://localhost:1313/posts/how-to-connect-a-raspberry-pi-5-to-usb-tty-cable/","summary":"\u003cp\u003eConnecting a Raspberry Pi 5 to a USB TTY cable is a common way to interact with it through a serial connection, especially for debugging or setting up the device without using a display.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003ePrerequists\u003c/strong\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eRaspberry Pi 5.\u003c/li\u003e\n\u003cli\u003eUSB TTY (serial) cable.\u003c/li\u003e\n\u003cli\u003eComputer with a terminal emulator (minicom/screen).\u003c/li\u003e\n\u003cli\u003eGPIO pinout diagram of Raspberry Pi 5 (for reference).\u003c/li\u003e\n\u003cli\u003ePower source for Raspberry Pi (optional if USB TTY can power it, though not recommended).\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"before-starting\"\u003e\u003cstrong\u003eBefore Starting!\u003c/strong\u003e\u003c/h3\u003e\n\u003ch3 id=\"issuse-with-firmware\"\u003e\u003cstrong\u003e\u003ca href=\"https://forums.raspberrypi.com/viewtopic.php?t=361397#p2171244\"\u003eIssuse with firmware\u003c/a\u003e\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003eUART does NOT work on the RPI5 from the factory. We will need a firmware update to fix this that prevents the dtoverlays for UARTs from working.\u003c/p\u003e","title":"How to Connect a Raspberry PI 5 to USB TTY Cable"},{"content":"Hosting a website on GitHub Pages with Hugo involves the following steps:\nCreating a website 1. Install Hugo and git\n\u0026gt; sudo pacman -S Hugo 2. Create a new Hugo site\n\u0026gt; hugo new site your-website 3. Add a Theme\nNavigate to your website directory and add a theme. You can choose one from the Hugo Themes .\n\u0026gt; cd your-website \u0026gt; git init \u0026gt; git submodule add https://github.com/adityatelange/hugo-PaperMod.git themes/hugo-PaperMod Now you will need to update the hugo.toml file for them to take effect. To do so you can either echo or addd it in the file.\n\u0026gt; echo \u0026quot;theme = 'hugo-PaperMod'\u0026quot; \u0026gt;\u0026gt; hugo.toml To view the website you can run it locally using Hugo\u0026rsquo;s development server to view the site. You can add -D to see your drafts.\n\u0026gt; hugo server 3. Add Content\nTo add a new page to your site.\n\u0026gt; hugo new content content/posts/yout-first-post.md This is it You have done it. YAY!\nHosting it on GitHub 1. Create a GitHub repository.\nClick the + icon in the top-right corner of:\u0026gt; [!WARNING] the GitHub interface and select New repository. Enter a repository name: yourusername.github.io Click Create repository. 2. Add Files for Your website\nClone the repository locally using Git:\ngit clone https://github.com//.git\nAdd your static site files (generated by Hugo) to the repository. Commit and push the changes:\n\u0026gt; git add -A \u0026gt; git commit -s -m \u0026quot;Initial commit\u0026quot; \u0026gt; git push origin main 3. Configure the Repository for GitHub Pages\nGo to the Settings tab of your new repository. Scroll down to the Pages section. Settings \u0026gt; Pages. In the center of your screen you will see this: Build and development Change the Source to GitHub Actions. 4. Create a file named hugo.yaml in a directory named .github/workflows.\n\u0026gt; mkdir -p .github/workflows \u0026gt; cd ./github/workflows touch hugo.yaml 5. Add content in the YAML file.\n# Sample workflow for building and deploying a Hugo site to GitHub Pages name: Deploy Hugo site to Pages on: # Runs on pushes targeting the default branch push: branches: - main # Allows you to run this workflow manually from the Actions tab workflow_dispatch: # Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages permissions: contents: read pages: write id-token: write # Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued. # However, do NOT cancel in-progress runs as we want to allow these production deployments to complete. concurrency: group: \u0026#34;pages\u0026#34; cancel-in-progress: false # Default to bash defaults: run: shell: bash jobs: # Build job build: runs-on: ubuntu-latest env: HUGO_VERSION: 0.141.0 steps: - name: Install Hugo CLI run: | wget -O ${{ runner.temp }}/hugo.deb https://github.com/gohugoio/hugo/releases/download/v${HUGO_VERSION}/hugo_extended_${HUGO_VERSION}_linux-amd64.deb \\ \u0026amp;\u0026amp; sudo dpkg -i ${{ runner.temp }}/hugo.deb - name: Install Dart Sass run: sudo snap install dart-sass - name: Checkout uses: actions/checkout@v4 with: submodules: recursive fetch-depth: 0 - name: Setup Pages id: pages uses: actions/configure-pages@v5 - name: Install Node.js dependencies run: \u0026#34;[[ -f package-lock.json || -f npm-shrinkwrap.json ]] \u0026amp;\u0026amp; npm ci || true\u0026#34; - name: Build with Hugo env: HUGO_CACHEDIR: ${{ runner.temp }}/hugo_cache HUGO_ENVIRONMENT: production TZ: America/Los_Angeles run: | hugo \\ --gc \\ --minify \\ --baseURL \u0026#34;${{ steps.pages.outputs.base_url }}/\u0026#34; - name: Upload artifact uses: actions/upload-pages-artifact@v3 with: path: ./public # Deployment job deploy: environment: name: github-pages url: ${{ steps.deployment.outputs.page_url }} runs-on: ubuntu-latest needs: build steps: - name: Deploy to GitHub Pages id: deployment uses: actions/deploy-pages@v4 5. Commit and push your GitHub repository.\n\u0026gt;git add -A \u0026gt;git commit -m \u0026quot;Create hugo.yaml\u0026quot; \u0026gt;git push 6. Deployment status From GitHub’s main menu, choose Actions. When GitHub has finished building and deploying your site, the color of the status indicator will change to green.\nStep 5: Verify Your GitHub Pages Site\nThe site will be live at https://yourusername.github.io.\n","permalink":"http://localhost:1313/posts/hosting-a-website-on-github-pages-with-hugo/","summary":"\u003cp\u003eHosting a website on GitHub Pages with Hugo involves the following steps:\u003c/p\u003e\n\u003ch1 id=\"creating-a-website\"\u003eCreating a website\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e1. Install Hugo and git\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; sudo pacman -S Hugo\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e2. Create a new Hugo site\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; hugo new site your-website\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e3. Add a Theme\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eNavigate to your website directory and add a theme. You can choose one from the \u003ca href=\"https://themes.gohugo.io/\"\u003eHugo Themes\u003c/a\u003e .\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; cd your-website\n\u0026gt; git init \n\u0026gt; git submodule add https://github.com/adityatelange/hugo-PaperMod.git themes/hugo-PaperMod\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow you will need to update the hugo.toml file for them to take effect. To do so you can either \u003cem\u003eecho\u003c/em\u003e or addd it in the file.\u003c/p\u003e","title":"Hosting a Website on Github Pages With Hugo"},{"content":"KVM Kernel-based Virtual Machine is a free and open-source virtualization module in the Linux kernel that allows the kernel to function as a hypervisor.\nInstallation For updates, run the following command:\n$ sudo pacman -Syu QEMU/KVM installation: We\u0026rsquo;ll install qemu and all the utils required:\n$ sudo pacman -S qemu vde2 ebtables iptables-nft nftables dms masq bridge-utils ovmf swptm Virtual Machine Manager installation: The virt-manager application is a graphical user interface for managing virtual machines through libvirt. It primarily targets KVM VMs.\n$ sudo pacman -S virt-manager Now everything is set to work. We can move towards downloading archlinux .iso file.\nDownload .iso file: Head towards: https://archlinux.org/download/ Scroll through and look for the server closest to you. Download archlinux-2024.10.01-x86_64.iso file. Setting up: Open terminal and run the following command:\n$ virt-manager You will see an interface similar to this:\nClick on \u0026lsquo;create a new virtual machine\u0026rsquo; (option with star). Select \u0026lsquo;Local install media\u0026rsquo;. Browse to your \u0026lsquo;archlinux-2024.10.01-x86_64.iso\u0026rsquo;. Add your desired VM configuration and create a disk image. Boot Menu: You will be prompted to a boot menu.\nSelect the topmost option to start the installation process. Archlinux Installer: You will be prompted to a terminal. The first step is to check if you are connected to the internet.\nRun:\n# ip addr show If it shows an IP address and says \u0026lsquo;UP\u0026rsquo;, that means you are good to go.\nIf not: You will need to connect to the internet using the \u0026lsquo;iwctl\u0026rsquo; method for Wi-Fi.\n# iwctl To search networks in your vicinity:\n[iwd]# station [your_wifi_interface] get-networks Get the name of the network you want to connect to. Exit from this prompt using \u0026rsquo;exit\u0026rsquo;.\nTo connect to the desired Wi-Fi network, run:\n# iwctl --passphrase \u0026#34;[wifi_password]\u0026#34; station [your_wifi_interface] connect [wifi_name] You can again run ip addr show to check if you are connected to the network.\nNow you can run the installation command. We\u0026rsquo;ll be using the archinstall method.\n# archinstall You will be prompted to an interface similar to this:\nWe will install Arch using this interface. Go through each option:\nArchinstall language: Choose your preferred language. Mirrors: Select the mirror region closest to you. Use \u0026lsquo;/\u0026rsquo; to search. Locales: Set language and keyboard layout. Disk configuration: Choose Best-effort default partition to format the system. Bootloader: Use the default \u0026lsquo;Grub\u0026rsquo; option. Swap: Select Swap on zram (default). Hostname: Leave as it is. Root password: Set the password for sudo/root privileges. User account: Set up a user account. Profile: Select Desktop. It includes essential packages. Others include Minimal, Server, and Xorg. In Desktop, select your desktop environment. We\u0026rsquo;ll use Gnome for simplicity.\nAudio: Use PipeWire (default) or PulseAudio. Kernels: Use the linux kernel. Additional packages: Install any required packages. Network Configuration: Use NetworkManager for a GUI in Gnome. Timezone: Set the timezone closest to you and enable time sync. Press Install. Congratulations! You\u0026rsquo;ve successfully installed Arch Linux.\n","permalink":"http://localhost:1313/posts/arch_kvm/","summary":"\u003ch1 id=\"kvm\"\u003eKVM\u003c/h1\u003e\n\u003cp\u003eKernel-based Virtual Machine is a free and open-source virtualization module in the Linux kernel that allows the kernel to function as a hypervisor.\u003c/p\u003e\n\u003ch2 id=\"installation\"\u003eInstallation\u003c/h2\u003e\n\u003cp\u003eFor updates, run the following command:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ sudo pacman -Syu\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"qemukvm-installation\"\u003eQEMU/KVM installation:\u003c/h3\u003e\n\u003cp\u003eWe\u0026rsquo;ll install qemu and all the utils required:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ sudo pacman -S qemu vde2 ebtables iptables-nft nftables dms masq bridge-utils ovmf swptm\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"virtual-machine-manager-installation\"\u003eVirtual Machine Manager installation:\u003c/h3\u003e\n\u003cp\u003eThe virt-manager application is a graphical user interface for managing virtual machines through libvirt. It primarily targets KVM VMs.\u003c/p\u003e","title":"archlinux installation in hypervisor through QEMU/KVM"},{"content":"","permalink":"http://localhost:1313/posts/github-cli-githubs-official-command-line-tool/","summary":"","title":""},{"content":"1. Introduction Sometimes you need to share a local application with the outside world — maybe to demo your project, test a webhook, or allow a teammate to access your development server.\nNormally, you’d need a public IP, port forwarding, or a cloud server. ngrok removes all that complexity by creating a secure tunnel from the internet directly to your machine, giving you a public URL instantly.\nIn this guide, we’ll walk through:\nInstalling ngrok on popular Linux distributions Authenticating your installation Exposing a local service to the internet Adding basic security Practical examples for real-world usage 2. Prerequisites Before we begin, make sure you have:\nA terminal A free ngrok account (for authentication token) A running local service (e.g., a Python HTTP server, web app, or API) 3. Installing ngrok on Linux We’ll cover installation for Arch Linux, Debian/Ubuntu, and Fedora.\n3.1 Arch Linux This package is not in the official repos, install it from the AUR:\nyay -S ngrok 3.2 Debian / Ubuntu sudo apt update sudo apt install snapd sudo snap install ngrok Alternatively, download the binary from the ngrok downloads page.\n3.3 Fedora sudo dnf install snapd sudo ln -s /var/lib/snapd/snap /snap sudo snap install ngrok 4. Authenticating ngrok Once installed, you need to connect it to your account so you can use custom domains, longer session times, and access the dashboard.\nSign in to ngrok dashboard. -\u0026gt; Your AuthToken Copy your AuthToken. Run: ngrok config add-authtoken \u0026lt;YOUR_TOKEN\u0026gt; You will see: Authtoken saved to configuration file: ~/.config/ngrok/ngrok.yml 5. Exposing a Local Service For example, if your local web server is running on port 8080:\nngrok http 8080 You’ll see output like:\nNow you can share the HTTPS URL with anyone. It wil be similar to: https://random.string.ngrok-free.app\n6. Adding Basic Security You can protect your tunnel with a simple username and password:\nngrok http --basic-auth=\u0026#34;user:password\u0026#34; 8080 Anyone visiting the public link will need credentials.\n7. Common Use Cases Webhook testing — Connect services like GitHub, Stripe, or Twilio to your local environment. Temporary demos — Share work-in-progress with clients without deployment. Remote device access — SSH into a Raspberry Pi without changing router settings. 8. Conclusion In just a few commands, you’ve learned how to:\nInstall ngrok on popular Linux distros Authenticate your installation Share a local service securely From here, you can explore ngrok’s advanced features like static domains, IP allowlists, and traffic inspection.\n","permalink":"http://localhost:1313/posts/ngrok/","summary":"\u003ch2 id=\"1-introduction\"\u003e1. Introduction\u003c/h2\u003e\n\u003cp\u003eSometimes you need to share a local application with the outside world — maybe to demo your project, test a webhook, or allow a teammate to access your development server.\u003c/p\u003e\n\u003cp\u003eNormally, you’d need a public IP, port forwarding, or a cloud server. \u003cstrong\u003engrok\u003c/strong\u003e removes all that complexity by creating a \u003cstrong\u003esecure tunnel\u003c/strong\u003e from the internet directly to your machine, giving you a public URL instantly.\u003c/p\u003e\n\u003cp\u003eIn this guide, we’ll walk through:\u003c/p\u003e","title":"Ngrok: Expose Localhost to the Internet"},{"content":"Creating a WhatsApp AI Assistant Using n8n: A Step-by-Step Guide Build your own AI-powered WhatsApp chatbot using n8n, WhatsApp Business Cloud API, and OpenAI. This guide walks you through every step—from setup to testing—with real-world error handling, solutions, and an example production-ready workflow.\n1. Introduction Want to chat with an AI on WhatsApp? In this tutorial, you\u0026rsquo;ll learn how to build a WhatsApp AI Assistant using:\nn8n (automation tool) WhatsApp Business Cloud API OpenAI (for generating intelligent replies) By the end, you\u0026rsquo;ll have a working chatbot and gain hands-on experience with APIs, webhooks, and automation.\n2. Prerequisites n8n account (Cloud or self-hosted) Meta Developer account with WhatsApp Business Cloud API access OpenAI API key Basic understanding of APIs and webhook workflows 3. Registering Your WhatsApp Business App A. Create WhatsApp App in Meta Developer Visit Meta for Developers Create a new app: choose Business → WhatsApp Link or create a WhatsApp Business Account B. Obtain Testing Credentials Your app dashboard will show:\nTest phone number Phone Number ID Temporary access token (valid for only 24 hours) Tip: For long-term use, generate a 60-day system-user token later.\nC. Add Recipients to Test List By default, only approved numbers can receive messages:\nNavigate to WhatsApp → API Setup Add numbers in E.164 format (e.g., +923001234567) Users must accept the invite via WhatsApp to become valid recipients 4. Configuring Your Webhook in n8n A. Create a Webhook Node Method: GET (for initial verification) Endpoint example: https://yourname.app.n8n.cloud/webhook/your-unique-id/webhook B. Verify the Webhook with Meta In your app’s Webhook section:\nCallback URL: your n8n webhook URL Verify Token: any secret string you choose (e.g., mySecret2025) C. Echo Back Meta’s Challenge Configure n8n\u0026rsquo;s Webhook node response:\nField Value Response Mode On Received Response Body {{$json[\u0026quot;query\u0026quot;][\u0026quot;hub.challenge\u0026quot;]}} This ensures Meta can verify your endpoint successfully.\n5. Processing Incoming Messages WhatsApp sends JSON data with structure like:\n{ \u0026#34;entry\u0026#34;: [ { \u0026#34;changes\u0026#34;: [ { \u0026#34;value\u0026#34;: { \u0026#34;messages\u0026#34;: [ { \u0026#34;from\u0026#34;: \u0026#34;923001234567\u0026#34;, \u0026#34;text\u0026#34;: { \u0026#34;body\u0026#34;: \u0026#34;Hello bot!\u0026#34; } } ], \u0026#34;metadata\u0026#34;: { \u0026#34;phone_number_id\u0026#34;: \u0026#34;698352170035199\u0026#34; } } } ] } ] } Extract:\nfrom: user’s number text.body: user’s text metadata.phone_number_id: correct sender ID 6. Integrating OpenAI for Responses Obtaining Your OpenAI API Key Before integrating OpenAI into your n8n workflow, you’ll need to get an API key from OpenAI.\nStep-by-Step: Sign up or log in to OpenAI. Navigate to your API Keys page. Click \u0026ldquo;Create new secret key\u0026rdquo;. Optionally name your key, then copy it immediately (you won’t be able to view it again). In n8n: Go to Credentials → Add New → choose OpenAI or HTTP Request. Paste your API key into the key field. Save the credentials. Security Tip: Keep your key private. Do not share it or commit it to public repositories.\nUse an HTTP Request node to call OpenAI:\nPOST https://api.openai.com/v1/chat/completions Authorization: Bearer YOUR_OPENAI_API_KEY Content-Type: application/json { \u0026#34;model\u0026#34;: \u0026#34;gpt-4o-mini\u0026#34;, \u0026#34;messages\u0026#34;: [ { \u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;You are a helpful WhatsApp AI assistant.\u0026#34; }, { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;{{ $json[...] }}\u0026#34; } ] } Replace {{ $json[...] }} with the actual path to the user\u0026rsquo;s message text from the Webhook node.\n7. Sending Replies via WhatsApp Use another HTTP Request node to respond:\nPOST https://graph.facebook.com/v21.0/{{ $json[...] }}/messages Authorization: Bearer YOUR_LONG_LIVED_TOKEN Content-Type: application/json { \u0026#34;messaging_product\u0026#34;: \u0026#34;whatsapp\u0026#34;, \u0026#34;to\u0026#34;: \u0026#34;{{ $json[...] }}\u0026#34;, \u0026#34;text\u0026#34;: { \u0026#34;body\u0026#34;: \u0026#34;{{ $node[\u0026#39;OpenAI Response\u0026#39;].json.choices[0].message.content }}\u0026#34; } } Use the metadata’s phone_number_id for the endpoint and from for the recipient. This avoids hardcoding and ensures proper routing.\n8. Example n8n Workflow Here’s the actual n8n workflow I used for my WhatsApp AI assistant. It integrates a product brochure PDF into a vector store for AI-powered Q\u0026amp;A, and handles WhatsApp message flow.\nStep-by-Step Breakdown: 1. Download Product Brochure PDF Downloads the brochure from a given URL. Extracts text from the PDF. 2. Create Product Brochure Vector Store Splits large text into chunks. Generates embeddings using OpenAI. Saves them in a vector store for fast semantic search. 3. Use the WhatsApp Trigger Listens for incoming WhatsApp messages. Routes them to supported or unsupported handlers. 3a. Handle Unsupported Messages Replies with a friendly error if the message type is not text. 4. Sales AI Agent Responds Uses OpenAI with memory + vector store retrieval to answer based on brochure content. 5. Reply to WhatsApp User Sends the AI-generated message back to the sender. Why this is effective:\nContext-aware answers via buffer memory. Reduced hallucinations thanks to vector store grounding. Smooth error handling for unsupported message types. 9. Common Errors \u0026amp; Fixes Recipient phone number not in allowed list\n→ Add as test number or switch to Live mode\n401 – Session expired\n→ Refresh token via Graph API:\nGET https://graph.facebook.com/v21.0/oauth/access_token ?grant_type=fb_exchange_token \u0026amp;client_id=YOUR_APP_ID \u0026amp;client_secret=YOUR_APP_SECRET \u0026amp;fb_exchange_token=YOUR_CURRENT_TOKEN Webhook verification failed\n→ Ensure verify token matches between Meta and n8n and echo hub.challenge\nNo execution data available\n→ Trigger workflow via actual WhatsApp message, not manual run\n10. Going Live Add a Privacy Policy URL in Meta App → Settings → Basic (required for live access) Switch app to Live mode once all compliance items are met Remove restricted recipient list Use WhatsApp message templates for messages sent after 24 hours of user interaction 11. Conclusion \u0026amp; Next Steps Congrats! You now have a WhatsApp AI Assistant built with n8n and OpenAI.\nWhere to go from here: Wire up custom knowledge (PDFs, documents) Implement memory for conversation context Launch multilingual support Export n8n workflow as JSON for reuse Need help? Join the n8n Community Forum or OpenAI Discord to connect with fellow builders.\nHappy automating!\n","permalink":"http://localhost:1313/posts/creating-whatsapp-ai-assistant-using-n8n2/","summary":"\u003ch1 id=\"creating-a-whatsapp-ai-assistant-using-n8n-a-step-by-step-guide\"\u003eCreating a WhatsApp AI Assistant Using n8n: A Step-by-Step Guide\u003c/h1\u003e\n\u003cp\u003eBuild your own AI-powered WhatsApp chatbot using \u003cstrong\u003en8n\u003c/strong\u003e, \u003cstrong\u003eWhatsApp Business Cloud API\u003c/strong\u003e, and \u003cstrong\u003eOpenAI\u003c/strong\u003e. This guide walks you through every step—from setup to testing—with real-world error handling, solutions, and an example production-ready workflow.\u003c/p\u003e\n\u003ch2 id=\"1-introduction\"\u003e1. Introduction\u003c/h2\u003e\n\u003cp\u003eWant to chat with an AI on WhatsApp? In this tutorial, you\u0026rsquo;ll learn how to build a \u003cstrong\u003eWhatsApp AI Assistant\u003c/strong\u003e using:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003en8n\u003c/strong\u003e (automation tool)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eWhatsApp Business Cloud API\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eOpenAI\u003c/strong\u003e (for generating intelligent replies)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eBy the end, you\u0026rsquo;ll have a working chatbot and gain hands-on experience with APIs, webhooks, and automation.\u003c/p\u003e","title":"Creating Whatsapp Ai Assistant Using N8n"},{"content":"Introduction A memory leak occurs when a program allocates memory dynamically (e.g., using malloc) and fails to release it using free. This leftover allocation can lead to wasted memory resources, eventually causing slowdowns or system crashes in long-running programs.\nValgrind is a powerful command-line tool available on Linux systems. It helps developers detect:\nMemory leaks Invalid memory access Uninitialized memory usage Mismatched memory management In this guide, we\u0026rsquo;ll walk through examples in C to learn how to detect and fix memory leaks using Valgrind.\nInstalling Valgrind On Arch Linux sudo pacman -S valgrind On Ubuntu/Debian sudo apt install valgrind On Fedora sudo dnf install valgrind Troubleshooting: Valgrind \u0026ldquo;cannot find mandatory redirection\u0026rdquo; on Arch Linux If you run Valgrind and get an error like:\nvalgrind: Fatal error at startup: a function redirection\nvalgrind: which is mandatory for this platform-tool combination\nvalgrind: cannot be set up.\n…you might be running a 32-bit executable on a 64-bit Arch Linux system.\nWhy this happens Valgrind needs to hook into low-level glibc functions from your binary’s architecture.\nIf your binary is 32-bit, Arch requires the 32-bit glibc runtime (lib32-glibc).\nWithout it, Valgrind can’t find the right function symbols and quits.\nFix Install the 32-bit glibc package:\nsudo pacman -S lib32-glibc After installation, re-run:\nvalgrind ./your-binary and it should work.\nUbuntu/Debian equivalent: sudo apt install libc6-dbg:i386\nBasic Example: Hello World Code #include \u0026lt;stdio.h\u0026gt; int main() { printf(\u0026#34;Hello World\\n\u0026#34;); return 0; } Compile and Run gcc main.c -o main.out ./main.out Run with Valgrind valgrind ./main.out You should see no errors or memory leaks in the output.\nIntroducing a Memory Leak Static Allocation (Safe) #include \u0026lt;stdio.h\u0026gt; int main() { char str[20] = \u0026#34;Hello\u0026#34;; printf(\u0026#34;%s\\n\u0026#34;, str); return 0; } This uses stack memory, so Valgrind will report no leaks.\nDynamic Allocation (With Leak) #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; int main() { char *str = malloc(20); strcpy(str, \u0026#34;Hello\u0026#34;); printf(\u0026#34;%s\\n\u0026#34;, str); return 0; // Forgot to free memory } Valgrind Output valgrind ./main.out You should see:\ndefinitely lost: 20 bytes in 1 blocks\nFixing the Memory Leak Add free(str); before returning:\nfree(str); Fixed Code #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; int main() { char *str = malloc(20); strcpy(str, \u0026#34;Hello\u0026#34;); printf(\u0026#34;%s\\n\u0026#34;, str); free(str); return 0; } Detailed Valgrind Options Use for deeper analysis:\nvalgrind --leak-check=full ./main.out Or even more detailed:\nvalgrind --leak-check=full --show-leak-kinds=all --track-origins=yes ./main.out Explanation:\n--leak-check=full: Display detailed leak info --show-leak-kinds=all: Show all kinds of leaks (definitely, indirectly lost, etc.) --track-origins=yes: Show where uninitialized values originate Summary Always free() memory allocated with malloc(), calloc(), or realloc(). Close all file streams with fclose(). Use Valgrind to identify and fix: Memory leaks Invalid memory writes Use-after-free bugs Recommended command: valgrind --leak-check=full --track-origins=yes ./your_program Valgrind is a critical tool for writing safe, efficient, and bug-free C programs.\n","permalink":"http://localhost:1313/posts/introductiontovalgrind/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eA \u003cstrong\u003ememory leak\u003c/strong\u003e occurs when a program allocates memory dynamically (e.g., using \u003ccode\u003emalloc\u003c/code\u003e) and fails to release it using \u003ccode\u003efree\u003c/code\u003e. This leftover allocation can lead to wasted memory resources, eventually causing slowdowns or system crashes in long-running programs.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eValgrind\u003c/strong\u003e is a powerful command-line tool available on Linux systems. It helps developers detect:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eMemory leaks\u003c/li\u003e\n\u003cli\u003eInvalid memory access\u003c/li\u003e\n\u003cli\u003eUninitialized memory usage\u003c/li\u003e\n\u003cli\u003eMismatched memory management\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIn this guide, we\u0026rsquo;ll walk through examples in C to learn how to detect and fix memory leaks using Valgrind.\u003c/p\u003e","title":"Detecting and Fixing Memory Leaks with Valgrind"},{"content":"QEMU-KVM on Arch Linux: Running Tiny Core Linux in a Lightweight VM Virtualization is a powerful tool for developers, sysadmins, and tinkerers alike. On Linux, QEMU-KVM stands out as a robust, high-performance virtualization stack. In this blog, well walk through setting up QEMU-KVM on Arch Linux and using it to run Tiny Core Linuxa super-lightweight distro perfect for testing and experimentation.\nWhat is QEMU-KVM QEMU (Quick Emulator) is a generic and open-source machine emulator. On its own, it can emulate various hardware systems. However, when paired with **KVM (Kernel-based Virtual Machine)**a Linux kernel module for virtualizationit can run virtual machines with near-native performance.\nQEMU provides device emulation and user-space management. KVM integrates with the Linux kernel and handles hardware-level virtualization. Together, they effectively form a Type 1 hypervisor because the Linux kernel (with KVM) handles core virtualization tasks directly on hardware.\nStep-by-Step: Installing QEMU-KVM on Arch Linux Step 1: Install Required Packages sudo pacman -Syu sudo pacman -S qemu virt-manager virt-viewer dnsmasq vde2 bridge-utils openbsd-netcat libvirt edk2-ovmf edk2-ovmf is for UEFI firmware support in VMs.\nStep 2: Enable and Start libvirtd sudo systemctl enable --now libvirtd.service Step 3: Add Your User to the libvirt Group sudo usermod -aG libvirt (whoami) newgrp libvirt Step 4: Verify KVM Support lsmod grep kvm And check CPU virtualization support:\negrep -c (vmxsvm) /proc/cpuinfo A value of 1 or more indicates virtualization support.\nExample: Running Tiny Core Linux on QEMU-KVM Now that your system is ready, lets run Tiny Core Linux, a minimalist Linux distro thats only 16MB\nStep 1: Download Tiny Core ISO wget http://tinycorelinux.net/14.x/x86/release/Core-current.iso Or visit http://tinycorelinux.net for the latest release.\nStep 2: Create a Virtual Disk (Optional) qemu-img create -f qcow2 tinycore.qcow2 512M This creates a 512MB disk image. Optional for RAM-only usage.\nStep 3: Launch the VM with KVM Acceleration qemu-system-x86_64 -enable-kvm -m 512 -cpu host -smp 1 -cdrom Core-current.iso -hda tinycore.qcow2 -boot d -net nic -net user -vga virtio -display sdl Key Flags Explained:\n-enable-kvm: Enables KVM hardware acceleration -m 512: Allocates 512MB RAM -cpu host: Uses the host CPU features -cdrom: Points to the Tiny Core ISO -hda: Uses a QCOW2 disk image -boot d: Boots from CD first -net user: Enables simple user-mode networking (e.g., for internet access) -display sdl: Uses SDL window for graphics (you can replace with gtk or virt-manager) Alternate: Boot Tiny Core in RAM Without Disk qemu-system-x86_64 -enable-kvm -m 256 -cdrom Core-current.iso -boot d -net nic -net user -vga std Conclusion With QEMU-KVM, Arch Linux becomes a full-featured Type 1 hypervisor. By combining kernel-level virtualization (KVM) with the flexibility of QEMU, you get a fast, customizable virtualization platform. Running Tiny Core Linux showcases just how lightweight and efficient this setup can be.\nWhether youre building VMs for testing, learning Linux internals, or experimenting with custom environments, QEMU-KVM on Arch is a powerful combination.\nHappy virtualizing\n","permalink":"http://localhost:1313/posts/qemu/","summary":"\u003ch1 id=\"qemu-kvm-on-arch-linux-running-tiny-core-linux-in-a-lightweight-vm\"\u003eQEMU-KVM on Arch Linux: Running Tiny Core Linux in a Lightweight VM\u003c/h1\u003e\n\u003cp\u003eVirtualization is a powerful tool for developers, sysadmins, and tinkerers alike. On Linux, \u003cstrong\u003eQEMU-KVM\u003c/strong\u003e stands out as a robust, high-performance virtualization stack. In this blog, well walk through setting up QEMU-KVM on \u003cstrong\u003eArch Linux\u003c/strong\u003e and using it to run \u003cstrong\u003eTiny Core Linux\u003c/strong\u003ea super-lightweight distro perfect for testing and experimentation.\u003c/p\u003e\n\u003ch2 id=\"what-is-qemu-kvm\"\u003eWhat is QEMU-KVM\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eQEMU (Quick Emulator)\u003c/strong\u003e is a generic and open-source machine emulator. On its own, it can emulate various hardware systems. However, when paired with **KVM (Kernel-based Virtual Machine)**a Linux kernel module for virtualizationit can run virtual machines with near-native performance.\u003c/p\u003e","title":"QEMU-KVM on Arch Linux: Running Tiny Core Linux in a Lightweight VM"},{"content":"Building the Linux Kernel Compiling the Linux Kernel involves multiple steps and can take some time depending on your hardware specifications.\nStep 1: Download the Kernel Source Code Start by visiting the Official Linux Kernel Website and downloading the latest available kernel source code. The downloaded file will be a compressed archive containing all necessary source files.\nStep 2: Extract the Source Code Once the download completes, extract the contents of the compressed archive using the tar command:\ntar xvf linux-6.13.tar.xz If the tar utility is not installed on your system, you can install it using:\nsudo pacman -S tar Note: Always ensure you are using the correct version number in the file name.\nStep 3: Install Required Dependencies To compile the kernel, you need to install various development tools and libraries. Install them using the following command:\nsudo pacman -S git fakeroot ncurses xz bc flex bison base-devel kmod cpio perl binutils util-linux jfsutils e2fsprogs xfsprogs squashfs-tools quota-tools Step 4: Configure the Kernel Navigate into the kernel source directory: cd linux-6.13 Use your current system’s configuration as a base:\nIf zcat is available, run:\nzcat /proc/config.gz \u0026gt; .config Otherwise, use this alternative method:\ncp /proc/config.gz ./ gunzip config.gz mv config .config Customize the kernel using a menu-driven interface:\nmake menuconfig make xconfig make oldconfig Modify the .config file directly:\nOpen it with a text editor:\nsudo vim .config Search for the line:\nCONFIG_EXT4_FS=m And change it to:\nCONFIG_EXT4_FS=y Step 5: Compile the Kernel Determine the number of CPU cores available to speed up compilation: nproc Compile the kernel using the number of cores found above. Replace n with that number: make -j\u0026lt;n\u0026gt; If you encounter any errors during or after this step, back up your .config file and reset the source tree with:\nmake mrproper This command cleans the build environment and restores the source tree to its original state.\nStep 6: Install Kernel Modules Kernel modules are essential for extending the kernel’s functionality and ensuring compatibility with various hardware. Install them with:\nsudo make modules_install Step 7: Install the Kernel You can install the compiled kernel using one of the two methods below:\nAutomatic installation: sudo make install Manual installation (if the above doesn\u0026rsquo;t work):\nCopy the kernel image:\nsudo cp arch/x86/boot/bzImage /boot/vmlinuz-linux-custom Copy the System.map file:\nsudo cp System.map /boot/System.map-linux-custom Copy the kernel configuration file:\nsudo cp .config /boot/config-linux-custom Step 8: Update the Bootloader If you use GRUB, follow these steps to add an entry for your custom kernel:\nFind the UUID of your root partition: lsblk -f Open the custom GRUB configuration file: sudo nvim /etc/grub.d/40_custom Add the following entry (replace paste-your-root-partition-uuid-here with the actual UUID): menuentry \u0026#39;Custom Linux Kernel\u0026#39; { linux /boot/vmlinuz-linux-custom root=UUID=paste-your-root-partition-uuid-here initrd /boot/initramfs-linux.img } Step 9: Generate Initramfs As you\u0026rsquo;ve compiled a new kernel, installed modules, and modified boot entries, generating a new initramfs is necessary. Run:\nsudo mkinitcpio -k 6.13-custom -c /etc/mkinitcpio.conf -g /boot/initramfs-linux-custom.img Make sure the version (6.13-custom) matches your compiled kernel.\nStep 10: Update GRUB Configuration Finally, update the GRUB configuration so that it includes your new kernel entry:\nsudo grub-mkconfig -o /boot/grub/grub.cfg Done! Congratulations! You’ve successfully compiled and installed your custom Linux Kernel. Enjoy your personalized system!\n","permalink":"http://localhost:1313/posts/kernal_compilation/","summary":"\u003ch1 id=\"building-the-linux-kernel\"\u003eBuilding the Linux Kernel\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003eCompiling the Linux Kernel involves multiple steps and can take some time depending on your hardware specifications.\u003c/strong\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"step-1-download-the-kernel-source-code\"\u003eStep 1: Download the Kernel Source Code\u003c/h3\u003e\n\u003cp\u003eStart by visiting the \u003ca href=\"https://www.kernel.org/\"\u003eOfficial Linux Kernel Website\u003c/a\u003e and downloading the latest available kernel source code. The downloaded file will be a compressed archive containing all necessary source files.\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"step-2-extract-the-source-code\"\u003eStep 2: Extract the Source Code\u003c/h3\u003e\n\u003cp\u003eOnce the download completes, extract the contents of the compressed archive using the \u003ccode\u003etar\u003c/code\u003e command:\u003c/p\u003e","title":"How to build Linux Kernal: Step by Step Guide"},{"content":"Introduction So, you’ve built a sleek website with Hugo and deployed it to GitHub Pages. Now, you want to give it a professional touch with a custom domain like yourdomain.tech instead of the default username.github.io URL. This guide walks you through the process step-by-step.\nPrerequisites A Hugo website hosted on GitHub Pages (public repository). A custom domain (e.g., yourdomain.tech) purchased from a registrar like Namecheap, Google Domains, etc. Basic familiarity with DNS settings and GitHub repository configurations. Step 1: Configure Your GitHub Repository First, ensure your GitHub Pages site is set up correctly:\nYour repository should be named \u0026lt;username\u0026gt;.github.io (for user/organization sites) or \u0026lt;repo-name\u0026gt; (for project sites). The gh-pages branch (or the /docs folder) should contain your Hugo-generated static files. Step 2: Configure DNS Settings for Your Domain Option 1: Use an Apex Domain (e.g., yourdomain.tech) If you want your site to live at the root domain (e.g., yourdomain.tech), configure A records in your DNS settings:\nGo to your domain registrar’s DNS management page. Create four A records pointing to GitHub’s IP addresses: Host: @ Type: A Value: 185.199.108.153 TTL: Automatic ","permalink":"http://localhost:1313/posts/customdomain/","summary":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003eSo, you’ve built a sleek website with Hugo and deployed it to GitHub Pages. Now, you want to give it a professional touch with a custom domain like \u003ccode\u003eyourdomain.tech\u003c/code\u003e instead of the default \u003ccode\u003eusername.github.io\u003c/code\u003e URL. This guide walks you through the process step-by-step.\u003c/p\u003e\n\u003ch2 id=\"prerequisites\"\u003ePrerequisites\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003eA Hugo website hosted on GitHub Pages (public repository).\u003c/li\u003e\n\u003cli\u003eA custom domain (e.g., \u003ccode\u003eyourdomain.tech\u003c/code\u003e) purchased from a registrar like Namecheap, Google Domains, etc.\u003c/li\u003e\n\u003cli\u003eBasic familiarity with DNS settings and GitHub repository configurations.\u003c/li\u003e\n\u003c/ol\u003e\n\u003chr\u003e\n\u003ch2 id=\"step-1-configure-your-github-repository\"\u003eStep 1: Configure Your GitHub Repository\u003c/h2\u003e\n\u003cp\u003eFirst, ensure your GitHub Pages site is set up correctly:\u003c/p\u003e","title":"How to up custom domain for GitHub Pages"},{"content":"Exception handling is a crucial aspect of writing robust and reliable Python code. Whether you\u0026rsquo;re a beginner or an experienced developer, getting an error, or exception, in your Python program means the entire program will crash. You don’t want this to happen in real-world programs. Instead, you want the program to detect errors, handle them, and then continue to run. In this blog, we\u0026rsquo;ll explore the fundamentals of exception handling in Python, including syntax, best practices, and advanced techniques.\nWhat Are Exceptions? Exceptions are runtime errors that disrupt the normal flow of a program. For example, trying to open a non-existent file, dividing by zero, or accessing an invalid index in a list will raise exceptions. If unhandled, these exceptions cause your program to crash.\nBasic Syntax: try and except The primary mechanism for handling exceptions in Python is the try-except block. Errors can be handled with with this. The code that could potentially have an error is put in a try clause. The program execution moves to the start of a following except clause if an error happens.\nHere\u0026rsquo;s the basic structure:\ndef cal(value): try: return 10 / value except ZeroDivisionError: print(\u0026#34;Cannot divide by zero!\u0026#34;) print(cal(0)) print(cal(2)) print(cal(3)) How It Works: The code inside the try block is executed. If an exception occurs, Python checks the except blocks for a matching exception type. If a match is found, the corresponding except block runs. Catching Specific Exceptions Always catch specific exceptions to avoid silencing unexpected errors. Python has many built-in exceptions (e.g., ValueError, TypeError, FileNotFoundError).\nimport math x = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) try: print(f\u0026#39;Square Root of {x} is {math.sqrt(x)}\u0026#39;) except ValueError: print(\u0026#39;Number is less than 0\u0026#39;) Output\nThe else Clause The else block runs only if no exceptions were raised in the try block. Use it to separate \u0026ldquo;happy path\u0026rdquo; code from error handling.\nimport math def sqr(value): try: x = math.sqrt(value) except ValueError: print(\u0026#39;Number is less than 0\u0026#39;) else: print(f\u0026#39;The Answer is: {x}\u0026#39;) value = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) sqr(value) Output The finally Clause The finally block runs regardless of whether an exception occurred. It’s ideal for cleanup tasks (e.g., closing files or releasing resources).\nimport math def sqr(value): try: x = math.sqrt(value) except ValueError: print(\u0026#39;Error\u0026#39;) else: print(f\u0026#39;The Answer is: {x}\u0026#39;) finally: print(\u0026#39;Program Ends\u0026#39;) value = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) sqr(value) Output Raising Exceptions Manually Use the raise keyword to trigger exceptions intentionally. This is useful for enforcing constraints.\ndef validate_age(age): if age \u0026lt; 0: raise ValueError(\u0026#34;Age cannot be negative!\u0026#34;) return age try: validate_age(-5) except ValueError as e: print(e) Creating Custom Exceptions Define custom exceptions by subclassing Python’s built-in Exception class. This makes your code more readable and errors more descriptive. (note: I have used RegEx, for that blog will be out soon :) )\nimport re class InvalidEmailError(Exception): \u0026#34;\u0026#34;\u0026#34;Raised when an email format is invalid.\u0026#34;\u0026#34;\u0026#34; pass def send_email(valid,email): if not valid: raise InvalidEmailError(f\u0026#34;Invalid email: {email}\u0026#34;) email = input(\u0026#39;Please enter your email: \u0026#39;) valid = re.match(r\u0026#39;^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\u0026#39;, email) try: send_email(valid, email) except InvalidEmailError as e: print(e) Output Logging a Python Error We can Log an exception in Python with an error. This can be done in the logging.exception() method. This function logs a message with level ERROR on this logger.\nimport math import logging def sqr(value): try: x = math.sqrt(value) except ValueError: logging.exception(\u0026#34;Error\u0026#34;) else: print(f\u0026#39;The Answer is: {x}\u0026#39;) finally: print(\u0026#39;Program Ends\u0026#39;) value = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) sqr(value) Output Best Practices for Exception Handling Catch specific exceptions: Avoid broad except: clauses that hide bugs. Keep try blocks minimal: Only wrap code that might raise an exception. Use finally for cleanup: Ensure resources are released (e.g., closing files). Log exceptions: Use logging.error() instead of print() for production code. Provide meaningful messages: Help debug issues faster with clear error descriptions. Avoid empty except blocks: Silent failures make debugging harder. Conclusion Exception handling is essential for writing better Python applications. By using try-except blocks effectively, catching specific errors, and with else/finally clauses, you can create programs that handle unexpected scenarios.\nNow go forth and write bulletproof Python code!\n","permalink":"http://localhost:1313/posts/exception_handling_in_python/","summary":"\u003cp\u003eException handling is a crucial aspect of writing robust and reliable Python code. Whether you\u0026rsquo;re a beginner or an experienced developer, getting an error, or exception, in your Python program means the entire program will crash. You don’t want this to happen in real-world programs. Instead, you want the program to detect errors, handle them, and then continue to run. In this blog, we\u0026rsquo;ll explore the fundamentals of exception handling in Python, including syntax, best practices, and advanced techniques.\u003c/p\u003e","title":"Exception Handling in Python: A Comprehensive Guide"},{"content":"Have you ever wanted your Python program to do multiple things at once? For example, downloading files while updating the UI, or processing data while listening for user input? That’s where multithreading comes in.\nIn this post, we’ll explore multithreading in Python — what it is, when to use it, and how to use it with simple examples.\n🧠 What is Multithreading? Multithreading is a way to run multiple threads (smaller units of a process) at the same time. It helps make your program more responsive or perform tasks in parallel, especially when tasks are I/O-bound (e.g., network calls, file reading, etc.).\nPython has a built-in module called threading that makes it easy to create and manage threads.\n⚠️ But Wait — Python\u0026rsquo;s GIL Before you jump in, it\u0026rsquo;s important to understand the Global Interpreter Lock (GIL). In CPython (the standard Python implementation), the GIL allows only one thread to execute Python bytecode at a time.\nThis means multithreading in Python is best suited for I/O-bound tasks, not CPU-bound tasks like heavy computations. For CPU-bound tasks, consider multiprocessing instead.\n🛠️ Using the threading Module Here\u0026rsquo;s a basic example to demonstrate multithreading:\nimport threading import time def print_numbers(): for i in range(5): print(f\u0026#34;Number: {i}\u0026#34;) time.sleep(1) def print_letters(): for letter in \u0026#39;abcde\u0026#39;: print(f\u0026#34;Letter: {letter}\u0026#34;) time.sleep(1) # Creating threads t1 = threading.Thread(target=print_numbers) t2 = threading.Thread(target=print_letters) # Starting threads t1.start() t2.start() # Wait for both threads to complete t1.join() t2.join() print(\u0026#34;Both threads have finished.\u0026#34;) 🔍 Output (interleaved): Number: 0 Letter: a Number: 1 Letter: b ... Both functions run at the same time, and you can see their output interleave. That’s multithreading in action!\n📦 Real-World Use Cases Downloading multiple files at once Handling multiple client connections on a server Running background tasks like logging or monitoring Keeping your GUI app responsive while doing other work 🧰 Extra Tools For more advanced usage:\nconcurrent.futures.ThreadPoolExecutor — easier thread management queue.Queue — safe way to share data between threads threading.Lock — prevents race conditions 🧪 Example with ThreadPoolExecutor from concurrent.futures import ThreadPoolExecutor import time def task(name): print(f\u0026#34;{name} starting\u0026#34;) time.sleep(2) print(f\u0026#34;{name} done\u0026#34;) with ThreadPoolExecutor(max_workers=2) as executor: executor.submit(task, \u0026#34;Task 1\u0026#34;) executor.submit(task, \u0026#34;Task 2\u0026#34;) ✅ Final Thoughts Multithreading in Python is a powerful tool when used correctly — especially for I/O-bound programs. Just remember the GIL limitation and use the right tool (like multiprocessing) when working with CPU-heavy tasks.\nThanks for reading! Happy threading 🧵🐍\n","permalink":"http://localhost:1313/posts/multithreading/","summary":"\u003cp\u003eHave you ever wanted your Python program to do multiple things at once? For example, downloading files while updating the UI, or processing data while listening for user input? That’s where \u003cstrong\u003emultithreading\u003c/strong\u003e comes in.\u003c/p\u003e\n\u003cp\u003eIn this post, we’ll explore multithreading in Python — what it is, when to use it, and how to use it with simple examples.\u003c/p\u003e\n\u003ch2 id=\"-what-is-multithreading\"\u003e🧠 What is Multithreading?\u003c/h2\u003e\n\u003cp\u003eMultithreading is a way to run multiple threads (smaller units of a process) at the same time. It helps make your program more responsive or perform tasks in parallel, especially when tasks are I/O-bound (e.g., network calls, file reading, etc.).\u003c/p\u003e","title":"Multithreading in Python"},{"content":"Running a Local LLM on Mobile: Testing PocketPal on iPhone 12 With the increasing accessibility of large language models (LLMs), running them locally on mobile devices is an exciting prospect. I recently tested PocketPal, a mobile LLM interface, on my iPhone 12, using a distilled 4-bit quantized model. Here’s a breakdown of my experience, covering installation, performance, and overall usability.\nWhy Run an LLM on Mobile? Running an LLM locally on a mobile device comes with several advantages:\nPrivacy: No data is sent to external servers. Offline Access: Works without an internet connection. Lower Cost: Avoids API costs associated with cloud-based models. What is Quantization? Quantization is a technique used to reduce the memory and computational requirements of machine learning models by representing their weights with lower precision numbers. Instead of using 32-bit floating-point numbers, models can be compressed into 8-bit or even 4-bit integers while maintaining reasonable accuracy.\nFor LLMs on mobile, 4-bit quantization significantly reduces the model size, making it feasible to run on devices with limited resources. However, this compression can lead to:\nSlightly reduced accuracy due to loss of precision. Faster inference times, as lower-bit computations require less processing power. Lower memory usage, allowing larger models to fit within mobile device constraints. Setting Up and Running PocketPal on iPhone 12 1. Download and Install PocketPal Open the App Store and search for PocketPal AI by Asghar Ghorbani. Download and install the app. Open the app and allow necessary permissions. 2. Adding a Model Navigate to the Models section in the PocketPal app. Click the + button to add a new model. You will see two options: Add from Hugging Face Add Local Model Select Add from Hugging Face to browse available models. 3. Selecting and Downloading a Model Search for DeepSeek-R1-Distill-Qwen-1.5B-Q4_0. Select the model and start downloading it (size: 1.06GB, 1.78B parameters). Once downloaded, the model will appear under the Ready to Use section. 4. Running Benchmarks I ran benchmarks on my iPhone 12 using the DeepSeek-R1-Distill-Qwen-1.5B-Q4_0 model. Here are the key results:\nModel Size: 1.06 GB with 1.78 billion parameters. Benchmark Configuration: Prompt Processing: 512 Token Generation: 128 Pipeline Length: 1 Repetitions: 3 Model Settings: Context Length: 1024 tokens Batch Size: 512 CPU Threads: 4 GPU Layers: 0 (fully CPU-based execution) Flash Attention: Disabled Performance Metrics: Prompt Processing Speed: 26.93 tokens/sec (±2.37) Token Generation Speed: 18.05 tokens/sec (±0.75) Total Execution Time: 1 minute 18 seconds Peak Memory Usage: 35.0% (1GB / 4GB) Live Demo: Running PocketPal on iPhone 12 Watch a live demonstration of PocketPal running a distilled 4-bit quantized model on an iPhone 12: Image: Video demonstration is available here: Video\nAnalysis of Results Decent Processing Speed: With a distilled 4-bit quantized model, the 18.05 t/s token generation rate is quite reasonable for mobile inference. Low Memory Footprint: The 1GB RAM usage means this can run on even mid-range smartphones. CPU-Based Execution: Since 0 GPU layers were used, this proves mobile CPUs are capable of running quantized LLMs efficiently. Flash Attention Disabled: If supported, enabling it might further optimize speed and reduce lag. Final Thoughts Running an LLM locally on an iPhone 12 with PocketPal is feasible but comes with trade-offs. It’s a promising step toward self-hosted AI assistants, though optimization and hardware improvements will be crucial for broader adoption. If you’re privacy-conscious or need offline AI capabilities, it’s definitely worth exploring!\nFuture Improvements I\u0026rsquo;d Like to See: Better memory efficiency to reduce battery drain. Enhanced speed for real-time interaction. More user-friendly model importing and switching. ","permalink":"http://localhost:1313/posts/llmonmobile/","summary":"\u003ch1 id=\"running-a-local-llm-on-mobile-testing-pocketpal-on-iphone-12\"\u003eRunning a Local LLM on Mobile: Testing PocketPal on iPhone 12\u003c/h1\u003e\n\u003cp\u003eWith the increasing accessibility of large language models (LLMs), running them locally on mobile devices is an exciting prospect. I recently tested \u003cstrong\u003ePocketPal\u003c/strong\u003e, a mobile LLM interface, on my \u003cstrong\u003eiPhone 12\u003c/strong\u003e, using a \u003cstrong\u003edistilled 4-bit quantized model\u003c/strong\u003e. Here’s a breakdown of my experience, covering installation, performance, and overall usability.\u003c/p\u003e\n\u003ch2 id=\"why-run-an-llm-on-mobile\"\u003eWhy Run an LLM on Mobile?\u003c/h2\u003e\n\u003cp\u003eRunning an LLM locally on a mobile device comes with several advantages:\u003c/p\u003e","title":"Running Large Language Models on Mobile: DeepSeek R1 on iPhone 12"},{"content":"Running DeepSeek-R1 1.5B on Raspberry Pi 5 (CPU-Only) Technical Insights Why Can We Run This on Raspberry Pi 5? Thanks to open-source advancements, we can now run large-scale AI models on small devices like the Raspberry Pi 5. Key factors enabling this include:\nOptimized lightweight models: DeepSeek-R1 1.5B is built efficiently to run on limited hardware. ARM64 Support: Modern AI frameworks support ARM-based architectures, enabling their use on RPi5. Open-source software: Platforms like Ollama make AI deployment accessible to all. Performance Considerations Running this model on an RPi5 without a GPU will be CPU-intensive. Consider reducing active processes to free up memory. If performance lags, use a lighter model or external processing (cloud inference). No GPU acceleration was used in this setup, meaning all computations rely solely on the CPU, which may affect inference speeds. This guide covers the installation and execution of DeepSeek-R1 1.5B on a Raspberry Pi 5, following the steps demonstrated in your images.\nPrerequisites Raspberry Pi 5 (ARM64 architecture, more powerful than previous versions) Debian-based Linux installed An internet connection At least 4GB RAM recommended for smooth operation Step 1: Log in to Your Raspberry Pi Upon booting, log in using your credentials:\nraspberrypi login: hisam Password: ****** Example login screen: Step 2: Install Curl Curl is required to fetch the installation script. Run:\nsudo apt install curl If it\u0026rsquo;s already installed, you\u0026rsquo;ll see:\ncurl is already the newest version... Example output: Step 3: Install Ollama Ollama is the runtime needed to execute DeepSeek models.\ncurl -fsSL https://ollama.com/install.sh | sh This will download and install Ollama.\nExample installation screen: Step 4: Enable and Start Ollama Service After installation, Ollama sets up a system service.\nollama The output will indicate success:\n\u0026gt;\u0026gt;\u0026gt; Creating ollama user... \u0026gt;\u0026gt;\u0026gt; Enabling and starting ollama service... \u0026gt;\u0026gt;\u0026gt; The Ollama API is now available at 127.0.0.1:11434. Example setup screen: Step 5: Pull and Run DeepSeek-R1 1.5B Now, pull and run the model:\nollama run deepseek-r1:1.5b This will download the model, which is about 1.1 GB in size.\nExample download screen: Once downloaded, the model is ready to run.\nStep 6: Execute DeepSeek-R1 1.5B Run the model and start interacting:\nollama run deepseek-r1:1.5b You should see a prompt where you can start typing queries:\n\u0026gt;\u0026gt;\u0026gt; Hey! Hello! How can I assist you today? 😊 Example interaction: Final Setup Image Video Demonstration Watch Video\nConclusion You have successfully installed and executed DeepSeek-R1 1.5B on your Raspberry Pi 5. This demonstrates the power of open-source AI, making it possible to run advanced models on small-scale devices. If you encounter performance issues, consider optimizing your setup or offloading computations.\nHappy coding!\n","permalink":"http://localhost:1313/posts/deepseek/","summary":"\u003ch1 id=\"running-deepseek-r1-15b-on-raspberry-pi-5-cpu-only\"\u003eRunning DeepSeek-R1 1.5B on Raspberry Pi 5 (CPU-Only)\u003c/h1\u003e\n\u003ch2 id=\"technical-insights\"\u003eTechnical Insights\u003c/h2\u003e\n\u003ch3 id=\"why-can-we-run-this-on-raspberry-pi-5\"\u003eWhy Can We Run This on Raspberry Pi 5?\u003c/h3\u003e\n\u003cp\u003eThanks to open-source advancements, we can now run large-scale AI models on small devices like the Raspberry Pi 5. Key factors enabling this include:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eOptimized lightweight models\u003c/strong\u003e: DeepSeek-R1 1.5B is built efficiently to run on limited hardware.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eARM64 Support\u003c/strong\u003e: Modern AI frameworks support ARM-based architectures, enabling their use on RPi5.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eOpen-source software\u003c/strong\u003e: Platforms like Ollama make AI deployment accessible to all.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"performance-considerations\"\u003ePerformance Considerations\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eRunning this model on an RPi5 \u003cstrong\u003ewithout a GPU\u003c/strong\u003e will be CPU-intensive.\u003c/li\u003e\n\u003cli\u003eConsider \u003cstrong\u003ereducing active processes\u003c/strong\u003e to free up memory.\u003c/li\u003e\n\u003cli\u003eIf performance lags, use a \u003cstrong\u003elighter model\u003c/strong\u003e or \u003cstrong\u003eexternal processing (cloud inference).\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eNo GPU acceleration was used\u003c/strong\u003e in this setup, meaning all computations rely solely on the CPU, which may affect inference speeds.\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003cp\u003eThis guide covers the installation and execution of DeepSeek-R1 1.5B on a Raspberry Pi 5, following the steps demonstrated in your images.\u003c/p\u003e","title":"DeepSeek-R1 on Raspberry Pi 5: Open-Source AI Without a GPU"},{"content":"Setting Up Neovim: An Easy and Beginner\u0026rsquo;s Guide Neovim is a modern and extensible text editor that enhances Vim’s capabilities. If you\u0026rsquo;re using Linux, setting up Neovim can be a rewarding experience, allowing you to customize it for an efficient workflow. In this guide, we\u0026rsquo;ll cover installing Neovim, setting up a basic configuration, and enhancing it with essential plugins to turn it into a full-fledged IDE.\n1. Installing Neovim sudo pacman -S neovim 2. Setting Up Neovim Configuration Neovim’s configuration is stored in ~/.config/nvim/. Create the directory and initialize a basic configuration:\nmkdir -p ~/.config/nvim nvim ~/.config/nvim/init.lua Minimal Configuration (init.lua) Add the following settings to your init.lua file:\n-- Enable line numbers vim.opt.number = true vim.opt.relativenumber = true -- Set tab size vim.opt.expandtab = true vim.opt.shiftwidth = 4 vim.opt.tabstop = 4 -- Enable mouse support vim.opt.mouse = \u0026#34;a\u0026#34; -- Set clipboard to system clipboard vim.opt.clipboard = \u0026#34;unnamedplus\u0026#34; Save and exit Neovim.\n3. Installing a Plugin Manager The best plugin manager for Neovim is lazy.nvim. Install it by running:\ngit clone --depth 1 https://github.com/folke/lazy.nvim.git \\ ~/.local/share/nvim/lazy/lazy.nvim Then, update your init.lua to load it:\nlocal lazypath = vim.fn.stdpath(\u0026#34;data\u0026#34;) .. \u0026#34;/lazy/lazy.nvim\u0026#34; if not vim.loop.fs_stat(lazypath) then vim.fn.system({ \u0026#34;git\u0026#34;, \u0026#34;clone\u0026#34;, \u0026#34;--filter=blob:none\u0026#34;, \u0026#34;https://github.com/folke/lazy.nvim.git\u0026#34;, lazypath }) end vim.opt.rtp:prepend(lazypath) 4. Installing Essential Plugins With lazy.nvim installed, you can add plugins in init.lua:\nrequire(\u0026#34;lazy\u0026#34;).setup({ \u0026#34;nvim-treesitter/nvim-treesitter\u0026#34;, -- Syntax highlighting \u0026#34;nvim-telescope/telescope.nvim\u0026#34;, -- Fuzzy finder \u0026#34;neovim/nvim-lspconfig\u0026#34;, -- LSP support \u0026#34;hrsh7th/nvim-cmp\u0026#34;, -- Auto-completion \u0026#34;hrsh7th/cmp-nvim-lsp\u0026#34;, -- LSP completion source \u0026#34;hrsh7th/cmp-buffer\u0026#34;, -- Buffer completion \u0026#34;hrsh7th/cmp-path\u0026#34;, -- Path completion \u0026#34;hrsh7th/cmp-nvim-lua\u0026#34;, -- Neovim Lua API completion \u0026#34;L3MON4D3/LuaSnip\u0026#34;, -- Snippet engine \u0026#34;saadparwaiz1/cmp_luasnip\u0026#34;, -- Snippet completion \u0026#34;nvim-lualine/lualine.nvim\u0026#34;, -- Status line \u0026#34;nvim-tree/nvim-tree.lua\u0026#34;, -- File explorer \u0026#34;tpope/vim-surround\u0026#34;, -- Surround text objects \u0026#34;tpope/vim-commentary\u0026#34;, -- Commenting shortcuts \u0026#34;lewis6991/gitsigns.nvim\u0026#34;, -- Git integration \u0026#34;akinsho/toggleterm.nvim\u0026#34;, -- Terminal management }) Save and exit Neovim, then open it and run:\n:Lazy sync This will install the plugins automatically.\n5. Setting Up Treesitter Treesitter provides better syntax highlighting and code parsing. Install it by adding the following to your init.lua:\nrequire\u0026#39;nvim-treesitter.configs\u0026#39;.setup { ensure_installed = \u0026#34;all\u0026#34;, highlight = { enable = true, }, indent = { enable = true, }, } Then, update Treesitter by running:\n:TSUpdate 6. Setting Up LSP (Language Server Protocol) LSP enables features like code completion and linting. Install LSP servers for your language:\n# Python sudo pacman -S python-lsp-server # C++ sudo pacman -S clang # JavaScript/TypeScript npm install -g typescript-language-server Then, enable LSP support in Neovim:\nlocal lspconfig = require(\u0026#34;lspconfig\u0026#34;) lspconfig.pyright.setup({}) -- Python lspconfig.ts_ls.setup({}) -- JavaScript/TypeScript lspconfig.clangd.setup({}) -- C++ Restart Neovim and check LSP status:\n:LspInfo 7. Enhancing Auto-Completion with nvim-cmp To enable code auto-completion, update your init.lua:\nlocal cmp = require\u0026#39;cmp\u0026#39; cmp.setup({ mapping = { [\u0026#39;\u0026lt;C-Space\u0026gt;\u0026#39;] = cmp.mapping.complete(), [\u0026#39;\u0026lt;CR\u0026gt;\u0026#39;] = cmp.mapping.confirm({ select = true }), }, sources = { { name = \u0026#39;nvim_lsp\u0026#39; }, { name = \u0026#39;buffer\u0026#39; }, { name = \u0026#39;path\u0026#39; }, { name = \u0026#39;luasnip\u0026#39; }, { name = \u0026#39;nvim_lua\u0026#39; }, } }) 9. Final Thoughts Congratulations! You now have a powerful, customized Neovim setup that functions as a full-fledged IDE. With features like Treesitter, LSP support, auto-completion, syntax highlighting, Git integration, and a file explorer, your development workflow will be much smoother.\nIf you’d like to further improve your Neovim experience, explore more plugins and tweak your settings. Good luck with that!\nFurther Reading Neovim Documentation Awesome Neovim Plugins Arch Wiki: Neovim ","permalink":"http://localhost:1313/posts/setting-up-neovim-on-arch-linux-a-beginners-guide/","summary":"\u003ch1 id=\"setting-up-neovim-an-easy-and-beginners-guide\"\u003eSetting Up Neovim: An Easy and Beginner\u0026rsquo;s Guide\u003c/h1\u003e\n\u003cp\u003eNeovim is a modern and extensible text editor that enhances Vim’s capabilities. If you\u0026rsquo;re using Linux, setting up Neovim can be a rewarding experience, allowing you to customize it for an efficient workflow. In this guide, we\u0026rsquo;ll cover installing Neovim, setting up a basic configuration, and enhancing it with essential plugins to turn it into a full-fledged IDE.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"1-installing-neovim\"\u003e\u003cstrong\u003e1. Installing Neovim\u003c/strong\u003e\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003esudo pacman -S neovim\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003chr\u003e\n\u003ch2 id=\"2-setting-up-neovim-configuration\"\u003e\u003cstrong\u003e2. Setting Up Neovim Configuration\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003eNeovim’s configuration is stored in \u003ccode\u003e~/.config/nvim/\u003c/code\u003e. Create the directory and initialize a basic configuration:\u003c/p\u003e","title":"Setting Up Neovim: A Beginner's Guide"},{"content":"Linux Kernal The majority of the kernel\u0026rsquo;s code is written in C, leveraging extensions provided by the GNU Compiler Collection (GCC) beyond standard C. Additionally, it includes assembly code for architecture-specific functions, such as optimizing memory usage and task execution. Architecturally, the Linux kernel is monolithic, meaning the entire OS operates within kernel space. However, it features a modular design, allowing software components to be integrated as modules, including dynamic loading.\nWhat Is A Kernel Module? A Linux kernel module is precisely defined as a code segment capable of dynamic loading and unloading within the kernel as needed. These modules enhance kernel capabilities without necessitating a system reboot. A notable example is seen in the device driver module, which facilitates kernel interaction with hardware components linked to the system.\nWriting a Custom Linux Kernel Module Linux kernel modules (LKMs) allow developers to extend the functionality of the Linux kernel without modifying its source code. This guide walks through writing a simple kernel module from scratch. Kernel modules are pieces of code that can be dynamically loaded and unloaded from the Linux kernel at runtime. They enable functionality such as device drivers, file system support, and system call extensions without requiring a kernel recompilation. LKMs are particularly useful for developing hardware drivers and testing new kernel features without rebooting the system.\nPrerequisites Ensure you have the necessary development tools installed. On an Arch Linux system, install them with:\nsudo pacman -Syu linux-headers base-devel Creating a Simple Kernel Module 1. Writing the Module Source Code Create a file named hello_module.c:\n#include \u0026lt;linux/module.h\u0026gt; #include \u0026lt;linux/kernel.h\u0026gt; #include \u0026lt;linux/init.h\u0026gt; MODULE_LICENSE(\u0026#34;GPL\u0026#34;); MODULE_AUTHOR(\u0026#34;Your Name\u0026#34;); MODULE_DESCRIPTION(\u0026#34;A simple Hello World kernel module\u0026#34;); static int __init hello_init(void) { printk(KERN_INFO \u0026#34;Hello, Kernel!\\n\u0026#34;); return 0; } static void __exit hello_exit(void) { printk(KERN_INFO \u0026#34;Goodbye, Kernel!\\n\u0026#34;); } module_init(hello_init); module_exit(hello_exit); Understanding the Kernel Module Code #include \u0026lt;linux/module.h\u0026gt;: Includes the necessary module macros and functions. #include \u0026lt;linux/kernel.h\u0026gt;: Provides kernel logging functions. #include \u0026lt;linux/init.h\u0026gt;: Defines initialization and cleanup macros. MODULE_LICENSE(\u0026quot;GPL\u0026quot;): Specifies the module\u0026rsquo;s license. MODULE_AUTHOR(\u0026quot;Your Name\u0026quot;): Specifies the author of the module. MODULE_DESCRIPTION(\u0026quot;A simple Hello World kernel module\u0026quot;): Provides a brief description. static int __init hello_init(void): The function executed when the module is loaded. static void __exit hello_exit(void): The function executed when the module is unloaded. module_init(hello_init): Registers hello_init as the module\u0026rsquo;s initialization function. module_exit(hello_exit): Registers hello_exit as the module\u0026rsquo;s cleanup function. 2. Writing the Makefile Create a Makefile in the same directory:\nobj-m += hello_module.o all: make -C /lib/modules/$(shell uname -r)/build M=$(PWD) modules clean: make -C /lib/modules/$(shell uname -r)/build M=$(PWD) clean Understanding the Makefile obj-m += hello_module.o: Specifies that hello_module.o is the object to be built as a module. all:: Defines the build target. make -C /lib/modules/$(shell uname -r)/build M=$(PWD) modules: Directs the kernel build system to compile the module. clean:: Cleans up the generated files. make -C /lib/modules/$(shell uname -r)/build M=$(PWD) clean: Cleans the build artifacts. 3. Compiling the Module Run:\nmake 4. Loading and Unloading the Module To insert the module into the kernel:\nsudo insmod hello_module.ko Check the kernel log:\ndmesg | tail To remove the module:\nsudo rmmod hello_module 5. Verifying the Module List loaded modules:\nlsmod | grep hello_module Understanding the Generated Files After building the module, several files are generated:\nhello_module.c: The source code of the module. hello_module.ko: The compiled kernel module file, ready to be loaded into the kernel. hello_module.o: An intermediate object file generated during compilation. hello_module.mod.c: An automatically generated file containing module metadata. hello_module.mod.o: An object file containing metadata compiled from hello_module.mod.c. hello_module.mod: Another metadata file required for module loading. Makefile: Contains instructions for building the module. Module.symvers: Stores information about exported symbols, useful for module dependencies. modules.order: Lists the order in which modules should be loaded. Conclusion This simple kernel module demonstrates the basics of module development. You can expand upon this by adding functionality such as handling parameters or interacting with hardware.\nHappy kernel hacking!\n","permalink":"http://localhost:1313/posts/how-to-write-a-custom-kernel-module/","summary":"\u003ch1 id=\"linux-kernal\"\u003eLinux Kernal\u003c/h1\u003e\n\u003cp\u003eThe majority of the kernel\u0026rsquo;s code is written in C, leveraging extensions provided by the GNU Compiler Collection (GCC) beyond standard C. Additionally, it includes assembly code for architecture-specific functions, such as optimizing memory usage and task execution. Architecturally, the Linux kernel is monolithic, meaning the entire OS operates within kernel space. However, it features a modular design, allowing software components to be integrated as modules, including dynamic loading.\u003c/p\u003e","title":"How to Write a Custom Kernel Module"},{"content":"What is it? gh is GitHub\u0026rsquo;s official command-line tool designed to extend Git\u0026rsquo;s functionality with GitHub-specific features.\nPurpose: Simplifies interaction with GitHub\u0026rsquo;s ecosystem directly from the terminal. Allows you to manage repositories and use GitHub features like issues, pull requests, and workflows.\nKey Features: GitHub-specific tasks:\nAuthentication: Easier login (gh auth login) without dealing with tokens manually. Repository Management: Create, fork, or clone repositories. Issues \u0026amp; Pull Requests: Manage issues, PRs, and comments directly. Actions: Manage and view GitHub Actions workflows. Works alongside Git for basic version control tasks. Use Case: Best for developers heavily using GitHub and its features (for example: pull requests, issues, and actions).\nHow it works Install gh:\n\u0026gt; yay -S github-cli Verify the installation:\n\u0026gt; gh --version Login with GitHub CLI (gh)\n\u0026gt; gh auth login Follow the interactive prompts to log in:\nChoose HTTPS or SSH for connection. Log in via a browser using a one-time code or SSH keys. Verify authentication:\n\u0026gt; gh auth status What\u0026rsquo;s best about it that you can install and use both Git and gh (GitHub CLI) seamlessly. Here\u0026rsquo;s how to set them up:\nInstall Git\n\u0026gt;sudo pacman -S git Check the installation:\n\u0026gt; git --version Using Git and gh Together You can now: Use Git for version control:\n\u0026gt; git clone https://github.com/username/repo.git \u0026gt; git add . \u0026gt; git commit -m \u0026quot;message\u0026quot; \u0026gt; git push ","permalink":"http://localhost:1313/posts/github-cli-githubs-official-command-line-tools/","summary":"\u003ch2 id=\"what-is-it\"\u003eWhat is it?\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003egh\u003c/strong\u003e is GitHub\u0026rsquo;s official command-line tool designed to extend Git\u0026rsquo;s functionality with GitHub-specific features.\u003c/p\u003e\n\u003ch2 id=\"purpose\"\u003ePurpose:\u003c/h2\u003e\n\u003cp\u003eSimplifies interaction with GitHub\u0026rsquo;s ecosystem directly from the terminal. Allows you to manage repositories and use GitHub features like issues, pull requests, and workflows.\u003c/p\u003e\n\u003ch2 id=\"key-features\"\u003eKey Features:\u003c/h2\u003e\n\u003cp\u003eGitHub-specific tasks:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAuthentication: Easier login (gh auth login) without dealing with tokens manually.\u003c/li\u003e\n\u003cli\u003eRepository Management: Create, fork, or clone repositories.\u003c/li\u003e\n\u003cli\u003eIssues \u0026amp; Pull Requests: Manage issues, PRs, and comments directly.\u003c/li\u003e\n\u003cli\u003eActions: Manage and view GitHub Actions workflows.\u003c/li\u003e\n\u003cli\u003eWorks alongside Git for basic version control tasks.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"use-case\"\u003eUse Case:\u003c/h2\u003e\n\u003cp\u003eBest for developers heavily using GitHub and its features (for example: pull requests, issues, and actions).\u003c/p\u003e","title":"GitHub CLI: GitHub's Official Command Line Tools"},{"content":"Connecting a Raspberry Pi 5 to a USB TTY cable is a common way to interact with it through a serial connection, especially for debugging or setting up the device without using a display.\nPrerequists\nRaspberry Pi 5. USB TTY (serial) cable. Computer with a terminal emulator (minicom/screen). GPIO pinout diagram of Raspberry Pi 5 (for reference). Power source for Raspberry Pi (optional if USB TTY can power it, though not recommended). Before Starting! Issuse with firmware UART does NOT work on the RPI5 from the factory. We will need a firmware update to fix this that prevents the dtoverlays for UARTs from working.\nInstall rpi-update with the following commands:\n\u0026gt; sudo curl -L --output /usr/bin/rpi-update https://raw.githubusercontent.com/Hexxeh/rpi-update/master/rpi-update \u0026amp;\u0026amp; sudo chmod +x /usr/bin/rpi-update Then update the firmware on your RPI5 with:\n\u0026gt; sudo rpi-update Enable UART To manually configure UART, you can edit the config.txt file.\nEdit /boot/firmware/config.txt and add:\n\u0026gt; enable_uart=1 How to Connect Locate the GPIO Pins Find the GPIO header on the Raspberry Pi 5. Identify the following pins: GND (Ground): Usually black wire on the USB TTY cable. TX (Transmit): Sends data from the Pi to the computer. RX (Receive): Receives data from the computer to the Pi.\nUse a GPIO pinout chart to locate these pins. For Raspberry Pi 5, it will likely be similar to previous models. Making connections You will need to connect:\nGND with Ground - Pin# 06 TX with GPIO14 - Pin# 08 RX with GPIO15 - Pin# 10 Plug the USB TTY Cable into the Computer\nInsert the USB end of the TTY cable into your computer. The cable will create a virtual COM port (e.g /dev/ttyUSB0). Configure and Access Serial Console\nOpen a terminal.\nIdentify the port with:\n\u0026gt; ls /dev/ttyUSB* Use a terminal emulator like screen or minicom to connect:\n\u0026gt; screen /dev/ttyUSB0 115200 *Replace /dev/ttyUSB0 with the actual port name.\nTurn on the Raspberry Pi. If everything is set up correctly, you should see boot messages in the terminal. Log in to the Pi using the default username (pi) and password (raspberry), or your custom credentials. You should see something similar to this.\nThis is it! You have done it. Congrats!\n","permalink":"http://localhost:1313/posts/how-to-connect-a-raspberry-pi-5-to-usb-tty-cable/","summary":"\u003cp\u003eConnecting a Raspberry Pi 5 to a USB TTY cable is a common way to interact with it through a serial connection, especially for debugging or setting up the device without using a display.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003ePrerequists\u003c/strong\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eRaspberry Pi 5.\u003c/li\u003e\n\u003cli\u003eUSB TTY (serial) cable.\u003c/li\u003e\n\u003cli\u003eComputer with a terminal emulator (minicom/screen).\u003c/li\u003e\n\u003cli\u003eGPIO pinout diagram of Raspberry Pi 5 (for reference).\u003c/li\u003e\n\u003cli\u003ePower source for Raspberry Pi (optional if USB TTY can power it, though not recommended).\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"before-starting\"\u003e\u003cstrong\u003eBefore Starting!\u003c/strong\u003e\u003c/h3\u003e\n\u003ch3 id=\"issuse-with-firmware\"\u003e\u003cstrong\u003e\u003ca href=\"https://forums.raspberrypi.com/viewtopic.php?t=361397#p2171244\"\u003eIssuse with firmware\u003c/a\u003e\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003eUART does NOT work on the RPI5 from the factory. We will need a firmware update to fix this that prevents the dtoverlays for UARTs from working.\u003c/p\u003e","title":"How to Connect a Raspberry PI 5 to USB TTY Cable"},{"content":"Hosting a website on GitHub Pages with Hugo involves the following steps:\nCreating a website 1. Install Hugo and git\n\u0026gt; sudo pacman -S Hugo 2. Create a new Hugo site\n\u0026gt; hugo new site your-website 3. Add a Theme\nNavigate to your website directory and add a theme. You can choose one from the Hugo Themes .\n\u0026gt; cd your-website \u0026gt; git init \u0026gt; git submodule add https://github.com/adityatelange/hugo-PaperMod.git themes/hugo-PaperMod Now you will need to update the hugo.toml file for them to take effect. To do so you can either echo or addd it in the file.\n\u0026gt; echo \u0026quot;theme = 'hugo-PaperMod'\u0026quot; \u0026gt;\u0026gt; hugo.toml To view the website you can run it locally using Hugo\u0026rsquo;s development server to view the site. You can add -D to see your drafts.\n\u0026gt; hugo server 3. Add Content\nTo add a new page to your site.\n\u0026gt; hugo new content content/posts/yout-first-post.md This is it You have done it. YAY!\nHosting it on GitHub 1. Create a GitHub repository.\nClick the + icon in the top-right corner of:\u0026gt; [!WARNING] the GitHub interface and select New repository. Enter a repository name: yourusername.github.io Click Create repository. 2. Add Files for Your website\nClone the repository locally using Git:\ngit clone https://github.com//.git\nAdd your static site files (generated by Hugo) to the repository. Commit and push the changes:\n\u0026gt; git add -A \u0026gt; git commit -s -m \u0026quot;Initial commit\u0026quot; \u0026gt; git push origin main 3. Configure the Repository for GitHub Pages\nGo to the Settings tab of your new repository. Scroll down to the Pages section. Settings \u0026gt; Pages. In the center of your screen you will see this: Build and development Change the Source to GitHub Actions. 4. Create a file named hugo.yaml in a directory named .github/workflows.\n\u0026gt; mkdir -p .github/workflows \u0026gt; cd ./github/workflows touch hugo.yaml 5. Add content in the YAML file.\n# Sample workflow for building and deploying a Hugo site to GitHub Pages name: Deploy Hugo site to Pages on: # Runs on pushes targeting the default branch push: branches: - main # Allows you to run this workflow manually from the Actions tab workflow_dispatch: # Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages permissions: contents: read pages: write id-token: write # Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued. # However, do NOT cancel in-progress runs as we want to allow these production deployments to complete. concurrency: group: \u0026#34;pages\u0026#34; cancel-in-progress: false # Default to bash defaults: run: shell: bash jobs: # Build job build: runs-on: ubuntu-latest env: HUGO_VERSION: 0.141.0 steps: - name: Install Hugo CLI run: | wget -O ${{ runner.temp }}/hugo.deb https://github.com/gohugoio/hugo/releases/download/v${HUGO_VERSION}/hugo_extended_${HUGO_VERSION}_linux-amd64.deb \\ \u0026amp;\u0026amp; sudo dpkg -i ${{ runner.temp }}/hugo.deb - name: Install Dart Sass run: sudo snap install dart-sass - name: Checkout uses: actions/checkout@v4 with: submodules: recursive fetch-depth: 0 - name: Setup Pages id: pages uses: actions/configure-pages@v5 - name: Install Node.js dependencies run: \u0026#34;[[ -f package-lock.json || -f npm-shrinkwrap.json ]] \u0026amp;\u0026amp; npm ci || true\u0026#34; - name: Build with Hugo env: HUGO_CACHEDIR: ${{ runner.temp }}/hugo_cache HUGO_ENVIRONMENT: production TZ: America/Los_Angeles run: | hugo \\ --gc \\ --minify \\ --baseURL \u0026#34;${{ steps.pages.outputs.base_url }}/\u0026#34; - name: Upload artifact uses: actions/upload-pages-artifact@v3 with: path: ./public # Deployment job deploy: environment: name: github-pages url: ${{ steps.deployment.outputs.page_url }} runs-on: ubuntu-latest needs: build steps: - name: Deploy to GitHub Pages id: deployment uses: actions/deploy-pages@v4 5. Commit and push your GitHub repository.\n\u0026gt;git add -A \u0026gt;git commit -m \u0026quot;Create hugo.yaml\u0026quot; \u0026gt;git push 6. Deployment status From GitHub’s main menu, choose Actions. When GitHub has finished building and deploying your site, the color of the status indicator will change to green.\nStep 5: Verify Your GitHub Pages Site\nThe site will be live at https://yourusername.github.io.\n","permalink":"http://localhost:1313/posts/hosting-a-website-on-github-pages-with-hugo/","summary":"\u003cp\u003eHosting a website on GitHub Pages with Hugo involves the following steps:\u003c/p\u003e\n\u003ch1 id=\"creating-a-website\"\u003eCreating a website\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e1. Install Hugo and git\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; sudo pacman -S Hugo\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e2. Create a new Hugo site\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; hugo new site your-website\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e3. Add a Theme\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eNavigate to your website directory and add a theme. You can choose one from the \u003ca href=\"https://themes.gohugo.io/\"\u003eHugo Themes\u003c/a\u003e .\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; cd your-website\n\u0026gt; git init \n\u0026gt; git submodule add https://github.com/adityatelange/hugo-PaperMod.git themes/hugo-PaperMod\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow you will need to update the hugo.toml file for them to take effect. To do so you can either \u003cem\u003eecho\u003c/em\u003e or addd it in the file.\u003c/p\u003e","title":"Hosting a Website on Github Pages With Hugo"},{"content":"KVM Kernel-based Virtual Machine is a free and open-source virtualization module in the Linux kernel that allows the kernel to function as a hypervisor.\nInstallation For updates, run the following command:\n$ sudo pacman -Syu QEMU/KVM installation: We\u0026rsquo;ll install qemu and all the utils required:\n$ sudo pacman -S qemu vde2 ebtables iptables-nft nftables dms masq bridge-utils ovmf swptm Virtual Machine Manager installation: The virt-manager application is a graphical user interface for managing virtual machines through libvirt. It primarily targets KVM VMs.\n$ sudo pacman -S virt-manager Now everything is set to work. We can move towards downloading archlinux .iso file.\nDownload .iso file: Head towards: https://archlinux.org/download/ Scroll through and look for the server closest to you. Download archlinux-2024.10.01-x86_64.iso file. Setting up: Open terminal and run the following command:\n$ virt-manager You will see an interface similar to this:\nClick on \u0026lsquo;create a new virtual machine\u0026rsquo; (option with star). Select \u0026lsquo;Local install media\u0026rsquo;. Browse to your \u0026lsquo;archlinux-2024.10.01-x86_64.iso\u0026rsquo;. Add your desired VM configuration and create a disk image. Boot Menu: You will be prompted to a boot menu.\nSelect the topmost option to start the installation process. Archlinux Installer: You will be prompted to a terminal. The first step is to check if you are connected to the internet.\nRun:\n# ip addr show If it shows an IP address and says \u0026lsquo;UP\u0026rsquo;, that means you are good to go.\nIf not: You will need to connect to the internet using the \u0026lsquo;iwctl\u0026rsquo; method for Wi-Fi.\n# iwctl To search networks in your vicinity:\n[iwd]# station [your_wifi_interface] get-networks Get the name of the network you want to connect to. Exit from this prompt using \u0026rsquo;exit\u0026rsquo;.\nTo connect to the desired Wi-Fi network, run:\n# iwctl --passphrase \u0026#34;[wifi_password]\u0026#34; station [your_wifi_interface] connect [wifi_name] You can again run ip addr show to check if you are connected to the network.\nNow you can run the installation command. We\u0026rsquo;ll be using the archinstall method.\n# archinstall You will be prompted to an interface similar to this:\nWe will install Arch using this interface. Go through each option:\nArchinstall language: Choose your preferred language. Mirrors: Select the mirror region closest to you. Use \u0026lsquo;/\u0026rsquo; to search. Locales: Set language and keyboard layout. Disk configuration: Choose Best-effort default partition to format the system. Bootloader: Use the default \u0026lsquo;Grub\u0026rsquo; option. Swap: Select Swap on zram (default). Hostname: Leave as it is. Root password: Set the password for sudo/root privileges. User account: Set up a user account. Profile: Select Desktop. It includes essential packages. Others include Minimal, Server, and Xorg. In Desktop, select your desktop environment. We\u0026rsquo;ll use Gnome for simplicity.\nAudio: Use PipeWire (default) or PulseAudio. Kernels: Use the linux kernel. Additional packages: Install any required packages. Network Configuration: Use NetworkManager for a GUI in Gnome. Timezone: Set the timezone closest to you and enable time sync. Press Install. Congratulations! You\u0026rsquo;ve successfully installed Arch Linux.\n","permalink":"http://localhost:1313/posts/arch_kvm/","summary":"\u003ch1 id=\"kvm\"\u003eKVM\u003c/h1\u003e\n\u003cp\u003eKernel-based Virtual Machine is a free and open-source virtualization module in the Linux kernel that allows the kernel to function as a hypervisor.\u003c/p\u003e\n\u003ch2 id=\"installation\"\u003eInstallation\u003c/h2\u003e\n\u003cp\u003eFor updates, run the following command:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ sudo pacman -Syu\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"qemukvm-installation\"\u003eQEMU/KVM installation:\u003c/h3\u003e\n\u003cp\u003eWe\u0026rsquo;ll install qemu and all the utils required:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ sudo pacman -S qemu vde2 ebtables iptables-nft nftables dms masq bridge-utils ovmf swptm\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"virtual-machine-manager-installation\"\u003eVirtual Machine Manager installation:\u003c/h3\u003e\n\u003cp\u003eThe virt-manager application is a graphical user interface for managing virtual machines through libvirt. It primarily targets KVM VMs.\u003c/p\u003e","title":"archlinux installation in hypervisor through QEMU/KVM"},{"content":"","permalink":"http://localhost:1313/posts/github-cli-githubs-official-command-line-tool/","summary":"","title":""},{"content":"1. Introduction Sometimes you need to share a local application with the outside world — maybe to demo your project, test a webhook, or allow a teammate to access your development server.\nNormally, you’d need a public IP, port forwarding, or a cloud server. ngrok removes all that complexity by creating a secure tunnel from the internet directly to your machine, giving you a public URL instantly.\nIn this guide, we’ll walk through:\nInstalling ngrok on popular Linux distributions Authenticating your installation Exposing a local service to the internet Adding basic security Practical examples for real-world usage 2. Prerequisites Before we begin, make sure you have:\nA terminal A free ngrok account (for authentication token) A running local service (e.g., a Python HTTP server, web app, or API) 3. Installing ngrok on Linux We’ll cover installation for Arch Linux, Debian/Ubuntu, and Fedora.\n3.1 Arch Linux This package is not in the official repos, install it from the AUR:\nyay -S ngrok 3.2 Debian / Ubuntu sudo apt update sudo apt install snapd sudo snap install ngrok Alternatively, download the binary from the ngrok downloads page.\n3.3 Fedora sudo dnf install snapd sudo ln -s /var/lib/snapd/snap /snap sudo snap install ngrok 4. Authenticating ngrok Once installed, you need to connect it to your account so you can use custom domains, longer session times, and access the dashboard.\nSign in to ngrok dashboard. -\u0026gt; Your AuthToken Copy your AuthToken. Run: ngrok config add-authtoken \u0026lt;YOUR_TOKEN\u0026gt; You will see: Authtoken saved to configuration file: ~/.config/ngrok/ngrok.yml 5. Exposing a Local Service For example, if your local web server is running on port 8080:\nngrok http 8080 You’ll see output like:\nNow you can share the HTTPS URL with anyone. It wil be similar to: https://random.string.ngrok-free.app\n6. Adding Basic Security You can protect your tunnel with a simple username and password:\nngrok http --basic-auth=\u0026#34;user:password\u0026#34; 8080 Anyone visiting the public link will need credentials.\n7. The Inspector 🕵️‍♀️ One of ngrok\u0026rsquo;s most powerful features is its built-in web interface, accessible at http://127.0.0.1:4040. This interface lets you inspect every single request that comes through your tunnel in real-time. You can see headers, request bodies, and response details, and even replay requests with a single click—an absolute lifesaver for debugging webhooks.\n8. Common Use Cases Webhook testing — Connect services like GitHub, Stripe, or Twilio to your local environment. Temporary demos — Share work-in-progress with clients without deployment. Remote device access — SSH into a Raspberry Pi without changing router settings. 9. Conclusion In just a few commands, you’ve learned how to:\nInstall ngrok on popular Linux distros Authenticate your installation Share a local service securely From here, you can explore ngrok’s advanced features like static domains, IP allowlists, and traffic inspection.\n","permalink":"http://localhost:1313/posts/ngrok/","summary":"\u003ch2 id=\"1-introduction\"\u003e1. Introduction\u003c/h2\u003e\n\u003cp\u003eSometimes you need to share a local application with the outside world — maybe to demo your project, test a webhook, or allow a teammate to access your development server.\u003c/p\u003e\n\u003cp\u003eNormally, you’d need a public IP, port forwarding, or a cloud server. \u003cstrong\u003engrok\u003c/strong\u003e removes all that complexity by creating a \u003cstrong\u003esecure tunnel\u003c/strong\u003e from the internet directly to your machine, giving you a public URL instantly.\u003c/p\u003e\n\u003cp\u003eIn this guide, we’ll walk through:\u003c/p\u003e","title":"Ngrok: Expose Localhost to the Internet"},{"content":"Creating a WhatsApp AI Assistant Using n8n: A Step-by-Step Guide Build your own AI-powered WhatsApp chatbot using n8n, WhatsApp Business Cloud API, and OpenAI. This guide walks you through every step—from setup to testing—with real-world error handling, solutions, and an example production-ready workflow.\n1. Introduction Want to chat with an AI on WhatsApp? In this tutorial, you\u0026rsquo;ll learn how to build a WhatsApp AI Assistant using:\nn8n (automation tool) WhatsApp Business Cloud API OpenAI (for generating intelligent replies) By the end, you\u0026rsquo;ll have a working chatbot and gain hands-on experience with APIs, webhooks, and automation.\n2. Prerequisites n8n account (Cloud or self-hosted) Meta Developer account with WhatsApp Business Cloud API access OpenAI API key Basic understanding of APIs and webhook workflows 3. Registering Your WhatsApp Business App A. Create WhatsApp App in Meta Developer Visit Meta for Developers Create a new app: choose Business → WhatsApp Link or create a WhatsApp Business Account B. Obtain Testing Credentials Your app dashboard will show:\nTest phone number Phone Number ID Temporary access token (valid for only 24 hours) Tip: For long-term use, generate a 60-day system-user token later.\nC. Add Recipients to Test List By default, only approved numbers can receive messages:\nNavigate to WhatsApp → API Setup Add numbers in E.164 format (e.g., +923001234567) Users must accept the invite via WhatsApp to become valid recipients 4. Configuring Your Webhook in n8n A. Create a Webhook Node Method: GET (for initial verification) Endpoint example: https://yourname.app.n8n.cloud/webhook/your-unique-id/webhook B. Verify the Webhook with Meta In your app’s Webhook section:\nCallback URL: your n8n webhook URL Verify Token: any secret string you choose (e.g., mySecret2025) C. Echo Back Meta’s Challenge Configure n8n\u0026rsquo;s Webhook node response:\nField Value Response Mode On Received Response Body {{$json[\u0026quot;query\u0026quot;][\u0026quot;hub.challenge\u0026quot;]}} This ensures Meta can verify your endpoint successfully.\n5. Processing Incoming Messages WhatsApp sends JSON data with structure like:\n{ \u0026#34;entry\u0026#34;: [ { \u0026#34;changes\u0026#34;: [ { \u0026#34;value\u0026#34;: { \u0026#34;messages\u0026#34;: [ { \u0026#34;from\u0026#34;: \u0026#34;923001234567\u0026#34;, \u0026#34;text\u0026#34;: { \u0026#34;body\u0026#34;: \u0026#34;Hello bot!\u0026#34; } } ], \u0026#34;metadata\u0026#34;: { \u0026#34;phone_number_id\u0026#34;: \u0026#34;698352170035199\u0026#34; } } } ] } ] } Extract:\nfrom: user’s number text.body: user’s text metadata.phone_number_id: correct sender ID 6. Integrating OpenAI for Responses Obtaining Your OpenAI API Key Before integrating OpenAI into your n8n workflow, you’ll need to get an API key from OpenAI.\nStep-by-Step: Sign up or log in to OpenAI. Navigate to your API Keys page. Click \u0026ldquo;Create new secret key\u0026rdquo;. Optionally name your key, then copy it immediately (you won’t be able to view it again). In n8n: Go to Credentials → Add New → choose OpenAI or HTTP Request. Paste your API key into the key field. Save the credentials. Security Tip: Keep your key private. Do not share it or commit it to public repositories.\nUse an HTTP Request node to call OpenAI:\nPOST https://api.openai.com/v1/chat/completions Authorization: Bearer YOUR_OPENAI_API_KEY Content-Type: application/json { \u0026#34;model\u0026#34;: \u0026#34;gpt-4o-mini\u0026#34;, \u0026#34;messages\u0026#34;: [ { \u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;You are a helpful WhatsApp AI assistant.\u0026#34; }, { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;{{ $json[...] }}\u0026#34; } ] } Replace {{ $json[...] }} with the actual path to the user\u0026rsquo;s message text from the Webhook node.\n7. Sending Replies via WhatsApp Use another HTTP Request node to respond:\nPOST https://graph.facebook.com/v21.0/{{ $json[...] }}/messages Authorization: Bearer YOUR_LONG_LIVED_TOKEN Content-Type: application/json { \u0026#34;messaging_product\u0026#34;: \u0026#34;whatsapp\u0026#34;, \u0026#34;to\u0026#34;: \u0026#34;{{ $json[...] }}\u0026#34;, \u0026#34;text\u0026#34;: { \u0026#34;body\u0026#34;: \u0026#34;{{ $node[\u0026#39;OpenAI Response\u0026#39;].json.choices[0].message.content }}\u0026#34; } } Use the metadata’s phone_number_id for the endpoint and from for the recipient. This avoids hardcoding and ensures proper routing.\n8. Example n8n Workflow Here’s the actual n8n workflow I used for my WhatsApp AI assistant. It integrates a product brochure PDF into a vector store for AI-powered Q\u0026amp;A, and handles WhatsApp message flow.\nStep-by-Step Breakdown: 1. Download Product Brochure PDF Downloads the brochure from a given URL. Extracts text from the PDF. 2. Create Product Brochure Vector Store Splits large text into chunks. Generates embeddings using OpenAI. Saves them in a vector store for fast semantic search. 3. Use the WhatsApp Trigger Listens for incoming WhatsApp messages. Routes them to supported or unsupported handlers. 3a. Handle Unsupported Messages Replies with a friendly error if the message type is not text. 4. Sales AI Agent Responds Uses OpenAI with memory + vector store retrieval to answer based on brochure content. 5. Reply to WhatsApp User Sends the AI-generated message back to the sender. Why this is effective:\nContext-aware answers via buffer memory. Reduced hallucinations thanks to vector store grounding. Smooth error handling for unsupported message types. 9. Common Errors \u0026amp; Fixes Recipient phone number not in allowed list\n→ Add as test number or switch to Live mode\n401 – Session expired\n→ Refresh token via Graph API:\nGET https://graph.facebook.com/v21.0/oauth/access_token ?grant_type=fb_exchange_token \u0026amp;client_id=YOUR_APP_ID \u0026amp;client_secret=YOUR_APP_SECRET \u0026amp;fb_exchange_token=YOUR_CURRENT_TOKEN Webhook verification failed\n→ Ensure verify token matches between Meta and n8n and echo hub.challenge\nNo execution data available\n→ Trigger workflow via actual WhatsApp message, not manual run\n10. Going Live Add a Privacy Policy URL in Meta App → Settings → Basic (required for live access) Switch app to Live mode once all compliance items are met Remove restricted recipient list Use WhatsApp message templates for messages sent after 24 hours of user interaction 11. Conclusion \u0026amp; Next Steps Congrats! You now have a WhatsApp AI Assistant built with n8n and OpenAI.\nWhere to go from here: Wire up custom knowledge (PDFs, documents) Implement memory for conversation context Launch multilingual support Export n8n workflow as JSON for reuse Need help? Join the n8n Community Forum or OpenAI Discord to connect with fellow builders.\nHappy automating!\n","permalink":"http://localhost:1313/posts/creating-whatsapp-ai-assistant-using-n8n2/","summary":"\u003ch1 id=\"creating-a-whatsapp-ai-assistant-using-n8n-a-step-by-step-guide\"\u003eCreating a WhatsApp AI Assistant Using n8n: A Step-by-Step Guide\u003c/h1\u003e\n\u003cp\u003eBuild your own AI-powered WhatsApp chatbot using \u003cstrong\u003en8n\u003c/strong\u003e, \u003cstrong\u003eWhatsApp Business Cloud API\u003c/strong\u003e, and \u003cstrong\u003eOpenAI\u003c/strong\u003e. This guide walks you through every step—from setup to testing—with real-world error handling, solutions, and an example production-ready workflow.\u003c/p\u003e\n\u003ch2 id=\"1-introduction\"\u003e1. Introduction\u003c/h2\u003e\n\u003cp\u003eWant to chat with an AI on WhatsApp? In this tutorial, you\u0026rsquo;ll learn how to build a \u003cstrong\u003eWhatsApp AI Assistant\u003c/strong\u003e using:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003en8n\u003c/strong\u003e (automation tool)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eWhatsApp Business Cloud API\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eOpenAI\u003c/strong\u003e (for generating intelligent replies)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eBy the end, you\u0026rsquo;ll have a working chatbot and gain hands-on experience with APIs, webhooks, and automation.\u003c/p\u003e","title":"Creating Whatsapp Ai Assistant Using N8n"},{"content":"Introduction A memory leak occurs when a program allocates memory dynamically (e.g., using malloc) and fails to release it using free. This leftover allocation can lead to wasted memory resources, eventually causing slowdowns or system crashes in long-running programs.\nValgrind is a powerful command-line tool available on Linux systems. It helps developers detect:\nMemory leaks Invalid memory access Uninitialized memory usage Mismatched memory management In this guide, we\u0026rsquo;ll walk through examples in C to learn how to detect and fix memory leaks using Valgrind.\nInstalling Valgrind On Arch Linux sudo pacman -S valgrind On Ubuntu/Debian sudo apt install valgrind On Fedora sudo dnf install valgrind Troubleshooting: Valgrind \u0026ldquo;cannot find mandatory redirection\u0026rdquo; on Arch Linux If you run Valgrind and get an error like:\nvalgrind: Fatal error at startup: a function redirection\nvalgrind: which is mandatory for this platform-tool combination\nvalgrind: cannot be set up.\n…you might be running a 32-bit executable on a 64-bit Arch Linux system.\nWhy this happens Valgrind needs to hook into low-level glibc functions from your binary’s architecture.\nIf your binary is 32-bit, Arch requires the 32-bit glibc runtime (lib32-glibc).\nWithout it, Valgrind can’t find the right function symbols and quits.\nFix Install the 32-bit glibc package:\nsudo pacman -S lib32-glibc After installation, re-run:\nvalgrind ./your-binary and it should work.\nUbuntu/Debian equivalent: sudo apt install libc6-dbg:i386\nBasic Example: Hello World Code #include \u0026lt;stdio.h\u0026gt; int main() { printf(\u0026#34;Hello World\\n\u0026#34;); return 0; } Compile and Run gcc main.c -o main.out ./main.out Run with Valgrind valgrind ./main.out You should see no errors or memory leaks in the output.\nIntroducing a Memory Leak Static Allocation (Safe) #include \u0026lt;stdio.h\u0026gt; int main() { char str[20] = \u0026#34;Hello\u0026#34;; printf(\u0026#34;%s\\n\u0026#34;, str); return 0; } This uses stack memory, so Valgrind will report no leaks.\nDynamic Allocation (With Leak) #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; int main() { char *str = malloc(20); strcpy(str, \u0026#34;Hello\u0026#34;); printf(\u0026#34;%s\\n\u0026#34;, str); return 0; // Forgot to free memory } Valgrind Output valgrind ./main.out You should see:\ndefinitely lost: 20 bytes in 1 blocks\nFixing the Memory Leak Add free(str); before returning:\nfree(str); Fixed Code #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; int main() { char *str = malloc(20); strcpy(str, \u0026#34;Hello\u0026#34;); printf(\u0026#34;%s\\n\u0026#34;, str); free(str); return 0; } Detailed Valgrind Options Use for deeper analysis:\nvalgrind --leak-check=full ./main.out Or even more detailed:\nvalgrind --leak-check=full --show-leak-kinds=all --track-origins=yes ./main.out Explanation:\n--leak-check=full: Display detailed leak info --show-leak-kinds=all: Show all kinds of leaks (definitely, indirectly lost, etc.) --track-origins=yes: Show where uninitialized values originate Summary Always free() memory allocated with malloc(), calloc(), or realloc(). Close all file streams with fclose(). Use Valgrind to identify and fix: Memory leaks Invalid memory writes Use-after-free bugs Recommended command: valgrind --leak-check=full --track-origins=yes ./your_program Valgrind is a critical tool for writing safe, efficient, and bug-free C programs.\n","permalink":"http://localhost:1313/posts/introductiontovalgrind/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eA \u003cstrong\u003ememory leak\u003c/strong\u003e occurs when a program allocates memory dynamically (e.g., using \u003ccode\u003emalloc\u003c/code\u003e) and fails to release it using \u003ccode\u003efree\u003c/code\u003e. This leftover allocation can lead to wasted memory resources, eventually causing slowdowns or system crashes in long-running programs.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eValgrind\u003c/strong\u003e is a powerful command-line tool available on Linux systems. It helps developers detect:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eMemory leaks\u003c/li\u003e\n\u003cli\u003eInvalid memory access\u003c/li\u003e\n\u003cli\u003eUninitialized memory usage\u003c/li\u003e\n\u003cli\u003eMismatched memory management\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIn this guide, we\u0026rsquo;ll walk through examples in C to learn how to detect and fix memory leaks using Valgrind.\u003c/p\u003e","title":"Detecting and Fixing Memory Leaks with Valgrind"},{"content":"QEMU-KVM on Arch Linux: Running Tiny Core Linux in a Lightweight VM Virtualization is a powerful tool for developers, sysadmins, and tinkerers alike. On Linux, QEMU-KVM stands out as a robust, high-performance virtualization stack. In this blog, well walk through setting up QEMU-KVM on Arch Linux and using it to run Tiny Core Linuxa super-lightweight distro perfect for testing and experimentation.\nWhat is QEMU-KVM QEMU (Quick Emulator) is a generic and open-source machine emulator. On its own, it can emulate various hardware systems. However, when paired with **KVM (Kernel-based Virtual Machine)**a Linux kernel module for virtualizationit can run virtual machines with near-native performance.\nQEMU provides device emulation and user-space management. KVM integrates with the Linux kernel and handles hardware-level virtualization. Together, they effectively form a Type 1 hypervisor because the Linux kernel (with KVM) handles core virtualization tasks directly on hardware.\nStep-by-Step: Installing QEMU-KVM on Arch Linux Step 1: Install Required Packages sudo pacman -Syu sudo pacman -S qemu virt-manager virt-viewer dnsmasq vde2 bridge-utils openbsd-netcat libvirt edk2-ovmf edk2-ovmf is for UEFI firmware support in VMs.\nStep 2: Enable and Start libvirtd sudo systemctl enable --now libvirtd.service Step 3: Add Your User to the libvirt Group sudo usermod -aG libvirt (whoami) newgrp libvirt Step 4: Verify KVM Support lsmod grep kvm And check CPU virtualization support:\negrep -c (vmxsvm) /proc/cpuinfo A value of 1 or more indicates virtualization support.\nExample: Running Tiny Core Linux on QEMU-KVM Now that your system is ready, lets run Tiny Core Linux, a minimalist Linux distro thats only 16MB\nStep 1: Download Tiny Core ISO wget http://tinycorelinux.net/14.x/x86/release/Core-current.iso Or visit http://tinycorelinux.net for the latest release.\nStep 2: Create a Virtual Disk (Optional) qemu-img create -f qcow2 tinycore.qcow2 512M This creates a 512MB disk image. Optional for RAM-only usage.\nStep 3: Launch the VM with KVM Acceleration qemu-system-x86_64 -enable-kvm -m 512 -cpu host -smp 1 -cdrom Core-current.iso -hda tinycore.qcow2 -boot d -net nic -net user -vga virtio -display sdl Key Flags Explained:\n-enable-kvm: Enables KVM hardware acceleration -m 512: Allocates 512MB RAM -cpu host: Uses the host CPU features -cdrom: Points to the Tiny Core ISO -hda: Uses a QCOW2 disk image -boot d: Boots from CD first -net user: Enables simple user-mode networking (e.g., for internet access) -display sdl: Uses SDL window for graphics (you can replace with gtk or virt-manager) Alternate: Boot Tiny Core in RAM Without Disk qemu-system-x86_64 -enable-kvm -m 256 -cdrom Core-current.iso -boot d -net nic -net user -vga std Conclusion With QEMU-KVM, Arch Linux becomes a full-featured Type 1 hypervisor. By combining kernel-level virtualization (KVM) with the flexibility of QEMU, you get a fast, customizable virtualization platform. Running Tiny Core Linux showcases just how lightweight and efficient this setup can be.\nWhether youre building VMs for testing, learning Linux internals, or experimenting with custom environments, QEMU-KVM on Arch is a powerful combination.\nHappy virtualizing\n","permalink":"http://localhost:1313/posts/qemu/","summary":"\u003ch1 id=\"qemu-kvm-on-arch-linux-running-tiny-core-linux-in-a-lightweight-vm\"\u003eQEMU-KVM on Arch Linux: Running Tiny Core Linux in a Lightweight VM\u003c/h1\u003e\n\u003cp\u003eVirtualization is a powerful tool for developers, sysadmins, and tinkerers alike. On Linux, \u003cstrong\u003eQEMU-KVM\u003c/strong\u003e stands out as a robust, high-performance virtualization stack. In this blog, well walk through setting up QEMU-KVM on \u003cstrong\u003eArch Linux\u003c/strong\u003e and using it to run \u003cstrong\u003eTiny Core Linux\u003c/strong\u003ea super-lightweight distro perfect for testing and experimentation.\u003c/p\u003e\n\u003ch2 id=\"what-is-qemu-kvm\"\u003eWhat is QEMU-KVM\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eQEMU (Quick Emulator)\u003c/strong\u003e is a generic and open-source machine emulator. On its own, it can emulate various hardware systems. However, when paired with **KVM (Kernel-based Virtual Machine)**a Linux kernel module for virtualizationit can run virtual machines with near-native performance.\u003c/p\u003e","title":"QEMU-KVM on Arch Linux: Running Tiny Core Linux in a Lightweight VM"},{"content":"Building the Linux Kernel Compiling the Linux Kernel involves multiple steps and can take some time depending on your hardware specifications.\nStep 1: Download the Kernel Source Code Start by visiting the Official Linux Kernel Website and downloading the latest available kernel source code. The downloaded file will be a compressed archive containing all necessary source files.\nStep 2: Extract the Source Code Once the download completes, extract the contents of the compressed archive using the tar command:\ntar xvf linux-6.13.tar.xz If the tar utility is not installed on your system, you can install it using:\nsudo pacman -S tar Note: Always ensure you are using the correct version number in the file name.\nStep 3: Install Required Dependencies To compile the kernel, you need to install various development tools and libraries. Install them using the following command:\nsudo pacman -S git fakeroot ncurses xz bc flex bison base-devel kmod cpio perl binutils util-linux jfsutils e2fsprogs xfsprogs squashfs-tools quota-tools Step 4: Configure the Kernel Navigate into the kernel source directory: cd linux-6.13 Use your current system’s configuration as a base:\nIf zcat is available, run:\nzcat /proc/config.gz \u0026gt; .config Otherwise, use this alternative method:\ncp /proc/config.gz ./ gunzip config.gz mv config .config Customize the kernel using a menu-driven interface:\nmake menuconfig make xconfig make oldconfig Modify the .config file directly:\nOpen it with a text editor:\nsudo vim .config Search for the line:\nCONFIG_EXT4_FS=m And change it to:\nCONFIG_EXT4_FS=y Step 5: Compile the Kernel Determine the number of CPU cores available to speed up compilation: nproc Compile the kernel using the number of cores found above. Replace n with that number: make -j\u0026lt;n\u0026gt; If you encounter any errors during or after this step, back up your .config file and reset the source tree with:\nmake mrproper This command cleans the build environment and restores the source tree to its original state.\nStep 6: Install Kernel Modules Kernel modules are essential for extending the kernel’s functionality and ensuring compatibility with various hardware. Install them with:\nsudo make modules_install Step 7: Install the Kernel You can install the compiled kernel using one of the two methods below:\nAutomatic installation: sudo make install Manual installation (if the above doesn\u0026rsquo;t work):\nCopy the kernel image:\nsudo cp arch/x86/boot/bzImage /boot/vmlinuz-linux-custom Copy the System.map file:\nsudo cp System.map /boot/System.map-linux-custom Copy the kernel configuration file:\nsudo cp .config /boot/config-linux-custom Step 8: Update the Bootloader If you use GRUB, follow these steps to add an entry for your custom kernel:\nFind the UUID of your root partition: lsblk -f Open the custom GRUB configuration file: sudo nvim /etc/grub.d/40_custom Add the following entry (replace paste-your-root-partition-uuid-here with the actual UUID): menuentry \u0026#39;Custom Linux Kernel\u0026#39; { linux /boot/vmlinuz-linux-custom root=UUID=paste-your-root-partition-uuid-here initrd /boot/initramfs-linux.img } Step 9: Generate Initramfs As you\u0026rsquo;ve compiled a new kernel, installed modules, and modified boot entries, generating a new initramfs is necessary. Run:\nsudo mkinitcpio -k 6.13-custom -c /etc/mkinitcpio.conf -g /boot/initramfs-linux-custom.img Make sure the version (6.13-custom) matches your compiled kernel.\nStep 10: Update GRUB Configuration Finally, update the GRUB configuration so that it includes your new kernel entry:\nsudo grub-mkconfig -o /boot/grub/grub.cfg Done! Congratulations! You’ve successfully compiled and installed your custom Linux Kernel. Enjoy your personalized system!\n","permalink":"http://localhost:1313/posts/kernal_compilation/","summary":"\u003ch1 id=\"building-the-linux-kernel\"\u003eBuilding the Linux Kernel\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003eCompiling the Linux Kernel involves multiple steps and can take some time depending on your hardware specifications.\u003c/strong\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"step-1-download-the-kernel-source-code\"\u003eStep 1: Download the Kernel Source Code\u003c/h3\u003e\n\u003cp\u003eStart by visiting the \u003ca href=\"https://www.kernel.org/\"\u003eOfficial Linux Kernel Website\u003c/a\u003e and downloading the latest available kernel source code. The downloaded file will be a compressed archive containing all necessary source files.\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"step-2-extract-the-source-code\"\u003eStep 2: Extract the Source Code\u003c/h3\u003e\n\u003cp\u003eOnce the download completes, extract the contents of the compressed archive using the \u003ccode\u003etar\u003c/code\u003e command:\u003c/p\u003e","title":"How to build Linux Kernal: Step by Step Guide"},{"content":"Introduction So, you’ve built a sleek website with Hugo and deployed it to GitHub Pages. Now, you want to give it a professional touch with a custom domain like yourdomain.tech instead of the default username.github.io URL. This guide walks you through the process step-by-step.\nPrerequisites A Hugo website hosted on GitHub Pages (public repository). A custom domain (e.g., yourdomain.tech) purchased from a registrar like Namecheap, Google Domains, etc. Basic familiarity with DNS settings and GitHub repository configurations. Step 1: Configure Your GitHub Repository First, ensure your GitHub Pages site is set up correctly:\nYour repository should be named \u0026lt;username\u0026gt;.github.io (for user/organization sites) or \u0026lt;repo-name\u0026gt; (for project sites). The gh-pages branch (or the /docs folder) should contain your Hugo-generated static files. Step 2: Configure DNS Settings for Your Domain Option 1: Use an Apex Domain (e.g., yourdomain.tech) If you want your site to live at the root domain (e.g., yourdomain.tech), configure A records in your DNS settings:\nGo to your domain registrar’s DNS management page. Create four A records pointing to GitHub’s IP addresses: Host: @ Type: A Value: 185.199.108.153 TTL: Automatic ","permalink":"http://localhost:1313/posts/customdomain/","summary":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003eSo, you’ve built a sleek website with Hugo and deployed it to GitHub Pages. Now, you want to give it a professional touch with a custom domain like \u003ccode\u003eyourdomain.tech\u003c/code\u003e instead of the default \u003ccode\u003eusername.github.io\u003c/code\u003e URL. This guide walks you through the process step-by-step.\u003c/p\u003e\n\u003ch2 id=\"prerequisites\"\u003ePrerequisites\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003eA Hugo website hosted on GitHub Pages (public repository).\u003c/li\u003e\n\u003cli\u003eA custom domain (e.g., \u003ccode\u003eyourdomain.tech\u003c/code\u003e) purchased from a registrar like Namecheap, Google Domains, etc.\u003c/li\u003e\n\u003cli\u003eBasic familiarity with DNS settings and GitHub repository configurations.\u003c/li\u003e\n\u003c/ol\u003e\n\u003chr\u003e\n\u003ch2 id=\"step-1-configure-your-github-repository\"\u003eStep 1: Configure Your GitHub Repository\u003c/h2\u003e\n\u003cp\u003eFirst, ensure your GitHub Pages site is set up correctly:\u003c/p\u003e","title":"How to up custom domain for GitHub Pages"},{"content":"Exception handling is a crucial aspect of writing robust and reliable Python code. Whether you\u0026rsquo;re a beginner or an experienced developer, getting an error, or exception, in your Python program means the entire program will crash. You don’t want this to happen in real-world programs. Instead, you want the program to detect errors, handle them, and then continue to run. In this blog, we\u0026rsquo;ll explore the fundamentals of exception handling in Python, including syntax, best practices, and advanced techniques.\nWhat Are Exceptions? Exceptions are runtime errors that disrupt the normal flow of a program. For example, trying to open a non-existent file, dividing by zero, or accessing an invalid index in a list will raise exceptions. If unhandled, these exceptions cause your program to crash.\nBasic Syntax: try and except The primary mechanism for handling exceptions in Python is the try-except block. Errors can be handled with with this. The code that could potentially have an error is put in a try clause. The program execution moves to the start of a following except clause if an error happens.\nHere\u0026rsquo;s the basic structure:\ndef cal(value): try: return 10 / value except ZeroDivisionError: print(\u0026#34;Cannot divide by zero!\u0026#34;) print(cal(0)) print(cal(2)) print(cal(3)) How It Works: The code inside the try block is executed. If an exception occurs, Python checks the except blocks for a matching exception type. If a match is found, the corresponding except block runs. Catching Specific Exceptions Always catch specific exceptions to avoid silencing unexpected errors. Python has many built-in exceptions (e.g., ValueError, TypeError, FileNotFoundError).\nimport math x = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) try: print(f\u0026#39;Square Root of {x} is {math.sqrt(x)}\u0026#39;) except ValueError: print(\u0026#39;Number is less than 0\u0026#39;) Output\nThe else Clause The else block runs only if no exceptions were raised in the try block. Use it to separate \u0026ldquo;happy path\u0026rdquo; code from error handling.\nimport math def sqr(value): try: x = math.sqrt(value) except ValueError: print(\u0026#39;Number is less than 0\u0026#39;) else: print(f\u0026#39;The Answer is: {x}\u0026#39;) value = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) sqr(value) Output The finally Clause The finally block runs regardless of whether an exception occurred. It’s ideal for cleanup tasks (e.g., closing files or releasing resources).\nimport math def sqr(value): try: x = math.sqrt(value) except ValueError: print(\u0026#39;Error\u0026#39;) else: print(f\u0026#39;The Answer is: {x}\u0026#39;) finally: print(\u0026#39;Program Ends\u0026#39;) value = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) sqr(value) Output Raising Exceptions Manually Use the raise keyword to trigger exceptions intentionally. This is useful for enforcing constraints.\ndef validate_age(age): if age \u0026lt; 0: raise ValueError(\u0026#34;Age cannot be negative!\u0026#34;) return age try: validate_age(-5) except ValueError as e: print(e) Creating Custom Exceptions Define custom exceptions by subclassing Python’s built-in Exception class. This makes your code more readable and errors more descriptive. (note: I have used RegEx, for that blog will be out soon :) )\nimport re class InvalidEmailError(Exception): \u0026#34;\u0026#34;\u0026#34;Raised when an email format is invalid.\u0026#34;\u0026#34;\u0026#34; pass def send_email(valid,email): if not valid: raise InvalidEmailError(f\u0026#34;Invalid email: {email}\u0026#34;) email = input(\u0026#39;Please enter your email: \u0026#39;) valid = re.match(r\u0026#39;^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\u0026#39;, email) try: send_email(valid, email) except InvalidEmailError as e: print(e) Output Logging a Python Error We can Log an exception in Python with an error. This can be done in the logging.exception() method. This function logs a message with level ERROR on this logger.\nimport math import logging def sqr(value): try: x = math.sqrt(value) except ValueError: logging.exception(\u0026#34;Error\u0026#34;) else: print(f\u0026#39;The Answer is: {x}\u0026#39;) finally: print(\u0026#39;Program Ends\u0026#39;) value = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) sqr(value) Output Best Practices for Exception Handling Catch specific exceptions: Avoid broad except: clauses that hide bugs. Keep try blocks minimal: Only wrap code that might raise an exception. Use finally for cleanup: Ensure resources are released (e.g., closing files). Log exceptions: Use logging.error() instead of print() for production code. Provide meaningful messages: Help debug issues faster with clear error descriptions. Avoid empty except blocks: Silent failures make debugging harder. Conclusion Exception handling is essential for writing better Python applications. By using try-except blocks effectively, catching specific errors, and with else/finally clauses, you can create programs that handle unexpected scenarios.\nNow go forth and write bulletproof Python code!\n","permalink":"http://localhost:1313/posts/exception_handling_in_python/","summary":"\u003cp\u003eException handling is a crucial aspect of writing robust and reliable Python code. Whether you\u0026rsquo;re a beginner or an experienced developer, getting an error, or exception, in your Python program means the entire program will crash. You don’t want this to happen in real-world programs. Instead, you want the program to detect errors, handle them, and then continue to run. In this blog, we\u0026rsquo;ll explore the fundamentals of exception handling in Python, including syntax, best practices, and advanced techniques.\u003c/p\u003e","title":"Exception Handling in Python: A Comprehensive Guide"},{"content":"Have you ever wanted your Python program to do multiple things at once? For example, downloading files while updating the UI, or processing data while listening for user input? That’s where multithreading comes in.\nIn this post, we’ll explore multithreading in Python — what it is, when to use it, and how to use it with simple examples.\n🧠 What is Multithreading? Multithreading is a way to run multiple threads (smaller units of a process) at the same time. It helps make your program more responsive or perform tasks in parallel, especially when tasks are I/O-bound (e.g., network calls, file reading, etc.).\nPython has a built-in module called threading that makes it easy to create and manage threads.\n⚠️ But Wait — Python\u0026rsquo;s GIL Before you jump in, it\u0026rsquo;s important to understand the Global Interpreter Lock (GIL). In CPython (the standard Python implementation), the GIL allows only one thread to execute Python bytecode at a time.\nThis means multithreading in Python is best suited for I/O-bound tasks, not CPU-bound tasks like heavy computations. For CPU-bound tasks, consider multiprocessing instead.\n🛠️ Using the threading Module Here\u0026rsquo;s a basic example to demonstrate multithreading:\nimport threading import time def print_numbers(): for i in range(5): print(f\u0026#34;Number: {i}\u0026#34;) time.sleep(1) def print_letters(): for letter in \u0026#39;abcde\u0026#39;: print(f\u0026#34;Letter: {letter}\u0026#34;) time.sleep(1) # Creating threads t1 = threading.Thread(target=print_numbers) t2 = threading.Thread(target=print_letters) # Starting threads t1.start() t2.start() # Wait for both threads to complete t1.join() t2.join() print(\u0026#34;Both threads have finished.\u0026#34;) 🔍 Output (interleaved): Number: 0 Letter: a Number: 1 Letter: b ... Both functions run at the same time, and you can see their output interleave. That’s multithreading in action!\n📦 Real-World Use Cases Downloading multiple files at once Handling multiple client connections on a server Running background tasks like logging or monitoring Keeping your GUI app responsive while doing other work 🧰 Extra Tools For more advanced usage:\nconcurrent.futures.ThreadPoolExecutor — easier thread management queue.Queue — safe way to share data between threads threading.Lock — prevents race conditions 🧪 Example with ThreadPoolExecutor from concurrent.futures import ThreadPoolExecutor import time def task(name): print(f\u0026#34;{name} starting\u0026#34;) time.sleep(2) print(f\u0026#34;{name} done\u0026#34;) with ThreadPoolExecutor(max_workers=2) as executor: executor.submit(task, \u0026#34;Task 1\u0026#34;) executor.submit(task, \u0026#34;Task 2\u0026#34;) ✅ Final Thoughts Multithreading in Python is a powerful tool when used correctly — especially for I/O-bound programs. Just remember the GIL limitation and use the right tool (like multiprocessing) when working with CPU-heavy tasks.\nThanks for reading! Happy threading 🧵🐍\n","permalink":"http://localhost:1313/posts/multithreading/","summary":"\u003cp\u003eHave you ever wanted your Python program to do multiple things at once? For example, downloading files while updating the UI, or processing data while listening for user input? That’s where \u003cstrong\u003emultithreading\u003c/strong\u003e comes in.\u003c/p\u003e\n\u003cp\u003eIn this post, we’ll explore multithreading in Python — what it is, when to use it, and how to use it with simple examples.\u003c/p\u003e\n\u003ch2 id=\"-what-is-multithreading\"\u003e🧠 What is Multithreading?\u003c/h2\u003e\n\u003cp\u003eMultithreading is a way to run multiple threads (smaller units of a process) at the same time. It helps make your program more responsive or perform tasks in parallel, especially when tasks are I/O-bound (e.g., network calls, file reading, etc.).\u003c/p\u003e","title":"Multithreading in Python"},{"content":"Running a Local LLM on Mobile: Testing PocketPal on iPhone 12 With the increasing accessibility of large language models (LLMs), running them locally on mobile devices is an exciting prospect. I recently tested PocketPal, a mobile LLM interface, on my iPhone 12, using a distilled 4-bit quantized model. Here’s a breakdown of my experience, covering installation, performance, and overall usability.\nWhy Run an LLM on Mobile? Running an LLM locally on a mobile device comes with several advantages:\nPrivacy: No data is sent to external servers. Offline Access: Works without an internet connection. Lower Cost: Avoids API costs associated with cloud-based models. What is Quantization? Quantization is a technique used to reduce the memory and computational requirements of machine learning models by representing their weights with lower precision numbers. Instead of using 32-bit floating-point numbers, models can be compressed into 8-bit or even 4-bit integers while maintaining reasonable accuracy.\nFor LLMs on mobile, 4-bit quantization significantly reduces the model size, making it feasible to run on devices with limited resources. However, this compression can lead to:\nSlightly reduced accuracy due to loss of precision. Faster inference times, as lower-bit computations require less processing power. Lower memory usage, allowing larger models to fit within mobile device constraints. Setting Up and Running PocketPal on iPhone 12 1. Download and Install PocketPal Open the App Store and search for PocketPal AI by Asghar Ghorbani. Download and install the app. Open the app and allow necessary permissions. 2. Adding a Model Navigate to the Models section in the PocketPal app. Click the + button to add a new model. You will see two options: Add from Hugging Face Add Local Model Select Add from Hugging Face to browse available models. 3. Selecting and Downloading a Model Search for DeepSeek-R1-Distill-Qwen-1.5B-Q4_0. Select the model and start downloading it (size: 1.06GB, 1.78B parameters). Once downloaded, the model will appear under the Ready to Use section. 4. Running Benchmarks I ran benchmarks on my iPhone 12 using the DeepSeek-R1-Distill-Qwen-1.5B-Q4_0 model. Here are the key results:\nModel Size: 1.06 GB with 1.78 billion parameters. Benchmark Configuration: Prompt Processing: 512 Token Generation: 128 Pipeline Length: 1 Repetitions: 3 Model Settings: Context Length: 1024 tokens Batch Size: 512 CPU Threads: 4 GPU Layers: 0 (fully CPU-based execution) Flash Attention: Disabled Performance Metrics: Prompt Processing Speed: 26.93 tokens/sec (±2.37) Token Generation Speed: 18.05 tokens/sec (±0.75) Total Execution Time: 1 minute 18 seconds Peak Memory Usage: 35.0% (1GB / 4GB) Live Demo: Running PocketPal on iPhone 12 Watch a live demonstration of PocketPal running a distilled 4-bit quantized model on an iPhone 12: Image: Video demonstration is available here: Video\nAnalysis of Results Decent Processing Speed: With a distilled 4-bit quantized model, the 18.05 t/s token generation rate is quite reasonable for mobile inference. Low Memory Footprint: The 1GB RAM usage means this can run on even mid-range smartphones. CPU-Based Execution: Since 0 GPU layers were used, this proves mobile CPUs are capable of running quantized LLMs efficiently. Flash Attention Disabled: If supported, enabling it might further optimize speed and reduce lag. Final Thoughts Running an LLM locally on an iPhone 12 with PocketPal is feasible but comes with trade-offs. It’s a promising step toward self-hosted AI assistants, though optimization and hardware improvements will be crucial for broader adoption. If you’re privacy-conscious or need offline AI capabilities, it’s definitely worth exploring!\nFuture Improvements I\u0026rsquo;d Like to See: Better memory efficiency to reduce battery drain. Enhanced speed for real-time interaction. More user-friendly model importing and switching. ","permalink":"http://localhost:1313/posts/llmonmobile/","summary":"\u003ch1 id=\"running-a-local-llm-on-mobile-testing-pocketpal-on-iphone-12\"\u003eRunning a Local LLM on Mobile: Testing PocketPal on iPhone 12\u003c/h1\u003e\n\u003cp\u003eWith the increasing accessibility of large language models (LLMs), running them locally on mobile devices is an exciting prospect. I recently tested \u003cstrong\u003ePocketPal\u003c/strong\u003e, a mobile LLM interface, on my \u003cstrong\u003eiPhone 12\u003c/strong\u003e, using a \u003cstrong\u003edistilled 4-bit quantized model\u003c/strong\u003e. Here’s a breakdown of my experience, covering installation, performance, and overall usability.\u003c/p\u003e\n\u003ch2 id=\"why-run-an-llm-on-mobile\"\u003eWhy Run an LLM on Mobile?\u003c/h2\u003e\n\u003cp\u003eRunning an LLM locally on a mobile device comes with several advantages:\u003c/p\u003e","title":"Running Large Language Models on Mobile: DeepSeek R1 on iPhone 12"},{"content":"Running DeepSeek-R1 1.5B on Raspberry Pi 5 (CPU-Only) Technical Insights Why Can We Run This on Raspberry Pi 5? Thanks to open-source advancements, we can now run large-scale AI models on small devices like the Raspberry Pi 5. Key factors enabling this include:\nOptimized lightweight models: DeepSeek-R1 1.5B is built efficiently to run on limited hardware. ARM64 Support: Modern AI frameworks support ARM-based architectures, enabling their use on RPi5. Open-source software: Platforms like Ollama make AI deployment accessible to all. Performance Considerations Running this model on an RPi5 without a GPU will be CPU-intensive. Consider reducing active processes to free up memory. If performance lags, use a lighter model or external processing (cloud inference). No GPU acceleration was used in this setup, meaning all computations rely solely on the CPU, which may affect inference speeds. This guide covers the installation and execution of DeepSeek-R1 1.5B on a Raspberry Pi 5, following the steps demonstrated in your images.\nPrerequisites Raspberry Pi 5 (ARM64 architecture, more powerful than previous versions) Debian-based Linux installed An internet connection At least 4GB RAM recommended for smooth operation Step 1: Log in to Your Raspberry Pi Upon booting, log in using your credentials:\nraspberrypi login: hisam Password: ****** Example login screen: Step 2: Install Curl Curl is required to fetch the installation script. Run:\nsudo apt install curl If it\u0026rsquo;s already installed, you\u0026rsquo;ll see:\ncurl is already the newest version... Example output: Step 3: Install Ollama Ollama is the runtime needed to execute DeepSeek models.\ncurl -fsSL https://ollama.com/install.sh | sh This will download and install Ollama.\nExample installation screen: Step 4: Enable and Start Ollama Service After installation, Ollama sets up a system service.\nollama The output will indicate success:\n\u0026gt;\u0026gt;\u0026gt; Creating ollama user... \u0026gt;\u0026gt;\u0026gt; Enabling and starting ollama service... \u0026gt;\u0026gt;\u0026gt; The Ollama API is now available at 127.0.0.1:11434. Example setup screen: Step 5: Pull and Run DeepSeek-R1 1.5B Now, pull and run the model:\nollama run deepseek-r1:1.5b This will download the model, which is about 1.1 GB in size.\nExample download screen: Once downloaded, the model is ready to run.\nStep 6: Execute DeepSeek-R1 1.5B Run the model and start interacting:\nollama run deepseek-r1:1.5b You should see a prompt where you can start typing queries:\n\u0026gt;\u0026gt;\u0026gt; Hey! Hello! How can I assist you today? 😊 Example interaction: Final Setup Image Video Demonstration Watch Video\nConclusion You have successfully installed and executed DeepSeek-R1 1.5B on your Raspberry Pi 5. This demonstrates the power of open-source AI, making it possible to run advanced models on small-scale devices. If you encounter performance issues, consider optimizing your setup or offloading computations.\nHappy coding!\n","permalink":"http://localhost:1313/posts/deepseek/","summary":"\u003ch1 id=\"running-deepseek-r1-15b-on-raspberry-pi-5-cpu-only\"\u003eRunning DeepSeek-R1 1.5B on Raspberry Pi 5 (CPU-Only)\u003c/h1\u003e\n\u003ch2 id=\"technical-insights\"\u003eTechnical Insights\u003c/h2\u003e\n\u003ch3 id=\"why-can-we-run-this-on-raspberry-pi-5\"\u003eWhy Can We Run This on Raspberry Pi 5?\u003c/h3\u003e\n\u003cp\u003eThanks to open-source advancements, we can now run large-scale AI models on small devices like the Raspberry Pi 5. Key factors enabling this include:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eOptimized lightweight models\u003c/strong\u003e: DeepSeek-R1 1.5B is built efficiently to run on limited hardware.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eARM64 Support\u003c/strong\u003e: Modern AI frameworks support ARM-based architectures, enabling their use on RPi5.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eOpen-source software\u003c/strong\u003e: Platforms like Ollama make AI deployment accessible to all.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"performance-considerations\"\u003ePerformance Considerations\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eRunning this model on an RPi5 \u003cstrong\u003ewithout a GPU\u003c/strong\u003e will be CPU-intensive.\u003c/li\u003e\n\u003cli\u003eConsider \u003cstrong\u003ereducing active processes\u003c/strong\u003e to free up memory.\u003c/li\u003e\n\u003cli\u003eIf performance lags, use a \u003cstrong\u003elighter model\u003c/strong\u003e or \u003cstrong\u003eexternal processing (cloud inference).\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eNo GPU acceleration was used\u003c/strong\u003e in this setup, meaning all computations rely solely on the CPU, which may affect inference speeds.\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003cp\u003eThis guide covers the installation and execution of DeepSeek-R1 1.5B on a Raspberry Pi 5, following the steps demonstrated in your images.\u003c/p\u003e","title":"DeepSeek-R1 on Raspberry Pi 5: Open-Source AI Without a GPU"},{"content":"Setting Up Neovim: An Easy and Beginner\u0026rsquo;s Guide Neovim is a modern and extensible text editor that enhances Vim’s capabilities. If you\u0026rsquo;re using Linux, setting up Neovim can be a rewarding experience, allowing you to customize it for an efficient workflow. In this guide, we\u0026rsquo;ll cover installing Neovim, setting up a basic configuration, and enhancing it with essential plugins to turn it into a full-fledged IDE.\n1. Installing Neovim sudo pacman -S neovim 2. Setting Up Neovim Configuration Neovim’s configuration is stored in ~/.config/nvim/. Create the directory and initialize a basic configuration:\nmkdir -p ~/.config/nvim nvim ~/.config/nvim/init.lua Minimal Configuration (init.lua) Add the following settings to your init.lua file:\n-- Enable line numbers vim.opt.number = true vim.opt.relativenumber = true -- Set tab size vim.opt.expandtab = true vim.opt.shiftwidth = 4 vim.opt.tabstop = 4 -- Enable mouse support vim.opt.mouse = \u0026#34;a\u0026#34; -- Set clipboard to system clipboard vim.opt.clipboard = \u0026#34;unnamedplus\u0026#34; Save and exit Neovim.\n3. Installing a Plugin Manager The best plugin manager for Neovim is lazy.nvim. Install it by running:\ngit clone --depth 1 https://github.com/folke/lazy.nvim.git \\ ~/.local/share/nvim/lazy/lazy.nvim Then, update your init.lua to load it:\nlocal lazypath = vim.fn.stdpath(\u0026#34;data\u0026#34;) .. \u0026#34;/lazy/lazy.nvim\u0026#34; if not vim.loop.fs_stat(lazypath) then vim.fn.system({ \u0026#34;git\u0026#34;, \u0026#34;clone\u0026#34;, \u0026#34;--filter=blob:none\u0026#34;, \u0026#34;https://github.com/folke/lazy.nvim.git\u0026#34;, lazypath }) end vim.opt.rtp:prepend(lazypath) 4. Installing Essential Plugins With lazy.nvim installed, you can add plugins in init.lua:\nrequire(\u0026#34;lazy\u0026#34;).setup({ \u0026#34;nvim-treesitter/nvim-treesitter\u0026#34;, -- Syntax highlighting \u0026#34;nvim-telescope/telescope.nvim\u0026#34;, -- Fuzzy finder \u0026#34;neovim/nvim-lspconfig\u0026#34;, -- LSP support \u0026#34;hrsh7th/nvim-cmp\u0026#34;, -- Auto-completion \u0026#34;hrsh7th/cmp-nvim-lsp\u0026#34;, -- LSP completion source \u0026#34;hrsh7th/cmp-buffer\u0026#34;, -- Buffer completion \u0026#34;hrsh7th/cmp-path\u0026#34;, -- Path completion \u0026#34;hrsh7th/cmp-nvim-lua\u0026#34;, -- Neovim Lua API completion \u0026#34;L3MON4D3/LuaSnip\u0026#34;, -- Snippet engine \u0026#34;saadparwaiz1/cmp_luasnip\u0026#34;, -- Snippet completion \u0026#34;nvim-lualine/lualine.nvim\u0026#34;, -- Status line \u0026#34;nvim-tree/nvim-tree.lua\u0026#34;, -- File explorer \u0026#34;tpope/vim-surround\u0026#34;, -- Surround text objects \u0026#34;tpope/vim-commentary\u0026#34;, -- Commenting shortcuts \u0026#34;lewis6991/gitsigns.nvim\u0026#34;, -- Git integration \u0026#34;akinsho/toggleterm.nvim\u0026#34;, -- Terminal management }) Save and exit Neovim, then open it and run:\n:Lazy sync This will install the plugins automatically.\n5. Setting Up Treesitter Treesitter provides better syntax highlighting and code parsing. Install it by adding the following to your init.lua:\nrequire\u0026#39;nvim-treesitter.configs\u0026#39;.setup { ensure_installed = \u0026#34;all\u0026#34;, highlight = { enable = true, }, indent = { enable = true, }, } Then, update Treesitter by running:\n:TSUpdate 6. Setting Up LSP (Language Server Protocol) LSP enables features like code completion and linting. Install LSP servers for your language:\n# Python sudo pacman -S python-lsp-server # C++ sudo pacman -S clang # JavaScript/TypeScript npm install -g typescript-language-server Then, enable LSP support in Neovim:\nlocal lspconfig = require(\u0026#34;lspconfig\u0026#34;) lspconfig.pyright.setup({}) -- Python lspconfig.ts_ls.setup({}) -- JavaScript/TypeScript lspconfig.clangd.setup({}) -- C++ Restart Neovim and check LSP status:\n:LspInfo 7. Enhancing Auto-Completion with nvim-cmp To enable code auto-completion, update your init.lua:\nlocal cmp = require\u0026#39;cmp\u0026#39; cmp.setup({ mapping = { [\u0026#39;\u0026lt;C-Space\u0026gt;\u0026#39;] = cmp.mapping.complete(), [\u0026#39;\u0026lt;CR\u0026gt;\u0026#39;] = cmp.mapping.confirm({ select = true }), }, sources = { { name = \u0026#39;nvim_lsp\u0026#39; }, { name = \u0026#39;buffer\u0026#39; }, { name = \u0026#39;path\u0026#39; }, { name = \u0026#39;luasnip\u0026#39; }, { name = \u0026#39;nvim_lua\u0026#39; }, } }) 9. Final Thoughts Congratulations! You now have a powerful, customized Neovim setup that functions as a full-fledged IDE. With features like Treesitter, LSP support, auto-completion, syntax highlighting, Git integration, and a file explorer, your development workflow will be much smoother.\nIf you’d like to further improve your Neovim experience, explore more plugins and tweak your settings. Good luck with that!\nFurther Reading Neovim Documentation Awesome Neovim Plugins Arch Wiki: Neovim ","permalink":"http://localhost:1313/posts/setting-up-neovim-on-arch-linux-a-beginners-guide/","summary":"\u003ch1 id=\"setting-up-neovim-an-easy-and-beginners-guide\"\u003eSetting Up Neovim: An Easy and Beginner\u0026rsquo;s Guide\u003c/h1\u003e\n\u003cp\u003eNeovim is a modern and extensible text editor that enhances Vim’s capabilities. If you\u0026rsquo;re using Linux, setting up Neovim can be a rewarding experience, allowing you to customize it for an efficient workflow. In this guide, we\u0026rsquo;ll cover installing Neovim, setting up a basic configuration, and enhancing it with essential plugins to turn it into a full-fledged IDE.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"1-installing-neovim\"\u003e\u003cstrong\u003e1. Installing Neovim\u003c/strong\u003e\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003esudo pacman -S neovim\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003chr\u003e\n\u003ch2 id=\"2-setting-up-neovim-configuration\"\u003e\u003cstrong\u003e2. Setting Up Neovim Configuration\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003eNeovim’s configuration is stored in \u003ccode\u003e~/.config/nvim/\u003c/code\u003e. Create the directory and initialize a basic configuration:\u003c/p\u003e","title":"Setting Up Neovim: A Beginner's Guide"},{"content":"Linux Kernal The majority of the kernel\u0026rsquo;s code is written in C, leveraging extensions provided by the GNU Compiler Collection (GCC) beyond standard C. Additionally, it includes assembly code for architecture-specific functions, such as optimizing memory usage and task execution. Architecturally, the Linux kernel is monolithic, meaning the entire OS operates within kernel space. However, it features a modular design, allowing software components to be integrated as modules, including dynamic loading.\nWhat Is A Kernel Module? A Linux kernel module is precisely defined as a code segment capable of dynamic loading and unloading within the kernel as needed. These modules enhance kernel capabilities without necessitating a system reboot. A notable example is seen in the device driver module, which facilitates kernel interaction with hardware components linked to the system.\nWriting a Custom Linux Kernel Module Linux kernel modules (LKMs) allow developers to extend the functionality of the Linux kernel without modifying its source code. This guide walks through writing a simple kernel module from scratch. Kernel modules are pieces of code that can be dynamically loaded and unloaded from the Linux kernel at runtime. They enable functionality such as device drivers, file system support, and system call extensions without requiring a kernel recompilation. LKMs are particularly useful for developing hardware drivers and testing new kernel features without rebooting the system.\nPrerequisites Ensure you have the necessary development tools installed. On an Arch Linux system, install them with:\nsudo pacman -Syu linux-headers base-devel Creating a Simple Kernel Module 1. Writing the Module Source Code Create a file named hello_module.c:\n#include \u0026lt;linux/module.h\u0026gt; #include \u0026lt;linux/kernel.h\u0026gt; #include \u0026lt;linux/init.h\u0026gt; MODULE_LICENSE(\u0026#34;GPL\u0026#34;); MODULE_AUTHOR(\u0026#34;Your Name\u0026#34;); MODULE_DESCRIPTION(\u0026#34;A simple Hello World kernel module\u0026#34;); static int __init hello_init(void) { printk(KERN_INFO \u0026#34;Hello, Kernel!\\n\u0026#34;); return 0; } static void __exit hello_exit(void) { printk(KERN_INFO \u0026#34;Goodbye, Kernel!\\n\u0026#34;); } module_init(hello_init); module_exit(hello_exit); Understanding the Kernel Module Code #include \u0026lt;linux/module.h\u0026gt;: Includes the necessary module macros and functions. #include \u0026lt;linux/kernel.h\u0026gt;: Provides kernel logging functions. #include \u0026lt;linux/init.h\u0026gt;: Defines initialization and cleanup macros. MODULE_LICENSE(\u0026quot;GPL\u0026quot;): Specifies the module\u0026rsquo;s license. MODULE_AUTHOR(\u0026quot;Your Name\u0026quot;): Specifies the author of the module. MODULE_DESCRIPTION(\u0026quot;A simple Hello World kernel module\u0026quot;): Provides a brief description. static int __init hello_init(void): The function executed when the module is loaded. static void __exit hello_exit(void): The function executed when the module is unloaded. module_init(hello_init): Registers hello_init as the module\u0026rsquo;s initialization function. module_exit(hello_exit): Registers hello_exit as the module\u0026rsquo;s cleanup function. 2. Writing the Makefile Create a Makefile in the same directory:\nobj-m += hello_module.o all: make -C /lib/modules/$(shell uname -r)/build M=$(PWD) modules clean: make -C /lib/modules/$(shell uname -r)/build M=$(PWD) clean Understanding the Makefile obj-m += hello_module.o: Specifies that hello_module.o is the object to be built as a module. all:: Defines the build target. make -C /lib/modules/$(shell uname -r)/build M=$(PWD) modules: Directs the kernel build system to compile the module. clean:: Cleans up the generated files. make -C /lib/modules/$(shell uname -r)/build M=$(PWD) clean: Cleans the build artifacts. 3. Compiling the Module Run:\nmake 4. Loading and Unloading the Module To insert the module into the kernel:\nsudo insmod hello_module.ko Check the kernel log:\ndmesg | tail To remove the module:\nsudo rmmod hello_module 5. Verifying the Module List loaded modules:\nlsmod | grep hello_module Understanding the Generated Files After building the module, several files are generated:\nhello_module.c: The source code of the module. hello_module.ko: The compiled kernel module file, ready to be loaded into the kernel. hello_module.o: An intermediate object file generated during compilation. hello_module.mod.c: An automatically generated file containing module metadata. hello_module.mod.o: An object file containing metadata compiled from hello_module.mod.c. hello_module.mod: Another metadata file required for module loading. Makefile: Contains instructions for building the module. Module.symvers: Stores information about exported symbols, useful for module dependencies. modules.order: Lists the order in which modules should be loaded. Conclusion This simple kernel module demonstrates the basics of module development. You can expand upon this by adding functionality such as handling parameters or interacting with hardware.\nHappy kernel hacking!\n","permalink":"http://localhost:1313/posts/how-to-write-a-custom-kernel-module/","summary":"\u003ch1 id=\"linux-kernal\"\u003eLinux Kernal\u003c/h1\u003e\n\u003cp\u003eThe majority of the kernel\u0026rsquo;s code is written in C, leveraging extensions provided by the GNU Compiler Collection (GCC) beyond standard C. Additionally, it includes assembly code for architecture-specific functions, such as optimizing memory usage and task execution. Architecturally, the Linux kernel is monolithic, meaning the entire OS operates within kernel space. However, it features a modular design, allowing software components to be integrated as modules, including dynamic loading.\u003c/p\u003e","title":"How to Write a Custom Kernel Module"},{"content":"What is it? gh is GitHub\u0026rsquo;s official command-line tool designed to extend Git\u0026rsquo;s functionality with GitHub-specific features.\nPurpose: Simplifies interaction with GitHub\u0026rsquo;s ecosystem directly from the terminal. Allows you to manage repositories and use GitHub features like issues, pull requests, and workflows.\nKey Features: GitHub-specific tasks:\nAuthentication: Easier login (gh auth login) without dealing with tokens manually. Repository Management: Create, fork, or clone repositories. Issues \u0026amp; Pull Requests: Manage issues, PRs, and comments directly. Actions: Manage and view GitHub Actions workflows. Works alongside Git for basic version control tasks. Use Case: Best for developers heavily using GitHub and its features (for example: pull requests, issues, and actions).\nHow it works Install gh:\n\u0026gt; yay -S github-cli Verify the installation:\n\u0026gt; gh --version Login with GitHub CLI (gh)\n\u0026gt; gh auth login Follow the interactive prompts to log in:\nChoose HTTPS or SSH for connection. Log in via a browser using a one-time code or SSH keys. Verify authentication:\n\u0026gt; gh auth status What\u0026rsquo;s best about it that you can install and use both Git and gh (GitHub CLI) seamlessly. Here\u0026rsquo;s how to set them up:\nInstall Git\n\u0026gt;sudo pacman -S git Check the installation:\n\u0026gt; git --version Using Git and gh Together You can now: Use Git for version control:\n\u0026gt; git clone https://github.com/username/repo.git \u0026gt; git add . \u0026gt; git commit -m \u0026quot;message\u0026quot; \u0026gt; git push ","permalink":"http://localhost:1313/posts/github-cli-githubs-official-command-line-tools/","summary":"\u003ch2 id=\"what-is-it\"\u003eWhat is it?\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003egh\u003c/strong\u003e is GitHub\u0026rsquo;s official command-line tool designed to extend Git\u0026rsquo;s functionality with GitHub-specific features.\u003c/p\u003e\n\u003ch2 id=\"purpose\"\u003ePurpose:\u003c/h2\u003e\n\u003cp\u003eSimplifies interaction with GitHub\u0026rsquo;s ecosystem directly from the terminal. Allows you to manage repositories and use GitHub features like issues, pull requests, and workflows.\u003c/p\u003e\n\u003ch2 id=\"key-features\"\u003eKey Features:\u003c/h2\u003e\n\u003cp\u003eGitHub-specific tasks:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAuthentication: Easier login (gh auth login) without dealing with tokens manually.\u003c/li\u003e\n\u003cli\u003eRepository Management: Create, fork, or clone repositories.\u003c/li\u003e\n\u003cli\u003eIssues \u0026amp; Pull Requests: Manage issues, PRs, and comments directly.\u003c/li\u003e\n\u003cli\u003eActions: Manage and view GitHub Actions workflows.\u003c/li\u003e\n\u003cli\u003eWorks alongside Git for basic version control tasks.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"use-case\"\u003eUse Case:\u003c/h2\u003e\n\u003cp\u003eBest for developers heavily using GitHub and its features (for example: pull requests, issues, and actions).\u003c/p\u003e","title":"GitHub CLI: GitHub's Official Command Line Tools"},{"content":"Connecting a Raspberry Pi 5 to a USB TTY cable is a common way to interact with it through a serial connection, especially for debugging or setting up the device without using a display.\nPrerequists\nRaspberry Pi 5. USB TTY (serial) cable. Computer with a terminal emulator (minicom/screen). GPIO pinout diagram of Raspberry Pi 5 (for reference). Power source for Raspberry Pi (optional if USB TTY can power it, though not recommended). Before Starting! Issuse with firmware UART does NOT work on the RPI5 from the factory. We will need a firmware update to fix this that prevents the dtoverlays for UARTs from working.\nInstall rpi-update with the following commands:\n\u0026gt; sudo curl -L --output /usr/bin/rpi-update https://raw.githubusercontent.com/Hexxeh/rpi-update/master/rpi-update \u0026amp;\u0026amp; sudo chmod +x /usr/bin/rpi-update Then update the firmware on your RPI5 with:\n\u0026gt; sudo rpi-update Enable UART To manually configure UART, you can edit the config.txt file.\nEdit /boot/firmware/config.txt and add:\n\u0026gt; enable_uart=1 How to Connect Locate the GPIO Pins Find the GPIO header on the Raspberry Pi 5. Identify the following pins: GND (Ground): Usually black wire on the USB TTY cable. TX (Transmit): Sends data from the Pi to the computer. RX (Receive): Receives data from the computer to the Pi.\nUse a GPIO pinout chart to locate these pins. For Raspberry Pi 5, it will likely be similar to previous models. Making connections You will need to connect:\nGND with Ground - Pin# 06 TX with GPIO14 - Pin# 08 RX with GPIO15 - Pin# 10 Plug the USB TTY Cable into the Computer\nInsert the USB end of the TTY cable into your computer. The cable will create a virtual COM port (e.g /dev/ttyUSB0). Configure and Access Serial Console\nOpen a terminal.\nIdentify the port with:\n\u0026gt; ls /dev/ttyUSB* Use a terminal emulator like screen or minicom to connect:\n\u0026gt; screen /dev/ttyUSB0 115200 *Replace /dev/ttyUSB0 with the actual port name.\nTurn on the Raspberry Pi. If everything is set up correctly, you should see boot messages in the terminal. Log in to the Pi using the default username (pi) and password (raspberry), or your custom credentials. You should see something similar to this.\nThis is it! You have done it. Congrats!\n","permalink":"http://localhost:1313/posts/how-to-connect-a-raspberry-pi-5-to-usb-tty-cable/","summary":"\u003cp\u003eConnecting a Raspberry Pi 5 to a USB TTY cable is a common way to interact with it through a serial connection, especially for debugging or setting up the device without using a display.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003ePrerequists\u003c/strong\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eRaspberry Pi 5.\u003c/li\u003e\n\u003cli\u003eUSB TTY (serial) cable.\u003c/li\u003e\n\u003cli\u003eComputer with a terminal emulator (minicom/screen).\u003c/li\u003e\n\u003cli\u003eGPIO pinout diagram of Raspberry Pi 5 (for reference).\u003c/li\u003e\n\u003cli\u003ePower source for Raspberry Pi (optional if USB TTY can power it, though not recommended).\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"before-starting\"\u003e\u003cstrong\u003eBefore Starting!\u003c/strong\u003e\u003c/h3\u003e\n\u003ch3 id=\"issuse-with-firmware\"\u003e\u003cstrong\u003e\u003ca href=\"https://forums.raspberrypi.com/viewtopic.php?t=361397#p2171244\"\u003eIssuse with firmware\u003c/a\u003e\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003eUART does NOT work on the RPI5 from the factory. We will need a firmware update to fix this that prevents the dtoverlays for UARTs from working.\u003c/p\u003e","title":"How to Connect a Raspberry PI 5 to USB TTY Cable"},{"content":"Hosting a website on GitHub Pages with Hugo involves the following steps:\nCreating a website 1. Install Hugo and git\n\u0026gt; sudo pacman -S Hugo 2. Create a new Hugo site\n\u0026gt; hugo new site your-website 3. Add a Theme\nNavigate to your website directory and add a theme. You can choose one from the Hugo Themes .\n\u0026gt; cd your-website \u0026gt; git init \u0026gt; git submodule add https://github.com/adityatelange/hugo-PaperMod.git themes/hugo-PaperMod Now you will need to update the hugo.toml file for them to take effect. To do so you can either echo or addd it in the file.\n\u0026gt; echo \u0026quot;theme = 'hugo-PaperMod'\u0026quot; \u0026gt;\u0026gt; hugo.toml To view the website you can run it locally using Hugo\u0026rsquo;s development server to view the site. You can add -D to see your drafts.\n\u0026gt; hugo server 3. Add Content\nTo add a new page to your site.\n\u0026gt; hugo new content content/posts/yout-first-post.md This is it You have done it. YAY!\nHosting it on GitHub 1. Create a GitHub repository.\nClick the + icon in the top-right corner of:\u0026gt; [!WARNING] the GitHub interface and select New repository. Enter a repository name: yourusername.github.io Click Create repository. 2. Add Files for Your website\nClone the repository locally using Git:\ngit clone https://github.com//.git\nAdd your static site files (generated by Hugo) to the repository. Commit and push the changes:\n\u0026gt; git add -A \u0026gt; git commit -s -m \u0026quot;Initial commit\u0026quot; \u0026gt; git push origin main 3. Configure the Repository for GitHub Pages\nGo to the Settings tab of your new repository. Scroll down to the Pages section. Settings \u0026gt; Pages. In the center of your screen you will see this: Build and development Change the Source to GitHub Actions. 4. Create a file named hugo.yaml in a directory named .github/workflows.\n\u0026gt; mkdir -p .github/workflows \u0026gt; cd ./github/workflows touch hugo.yaml 5. Add content in the YAML file.\n# Sample workflow for building and deploying a Hugo site to GitHub Pages name: Deploy Hugo site to Pages on: # Runs on pushes targeting the default branch push: branches: - main # Allows you to run this workflow manually from the Actions tab workflow_dispatch: # Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages permissions: contents: read pages: write id-token: write # Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued. # However, do NOT cancel in-progress runs as we want to allow these production deployments to complete. concurrency: group: \u0026#34;pages\u0026#34; cancel-in-progress: false # Default to bash defaults: run: shell: bash jobs: # Build job build: runs-on: ubuntu-latest env: HUGO_VERSION: 0.141.0 steps: - name: Install Hugo CLI run: | wget -O ${{ runner.temp }}/hugo.deb https://github.com/gohugoio/hugo/releases/download/v${HUGO_VERSION}/hugo_extended_${HUGO_VERSION}_linux-amd64.deb \\ \u0026amp;\u0026amp; sudo dpkg -i ${{ runner.temp }}/hugo.deb - name: Install Dart Sass run: sudo snap install dart-sass - name: Checkout uses: actions/checkout@v4 with: submodules: recursive fetch-depth: 0 - name: Setup Pages id: pages uses: actions/configure-pages@v5 - name: Install Node.js dependencies run: \u0026#34;[[ -f package-lock.json || -f npm-shrinkwrap.json ]] \u0026amp;\u0026amp; npm ci || true\u0026#34; - name: Build with Hugo env: HUGO_CACHEDIR: ${{ runner.temp }}/hugo_cache HUGO_ENVIRONMENT: production TZ: America/Los_Angeles run: | hugo \\ --gc \\ --minify \\ --baseURL \u0026#34;${{ steps.pages.outputs.base_url }}/\u0026#34; - name: Upload artifact uses: actions/upload-pages-artifact@v3 with: path: ./public # Deployment job deploy: environment: name: github-pages url: ${{ steps.deployment.outputs.page_url }} runs-on: ubuntu-latest needs: build steps: - name: Deploy to GitHub Pages id: deployment uses: actions/deploy-pages@v4 5. Commit and push your GitHub repository.\n\u0026gt;git add -A \u0026gt;git commit -m \u0026quot;Create hugo.yaml\u0026quot; \u0026gt;git push 6. Deployment status From GitHub’s main menu, choose Actions. When GitHub has finished building and deploying your site, the color of the status indicator will change to green.\nStep 5: Verify Your GitHub Pages Site\nThe site will be live at https://yourusername.github.io.\n","permalink":"http://localhost:1313/posts/hosting-a-website-on-github-pages-with-hugo/","summary":"\u003cp\u003eHosting a website on GitHub Pages with Hugo involves the following steps:\u003c/p\u003e\n\u003ch1 id=\"creating-a-website\"\u003eCreating a website\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e1. Install Hugo and git\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; sudo pacman -S Hugo\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e2. Create a new Hugo site\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; hugo new site your-website\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e3. Add a Theme\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eNavigate to your website directory and add a theme. You can choose one from the \u003ca href=\"https://themes.gohugo.io/\"\u003eHugo Themes\u003c/a\u003e .\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; cd your-website\n\u0026gt; git init \n\u0026gt; git submodule add https://github.com/adityatelange/hugo-PaperMod.git themes/hugo-PaperMod\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow you will need to update the hugo.toml file for them to take effect. To do so you can either \u003cem\u003eecho\u003c/em\u003e or addd it in the file.\u003c/p\u003e","title":"Hosting a Website on Github Pages With Hugo"},{"content":"KVM Kernel-based Virtual Machine is a free and open-source virtualization module in the Linux kernel that allows the kernel to function as a hypervisor.\nInstallation For updates, run the following command:\n$ sudo pacman -Syu QEMU/KVM installation: We\u0026rsquo;ll install qemu and all the utils required:\n$ sudo pacman -S qemu vde2 ebtables iptables-nft nftables dms masq bridge-utils ovmf swptm Virtual Machine Manager installation: The virt-manager application is a graphical user interface for managing virtual machines through libvirt. It primarily targets KVM VMs.\n$ sudo pacman -S virt-manager Now everything is set to work. We can move towards downloading archlinux .iso file.\nDownload .iso file: Head towards: https://archlinux.org/download/ Scroll through and look for the server closest to you. Download archlinux-2024.10.01-x86_64.iso file. Setting up: Open terminal and run the following command:\n$ virt-manager You will see an interface similar to this:\nClick on \u0026lsquo;create a new virtual machine\u0026rsquo; (option with star). Select \u0026lsquo;Local install media\u0026rsquo;. Browse to your \u0026lsquo;archlinux-2024.10.01-x86_64.iso\u0026rsquo;. Add your desired VM configuration and create a disk image. Boot Menu: You will be prompted to a boot menu.\nSelect the topmost option to start the installation process. Archlinux Installer: You will be prompted to a terminal. The first step is to check if you are connected to the internet.\nRun:\n# ip addr show If it shows an IP address and says \u0026lsquo;UP\u0026rsquo;, that means you are good to go.\nIf not: You will need to connect to the internet using the \u0026lsquo;iwctl\u0026rsquo; method for Wi-Fi.\n# iwctl To search networks in your vicinity:\n[iwd]# station [your_wifi_interface] get-networks Get the name of the network you want to connect to. Exit from this prompt using \u0026rsquo;exit\u0026rsquo;.\nTo connect to the desired Wi-Fi network, run:\n# iwctl --passphrase \u0026#34;[wifi_password]\u0026#34; station [your_wifi_interface] connect [wifi_name] You can again run ip addr show to check if you are connected to the network.\nNow you can run the installation command. We\u0026rsquo;ll be using the archinstall method.\n# archinstall You will be prompted to an interface similar to this:\nWe will install Arch using this interface. Go through each option:\nArchinstall language: Choose your preferred language. Mirrors: Select the mirror region closest to you. Use \u0026lsquo;/\u0026rsquo; to search. Locales: Set language and keyboard layout. Disk configuration: Choose Best-effort default partition to format the system. Bootloader: Use the default \u0026lsquo;Grub\u0026rsquo; option. Swap: Select Swap on zram (default). Hostname: Leave as it is. Root password: Set the password for sudo/root privileges. User account: Set up a user account. Profile: Select Desktop. It includes essential packages. Others include Minimal, Server, and Xorg. In Desktop, select your desktop environment. We\u0026rsquo;ll use Gnome for simplicity.\nAudio: Use PipeWire (default) or PulseAudio. Kernels: Use the linux kernel. Additional packages: Install any required packages. Network Configuration: Use NetworkManager for a GUI in Gnome. Timezone: Set the timezone closest to you and enable time sync. Press Install. Congratulations! You\u0026rsquo;ve successfully installed Arch Linux.\n","permalink":"http://localhost:1313/posts/arch_kvm/","summary":"\u003ch1 id=\"kvm\"\u003eKVM\u003c/h1\u003e\n\u003cp\u003eKernel-based Virtual Machine is a free and open-source virtualization module in the Linux kernel that allows the kernel to function as a hypervisor.\u003c/p\u003e\n\u003ch2 id=\"installation\"\u003eInstallation\u003c/h2\u003e\n\u003cp\u003eFor updates, run the following command:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ sudo pacman -Syu\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"qemukvm-installation\"\u003eQEMU/KVM installation:\u003c/h3\u003e\n\u003cp\u003eWe\u0026rsquo;ll install qemu and all the utils required:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ sudo pacman -S qemu vde2 ebtables iptables-nft nftables dms masq bridge-utils ovmf swptm\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"virtual-machine-manager-installation\"\u003eVirtual Machine Manager installation:\u003c/h3\u003e\n\u003cp\u003eThe virt-manager application is a graphical user interface for managing virtual machines through libvirt. It primarily targets KVM VMs.\u003c/p\u003e","title":"archlinux installation in hypervisor through QEMU/KVM"},{"content":"","permalink":"http://localhost:1313/posts/github-cli-githubs-official-command-line-tool/","summary":"","title":""},{"content":"1. Introduction Sometimes you need to share a local application with the outside world — maybe to demo your project, test a webhook, or allow a teammate to access your development server.\nNormally, you’d need a public IP, port forwarding, or a cloud server. ngrok removes all that complexity by creating a secure tunnel from the internet directly to your machine, giving you a public URL instantly.\nIn this guide, we’ll walk through:\nInstalling ngrok on popular Linux distributions Authenticating your installation Exposing a local service to the internet Adding basic security Practical examples for real-world usage 2. Prerequisites Before we begin, make sure you have:\nA terminal A free ngrok account (for authentication token) A running local service (e.g., a Python HTTP server, web app, or API) 3. Installing ngrok on Linux We’ll cover installation for Arch Linux, Debian/Ubuntu, and Fedora.\n3.1 Arch Linux This package is not in the official repos, install it from the AUR:\nyay -S ngrok 3.2 Debian / Ubuntu sudo apt update sudo apt install snapd sudo snap install ngrok Alternatively, download the binary from the ngrok downloads page.\n3.3 Fedora sudo dnf install snapd sudo ln -s /var/lib/snapd/snap /snap sudo snap install ngrok 4. Authenticating ngrok Once installed, you need to connect it to your account so you can use custom domains, longer session times, and access the dashboard.\nSign in to ngrok dashboard. -\u0026gt; Your AuthToken Copy your AuthToken. Run: ngrok config add-authtoken \u0026lt;YOUR_TOKEN\u0026gt; You will see: Authtoken saved to configuration file: ~/.config/ngrok/ngrok.yml 5. Exposing a Local Service For example, if your local web server is running on port 8080:\nngrok http 8080 You’ll see output like:\nNow you can share the HTTPS URL with anyone. It wil be similar to: https://random.string.ngrok-free.app\n6. Adding Basic Security You can protect your tunnel with a simple username and password:\nngrok http --basic-auth=\u0026#34;user:password\u0026#34; 8080 Anyone visiting the public link will need credentials.\n7. The Inspector One of ngrok\u0026rsquo;s most powerful features is its built-in web interface, accessible at http://127.0.0.1:4040. This interface lets you inspect every single request that comes through your tunnel in real-time. You can see headers, request bodies, and response details, and even replay requests with a single click—an absolute lifesaver for debugging webhooks.\n8. Common Use Cases Webhook testing — Connect services like GitHub, Stripe, or Twilio to your local environment. Temporary demos — Share work-in-progress with clients without deployment. Remote device access — SSH into a Raspberry Pi without changing router settings. 9. Conclusion In just a few commands, you’ve learned how to:\nInstall ngrok on popular Linux distros Authenticate your installation Share a local service securely From here, you can explore ngrok’s advanced features like static domains, IP allowlists, and traffic inspection.\n","permalink":"http://localhost:1313/posts/ngrok/","summary":"\u003ch2 id=\"1-introduction\"\u003e1. Introduction\u003c/h2\u003e\n\u003cp\u003eSometimes you need to share a local application with the outside world — maybe to demo your project, test a webhook, or allow a teammate to access your development server.\u003c/p\u003e\n\u003cp\u003eNormally, you’d need a public IP, port forwarding, or a cloud server. \u003cstrong\u003engrok\u003c/strong\u003e removes all that complexity by creating a \u003cstrong\u003esecure tunnel\u003c/strong\u003e from the internet directly to your machine, giving you a public URL instantly.\u003c/p\u003e\n\u003cp\u003eIn this guide, we’ll walk through:\u003c/p\u003e","title":"Ngrok: Expose Localhost to the Internet"},{"content":"Creating a WhatsApp AI Assistant Using n8n: A Step-by-Step Guide Build your own AI-powered WhatsApp chatbot using n8n, WhatsApp Business Cloud API, and OpenAI. This guide walks you through every step—from setup to testing—with real-world error handling, solutions, and an example production-ready workflow.\n1. Introduction Want to chat with an AI on WhatsApp? In this tutorial, you\u0026rsquo;ll learn how to build a WhatsApp AI Assistant using:\nn8n (automation tool) WhatsApp Business Cloud API OpenAI (for generating intelligent replies) By the end, you\u0026rsquo;ll have a working chatbot and gain hands-on experience with APIs, webhooks, and automation.\n2. Prerequisites n8n account (Cloud or self-hosted) Meta Developer account with WhatsApp Business Cloud API access OpenAI API key Basic understanding of APIs and webhook workflows 3. Registering Your WhatsApp Business App A. Create WhatsApp App in Meta Developer Visit Meta for Developers Create a new app: choose Business → WhatsApp Link or create a WhatsApp Business Account B. Obtain Testing Credentials Your app dashboard will show:\nTest phone number Phone Number ID Temporary access token (valid for only 24 hours) Tip: For long-term use, generate a 60-day system-user token later.\nC. Add Recipients to Test List By default, only approved numbers can receive messages:\nNavigate to WhatsApp → API Setup Add numbers in E.164 format (e.g., +923001234567) Users must accept the invite via WhatsApp to become valid recipients 4. Configuring Your Webhook in n8n A. Create a Webhook Node Method: GET (for initial verification) Endpoint example: https://yourname.app.n8n.cloud/webhook/your-unique-id/webhook B. Verify the Webhook with Meta In your app’s Webhook section:\nCallback URL: your n8n webhook URL Verify Token: any secret string you choose (e.g., mySecret2025) C. Echo Back Meta’s Challenge Configure n8n\u0026rsquo;s Webhook node response:\nField Value Response Mode On Received Response Body {{$json[\u0026quot;query\u0026quot;][\u0026quot;hub.challenge\u0026quot;]}} This ensures Meta can verify your endpoint successfully.\n5. Processing Incoming Messages WhatsApp sends JSON data with structure like:\n{ \u0026#34;entry\u0026#34;: [ { \u0026#34;changes\u0026#34;: [ { \u0026#34;value\u0026#34;: { \u0026#34;messages\u0026#34;: [ { \u0026#34;from\u0026#34;: \u0026#34;923001234567\u0026#34;, \u0026#34;text\u0026#34;: { \u0026#34;body\u0026#34;: \u0026#34;Hello bot!\u0026#34; } } ], \u0026#34;metadata\u0026#34;: { \u0026#34;phone_number_id\u0026#34;: \u0026#34;698352170035199\u0026#34; } } } ] } ] } Extract:\nfrom: user’s number text.body: user’s text metadata.phone_number_id: correct sender ID 6. Integrating OpenAI for Responses Obtaining Your OpenAI API Key Before integrating OpenAI into your n8n workflow, you’ll need to get an API key from OpenAI.\nStep-by-Step: Sign up or log in to OpenAI. Navigate to your API Keys page. Click \u0026ldquo;Create new secret key\u0026rdquo;. Optionally name your key, then copy it immediately (you won’t be able to view it again). In n8n: Go to Credentials → Add New → choose OpenAI or HTTP Request. Paste your API key into the key field. Save the credentials. Security Tip: Keep your key private. Do not share it or commit it to public repositories.\nUse an HTTP Request node to call OpenAI:\nPOST https://api.openai.com/v1/chat/completions Authorization: Bearer YOUR_OPENAI_API_KEY Content-Type: application/json { \u0026#34;model\u0026#34;: \u0026#34;gpt-4o-mini\u0026#34;, \u0026#34;messages\u0026#34;: [ { \u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;You are a helpful WhatsApp AI assistant.\u0026#34; }, { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;{{ $json[...] }}\u0026#34; } ] } Replace {{ $json[...] }} with the actual path to the user\u0026rsquo;s message text from the Webhook node.\n7. Sending Replies via WhatsApp Use another HTTP Request node to respond:\nPOST https://graph.facebook.com/v21.0/{{ $json[...] }}/messages Authorization: Bearer YOUR_LONG_LIVED_TOKEN Content-Type: application/json { \u0026#34;messaging_product\u0026#34;: \u0026#34;whatsapp\u0026#34;, \u0026#34;to\u0026#34;: \u0026#34;{{ $json[...] }}\u0026#34;, \u0026#34;text\u0026#34;: { \u0026#34;body\u0026#34;: \u0026#34;{{ $node[\u0026#39;OpenAI Response\u0026#39;].json.choices[0].message.content }}\u0026#34; } } Use the metadata’s phone_number_id for the endpoint and from for the recipient. This avoids hardcoding and ensures proper routing.\n8. Example n8n Workflow Here’s the actual n8n workflow I used for my WhatsApp AI assistant. It integrates a product brochure PDF into a vector store for AI-powered Q\u0026amp;A, and handles WhatsApp message flow.\nStep-by-Step Breakdown: 1. Download Product Brochure PDF Downloads the brochure from a given URL. Extracts text from the PDF. 2. Create Product Brochure Vector Store Splits large text into chunks. Generates embeddings using OpenAI. Saves them in a vector store for fast semantic search. 3. Use the WhatsApp Trigger Listens for incoming WhatsApp messages. Routes them to supported or unsupported handlers. 3a. Handle Unsupported Messages Replies with a friendly error if the message type is not text. 4. Sales AI Agent Responds Uses OpenAI with memory + vector store retrieval to answer based on brochure content. 5. Reply to WhatsApp User Sends the AI-generated message back to the sender. Why this is effective:\nContext-aware answers via buffer memory. Reduced hallucinations thanks to vector store grounding. Smooth error handling for unsupported message types. 9. Common Errors \u0026amp; Fixes Recipient phone number not in allowed list\n→ Add as test number or switch to Live mode\n401 – Session expired\n→ Refresh token via Graph API:\nGET https://graph.facebook.com/v21.0/oauth/access_token ?grant_type=fb_exchange_token \u0026amp;client_id=YOUR_APP_ID \u0026amp;client_secret=YOUR_APP_SECRET \u0026amp;fb_exchange_token=YOUR_CURRENT_TOKEN Webhook verification failed\n→ Ensure verify token matches between Meta and n8n and echo hub.challenge\nNo execution data available\n→ Trigger workflow via actual WhatsApp message, not manual run\n10. Going Live Add a Privacy Policy URL in Meta App → Settings → Basic (required for live access) Switch app to Live mode once all compliance items are met Remove restricted recipient list Use WhatsApp message templates for messages sent after 24 hours of user interaction 11. Conclusion \u0026amp; Next Steps Congrats! You now have a WhatsApp AI Assistant built with n8n and OpenAI.\nWhere to go from here: Wire up custom knowledge (PDFs, documents) Implement memory for conversation context Launch multilingual support Export n8n workflow as JSON for reuse Need help? Join the n8n Community Forum or OpenAI Discord to connect with fellow builders.\nHappy automating!\n","permalink":"http://localhost:1313/posts/creating-whatsapp-ai-assistant-using-n8n2/","summary":"\u003ch1 id=\"creating-a-whatsapp-ai-assistant-using-n8n-a-step-by-step-guide\"\u003eCreating a WhatsApp AI Assistant Using n8n: A Step-by-Step Guide\u003c/h1\u003e\n\u003cp\u003eBuild your own AI-powered WhatsApp chatbot using \u003cstrong\u003en8n\u003c/strong\u003e, \u003cstrong\u003eWhatsApp Business Cloud API\u003c/strong\u003e, and \u003cstrong\u003eOpenAI\u003c/strong\u003e. This guide walks you through every step—from setup to testing—with real-world error handling, solutions, and an example production-ready workflow.\u003c/p\u003e\n\u003ch2 id=\"1-introduction\"\u003e1. Introduction\u003c/h2\u003e\n\u003cp\u003eWant to chat with an AI on WhatsApp? In this tutorial, you\u0026rsquo;ll learn how to build a \u003cstrong\u003eWhatsApp AI Assistant\u003c/strong\u003e using:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003en8n\u003c/strong\u003e (automation tool)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eWhatsApp Business Cloud API\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eOpenAI\u003c/strong\u003e (for generating intelligent replies)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eBy the end, you\u0026rsquo;ll have a working chatbot and gain hands-on experience with APIs, webhooks, and automation.\u003c/p\u003e","title":"Creating Whatsapp Ai Assistant Using N8n"},{"content":"Introduction A memory leak occurs when a program allocates memory dynamically (e.g., using malloc) and fails to release it using free. This leftover allocation can lead to wasted memory resources, eventually causing slowdowns or system crashes in long-running programs.\nValgrind is a powerful command-line tool available on Linux systems. It helps developers detect:\nMemory leaks Invalid memory access Uninitialized memory usage Mismatched memory management In this guide, we\u0026rsquo;ll walk through examples in C to learn how to detect and fix memory leaks using Valgrind.\nInstalling Valgrind On Arch Linux sudo pacman -S valgrind On Ubuntu/Debian sudo apt install valgrind On Fedora sudo dnf install valgrind Troubleshooting: Valgrind \u0026ldquo;cannot find mandatory redirection\u0026rdquo; on Arch Linux If you run Valgrind and get an error like:\nvalgrind: Fatal error at startup: a function redirection\nvalgrind: which is mandatory for this platform-tool combination\nvalgrind: cannot be set up.\n…you might be running a 32-bit executable on a 64-bit Arch Linux system.\nWhy this happens Valgrind needs to hook into low-level glibc functions from your binary’s architecture.\nIf your binary is 32-bit, Arch requires the 32-bit glibc runtime (lib32-glibc).\nWithout it, Valgrind can’t find the right function symbols and quits.\nFix Install the 32-bit glibc package:\nsudo pacman -S lib32-glibc After installation, re-run:\nvalgrind ./your-binary and it should work.\nUbuntu/Debian equivalent: sudo apt install libc6-dbg:i386\nBasic Example: Hello World Code #include \u0026lt;stdio.h\u0026gt; int main() { printf(\u0026#34;Hello World\\n\u0026#34;); return 0; } Compile and Run gcc main.c -o main.out ./main.out Run with Valgrind valgrind ./main.out You should see no errors or memory leaks in the output.\nIntroducing a Memory Leak Static Allocation (Safe) #include \u0026lt;stdio.h\u0026gt; int main() { char str[20] = \u0026#34;Hello\u0026#34;; printf(\u0026#34;%s\\n\u0026#34;, str); return 0; } This uses stack memory, so Valgrind will report no leaks.\nDynamic Allocation (With Leak) #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; int main() { char *str = malloc(20); strcpy(str, \u0026#34;Hello\u0026#34;); printf(\u0026#34;%s\\n\u0026#34;, str); return 0; // Forgot to free memory } Valgrind Output valgrind ./main.out You should see:\ndefinitely lost: 20 bytes in 1 blocks\nFixing the Memory Leak Add free(str); before returning:\nfree(str); Fixed Code #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; int main() { char *str = malloc(20); strcpy(str, \u0026#34;Hello\u0026#34;); printf(\u0026#34;%s\\n\u0026#34;, str); free(str); return 0; } Detailed Valgrind Options Use for deeper analysis:\nvalgrind --leak-check=full ./main.out Or even more detailed:\nvalgrind --leak-check=full --show-leak-kinds=all --track-origins=yes ./main.out Explanation:\n--leak-check=full: Display detailed leak info --show-leak-kinds=all: Show all kinds of leaks (definitely, indirectly lost, etc.) --track-origins=yes: Show where uninitialized values originate Summary Always free() memory allocated with malloc(), calloc(), or realloc(). Close all file streams with fclose(). Use Valgrind to identify and fix: Memory leaks Invalid memory writes Use-after-free bugs Recommended command: valgrind --leak-check=full --track-origins=yes ./your_program Valgrind is a critical tool for writing safe, efficient, and bug-free C programs.\n","permalink":"http://localhost:1313/posts/introductiontovalgrind/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eA \u003cstrong\u003ememory leak\u003c/strong\u003e occurs when a program allocates memory dynamically (e.g., using \u003ccode\u003emalloc\u003c/code\u003e) and fails to release it using \u003ccode\u003efree\u003c/code\u003e. This leftover allocation can lead to wasted memory resources, eventually causing slowdowns or system crashes in long-running programs.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eValgrind\u003c/strong\u003e is a powerful command-line tool available on Linux systems. It helps developers detect:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eMemory leaks\u003c/li\u003e\n\u003cli\u003eInvalid memory access\u003c/li\u003e\n\u003cli\u003eUninitialized memory usage\u003c/li\u003e\n\u003cli\u003eMismatched memory management\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIn this guide, we\u0026rsquo;ll walk through examples in C to learn how to detect and fix memory leaks using Valgrind.\u003c/p\u003e","title":"Detecting and Fixing Memory Leaks with Valgrind"},{"content":"QEMU-KVM on Arch Linux: Running Tiny Core Linux in a Lightweight VM Virtualization is a powerful tool for developers, sysadmins, and tinkerers alike. On Linux, QEMU-KVM stands out as a robust, high-performance virtualization stack. In this blog, well walk through setting up QEMU-KVM on Arch Linux and using it to run Tiny Core Linuxa super-lightweight distro perfect for testing and experimentation.\nWhat is QEMU-KVM QEMU (Quick Emulator) is a generic and open-source machine emulator. On its own, it can emulate various hardware systems. However, when paired with **KVM (Kernel-based Virtual Machine)**a Linux kernel module for virtualizationit can run virtual machines with near-native performance.\nQEMU provides device emulation and user-space management. KVM integrates with the Linux kernel and handles hardware-level virtualization. Together, they effectively form a Type 1 hypervisor because the Linux kernel (with KVM) handles core virtualization tasks directly on hardware.\nStep-by-Step: Installing QEMU-KVM on Arch Linux Step 1: Install Required Packages sudo pacman -Syu sudo pacman -S qemu virt-manager virt-viewer dnsmasq vde2 bridge-utils openbsd-netcat libvirt edk2-ovmf edk2-ovmf is for UEFI firmware support in VMs.\nStep 2: Enable and Start libvirtd sudo systemctl enable --now libvirtd.service Step 3: Add Your User to the libvirt Group sudo usermod -aG libvirt (whoami) newgrp libvirt Step 4: Verify KVM Support lsmod grep kvm And check CPU virtualization support:\negrep -c (vmxsvm) /proc/cpuinfo A value of 1 or more indicates virtualization support.\nExample: Running Tiny Core Linux on QEMU-KVM Now that your system is ready, lets run Tiny Core Linux, a minimalist Linux distro thats only 16MB\nStep 1: Download Tiny Core ISO wget http://tinycorelinux.net/14.x/x86/release/Core-current.iso Or visit http://tinycorelinux.net for the latest release.\nStep 2: Create a Virtual Disk (Optional) qemu-img create -f qcow2 tinycore.qcow2 512M This creates a 512MB disk image. Optional for RAM-only usage.\nStep 3: Launch the VM with KVM Acceleration qemu-system-x86_64 -enable-kvm -m 512 -cpu host -smp 1 -cdrom Core-current.iso -hda tinycore.qcow2 -boot d -net nic -net user -vga virtio -display sdl Key Flags Explained:\n-enable-kvm: Enables KVM hardware acceleration -m 512: Allocates 512MB RAM -cpu host: Uses the host CPU features -cdrom: Points to the Tiny Core ISO -hda: Uses a QCOW2 disk image -boot d: Boots from CD first -net user: Enables simple user-mode networking (e.g., for internet access) -display sdl: Uses SDL window for graphics (you can replace with gtk or virt-manager) Alternate: Boot Tiny Core in RAM Without Disk qemu-system-x86_64 -enable-kvm -m 256 -cdrom Core-current.iso -boot d -net nic -net user -vga std Conclusion With QEMU-KVM, Arch Linux becomes a full-featured Type 1 hypervisor. By combining kernel-level virtualization (KVM) with the flexibility of QEMU, you get a fast, customizable virtualization platform. Running Tiny Core Linux showcases just how lightweight and efficient this setup can be.\nWhether youre building VMs for testing, learning Linux internals, or experimenting with custom environments, QEMU-KVM on Arch is a powerful combination.\nHappy virtualizing\n","permalink":"http://localhost:1313/posts/qemu/","summary":"\u003ch1 id=\"qemu-kvm-on-arch-linux-running-tiny-core-linux-in-a-lightweight-vm\"\u003eQEMU-KVM on Arch Linux: Running Tiny Core Linux in a Lightweight VM\u003c/h1\u003e\n\u003cp\u003eVirtualization is a powerful tool for developers, sysadmins, and tinkerers alike. On Linux, \u003cstrong\u003eQEMU-KVM\u003c/strong\u003e stands out as a robust, high-performance virtualization stack. In this blog, well walk through setting up QEMU-KVM on \u003cstrong\u003eArch Linux\u003c/strong\u003e and using it to run \u003cstrong\u003eTiny Core Linux\u003c/strong\u003ea super-lightweight distro perfect for testing and experimentation.\u003c/p\u003e\n\u003ch2 id=\"what-is-qemu-kvm\"\u003eWhat is QEMU-KVM\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eQEMU (Quick Emulator)\u003c/strong\u003e is a generic and open-source machine emulator. On its own, it can emulate various hardware systems. However, when paired with **KVM (Kernel-based Virtual Machine)**a Linux kernel module for virtualizationit can run virtual machines with near-native performance.\u003c/p\u003e","title":"QEMU-KVM on Arch Linux: Running Tiny Core Linux in a Lightweight VM"},{"content":"Building the Linux Kernel Compiling the Linux Kernel involves multiple steps and can take some time depending on your hardware specifications.\nStep 1: Download the Kernel Source Code Start by visiting the Official Linux Kernel Website and downloading the latest available kernel source code. The downloaded file will be a compressed archive containing all necessary source files.\nStep 2: Extract the Source Code Once the download completes, extract the contents of the compressed archive using the tar command:\ntar xvf linux-6.13.tar.xz If the tar utility is not installed on your system, you can install it using:\nsudo pacman -S tar Note: Always ensure you are using the correct version number in the file name.\nStep 3: Install Required Dependencies To compile the kernel, you need to install various development tools and libraries. Install them using the following command:\nsudo pacman -S git fakeroot ncurses xz bc flex bison base-devel kmod cpio perl binutils util-linux jfsutils e2fsprogs xfsprogs squashfs-tools quota-tools Step 4: Configure the Kernel Navigate into the kernel source directory: cd linux-6.13 Use your current system’s configuration as a base:\nIf zcat is available, run:\nzcat /proc/config.gz \u0026gt; .config Otherwise, use this alternative method:\ncp /proc/config.gz ./ gunzip config.gz mv config .config Customize the kernel using a menu-driven interface:\nmake menuconfig make xconfig make oldconfig Modify the .config file directly:\nOpen it with a text editor:\nsudo vim .config Search for the line:\nCONFIG_EXT4_FS=m And change it to:\nCONFIG_EXT4_FS=y Step 5: Compile the Kernel Determine the number of CPU cores available to speed up compilation: nproc Compile the kernel using the number of cores found above. Replace n with that number: make -j\u0026lt;n\u0026gt; If you encounter any errors during or after this step, back up your .config file and reset the source tree with:\nmake mrproper This command cleans the build environment and restores the source tree to its original state.\nStep 6: Install Kernel Modules Kernel modules are essential for extending the kernel’s functionality and ensuring compatibility with various hardware. Install them with:\nsudo make modules_install Step 7: Install the Kernel You can install the compiled kernel using one of the two methods below:\nAutomatic installation: sudo make install Manual installation (if the above doesn\u0026rsquo;t work):\nCopy the kernel image:\nsudo cp arch/x86/boot/bzImage /boot/vmlinuz-linux-custom Copy the System.map file:\nsudo cp System.map /boot/System.map-linux-custom Copy the kernel configuration file:\nsudo cp .config /boot/config-linux-custom Step 8: Update the Bootloader If you use GRUB, follow these steps to add an entry for your custom kernel:\nFind the UUID of your root partition: lsblk -f Open the custom GRUB configuration file: sudo nvim /etc/grub.d/40_custom Add the following entry (replace paste-your-root-partition-uuid-here with the actual UUID): menuentry \u0026#39;Custom Linux Kernel\u0026#39; { linux /boot/vmlinuz-linux-custom root=UUID=paste-your-root-partition-uuid-here initrd /boot/initramfs-linux.img } Step 9: Generate Initramfs As you\u0026rsquo;ve compiled a new kernel, installed modules, and modified boot entries, generating a new initramfs is necessary. Run:\nsudo mkinitcpio -k 6.13-custom -c /etc/mkinitcpio.conf -g /boot/initramfs-linux-custom.img Make sure the version (6.13-custom) matches your compiled kernel.\nStep 10: Update GRUB Configuration Finally, update the GRUB configuration so that it includes your new kernel entry:\nsudo grub-mkconfig -o /boot/grub/grub.cfg Done! Congratulations! You’ve successfully compiled and installed your custom Linux Kernel. Enjoy your personalized system!\n","permalink":"http://localhost:1313/posts/kernal_compilation/","summary":"\u003ch1 id=\"building-the-linux-kernel\"\u003eBuilding the Linux Kernel\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003eCompiling the Linux Kernel involves multiple steps and can take some time depending on your hardware specifications.\u003c/strong\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"step-1-download-the-kernel-source-code\"\u003eStep 1: Download the Kernel Source Code\u003c/h3\u003e\n\u003cp\u003eStart by visiting the \u003ca href=\"https://www.kernel.org/\"\u003eOfficial Linux Kernel Website\u003c/a\u003e and downloading the latest available kernel source code. The downloaded file will be a compressed archive containing all necessary source files.\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"step-2-extract-the-source-code\"\u003eStep 2: Extract the Source Code\u003c/h3\u003e\n\u003cp\u003eOnce the download completes, extract the contents of the compressed archive using the \u003ccode\u003etar\u003c/code\u003e command:\u003c/p\u003e","title":"How to build Linux Kernal: Step by Step Guide"},{"content":"Introduction So, you’ve built a sleek website with Hugo and deployed it to GitHub Pages. Now, you want to give it a professional touch with a custom domain like yourdomain.tech instead of the default username.github.io URL. This guide walks you through the process step-by-step.\nPrerequisites A Hugo website hosted on GitHub Pages (public repository). A custom domain (e.g., yourdomain.tech) purchased from a registrar like Namecheap, Google Domains, etc. Basic familiarity with DNS settings and GitHub repository configurations. Step 1: Configure Your GitHub Repository First, ensure your GitHub Pages site is set up correctly:\nYour repository should be named \u0026lt;username\u0026gt;.github.io (for user/organization sites) or \u0026lt;repo-name\u0026gt; (for project sites). The gh-pages branch (or the /docs folder) should contain your Hugo-generated static files. Step 2: Configure DNS Settings for Your Domain Option 1: Use an Apex Domain (e.g., yourdomain.tech) If you want your site to live at the root domain (e.g., yourdomain.tech), configure A records in your DNS settings:\nGo to your domain registrar’s DNS management page. Create four A records pointing to GitHub’s IP addresses: Host: @ Type: A Value: 185.199.108.153 TTL: Automatic ","permalink":"http://localhost:1313/posts/customdomain/","summary":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003eSo, you’ve built a sleek website with Hugo and deployed it to GitHub Pages. Now, you want to give it a professional touch with a custom domain like \u003ccode\u003eyourdomain.tech\u003c/code\u003e instead of the default \u003ccode\u003eusername.github.io\u003c/code\u003e URL. This guide walks you through the process step-by-step.\u003c/p\u003e\n\u003ch2 id=\"prerequisites\"\u003ePrerequisites\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003eA Hugo website hosted on GitHub Pages (public repository).\u003c/li\u003e\n\u003cli\u003eA custom domain (e.g., \u003ccode\u003eyourdomain.tech\u003c/code\u003e) purchased from a registrar like Namecheap, Google Domains, etc.\u003c/li\u003e\n\u003cli\u003eBasic familiarity with DNS settings and GitHub repository configurations.\u003c/li\u003e\n\u003c/ol\u003e\n\u003chr\u003e\n\u003ch2 id=\"step-1-configure-your-github-repository\"\u003eStep 1: Configure Your GitHub Repository\u003c/h2\u003e\n\u003cp\u003eFirst, ensure your GitHub Pages site is set up correctly:\u003c/p\u003e","title":"How to up custom domain for GitHub Pages"},{"content":"Exception handling is a crucial aspect of writing robust and reliable Python code. Whether you\u0026rsquo;re a beginner or an experienced developer, getting an error, or exception, in your Python program means the entire program will crash. You don’t want this to happen in real-world programs. Instead, you want the program to detect errors, handle them, and then continue to run. In this blog, we\u0026rsquo;ll explore the fundamentals of exception handling in Python, including syntax, best practices, and advanced techniques.\nWhat Are Exceptions? Exceptions are runtime errors that disrupt the normal flow of a program. For example, trying to open a non-existent file, dividing by zero, or accessing an invalid index in a list will raise exceptions. If unhandled, these exceptions cause your program to crash.\nBasic Syntax: try and except The primary mechanism for handling exceptions in Python is the try-except block. Errors can be handled with with this. The code that could potentially have an error is put in a try clause. The program execution moves to the start of a following except clause if an error happens.\nHere\u0026rsquo;s the basic structure:\ndef cal(value): try: return 10 / value except ZeroDivisionError: print(\u0026#34;Cannot divide by zero!\u0026#34;) print(cal(0)) print(cal(2)) print(cal(3)) How It Works: The code inside the try block is executed. If an exception occurs, Python checks the except blocks for a matching exception type. If a match is found, the corresponding except block runs. Catching Specific Exceptions Always catch specific exceptions to avoid silencing unexpected errors. Python has many built-in exceptions (e.g., ValueError, TypeError, FileNotFoundError).\nimport math x = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) try: print(f\u0026#39;Square Root of {x} is {math.sqrt(x)}\u0026#39;) except ValueError: print(\u0026#39;Number is less than 0\u0026#39;) Output\nThe else Clause The else block runs only if no exceptions were raised in the try block. Use it to separate \u0026ldquo;happy path\u0026rdquo; code from error handling.\nimport math def sqr(value): try: x = math.sqrt(value) except ValueError: print(\u0026#39;Number is less than 0\u0026#39;) else: print(f\u0026#39;The Answer is: {x}\u0026#39;) value = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) sqr(value) Output The finally Clause The finally block runs regardless of whether an exception occurred. It’s ideal for cleanup tasks (e.g., closing files or releasing resources).\nimport math def sqr(value): try: x = math.sqrt(value) except ValueError: print(\u0026#39;Error\u0026#39;) else: print(f\u0026#39;The Answer is: {x}\u0026#39;) finally: print(\u0026#39;Program Ends\u0026#39;) value = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) sqr(value) Output Raising Exceptions Manually Use the raise keyword to trigger exceptions intentionally. This is useful for enforcing constraints.\ndef validate_age(age): if age \u0026lt; 0: raise ValueError(\u0026#34;Age cannot be negative!\u0026#34;) return age try: validate_age(-5) except ValueError as e: print(e) Creating Custom Exceptions Define custom exceptions by subclassing Python’s built-in Exception class. This makes your code more readable and errors more descriptive. (note: I have used RegEx, for that blog will be out soon :) )\nimport re class InvalidEmailError(Exception): \u0026#34;\u0026#34;\u0026#34;Raised when an email format is invalid.\u0026#34;\u0026#34;\u0026#34; pass def send_email(valid,email): if not valid: raise InvalidEmailError(f\u0026#34;Invalid email: {email}\u0026#34;) email = input(\u0026#39;Please enter your email: \u0026#39;) valid = re.match(r\u0026#39;^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\u0026#39;, email) try: send_email(valid, email) except InvalidEmailError as e: print(e) Output Logging a Python Error We can Log an exception in Python with an error. This can be done in the logging.exception() method. This function logs a message with level ERROR on this logger.\nimport math import logging def sqr(value): try: x = math.sqrt(value) except ValueError: logging.exception(\u0026#34;Error\u0026#34;) else: print(f\u0026#39;The Answer is: {x}\u0026#39;) finally: print(\u0026#39;Program Ends\u0026#39;) value = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) sqr(value) Output Best Practices for Exception Handling Catch specific exceptions: Avoid broad except: clauses that hide bugs. Keep try blocks minimal: Only wrap code that might raise an exception. Use finally for cleanup: Ensure resources are released (e.g., closing files). Log exceptions: Use logging.error() instead of print() for production code. Provide meaningful messages: Help debug issues faster with clear error descriptions. Avoid empty except blocks: Silent failures make debugging harder. Conclusion Exception handling is essential for writing better Python applications. By using try-except blocks effectively, catching specific errors, and with else/finally clauses, you can create programs that handle unexpected scenarios.\nNow go forth and write bulletproof Python code!\n","permalink":"http://localhost:1313/posts/exception_handling_in_python/","summary":"\u003cp\u003eException handling is a crucial aspect of writing robust and reliable Python code. Whether you\u0026rsquo;re a beginner or an experienced developer, getting an error, or exception, in your Python program means the entire program will crash. You don’t want this to happen in real-world programs. Instead, you want the program to detect errors, handle them, and then continue to run. In this blog, we\u0026rsquo;ll explore the fundamentals of exception handling in Python, including syntax, best practices, and advanced techniques.\u003c/p\u003e","title":"Exception Handling in Python: A Comprehensive Guide"},{"content":"Have you ever wanted your Python program to do multiple things at once? For example, downloading files while updating the UI, or processing data while listening for user input? That’s where multithreading comes in.\nIn this post, we’ll explore multithreading in Python — what it is, when to use it, and how to use it with simple examples.\n🧠 What is Multithreading? Multithreading is a way to run multiple threads (smaller units of a process) at the same time. It helps make your program more responsive or perform tasks in parallel, especially when tasks are I/O-bound (e.g., network calls, file reading, etc.).\nPython has a built-in module called threading that makes it easy to create and manage threads.\n⚠️ But Wait — Python\u0026rsquo;s GIL Before you jump in, it\u0026rsquo;s important to understand the Global Interpreter Lock (GIL). In CPython (the standard Python implementation), the GIL allows only one thread to execute Python bytecode at a time.\nThis means multithreading in Python is best suited for I/O-bound tasks, not CPU-bound tasks like heavy computations. For CPU-bound tasks, consider multiprocessing instead.\n🛠️ Using the threading Module Here\u0026rsquo;s a basic example to demonstrate multithreading:\nimport threading import time def print_numbers(): for i in range(5): print(f\u0026#34;Number: {i}\u0026#34;) time.sleep(1) def print_letters(): for letter in \u0026#39;abcde\u0026#39;: print(f\u0026#34;Letter: {letter}\u0026#34;) time.sleep(1) # Creating threads t1 = threading.Thread(target=print_numbers) t2 = threading.Thread(target=print_letters) # Starting threads t1.start() t2.start() # Wait for both threads to complete t1.join() t2.join() print(\u0026#34;Both threads have finished.\u0026#34;) 🔍 Output (interleaved): Number: 0 Letter: a Number: 1 Letter: b ... Both functions run at the same time, and you can see their output interleave. That’s multithreading in action!\n📦 Real-World Use Cases Downloading multiple files at once Handling multiple client connections on a server Running background tasks like logging or monitoring Keeping your GUI app responsive while doing other work 🧰 Extra Tools For more advanced usage:\nconcurrent.futures.ThreadPoolExecutor — easier thread management queue.Queue — safe way to share data between threads threading.Lock — prevents race conditions 🧪 Example with ThreadPoolExecutor from concurrent.futures import ThreadPoolExecutor import time def task(name): print(f\u0026#34;{name} starting\u0026#34;) time.sleep(2) print(f\u0026#34;{name} done\u0026#34;) with ThreadPoolExecutor(max_workers=2) as executor: executor.submit(task, \u0026#34;Task 1\u0026#34;) executor.submit(task, \u0026#34;Task 2\u0026#34;) ✅ Final Thoughts Multithreading in Python is a powerful tool when used correctly — especially for I/O-bound programs. Just remember the GIL limitation and use the right tool (like multiprocessing) when working with CPU-heavy tasks.\nThanks for reading! Happy threading 🧵🐍\n","permalink":"http://localhost:1313/posts/multithreading/","summary":"\u003cp\u003eHave you ever wanted your Python program to do multiple things at once? For example, downloading files while updating the UI, or processing data while listening for user input? That’s where \u003cstrong\u003emultithreading\u003c/strong\u003e comes in.\u003c/p\u003e\n\u003cp\u003eIn this post, we’ll explore multithreading in Python — what it is, when to use it, and how to use it with simple examples.\u003c/p\u003e\n\u003ch2 id=\"-what-is-multithreading\"\u003e🧠 What is Multithreading?\u003c/h2\u003e\n\u003cp\u003eMultithreading is a way to run multiple threads (smaller units of a process) at the same time. It helps make your program more responsive or perform tasks in parallel, especially when tasks are I/O-bound (e.g., network calls, file reading, etc.).\u003c/p\u003e","title":"Multithreading in Python"},{"content":"Running a Local LLM on Mobile: Testing PocketPal on iPhone 12 With the increasing accessibility of large language models (LLMs), running them locally on mobile devices is an exciting prospect. I recently tested PocketPal, a mobile LLM interface, on my iPhone 12, using a distilled 4-bit quantized model. Here’s a breakdown of my experience, covering installation, performance, and overall usability.\nWhy Run an LLM on Mobile? Running an LLM locally on a mobile device comes with several advantages:\nPrivacy: No data is sent to external servers. Offline Access: Works without an internet connection. Lower Cost: Avoids API costs associated with cloud-based models. What is Quantization? Quantization is a technique used to reduce the memory and computational requirements of machine learning models by representing their weights with lower precision numbers. Instead of using 32-bit floating-point numbers, models can be compressed into 8-bit or even 4-bit integers while maintaining reasonable accuracy.\nFor LLMs on mobile, 4-bit quantization significantly reduces the model size, making it feasible to run on devices with limited resources. However, this compression can lead to:\nSlightly reduced accuracy due to loss of precision. Faster inference times, as lower-bit computations require less processing power. Lower memory usage, allowing larger models to fit within mobile device constraints. Setting Up and Running PocketPal on iPhone 12 1. Download and Install PocketPal Open the App Store and search for PocketPal AI by Asghar Ghorbani. Download and install the app. Open the app and allow necessary permissions. 2. Adding a Model Navigate to the Models section in the PocketPal app. Click the + button to add a new model. You will see two options: Add from Hugging Face Add Local Model Select Add from Hugging Face to browse available models. 3. Selecting and Downloading a Model Search for DeepSeek-R1-Distill-Qwen-1.5B-Q4_0. Select the model and start downloading it (size: 1.06GB, 1.78B parameters). Once downloaded, the model will appear under the Ready to Use section. 4. Running Benchmarks I ran benchmarks on my iPhone 12 using the DeepSeek-R1-Distill-Qwen-1.5B-Q4_0 model. Here are the key results:\nModel Size: 1.06 GB with 1.78 billion parameters. Benchmark Configuration: Prompt Processing: 512 Token Generation: 128 Pipeline Length: 1 Repetitions: 3 Model Settings: Context Length: 1024 tokens Batch Size: 512 CPU Threads: 4 GPU Layers: 0 (fully CPU-based execution) Flash Attention: Disabled Performance Metrics: Prompt Processing Speed: 26.93 tokens/sec (±2.37) Token Generation Speed: 18.05 tokens/sec (±0.75) Total Execution Time: 1 minute 18 seconds Peak Memory Usage: 35.0% (1GB / 4GB) Live Demo: Running PocketPal on iPhone 12 Watch a live demonstration of PocketPal running a distilled 4-bit quantized model on an iPhone 12: Image: Video demonstration is available here: Video\nAnalysis of Results Decent Processing Speed: With a distilled 4-bit quantized model, the 18.05 t/s token generation rate is quite reasonable for mobile inference. Low Memory Footprint: The 1GB RAM usage means this can run on even mid-range smartphones. CPU-Based Execution: Since 0 GPU layers were used, this proves mobile CPUs are capable of running quantized LLMs efficiently. Flash Attention Disabled: If supported, enabling it might further optimize speed and reduce lag. Final Thoughts Running an LLM locally on an iPhone 12 with PocketPal is feasible but comes with trade-offs. It’s a promising step toward self-hosted AI assistants, though optimization and hardware improvements will be crucial for broader adoption. If you’re privacy-conscious or need offline AI capabilities, it’s definitely worth exploring!\nFuture Improvements I\u0026rsquo;d Like to See: Better memory efficiency to reduce battery drain. Enhanced speed for real-time interaction. More user-friendly model importing and switching. ","permalink":"http://localhost:1313/posts/llmonmobile/","summary":"\u003ch1 id=\"running-a-local-llm-on-mobile-testing-pocketpal-on-iphone-12\"\u003eRunning a Local LLM on Mobile: Testing PocketPal on iPhone 12\u003c/h1\u003e\n\u003cp\u003eWith the increasing accessibility of large language models (LLMs), running them locally on mobile devices is an exciting prospect. I recently tested \u003cstrong\u003ePocketPal\u003c/strong\u003e, a mobile LLM interface, on my \u003cstrong\u003eiPhone 12\u003c/strong\u003e, using a \u003cstrong\u003edistilled 4-bit quantized model\u003c/strong\u003e. Here’s a breakdown of my experience, covering installation, performance, and overall usability.\u003c/p\u003e\n\u003ch2 id=\"why-run-an-llm-on-mobile\"\u003eWhy Run an LLM on Mobile?\u003c/h2\u003e\n\u003cp\u003eRunning an LLM locally on a mobile device comes with several advantages:\u003c/p\u003e","title":"Running Large Language Models on Mobile: DeepSeek R1 on iPhone 12"},{"content":"Running DeepSeek-R1 1.5B on Raspberry Pi 5 (CPU-Only) Technical Insights Why Can We Run This on Raspberry Pi 5? Thanks to open-source advancements, we can now run large-scale AI models on small devices like the Raspberry Pi 5. Key factors enabling this include:\nOptimized lightweight models: DeepSeek-R1 1.5B is built efficiently to run on limited hardware. ARM64 Support: Modern AI frameworks support ARM-based architectures, enabling their use on RPi5. Open-source software: Platforms like Ollama make AI deployment accessible to all. Performance Considerations Running this model on an RPi5 without a GPU will be CPU-intensive. Consider reducing active processes to free up memory. If performance lags, use a lighter model or external processing (cloud inference). No GPU acceleration was used in this setup, meaning all computations rely solely on the CPU, which may affect inference speeds. This guide covers the installation and execution of DeepSeek-R1 1.5B on a Raspberry Pi 5, following the steps demonstrated in your images.\nPrerequisites Raspberry Pi 5 (ARM64 architecture, more powerful than previous versions) Debian-based Linux installed An internet connection At least 4GB RAM recommended for smooth operation Step 1: Log in to Your Raspberry Pi Upon booting, log in using your credentials:\nraspberrypi login: hisam Password: ****** Example login screen: Step 2: Install Curl Curl is required to fetch the installation script. Run:\nsudo apt install curl If it\u0026rsquo;s already installed, you\u0026rsquo;ll see:\ncurl is already the newest version... Example output: Step 3: Install Ollama Ollama is the runtime needed to execute DeepSeek models.\ncurl -fsSL https://ollama.com/install.sh | sh This will download and install Ollama.\nExample installation screen: Step 4: Enable and Start Ollama Service After installation, Ollama sets up a system service.\nollama The output will indicate success:\n\u0026gt;\u0026gt;\u0026gt; Creating ollama user... \u0026gt;\u0026gt;\u0026gt; Enabling and starting ollama service... \u0026gt;\u0026gt;\u0026gt; The Ollama API is now available at 127.0.0.1:11434. Example setup screen: Step 5: Pull and Run DeepSeek-R1 1.5B Now, pull and run the model:\nollama run deepseek-r1:1.5b This will download the model, which is about 1.1 GB in size.\nExample download screen: Once downloaded, the model is ready to run.\nStep 6: Execute DeepSeek-R1 1.5B Run the model and start interacting:\nollama run deepseek-r1:1.5b You should see a prompt where you can start typing queries:\n\u0026gt;\u0026gt;\u0026gt; Hey! Hello! How can I assist you today? 😊 Example interaction: Final Setup Image Video Demonstration Watch Video\nConclusion You have successfully installed and executed DeepSeek-R1 1.5B on your Raspberry Pi 5. This demonstrates the power of open-source AI, making it possible to run advanced models on small-scale devices. If you encounter performance issues, consider optimizing your setup or offloading computations.\nHappy coding!\n","permalink":"http://localhost:1313/posts/deepseek/","summary":"\u003ch1 id=\"running-deepseek-r1-15b-on-raspberry-pi-5-cpu-only\"\u003eRunning DeepSeek-R1 1.5B on Raspberry Pi 5 (CPU-Only)\u003c/h1\u003e\n\u003ch2 id=\"technical-insights\"\u003eTechnical Insights\u003c/h2\u003e\n\u003ch3 id=\"why-can-we-run-this-on-raspberry-pi-5\"\u003eWhy Can We Run This on Raspberry Pi 5?\u003c/h3\u003e\n\u003cp\u003eThanks to open-source advancements, we can now run large-scale AI models on small devices like the Raspberry Pi 5. Key factors enabling this include:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eOptimized lightweight models\u003c/strong\u003e: DeepSeek-R1 1.5B is built efficiently to run on limited hardware.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eARM64 Support\u003c/strong\u003e: Modern AI frameworks support ARM-based architectures, enabling their use on RPi5.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eOpen-source software\u003c/strong\u003e: Platforms like Ollama make AI deployment accessible to all.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"performance-considerations\"\u003ePerformance Considerations\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eRunning this model on an RPi5 \u003cstrong\u003ewithout a GPU\u003c/strong\u003e will be CPU-intensive.\u003c/li\u003e\n\u003cli\u003eConsider \u003cstrong\u003ereducing active processes\u003c/strong\u003e to free up memory.\u003c/li\u003e\n\u003cli\u003eIf performance lags, use a \u003cstrong\u003elighter model\u003c/strong\u003e or \u003cstrong\u003eexternal processing (cloud inference).\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eNo GPU acceleration was used\u003c/strong\u003e in this setup, meaning all computations rely solely on the CPU, which may affect inference speeds.\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003cp\u003eThis guide covers the installation and execution of DeepSeek-R1 1.5B on a Raspberry Pi 5, following the steps demonstrated in your images.\u003c/p\u003e","title":"DeepSeek-R1 on Raspberry Pi 5: Open-Source AI Without a GPU"},{"content":"Setting Up Neovim: An Easy and Beginner\u0026rsquo;s Guide Neovim is a modern and extensible text editor that enhances Vim’s capabilities. If you\u0026rsquo;re using Linux, setting up Neovim can be a rewarding experience, allowing you to customize it for an efficient workflow. In this guide, we\u0026rsquo;ll cover installing Neovim, setting up a basic configuration, and enhancing it with essential plugins to turn it into a full-fledged IDE.\n1. Installing Neovim sudo pacman -S neovim 2. Setting Up Neovim Configuration Neovim’s configuration is stored in ~/.config/nvim/. Create the directory and initialize a basic configuration:\nmkdir -p ~/.config/nvim nvim ~/.config/nvim/init.lua Minimal Configuration (init.lua) Add the following settings to your init.lua file:\n-- Enable line numbers vim.opt.number = true vim.opt.relativenumber = true -- Set tab size vim.opt.expandtab = true vim.opt.shiftwidth = 4 vim.opt.tabstop = 4 -- Enable mouse support vim.opt.mouse = \u0026#34;a\u0026#34; -- Set clipboard to system clipboard vim.opt.clipboard = \u0026#34;unnamedplus\u0026#34; Save and exit Neovim.\n3. Installing a Plugin Manager The best plugin manager for Neovim is lazy.nvim. Install it by running:\ngit clone --depth 1 https://github.com/folke/lazy.nvim.git \\ ~/.local/share/nvim/lazy/lazy.nvim Then, update your init.lua to load it:\nlocal lazypath = vim.fn.stdpath(\u0026#34;data\u0026#34;) .. \u0026#34;/lazy/lazy.nvim\u0026#34; if not vim.loop.fs_stat(lazypath) then vim.fn.system({ \u0026#34;git\u0026#34;, \u0026#34;clone\u0026#34;, \u0026#34;--filter=blob:none\u0026#34;, \u0026#34;https://github.com/folke/lazy.nvim.git\u0026#34;, lazypath }) end vim.opt.rtp:prepend(lazypath) 4. Installing Essential Plugins With lazy.nvim installed, you can add plugins in init.lua:\nrequire(\u0026#34;lazy\u0026#34;).setup({ \u0026#34;nvim-treesitter/nvim-treesitter\u0026#34;, -- Syntax highlighting \u0026#34;nvim-telescope/telescope.nvim\u0026#34;, -- Fuzzy finder \u0026#34;neovim/nvim-lspconfig\u0026#34;, -- LSP support \u0026#34;hrsh7th/nvim-cmp\u0026#34;, -- Auto-completion \u0026#34;hrsh7th/cmp-nvim-lsp\u0026#34;, -- LSP completion source \u0026#34;hrsh7th/cmp-buffer\u0026#34;, -- Buffer completion \u0026#34;hrsh7th/cmp-path\u0026#34;, -- Path completion \u0026#34;hrsh7th/cmp-nvim-lua\u0026#34;, -- Neovim Lua API completion \u0026#34;L3MON4D3/LuaSnip\u0026#34;, -- Snippet engine \u0026#34;saadparwaiz1/cmp_luasnip\u0026#34;, -- Snippet completion \u0026#34;nvim-lualine/lualine.nvim\u0026#34;, -- Status line \u0026#34;nvim-tree/nvim-tree.lua\u0026#34;, -- File explorer \u0026#34;tpope/vim-surround\u0026#34;, -- Surround text objects \u0026#34;tpope/vim-commentary\u0026#34;, -- Commenting shortcuts \u0026#34;lewis6991/gitsigns.nvim\u0026#34;, -- Git integration \u0026#34;akinsho/toggleterm.nvim\u0026#34;, -- Terminal management }) Save and exit Neovim, then open it and run:\n:Lazy sync This will install the plugins automatically.\n5. Setting Up Treesitter Treesitter provides better syntax highlighting and code parsing. Install it by adding the following to your init.lua:\nrequire\u0026#39;nvim-treesitter.configs\u0026#39;.setup { ensure_installed = \u0026#34;all\u0026#34;, highlight = { enable = true, }, indent = { enable = true, }, } Then, update Treesitter by running:\n:TSUpdate 6. Setting Up LSP (Language Server Protocol) LSP enables features like code completion and linting. Install LSP servers for your language:\n# Python sudo pacman -S python-lsp-server # C++ sudo pacman -S clang # JavaScript/TypeScript npm install -g typescript-language-server Then, enable LSP support in Neovim:\nlocal lspconfig = require(\u0026#34;lspconfig\u0026#34;) lspconfig.pyright.setup({}) -- Python lspconfig.ts_ls.setup({}) -- JavaScript/TypeScript lspconfig.clangd.setup({}) -- C++ Restart Neovim and check LSP status:\n:LspInfo 7. Enhancing Auto-Completion with nvim-cmp To enable code auto-completion, update your init.lua:\nlocal cmp = require\u0026#39;cmp\u0026#39; cmp.setup({ mapping = { [\u0026#39;\u0026lt;C-Space\u0026gt;\u0026#39;] = cmp.mapping.complete(), [\u0026#39;\u0026lt;CR\u0026gt;\u0026#39;] = cmp.mapping.confirm({ select = true }), }, sources = { { name = \u0026#39;nvim_lsp\u0026#39; }, { name = \u0026#39;buffer\u0026#39; }, { name = \u0026#39;path\u0026#39; }, { name = \u0026#39;luasnip\u0026#39; }, { name = \u0026#39;nvim_lua\u0026#39; }, } }) 9. Final Thoughts Congratulations! You now have a powerful, customized Neovim setup that functions as a full-fledged IDE. With features like Treesitter, LSP support, auto-completion, syntax highlighting, Git integration, and a file explorer, your development workflow will be much smoother.\nIf you’d like to further improve your Neovim experience, explore more plugins and tweak your settings. Good luck with that!\nFurther Reading Neovim Documentation Awesome Neovim Plugins Arch Wiki: Neovim ","permalink":"http://localhost:1313/posts/setting-up-neovim-on-arch-linux-a-beginners-guide/","summary":"\u003ch1 id=\"setting-up-neovim-an-easy-and-beginners-guide\"\u003eSetting Up Neovim: An Easy and Beginner\u0026rsquo;s Guide\u003c/h1\u003e\n\u003cp\u003eNeovim is a modern and extensible text editor that enhances Vim’s capabilities. If you\u0026rsquo;re using Linux, setting up Neovim can be a rewarding experience, allowing you to customize it for an efficient workflow. In this guide, we\u0026rsquo;ll cover installing Neovim, setting up a basic configuration, and enhancing it with essential plugins to turn it into a full-fledged IDE.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"1-installing-neovim\"\u003e\u003cstrong\u003e1. Installing Neovim\u003c/strong\u003e\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003esudo pacman -S neovim\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003chr\u003e\n\u003ch2 id=\"2-setting-up-neovim-configuration\"\u003e\u003cstrong\u003e2. Setting Up Neovim Configuration\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003eNeovim’s configuration is stored in \u003ccode\u003e~/.config/nvim/\u003c/code\u003e. Create the directory and initialize a basic configuration:\u003c/p\u003e","title":"Setting Up Neovim: A Beginner's Guide"},{"content":"Linux Kernal The majority of the kernel\u0026rsquo;s code is written in C, leveraging extensions provided by the GNU Compiler Collection (GCC) beyond standard C. Additionally, it includes assembly code for architecture-specific functions, such as optimizing memory usage and task execution. Architecturally, the Linux kernel is monolithic, meaning the entire OS operates within kernel space. However, it features a modular design, allowing software components to be integrated as modules, including dynamic loading.\nWhat Is A Kernel Module? A Linux kernel module is precisely defined as a code segment capable of dynamic loading and unloading within the kernel as needed. These modules enhance kernel capabilities without necessitating a system reboot. A notable example is seen in the device driver module, which facilitates kernel interaction with hardware components linked to the system.\nWriting a Custom Linux Kernel Module Linux kernel modules (LKMs) allow developers to extend the functionality of the Linux kernel without modifying its source code. This guide walks through writing a simple kernel module from scratch. Kernel modules are pieces of code that can be dynamically loaded and unloaded from the Linux kernel at runtime. They enable functionality such as device drivers, file system support, and system call extensions without requiring a kernel recompilation. LKMs are particularly useful for developing hardware drivers and testing new kernel features without rebooting the system.\nPrerequisites Ensure you have the necessary development tools installed. On an Arch Linux system, install them with:\nsudo pacman -Syu linux-headers base-devel Creating a Simple Kernel Module 1. Writing the Module Source Code Create a file named hello_module.c:\n#include \u0026lt;linux/module.h\u0026gt; #include \u0026lt;linux/kernel.h\u0026gt; #include \u0026lt;linux/init.h\u0026gt; MODULE_LICENSE(\u0026#34;GPL\u0026#34;); MODULE_AUTHOR(\u0026#34;Your Name\u0026#34;); MODULE_DESCRIPTION(\u0026#34;A simple Hello World kernel module\u0026#34;); static int __init hello_init(void) { printk(KERN_INFO \u0026#34;Hello, Kernel!\\n\u0026#34;); return 0; } static void __exit hello_exit(void) { printk(KERN_INFO \u0026#34;Goodbye, Kernel!\\n\u0026#34;); } module_init(hello_init); module_exit(hello_exit); Understanding the Kernel Module Code #include \u0026lt;linux/module.h\u0026gt;: Includes the necessary module macros and functions. #include \u0026lt;linux/kernel.h\u0026gt;: Provides kernel logging functions. #include \u0026lt;linux/init.h\u0026gt;: Defines initialization and cleanup macros. MODULE_LICENSE(\u0026quot;GPL\u0026quot;): Specifies the module\u0026rsquo;s license. MODULE_AUTHOR(\u0026quot;Your Name\u0026quot;): Specifies the author of the module. MODULE_DESCRIPTION(\u0026quot;A simple Hello World kernel module\u0026quot;): Provides a brief description. static int __init hello_init(void): The function executed when the module is loaded. static void __exit hello_exit(void): The function executed when the module is unloaded. module_init(hello_init): Registers hello_init as the module\u0026rsquo;s initialization function. module_exit(hello_exit): Registers hello_exit as the module\u0026rsquo;s cleanup function. 2. Writing the Makefile Create a Makefile in the same directory:\nobj-m += hello_module.o all: make -C /lib/modules/$(shell uname -r)/build M=$(PWD) modules clean: make -C /lib/modules/$(shell uname -r)/build M=$(PWD) clean Understanding the Makefile obj-m += hello_module.o: Specifies that hello_module.o is the object to be built as a module. all:: Defines the build target. make -C /lib/modules/$(shell uname -r)/build M=$(PWD) modules: Directs the kernel build system to compile the module. clean:: Cleans up the generated files. make -C /lib/modules/$(shell uname -r)/build M=$(PWD) clean: Cleans the build artifacts. 3. Compiling the Module Run:\nmake 4. Loading and Unloading the Module To insert the module into the kernel:\nsudo insmod hello_module.ko Check the kernel log:\ndmesg | tail To remove the module:\nsudo rmmod hello_module 5. Verifying the Module List loaded modules:\nlsmod | grep hello_module Understanding the Generated Files After building the module, several files are generated:\nhello_module.c: The source code of the module. hello_module.ko: The compiled kernel module file, ready to be loaded into the kernel. hello_module.o: An intermediate object file generated during compilation. hello_module.mod.c: An automatically generated file containing module metadata. hello_module.mod.o: An object file containing metadata compiled from hello_module.mod.c. hello_module.mod: Another metadata file required for module loading. Makefile: Contains instructions for building the module. Module.symvers: Stores information about exported symbols, useful for module dependencies. modules.order: Lists the order in which modules should be loaded. Conclusion This simple kernel module demonstrates the basics of module development. You can expand upon this by adding functionality such as handling parameters or interacting with hardware.\nHappy kernel hacking!\n","permalink":"http://localhost:1313/posts/how-to-write-a-custom-kernel-module/","summary":"\u003ch1 id=\"linux-kernal\"\u003eLinux Kernal\u003c/h1\u003e\n\u003cp\u003eThe majority of the kernel\u0026rsquo;s code is written in C, leveraging extensions provided by the GNU Compiler Collection (GCC) beyond standard C. Additionally, it includes assembly code for architecture-specific functions, such as optimizing memory usage and task execution. Architecturally, the Linux kernel is monolithic, meaning the entire OS operates within kernel space. However, it features a modular design, allowing software components to be integrated as modules, including dynamic loading.\u003c/p\u003e","title":"How to Write a Custom Kernel Module"},{"content":"What is it? gh is GitHub\u0026rsquo;s official command-line tool designed to extend Git\u0026rsquo;s functionality with GitHub-specific features.\nPurpose: Simplifies interaction with GitHub\u0026rsquo;s ecosystem directly from the terminal. Allows you to manage repositories and use GitHub features like issues, pull requests, and workflows.\nKey Features: GitHub-specific tasks:\nAuthentication: Easier login (gh auth login) without dealing with tokens manually. Repository Management: Create, fork, or clone repositories. Issues \u0026amp; Pull Requests: Manage issues, PRs, and comments directly. Actions: Manage and view GitHub Actions workflows. Works alongside Git for basic version control tasks. Use Case: Best for developers heavily using GitHub and its features (for example: pull requests, issues, and actions).\nHow it works Install gh:\n\u0026gt; yay -S github-cli Verify the installation:\n\u0026gt; gh --version Login with GitHub CLI (gh)\n\u0026gt; gh auth login Follow the interactive prompts to log in:\nChoose HTTPS or SSH for connection. Log in via a browser using a one-time code or SSH keys. Verify authentication:\n\u0026gt; gh auth status What\u0026rsquo;s best about it that you can install and use both Git and gh (GitHub CLI) seamlessly. Here\u0026rsquo;s how to set them up:\nInstall Git\n\u0026gt;sudo pacman -S git Check the installation:\n\u0026gt; git --version Using Git and gh Together You can now: Use Git for version control:\n\u0026gt; git clone https://github.com/username/repo.git \u0026gt; git add . \u0026gt; git commit -m \u0026quot;message\u0026quot; \u0026gt; git push ","permalink":"http://localhost:1313/posts/github-cli-githubs-official-command-line-tools/","summary":"\u003ch2 id=\"what-is-it\"\u003eWhat is it?\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003egh\u003c/strong\u003e is GitHub\u0026rsquo;s official command-line tool designed to extend Git\u0026rsquo;s functionality with GitHub-specific features.\u003c/p\u003e\n\u003ch2 id=\"purpose\"\u003ePurpose:\u003c/h2\u003e\n\u003cp\u003eSimplifies interaction with GitHub\u0026rsquo;s ecosystem directly from the terminal. Allows you to manage repositories and use GitHub features like issues, pull requests, and workflows.\u003c/p\u003e\n\u003ch2 id=\"key-features\"\u003eKey Features:\u003c/h2\u003e\n\u003cp\u003eGitHub-specific tasks:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAuthentication: Easier login (gh auth login) without dealing with tokens manually.\u003c/li\u003e\n\u003cli\u003eRepository Management: Create, fork, or clone repositories.\u003c/li\u003e\n\u003cli\u003eIssues \u0026amp; Pull Requests: Manage issues, PRs, and comments directly.\u003c/li\u003e\n\u003cli\u003eActions: Manage and view GitHub Actions workflows.\u003c/li\u003e\n\u003cli\u003eWorks alongside Git for basic version control tasks.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"use-case\"\u003eUse Case:\u003c/h2\u003e\n\u003cp\u003eBest for developers heavily using GitHub and its features (for example: pull requests, issues, and actions).\u003c/p\u003e","title":"GitHub CLI: GitHub's Official Command Line Tools"},{"content":"Connecting a Raspberry Pi 5 to a USB TTY cable is a common way to interact with it through a serial connection, especially for debugging or setting up the device without using a display.\nPrerequists\nRaspberry Pi 5. USB TTY (serial) cable. Computer with a terminal emulator (minicom/screen). GPIO pinout diagram of Raspberry Pi 5 (for reference). Power source for Raspberry Pi (optional if USB TTY can power it, though not recommended). Before Starting! Issuse with firmware UART does NOT work on the RPI5 from the factory. We will need a firmware update to fix this that prevents the dtoverlays for UARTs from working.\nInstall rpi-update with the following commands:\n\u0026gt; sudo curl -L --output /usr/bin/rpi-update https://raw.githubusercontent.com/Hexxeh/rpi-update/master/rpi-update \u0026amp;\u0026amp; sudo chmod +x /usr/bin/rpi-update Then update the firmware on your RPI5 with:\n\u0026gt; sudo rpi-update Enable UART To manually configure UART, you can edit the config.txt file.\nEdit /boot/firmware/config.txt and add:\n\u0026gt; enable_uart=1 How to Connect Locate the GPIO Pins Find the GPIO header on the Raspberry Pi 5. Identify the following pins: GND (Ground): Usually black wire on the USB TTY cable. TX (Transmit): Sends data from the Pi to the computer. RX (Receive): Receives data from the computer to the Pi.\nUse a GPIO pinout chart to locate these pins. For Raspberry Pi 5, it will likely be similar to previous models. Making connections You will need to connect:\nGND with Ground - Pin# 06 TX with GPIO14 - Pin# 08 RX with GPIO15 - Pin# 10 Plug the USB TTY Cable into the Computer\nInsert the USB end of the TTY cable into your computer. The cable will create a virtual COM port (e.g /dev/ttyUSB0). Configure and Access Serial Console\nOpen a terminal.\nIdentify the port with:\n\u0026gt; ls /dev/ttyUSB* Use a terminal emulator like screen or minicom to connect:\n\u0026gt; screen /dev/ttyUSB0 115200 *Replace /dev/ttyUSB0 with the actual port name.\nTurn on the Raspberry Pi. If everything is set up correctly, you should see boot messages in the terminal. Log in to the Pi using the default username (pi) and password (raspberry), or your custom credentials. You should see something similar to this.\nThis is it! You have done it. Congrats!\n","permalink":"http://localhost:1313/posts/how-to-connect-a-raspberry-pi-5-to-usb-tty-cable/","summary":"\u003cp\u003eConnecting a Raspberry Pi 5 to a USB TTY cable is a common way to interact with it through a serial connection, especially for debugging or setting up the device without using a display.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003ePrerequists\u003c/strong\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eRaspberry Pi 5.\u003c/li\u003e\n\u003cli\u003eUSB TTY (serial) cable.\u003c/li\u003e\n\u003cli\u003eComputer with a terminal emulator (minicom/screen).\u003c/li\u003e\n\u003cli\u003eGPIO pinout diagram of Raspberry Pi 5 (for reference).\u003c/li\u003e\n\u003cli\u003ePower source for Raspberry Pi (optional if USB TTY can power it, though not recommended).\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"before-starting\"\u003e\u003cstrong\u003eBefore Starting!\u003c/strong\u003e\u003c/h3\u003e\n\u003ch3 id=\"issuse-with-firmware\"\u003e\u003cstrong\u003e\u003ca href=\"https://forums.raspberrypi.com/viewtopic.php?t=361397#p2171244\"\u003eIssuse with firmware\u003c/a\u003e\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003eUART does NOT work on the RPI5 from the factory. We will need a firmware update to fix this that prevents the dtoverlays for UARTs from working.\u003c/p\u003e","title":"How to Connect a Raspberry PI 5 to USB TTY Cable"},{"content":"Hosting a website on GitHub Pages with Hugo involves the following steps:\nCreating a website 1. Install Hugo and git\n\u0026gt; sudo pacman -S Hugo 2. Create a new Hugo site\n\u0026gt; hugo new site your-website 3. Add a Theme\nNavigate to your website directory and add a theme. You can choose one from the Hugo Themes .\n\u0026gt; cd your-website \u0026gt; git init \u0026gt; git submodule add https://github.com/adityatelange/hugo-PaperMod.git themes/hugo-PaperMod Now you will need to update the hugo.toml file for them to take effect. To do so you can either echo or addd it in the file.\n\u0026gt; echo \u0026quot;theme = 'hugo-PaperMod'\u0026quot; \u0026gt;\u0026gt; hugo.toml To view the website you can run it locally using Hugo\u0026rsquo;s development server to view the site. You can add -D to see your drafts.\n\u0026gt; hugo server 3. Add Content\nTo add a new page to your site.\n\u0026gt; hugo new content content/posts/yout-first-post.md This is it You have done it. YAY!\nHosting it on GitHub 1. Create a GitHub repository.\nClick the + icon in the top-right corner of:\u0026gt; [!WARNING] the GitHub interface and select New repository. Enter a repository name: yourusername.github.io Click Create repository. 2. Add Files for Your website\nClone the repository locally using Git:\ngit clone https://github.com//.git\nAdd your static site files (generated by Hugo) to the repository. Commit and push the changes:\n\u0026gt; git add -A \u0026gt; git commit -s -m \u0026quot;Initial commit\u0026quot; \u0026gt; git push origin main 3. Configure the Repository for GitHub Pages\nGo to the Settings tab of your new repository. Scroll down to the Pages section. Settings \u0026gt; Pages. In the center of your screen you will see this: Build and development Change the Source to GitHub Actions. 4. Create a file named hugo.yaml in a directory named .github/workflows.\n\u0026gt; mkdir -p .github/workflows \u0026gt; cd ./github/workflows touch hugo.yaml 5. Add content in the YAML file.\n# Sample workflow for building and deploying a Hugo site to GitHub Pages name: Deploy Hugo site to Pages on: # Runs on pushes targeting the default branch push: branches: - main # Allows you to run this workflow manually from the Actions tab workflow_dispatch: # Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages permissions: contents: read pages: write id-token: write # Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued. # However, do NOT cancel in-progress runs as we want to allow these production deployments to complete. concurrency: group: \u0026#34;pages\u0026#34; cancel-in-progress: false # Default to bash defaults: run: shell: bash jobs: # Build job build: runs-on: ubuntu-latest env: HUGO_VERSION: 0.141.0 steps: - name: Install Hugo CLI run: | wget -O ${{ runner.temp }}/hugo.deb https://github.com/gohugoio/hugo/releases/download/v${HUGO_VERSION}/hugo_extended_${HUGO_VERSION}_linux-amd64.deb \\ \u0026amp;\u0026amp; sudo dpkg -i ${{ runner.temp }}/hugo.deb - name: Install Dart Sass run: sudo snap install dart-sass - name: Checkout uses: actions/checkout@v4 with: submodules: recursive fetch-depth: 0 - name: Setup Pages id: pages uses: actions/configure-pages@v5 - name: Install Node.js dependencies run: \u0026#34;[[ -f package-lock.json || -f npm-shrinkwrap.json ]] \u0026amp;\u0026amp; npm ci || true\u0026#34; - name: Build with Hugo env: HUGO_CACHEDIR: ${{ runner.temp }}/hugo_cache HUGO_ENVIRONMENT: production TZ: America/Los_Angeles run: | hugo \\ --gc \\ --minify \\ --baseURL \u0026#34;${{ steps.pages.outputs.base_url }}/\u0026#34; - name: Upload artifact uses: actions/upload-pages-artifact@v3 with: path: ./public # Deployment job deploy: environment: name: github-pages url: ${{ steps.deployment.outputs.page_url }} runs-on: ubuntu-latest needs: build steps: - name: Deploy to GitHub Pages id: deployment uses: actions/deploy-pages@v4 5. Commit and push your GitHub repository.\n\u0026gt;git add -A \u0026gt;git commit -m \u0026quot;Create hugo.yaml\u0026quot; \u0026gt;git push 6. Deployment status From GitHub’s main menu, choose Actions. When GitHub has finished building and deploying your site, the color of the status indicator will change to green.\nStep 5: Verify Your GitHub Pages Site\nThe site will be live at https://yourusername.github.io.\n","permalink":"http://localhost:1313/posts/hosting-a-website-on-github-pages-with-hugo/","summary":"\u003cp\u003eHosting a website on GitHub Pages with Hugo involves the following steps:\u003c/p\u003e\n\u003ch1 id=\"creating-a-website\"\u003eCreating a website\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e1. Install Hugo and git\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; sudo pacman -S Hugo\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e2. Create a new Hugo site\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; hugo new site your-website\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e3. Add a Theme\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eNavigate to your website directory and add a theme. You can choose one from the \u003ca href=\"https://themes.gohugo.io/\"\u003eHugo Themes\u003c/a\u003e .\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; cd your-website\n\u0026gt; git init \n\u0026gt; git submodule add https://github.com/adityatelange/hugo-PaperMod.git themes/hugo-PaperMod\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow you will need to update the hugo.toml file for them to take effect. To do so you can either \u003cem\u003eecho\u003c/em\u003e or addd it in the file.\u003c/p\u003e","title":"Hosting a Website on Github Pages With Hugo"},{"content":"KVM Kernel-based Virtual Machine is a free and open-source virtualization module in the Linux kernel that allows the kernel to function as a hypervisor.\nInstallation For updates, run the following command:\n$ sudo pacman -Syu QEMU/KVM installation: We\u0026rsquo;ll install qemu and all the utils required:\n$ sudo pacman -S qemu vde2 ebtables iptables-nft nftables dms masq bridge-utils ovmf swptm Virtual Machine Manager installation: The virt-manager application is a graphical user interface for managing virtual machines through libvirt. It primarily targets KVM VMs.\n$ sudo pacman -S virt-manager Now everything is set to work. We can move towards downloading archlinux .iso file.\nDownload .iso file: Head towards: https://archlinux.org/download/ Scroll through and look for the server closest to you. Download archlinux-2024.10.01-x86_64.iso file. Setting up: Open terminal and run the following command:\n$ virt-manager You will see an interface similar to this:\nClick on \u0026lsquo;create a new virtual machine\u0026rsquo; (option with star). Select \u0026lsquo;Local install media\u0026rsquo;. Browse to your \u0026lsquo;archlinux-2024.10.01-x86_64.iso\u0026rsquo;. Add your desired VM configuration and create a disk image. Boot Menu: You will be prompted to a boot menu.\nSelect the topmost option to start the installation process. Archlinux Installer: You will be prompted to a terminal. The first step is to check if you are connected to the internet.\nRun:\n# ip addr show If it shows an IP address and says \u0026lsquo;UP\u0026rsquo;, that means you are good to go.\nIf not: You will need to connect to the internet using the \u0026lsquo;iwctl\u0026rsquo; method for Wi-Fi.\n# iwctl To search networks in your vicinity:\n[iwd]# station [your_wifi_interface] get-networks Get the name of the network you want to connect to. Exit from this prompt using \u0026rsquo;exit\u0026rsquo;.\nTo connect to the desired Wi-Fi network, run:\n# iwctl --passphrase \u0026#34;[wifi_password]\u0026#34; station [your_wifi_interface] connect [wifi_name] You can again run ip addr show to check if you are connected to the network.\nNow you can run the installation command. We\u0026rsquo;ll be using the archinstall method.\n# archinstall You will be prompted to an interface similar to this:\nWe will install Arch using this interface. Go through each option:\nArchinstall language: Choose your preferred language. Mirrors: Select the mirror region closest to you. Use \u0026lsquo;/\u0026rsquo; to search. Locales: Set language and keyboard layout. Disk configuration: Choose Best-effort default partition to format the system. Bootloader: Use the default \u0026lsquo;Grub\u0026rsquo; option. Swap: Select Swap on zram (default). Hostname: Leave as it is. Root password: Set the password for sudo/root privileges. User account: Set up a user account. Profile: Select Desktop. It includes essential packages. Others include Minimal, Server, and Xorg. In Desktop, select your desktop environment. We\u0026rsquo;ll use Gnome for simplicity.\nAudio: Use PipeWire (default) or PulseAudio. Kernels: Use the linux kernel. Additional packages: Install any required packages. Network Configuration: Use NetworkManager for a GUI in Gnome. Timezone: Set the timezone closest to you and enable time sync. Press Install. Congratulations! You\u0026rsquo;ve successfully installed Arch Linux.\n","permalink":"http://localhost:1313/posts/arch_kvm/","summary":"\u003ch1 id=\"kvm\"\u003eKVM\u003c/h1\u003e\n\u003cp\u003eKernel-based Virtual Machine is a free and open-source virtualization module in the Linux kernel that allows the kernel to function as a hypervisor.\u003c/p\u003e\n\u003ch2 id=\"installation\"\u003eInstallation\u003c/h2\u003e\n\u003cp\u003eFor updates, run the following command:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ sudo pacman -Syu\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"qemukvm-installation\"\u003eQEMU/KVM installation:\u003c/h3\u003e\n\u003cp\u003eWe\u0026rsquo;ll install qemu and all the utils required:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ sudo pacman -S qemu vde2 ebtables iptables-nft nftables dms masq bridge-utils ovmf swptm\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"virtual-machine-manager-installation\"\u003eVirtual Machine Manager installation:\u003c/h3\u003e\n\u003cp\u003eThe virt-manager application is a graphical user interface for managing virtual machines through libvirt. It primarily targets KVM VMs.\u003c/p\u003e","title":"archlinux installation in hypervisor through QEMU/KVM"},{"content":"","permalink":"http://localhost:1313/posts/github-cli-githubs-official-command-line-tool/","summary":"","title":""},{"content":"1. Introduction Sometimes you need to share a local application with the outside world — maybe to demo your project, test a webhook, or allow a teammate to access your development server.\nNormally, you’d need a public IP, port forwarding, or a cloud server. ngrok removes all that complexity by creating a secure tunnel from the internet directly to your machine, giving you a public URL instantly.\nIn this guide, we’ll walk through:\nInstalling ngrok on popular Linux distributions Authenticating your installation Exposing a local service to the internet Adding basic security Practical examples for real-world usage 2. Prerequisites Before we begin, make sure you have:\nA terminal A free ngrok account (for authentication token) A running local service (e.g., a Python HTTP server, web app, or API) 3. Installing ngrok on Linux We’ll cover installation for Arch Linux, Debian/Ubuntu, and Fedora.\n3.1 Arch Linux This package is not in the official repos, install it from the AUR:\nyay -S ngrok 3.2 Debian / Ubuntu sudo apt update sudo apt install snapd sudo snap install ngrok Alternatively, download the binary from the ngrok downloads page.\n3.3 Fedora sudo dnf install snapd sudo ln -s /var/lib/snapd/snap /snap sudo snap install ngrok 4. Authenticating ngrok Once installed, you need to connect it to your account so you can use custom domains, longer session times, and access the dashboard.\nSign in to ngrok dashboard. -\u0026gt; Your AuthToken Copy your AuthToken. Run: ngrok config add-authtoken \u0026lt;YOUR_TOKEN\u0026gt; You will see: Authtoken saved to configuration file: ~/.config/ngrok/ngrok.yml 5. Exposing a Local Service For example, if your local web server is running on port 8080:\nngrok http 8080 You’ll see output like:\nNow you can share the HTTPS URL with anyone. It wil be similar to: https://random.string.ngrok-free.app\n6. Adding Basic Security You can protect your tunnel with a simple username and password:\nngrok http --basic-auth=\u0026#34;user:password\u0026#34; 8080 Anyone visiting the public link will need credentials.\n7. The Inspector One of ngrok\u0026rsquo;s most powerful features is its built-in web interface, accessible at http://127.0.0.1:4040. This interface lets you inspect every single request that comes through your tunnel in real-time. You can see headers, request bodies, and response details, and even replay requests with a single click—an absolute lifesaver for debugging webhooks.\n8. Common Use Cases Webhook testing — Connect services like GitHub, Stripe, or Twilio to your local environment. Temporary demos — Share work-in-progress with clients without deployment. Remote device access — SSH into a Raspberry Pi without changing router settings. 9. Conclusion In just a few commands, you’ve learned how to:\nInstall ngrok on popular Linux distros Authenticate your installation Share a local service securely From here, you can explore ngrok’s advanced features like static domains, IP allowlists, and traffic inspection.\n","permalink":"http://localhost:1313/posts/ngrok/","summary":"\u003ch2 id=\"1-introduction\"\u003e1. Introduction\u003c/h2\u003e\n\u003cp\u003eSometimes you need to share a local application with the outside world — maybe to demo your project, test a webhook, or allow a teammate to access your development server.\u003c/p\u003e\n\u003cp\u003eNormally, you’d need a public IP, port forwarding, or a cloud server. \u003cstrong\u003engrok\u003c/strong\u003e removes all that complexity by creating a \u003cstrong\u003esecure tunnel\u003c/strong\u003e from the internet directly to your machine, giving you a public URL instantly.\u003c/p\u003e\n\u003cp\u003eIn this guide, we’ll walk through:\u003c/p\u003e","title":"Ngrok: Expose Localhost to the Internet"},{"content":"Creating a WhatsApp AI Assistant Using n8n: A Step-by-Step Guide Build your own AI-powered WhatsApp chatbot using n8n, WhatsApp Business Cloud API, and OpenAI. This guide walks you through every step—from setup to testing—with real-world error handling, solutions, and an example production-ready workflow.\n1. Introduction Want to chat with an AI on WhatsApp? In this tutorial, you\u0026rsquo;ll learn how to build a WhatsApp AI Assistant using:\nn8n (automation tool) WhatsApp Business Cloud API OpenAI (for generating intelligent replies) By the end, you\u0026rsquo;ll have a working chatbot and gain hands-on experience with APIs, webhooks, and automation.\n2. Prerequisites n8n account (Cloud or self-hosted) Meta Developer account with WhatsApp Business Cloud API access OpenAI API key Basic understanding of APIs and webhook workflows 3. Registering Your WhatsApp Business App A. Create WhatsApp App in Meta Developer Visit Meta for Developers Create a new app: choose Business → WhatsApp Link or create a WhatsApp Business Account B. Obtain Testing Credentials Your app dashboard will show:\nTest phone number Phone Number ID Temporary access token (valid for only 24 hours) Tip: For long-term use, generate a 60-day system-user token later.\nC. Add Recipients to Test List By default, only approved numbers can receive messages:\nNavigate to WhatsApp → API Setup Add numbers in E.164 format (e.g., +923001234567) Users must accept the invite via WhatsApp to become valid recipients 4. Configuring Your Webhook in n8n A. Create a Webhook Node Method: GET (for initial verification) Endpoint example: https://yourname.app.n8n.cloud/webhook/your-unique-id/webhook B. Verify the Webhook with Meta In your app’s Webhook section:\nCallback URL: your n8n webhook URL Verify Token: any secret string you choose (e.g., mySecret2025) C. Echo Back Meta’s Challenge Configure n8n\u0026rsquo;s Webhook node response:\nField Value Response Mode On Received Response Body {{$json[\u0026quot;query\u0026quot;][\u0026quot;hub.challenge\u0026quot;]}} This ensures Meta can verify your endpoint successfully.\n5. Processing Incoming Messages WhatsApp sends JSON data with structure like:\n{ \u0026#34;entry\u0026#34;: [ { \u0026#34;changes\u0026#34;: [ { \u0026#34;value\u0026#34;: { \u0026#34;messages\u0026#34;: [ { \u0026#34;from\u0026#34;: \u0026#34;923001234567\u0026#34;, \u0026#34;text\u0026#34;: { \u0026#34;body\u0026#34;: \u0026#34;Hello bot!\u0026#34; } } ], \u0026#34;metadata\u0026#34;: { \u0026#34;phone_number_id\u0026#34;: \u0026#34;698352170035199\u0026#34; } } } ] } ] } Extract:\nfrom: user’s number text.body: user’s text metadata.phone_number_id: correct sender ID 6. Integrating OpenAI for Responses Obtaining Your OpenAI API Key Before integrating OpenAI into your n8n workflow, you’ll need to get an API key from OpenAI.\nStep-by-Step: Sign up or log in to OpenAI. Navigate to your API Keys page. Click \u0026ldquo;Create new secret key\u0026rdquo;. Optionally name your key, then copy it immediately (you won’t be able to view it again). In n8n: Go to Credentials → Add New → choose OpenAI or HTTP Request. Paste your API key into the key field. Save the credentials. Security Tip: Keep your key private. Do not share it or commit it to public repositories.\nUse an HTTP Request node to call OpenAI:\nPOST https://api.openai.com/v1/chat/completions Authorization: Bearer YOUR_OPENAI_API_KEY Content-Type: application/json { \u0026#34;model\u0026#34;: \u0026#34;gpt-4o-mini\u0026#34;, \u0026#34;messages\u0026#34;: [ { \u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;You are a helpful WhatsApp AI assistant.\u0026#34; }, { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;{{ $json[...] }}\u0026#34; } ] } Replace {{ $json[...] }} with the actual path to the user\u0026rsquo;s message text from the Webhook node.\n7. Sending Replies via WhatsApp Use another HTTP Request node to respond:\nPOST https://graph.facebook.com/v21.0/{{ $json[...] }}/messages Authorization: Bearer YOUR_LONG_LIVED_TOKEN Content-Type: application/json { \u0026#34;messaging_product\u0026#34;: \u0026#34;whatsapp\u0026#34;, \u0026#34;to\u0026#34;: \u0026#34;{{ $json[...] }}\u0026#34;, \u0026#34;text\u0026#34;: { \u0026#34;body\u0026#34;: \u0026#34;{{ $node[\u0026#39;OpenAI Response\u0026#39;].json.choices[0].message.content }}\u0026#34; } } Use the metadata’s phone_number_id for the endpoint and from for the recipient. This avoids hardcoding and ensures proper routing.\n8. Example n8n Workflow Here’s the actual n8n workflow I used for my WhatsApp AI assistant. It integrates a product brochure PDF into a vector store for AI-powered Q\u0026amp;A, and handles WhatsApp message flow.\nStep-by-Step Breakdown: 1. Download Product Brochure PDF Downloads the brochure from a given URL. Extracts text from the PDF. 2. Create Product Brochure Vector Store Splits large text into chunks. Generates embeddings using OpenAI. Saves them in a vector store for fast semantic search. 3. Use the WhatsApp Trigger Listens for incoming WhatsApp messages. Routes them to supported or unsupported handlers. 3a. Handle Unsupported Messages Replies with a friendly error if the message type is not text. 4. Sales AI Agent Responds Uses OpenAI with memory + vector store retrieval to answer based on brochure content. 5. Reply to WhatsApp User Sends the AI-generated message back to the sender. Why this is effective:\nContext-aware answers via buffer memory. Reduced hallucinations thanks to vector store grounding. Smooth error handling for unsupported message types. 9. Common Errors \u0026amp; Fixes Recipient phone number not in allowed list\n→ Add as test number or switch to Live mode\n401 – Session expired\n→ Refresh token via Graph API:\nGET https://graph.facebook.com/v21.0/oauth/access_token ?grant_type=fb_exchange_token \u0026amp;client_id=YOUR_APP_ID \u0026amp;client_secret=YOUR_APP_SECRET \u0026amp;fb_exchange_token=YOUR_CURRENT_TOKEN Webhook verification failed\n→ Ensure verify token matches between Meta and n8n and echo hub.challenge\nNo execution data available\n→ Trigger workflow via actual WhatsApp message, not manual run\n10. Going Live Add a Privacy Policy URL in Meta App → Settings → Basic (required for live access) Switch app to Live mode once all compliance items are met Remove restricted recipient list Use WhatsApp message templates for messages sent after 24 hours of user interaction 11. Conclusion \u0026amp; Next Steps Congrats! You now have a WhatsApp AI Assistant built with n8n and OpenAI.\nWhere to go from here: Wire up custom knowledge (PDFs, documents) Implement memory for conversation context Launch multilingual support Export n8n workflow as JSON for reuse Need help? Join the n8n Community Forum or OpenAI Discord to connect with fellow builders.\nHappy automating!\n","permalink":"http://localhost:1313/posts/creating-whatsapp-ai-assistant-using-n8n2/","summary":"\u003ch1 id=\"creating-a-whatsapp-ai-assistant-using-n8n-a-step-by-step-guide\"\u003eCreating a WhatsApp AI Assistant Using n8n: A Step-by-Step Guide\u003c/h1\u003e\n\u003cp\u003eBuild your own AI-powered WhatsApp chatbot using \u003cstrong\u003en8n\u003c/strong\u003e, \u003cstrong\u003eWhatsApp Business Cloud API\u003c/strong\u003e, and \u003cstrong\u003eOpenAI\u003c/strong\u003e. This guide walks you through every step—from setup to testing—with real-world error handling, solutions, and an example production-ready workflow.\u003c/p\u003e\n\u003ch2 id=\"1-introduction\"\u003e1. Introduction\u003c/h2\u003e\n\u003cp\u003eWant to chat with an AI on WhatsApp? In this tutorial, you\u0026rsquo;ll learn how to build a \u003cstrong\u003eWhatsApp AI Assistant\u003c/strong\u003e using:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003en8n\u003c/strong\u003e (automation tool)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eWhatsApp Business Cloud API\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eOpenAI\u003c/strong\u003e (for generating intelligent replies)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eBy the end, you\u0026rsquo;ll have a working chatbot and gain hands-on experience with APIs, webhooks, and automation.\u003c/p\u003e","title":"Creating Whatsapp Ai Assistant Using N8n"},{"content":"Introduction A memory leak occurs when a program allocates memory dynamically (e.g., using malloc) and fails to release it using free. This leftover allocation can lead to wasted memory resources, eventually causing slowdowns or system crashes in long-running programs.\nValgrind is a powerful command-line tool available on Linux systems. It helps developers detect:\nMemory leaks Invalid memory access Uninitialized memory usage Mismatched memory management In this guide, we\u0026rsquo;ll walk through examples in C to learn how to detect and fix memory leaks using Valgrind.\nInstalling Valgrind On Arch Linux sudo pacman -S valgrind On Ubuntu/Debian sudo apt install valgrind On Fedora sudo dnf install valgrind Troubleshooting: Valgrind \u0026ldquo;cannot find mandatory redirection\u0026rdquo; on Arch Linux If you run Valgrind and get an error like:\nvalgrind: Fatal error at startup: a function redirection\nvalgrind: which is mandatory for this platform-tool combination\nvalgrind: cannot be set up.\n…you might be running a 32-bit executable on a 64-bit Arch Linux system.\nWhy this happens Valgrind needs to hook into low-level glibc functions from your binary’s architecture.\nIf your binary is 32-bit, Arch requires the 32-bit glibc runtime (lib32-glibc).\nWithout it, Valgrind can’t find the right function symbols and quits.\nFix Install the 32-bit glibc package:\nsudo pacman -S lib32-glibc After installation, re-run:\nvalgrind ./your-binary and it should work.\nUbuntu/Debian equivalent: sudo apt install libc6-dbg:i386\nBasic Example: Hello World Code #include \u0026lt;stdio.h\u0026gt; int main() { printf(\u0026#34;Hello World\\n\u0026#34;); return 0; } Compile and Run gcc main.c -o main.out ./main.out Run with Valgrind valgrind ./main.out You should see no errors or memory leaks in the output.\nIntroducing a Memory Leak Static Allocation (Safe) #include \u0026lt;stdio.h\u0026gt; int main() { char str[20] = \u0026#34;Hello\u0026#34;; printf(\u0026#34;%s\\n\u0026#34;, str); return 0; } This uses stack memory, so Valgrind will report no leaks.\nDynamic Allocation (With Leak) #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; int main() { char *str = malloc(20); strcpy(str, \u0026#34;Hello\u0026#34;); printf(\u0026#34;%s\\n\u0026#34;, str); return 0; // Forgot to free memory } Valgrind Output valgrind ./main.out You should see:\ndefinitely lost: 20 bytes in 1 blocks\nFixing the Memory Leak Add free(str); before returning:\nfree(str); Fixed Code #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; int main() { char *str = malloc(20); strcpy(str, \u0026#34;Hello\u0026#34;); printf(\u0026#34;%s\\n\u0026#34;, str); free(str); return 0; } Detailed Valgrind Options Use for deeper analysis:\nvalgrind --leak-check=full ./main.out Or even more detailed:\nvalgrind --leak-check=full --show-leak-kinds=all --track-origins=yes ./main.out Explanation:\n--leak-check=full: Display detailed leak info --show-leak-kinds=all: Show all kinds of leaks (definitely, indirectly lost, etc.) --track-origins=yes: Show where uninitialized values originate Summary Always free() memory allocated with malloc(), calloc(), or realloc(). Close all file streams with fclose(). Use Valgrind to identify and fix: Memory leaks Invalid memory writes Use-after-free bugs Recommended command: valgrind --leak-check=full --track-origins=yes ./your_program Valgrind is a critical tool for writing safe, efficient, and bug-free C programs.\n","permalink":"http://localhost:1313/posts/introductiontovalgrind/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eA \u003cstrong\u003ememory leak\u003c/strong\u003e occurs when a program allocates memory dynamically (e.g., using \u003ccode\u003emalloc\u003c/code\u003e) and fails to release it using \u003ccode\u003efree\u003c/code\u003e. This leftover allocation can lead to wasted memory resources, eventually causing slowdowns or system crashes in long-running programs.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eValgrind\u003c/strong\u003e is a powerful command-line tool available on Linux systems. It helps developers detect:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eMemory leaks\u003c/li\u003e\n\u003cli\u003eInvalid memory access\u003c/li\u003e\n\u003cli\u003eUninitialized memory usage\u003c/li\u003e\n\u003cli\u003eMismatched memory management\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIn this guide, we\u0026rsquo;ll walk through examples in C to learn how to detect and fix memory leaks using Valgrind.\u003c/p\u003e","title":"Detecting and Fixing Memory Leaks with Valgrind"},{"content":"QEMU-KVM on Arch Linux: Running Tiny Core Linux in a Lightweight VM Virtualization is a powerful tool for developers, sysadmins, and tinkerers alike. On Linux, QEMU-KVM stands out as a robust, high-performance virtualization stack. In this blog, well walk through setting up QEMU-KVM on Arch Linux and using it to run Tiny Core Linuxa super-lightweight distro perfect for testing and experimentation.\nWhat is QEMU-KVM QEMU (Quick Emulator) is a generic and open-source machine emulator. On its own, it can emulate various hardware systems. However, when paired with **KVM (Kernel-based Virtual Machine)**a Linux kernel module for virtualizationit can run virtual machines with near-native performance.\nQEMU provides device emulation and user-space management. KVM integrates with the Linux kernel and handles hardware-level virtualization. Together, they effectively form a Type 1 hypervisor because the Linux kernel (with KVM) handles core virtualization tasks directly on hardware.\nStep-by-Step: Installing QEMU-KVM on Arch Linux Step 1: Install Required Packages sudo pacman -Syu sudo pacman -S qemu virt-manager virt-viewer dnsmasq vde2 bridge-utils openbsd-netcat libvirt edk2-ovmf edk2-ovmf is for UEFI firmware support in VMs.\nStep 2: Enable and Start libvirtd sudo systemctl enable --now libvirtd.service Step 3: Add Your User to the libvirt Group sudo usermod -aG libvirt (whoami) newgrp libvirt Step 4: Verify KVM Support lsmod grep kvm And check CPU virtualization support:\negrep -c (vmxsvm) /proc/cpuinfo A value of 1 or more indicates virtualization support.\nExample: Running Tiny Core Linux on QEMU-KVM Now that your system is ready, lets run Tiny Core Linux, a minimalist Linux distro thats only 16MB\nStep 1: Download Tiny Core ISO wget http://tinycorelinux.net/14.x/x86/release/Core-current.iso Or visit http://tinycorelinux.net for the latest release.\nStep 2: Create a Virtual Disk (Optional) qemu-img create -f qcow2 tinycore.qcow2 512M This creates a 512MB disk image. Optional for RAM-only usage.\nStep 3: Launch the VM with KVM Acceleration qemu-system-x86_64 -enable-kvm -m 512 -cpu host -smp 1 -cdrom Core-current.iso -hda tinycore.qcow2 -boot d -net nic -net user -vga virtio -display sdl Key Flags Explained:\n-enable-kvm: Enables KVM hardware acceleration -m 512: Allocates 512MB RAM -cpu host: Uses the host CPU features -cdrom: Points to the Tiny Core ISO -hda: Uses a QCOW2 disk image -boot d: Boots from CD first -net user: Enables simple user-mode networking (e.g., for internet access) -display sdl: Uses SDL window for graphics (you can replace with gtk or virt-manager) Alternate: Boot Tiny Core in RAM Without Disk qemu-system-x86_64 -enable-kvm -m 256 -cdrom Core-current.iso -boot d -net nic -net user -vga std Conclusion With QEMU-KVM, Arch Linux becomes a full-featured Type 1 hypervisor. By combining kernel-level virtualization (KVM) with the flexibility of QEMU, you get a fast, customizable virtualization platform. Running Tiny Core Linux showcases just how lightweight and efficient this setup can be.\nWhether youre building VMs for testing, learning Linux internals, or experimenting with custom environments, QEMU-KVM on Arch is a powerful combination.\nHappy virtualizing\n","permalink":"http://localhost:1313/posts/qemu/","summary":"\u003ch1 id=\"qemu-kvm-on-arch-linux-running-tiny-core-linux-in-a-lightweight-vm\"\u003eQEMU-KVM on Arch Linux: Running Tiny Core Linux in a Lightweight VM\u003c/h1\u003e\n\u003cp\u003eVirtualization is a powerful tool for developers, sysadmins, and tinkerers alike. On Linux, \u003cstrong\u003eQEMU-KVM\u003c/strong\u003e stands out as a robust, high-performance virtualization stack. In this blog, well walk through setting up QEMU-KVM on \u003cstrong\u003eArch Linux\u003c/strong\u003e and using it to run \u003cstrong\u003eTiny Core Linux\u003c/strong\u003ea super-lightweight distro perfect for testing and experimentation.\u003c/p\u003e\n\u003ch2 id=\"what-is-qemu-kvm\"\u003eWhat is QEMU-KVM\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eQEMU (Quick Emulator)\u003c/strong\u003e is a generic and open-source machine emulator. On its own, it can emulate various hardware systems. However, when paired with **KVM (Kernel-based Virtual Machine)**a Linux kernel module for virtualizationit can run virtual machines with near-native performance.\u003c/p\u003e","title":"QEMU-KVM on Arch Linux: Running Tiny Core Linux in a Lightweight VM"},{"content":"Building the Linux Kernel Compiling the Linux Kernel involves multiple steps and can take some time depending on your hardware specifications.\nStep 1: Download the Kernel Source Code Start by visiting the Official Linux Kernel Website and downloading the latest available kernel source code. The downloaded file will be a compressed archive containing all necessary source files.\nStep 2: Extract the Source Code Once the download completes, extract the contents of the compressed archive using the tar command:\ntar xvf linux-6.13.tar.xz If the tar utility is not installed on your system, you can install it using:\nsudo pacman -S tar Note: Always ensure you are using the correct version number in the file name.\nStep 3: Install Required Dependencies To compile the kernel, you need to install various development tools and libraries. Install them using the following command:\nsudo pacman -S git fakeroot ncurses xz bc flex bison base-devel kmod cpio perl binutils util-linux jfsutils e2fsprogs xfsprogs squashfs-tools quota-tools Step 4: Configure the Kernel Navigate into the kernel source directory: cd linux-6.13 Use your current system’s configuration as a base:\nIf zcat is available, run:\nzcat /proc/config.gz \u0026gt; .config Otherwise, use this alternative method:\ncp /proc/config.gz ./ gunzip config.gz mv config .config Customize the kernel using a menu-driven interface:\nmake menuconfig make xconfig make oldconfig Modify the .config file directly:\nOpen it with a text editor:\nsudo vim .config Search for the line:\nCONFIG_EXT4_FS=m And change it to:\nCONFIG_EXT4_FS=y Step 5: Compile the Kernel Determine the number of CPU cores available to speed up compilation: nproc Compile the kernel using the number of cores found above. Replace n with that number: make -j\u0026lt;n\u0026gt; If you encounter any errors during or after this step, back up your .config file and reset the source tree with:\nmake mrproper This command cleans the build environment and restores the source tree to its original state.\nStep 6: Install Kernel Modules Kernel modules are essential for extending the kernel’s functionality and ensuring compatibility with various hardware. Install them with:\nsudo make modules_install Step 7: Install the Kernel You can install the compiled kernel using one of the two methods below:\nAutomatic installation: sudo make install Manual installation (if the above doesn\u0026rsquo;t work):\nCopy the kernel image:\nsudo cp arch/x86/boot/bzImage /boot/vmlinuz-linux-custom Copy the System.map file:\nsudo cp System.map /boot/System.map-linux-custom Copy the kernel configuration file:\nsudo cp .config /boot/config-linux-custom Step 8: Update the Bootloader If you use GRUB, follow these steps to add an entry for your custom kernel:\nFind the UUID of your root partition: lsblk -f Open the custom GRUB configuration file: sudo nvim /etc/grub.d/40_custom Add the following entry (replace paste-your-root-partition-uuid-here with the actual UUID): menuentry \u0026#39;Custom Linux Kernel\u0026#39; { linux /boot/vmlinuz-linux-custom root=UUID=paste-your-root-partition-uuid-here initrd /boot/initramfs-linux.img } Step 9: Generate Initramfs As you\u0026rsquo;ve compiled a new kernel, installed modules, and modified boot entries, generating a new initramfs is necessary. Run:\nsudo mkinitcpio -k 6.13-custom -c /etc/mkinitcpio.conf -g /boot/initramfs-linux-custom.img Make sure the version (6.13-custom) matches your compiled kernel.\nStep 10: Update GRUB Configuration Finally, update the GRUB configuration so that it includes your new kernel entry:\nsudo grub-mkconfig -o /boot/grub/grub.cfg Done! Congratulations! You’ve successfully compiled and installed your custom Linux Kernel. Enjoy your personalized system!\n","permalink":"http://localhost:1313/posts/kernal_compilation/","summary":"\u003ch1 id=\"building-the-linux-kernel\"\u003eBuilding the Linux Kernel\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003eCompiling the Linux Kernel involves multiple steps and can take some time depending on your hardware specifications.\u003c/strong\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"step-1-download-the-kernel-source-code\"\u003eStep 1: Download the Kernel Source Code\u003c/h3\u003e\n\u003cp\u003eStart by visiting the \u003ca href=\"https://www.kernel.org/\"\u003eOfficial Linux Kernel Website\u003c/a\u003e and downloading the latest available kernel source code. The downloaded file will be a compressed archive containing all necessary source files.\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"step-2-extract-the-source-code\"\u003eStep 2: Extract the Source Code\u003c/h3\u003e\n\u003cp\u003eOnce the download completes, extract the contents of the compressed archive using the \u003ccode\u003etar\u003c/code\u003e command:\u003c/p\u003e","title":"How to build Linux Kernal: Step by Step Guide"},{"content":"Introduction So, you’ve built a sleek website with Hugo and deployed it to GitHub Pages. Now, you want to give it a professional touch with a custom domain like yourdomain.tech instead of the default username.github.io URL. This guide walks you through the process step-by-step.\nPrerequisites A Hugo website hosted on GitHub Pages (public repository). A custom domain (e.g., yourdomain.tech) purchased from a registrar like Namecheap, Google Domains, etc. Basic familiarity with DNS settings and GitHub repository configurations. Step 1: Configure Your GitHub Repository First, ensure your GitHub Pages site is set up correctly:\nYour repository should be named \u0026lt;username\u0026gt;.github.io (for user/organization sites) or \u0026lt;repo-name\u0026gt; (for project sites). The gh-pages branch (or the /docs folder) should contain your Hugo-generated static files. Step 2: Configure DNS Settings for Your Domain Option 1: Use an Apex Domain (e.g., yourdomain.tech) If you want your site to live at the root domain (e.g., yourdomain.tech), configure A records in your DNS settings:\nGo to your domain registrar’s DNS management page. Create four A records pointing to GitHub’s IP addresses: Host: @ Type: A Value: 185.199.108.153 TTL: Automatic ","permalink":"http://localhost:1313/posts/customdomain/","summary":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003eSo, you’ve built a sleek website with Hugo and deployed it to GitHub Pages. Now, you want to give it a professional touch with a custom domain like \u003ccode\u003eyourdomain.tech\u003c/code\u003e instead of the default \u003ccode\u003eusername.github.io\u003c/code\u003e URL. This guide walks you through the process step-by-step.\u003c/p\u003e\n\u003ch2 id=\"prerequisites\"\u003ePrerequisites\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003eA Hugo website hosted on GitHub Pages (public repository).\u003c/li\u003e\n\u003cli\u003eA custom domain (e.g., \u003ccode\u003eyourdomain.tech\u003c/code\u003e) purchased from a registrar like Namecheap, Google Domains, etc.\u003c/li\u003e\n\u003cli\u003eBasic familiarity with DNS settings and GitHub repository configurations.\u003c/li\u003e\n\u003c/ol\u003e\n\u003chr\u003e\n\u003ch2 id=\"step-1-configure-your-github-repository\"\u003eStep 1: Configure Your GitHub Repository\u003c/h2\u003e\n\u003cp\u003eFirst, ensure your GitHub Pages site is set up correctly:\u003c/p\u003e","title":"How to up custom domain for GitHub Pages"},{"content":"Exception handling is a crucial aspect of writing robust and reliable Python code. Whether you\u0026rsquo;re a beginner or an experienced developer, getting an error, or exception, in your Python program means the entire program will crash. You don’t want this to happen in real-world programs. Instead, you want the program to detect errors, handle them, and then continue to run. In this blog, we\u0026rsquo;ll explore the fundamentals of exception handling in Python, including syntax, best practices, and advanced techniques.\nWhat Are Exceptions? Exceptions are runtime errors that disrupt the normal flow of a program. For example, trying to open a non-existent file, dividing by zero, or accessing an invalid index in a list will raise exceptions. If unhandled, these exceptions cause your program to crash.\nBasic Syntax: try and except The primary mechanism for handling exceptions in Python is the try-except block. Errors can be handled with with this. The code that could potentially have an error is put in a try clause. The program execution moves to the start of a following except clause if an error happens.\nHere\u0026rsquo;s the basic structure:\ndef cal(value): try: return 10 / value except ZeroDivisionError: print(\u0026#34;Cannot divide by zero!\u0026#34;) print(cal(0)) print(cal(2)) print(cal(3)) How It Works: The code inside the try block is executed. If an exception occurs, Python checks the except blocks for a matching exception type. If a match is found, the corresponding except block runs. Catching Specific Exceptions Always catch specific exceptions to avoid silencing unexpected errors. Python has many built-in exceptions (e.g., ValueError, TypeError, FileNotFoundError).\nimport math x = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) try: print(f\u0026#39;Square Root of {x} is {math.sqrt(x)}\u0026#39;) except ValueError: print(\u0026#39;Number is less than 0\u0026#39;) Output\nThe else Clause The else block runs only if no exceptions were raised in the try block. Use it to separate \u0026ldquo;happy path\u0026rdquo; code from error handling.\nimport math def sqr(value): try: x = math.sqrt(value) except ValueError: print(\u0026#39;Number is less than 0\u0026#39;) else: print(f\u0026#39;The Answer is: {x}\u0026#39;) value = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) sqr(value) Output The finally Clause The finally block runs regardless of whether an exception occurred. It’s ideal for cleanup tasks (e.g., closing files or releasing resources).\nimport math def sqr(value): try: x = math.sqrt(value) except ValueError: print(\u0026#39;Error\u0026#39;) else: print(f\u0026#39;The Answer is: {x}\u0026#39;) finally: print(\u0026#39;Program Ends\u0026#39;) value = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) sqr(value) Output Raising Exceptions Manually Use the raise keyword to trigger exceptions intentionally. This is useful for enforcing constraints.\ndef validate_age(age): if age \u0026lt; 0: raise ValueError(\u0026#34;Age cannot be negative!\u0026#34;) return age try: validate_age(-5) except ValueError as e: print(e) Creating Custom Exceptions Define custom exceptions by subclassing Python’s built-in Exception class. This makes your code more readable and errors more descriptive. (note: I have used RegEx, for that blog will be out soon :) )\nimport re class InvalidEmailError(Exception): \u0026#34;\u0026#34;\u0026#34;Raised when an email format is invalid.\u0026#34;\u0026#34;\u0026#34; pass def send_email(valid,email): if not valid: raise InvalidEmailError(f\u0026#34;Invalid email: {email}\u0026#34;) email = input(\u0026#39;Please enter your email: \u0026#39;) valid = re.match(r\u0026#39;^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\u0026#39;, email) try: send_email(valid, email) except InvalidEmailError as e: print(e) Output Logging a Python Error We can Log an exception in Python with an error. This can be done in the logging.exception() method. This function logs a message with level ERROR on this logger.\nimport math import logging def sqr(value): try: x = math.sqrt(value) except ValueError: logging.exception(\u0026#34;Error\u0026#34;) else: print(f\u0026#39;The Answer is: {x}\u0026#39;) finally: print(\u0026#39;Program Ends\u0026#39;) value = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) sqr(value) Output Best Practices for Exception Handling Catch specific exceptions: Avoid broad except: clauses that hide bugs. Keep try blocks minimal: Only wrap code that might raise an exception. Use finally for cleanup: Ensure resources are released (e.g., closing files). Log exceptions: Use logging.error() instead of print() for production code. Provide meaningful messages: Help debug issues faster with clear error descriptions. Avoid empty except blocks: Silent failures make debugging harder. Conclusion Exception handling is essential for writing better Python applications. By using try-except blocks effectively, catching specific errors, and with else/finally clauses, you can create programs that handle unexpected scenarios.\nNow go forth and write bulletproof Python code!\n","permalink":"http://localhost:1313/posts/exception_handling_in_python/","summary":"\u003cp\u003eException handling is a crucial aspect of writing robust and reliable Python code. Whether you\u0026rsquo;re a beginner or an experienced developer, getting an error, or exception, in your Python program means the entire program will crash. You don’t want this to happen in real-world programs. Instead, you want the program to detect errors, handle them, and then continue to run. In this blog, we\u0026rsquo;ll explore the fundamentals of exception handling in Python, including syntax, best practices, and advanced techniques.\u003c/p\u003e","title":"Exception Handling in Python: A Comprehensive Guide"},{"content":"Have you ever wanted your Python program to do multiple things at once? For example, downloading files while updating the UI, or processing data while listening for user input? That’s where multithreading comes in.\nIn this post, we’ll explore multithreading in Python — what it is, when to use it, and how to use it with simple examples.\n🧠 What is Multithreading? Multithreading is a way to run multiple threads (smaller units of a process) at the same time. It helps make your program more responsive or perform tasks in parallel, especially when tasks are I/O-bound (e.g., network calls, file reading, etc.).\nPython has a built-in module called threading that makes it easy to create and manage threads.\n⚠️ But Wait — Python\u0026rsquo;s GIL Before you jump in, it\u0026rsquo;s important to understand the Global Interpreter Lock (GIL). In CPython (the standard Python implementation), the GIL allows only one thread to execute Python bytecode at a time.\nThis means multithreading in Python is best suited for I/O-bound tasks, not CPU-bound tasks like heavy computations. For CPU-bound tasks, consider multiprocessing instead.\n🛠️ Using the threading Module Here\u0026rsquo;s a basic example to demonstrate multithreading:\nimport threading import time def print_numbers(): for i in range(5): print(f\u0026#34;Number: {i}\u0026#34;) time.sleep(1) def print_letters(): for letter in \u0026#39;abcde\u0026#39;: print(f\u0026#34;Letter: {letter}\u0026#34;) time.sleep(1) # Creating threads t1 = threading.Thread(target=print_numbers) t2 = threading.Thread(target=print_letters) # Starting threads t1.start() t2.start() # Wait for both threads to complete t1.join() t2.join() print(\u0026#34;Both threads have finished.\u0026#34;) 🔍 Output (interleaved): Number: 0 Letter: a Number: 1 Letter: b ... Both functions run at the same time, and you can see their output interleave. That’s multithreading in action!\n📦 Real-World Use Cases Downloading multiple files at once Handling multiple client connections on a server Running background tasks like logging or monitoring Keeping your GUI app responsive while doing other work 🧰 Extra Tools For more advanced usage:\nconcurrent.futures.ThreadPoolExecutor — easier thread management queue.Queue — safe way to share data between threads threading.Lock — prevents race conditions 🧪 Example with ThreadPoolExecutor from concurrent.futures import ThreadPoolExecutor import time def task(name): print(f\u0026#34;{name} starting\u0026#34;) time.sleep(2) print(f\u0026#34;{name} done\u0026#34;) with ThreadPoolExecutor(max_workers=2) as executor: executor.submit(task, \u0026#34;Task 1\u0026#34;) executor.submit(task, \u0026#34;Task 2\u0026#34;) ✅ Final Thoughts Multithreading in Python is a powerful tool when used correctly — especially for I/O-bound programs. Just remember the GIL limitation and use the right tool (like multiprocessing) when working with CPU-heavy tasks.\nThanks for reading! Happy threading 🧵🐍\n","permalink":"http://localhost:1313/posts/multithreading/","summary":"\u003cp\u003eHave you ever wanted your Python program to do multiple things at once? For example, downloading files while updating the UI, or processing data while listening for user input? That’s where \u003cstrong\u003emultithreading\u003c/strong\u003e comes in.\u003c/p\u003e\n\u003cp\u003eIn this post, we’ll explore multithreading in Python — what it is, when to use it, and how to use it with simple examples.\u003c/p\u003e\n\u003ch2 id=\"-what-is-multithreading\"\u003e🧠 What is Multithreading?\u003c/h2\u003e\n\u003cp\u003eMultithreading is a way to run multiple threads (smaller units of a process) at the same time. It helps make your program more responsive or perform tasks in parallel, especially when tasks are I/O-bound (e.g., network calls, file reading, etc.).\u003c/p\u003e","title":"Multithreading in Python"},{"content":"Running a Local LLM on Mobile: Testing PocketPal on iPhone 12 With the increasing accessibility of large language models (LLMs), running them locally on mobile devices is an exciting prospect. I recently tested PocketPal, a mobile LLM interface, on my iPhone 12, using a distilled 4-bit quantized model. Here’s a breakdown of my experience, covering installation, performance, and overall usability.\nWhy Run an LLM on Mobile? Running an LLM locally on a mobile device comes with several advantages:\nPrivacy: No data is sent to external servers. Offline Access: Works without an internet connection. Lower Cost: Avoids API costs associated with cloud-based models. What is Quantization? Quantization is a technique used to reduce the memory and computational requirements of machine learning models by representing their weights with lower precision numbers. Instead of using 32-bit floating-point numbers, models can be compressed into 8-bit or even 4-bit integers while maintaining reasonable accuracy.\nFor LLMs on mobile, 4-bit quantization significantly reduces the model size, making it feasible to run on devices with limited resources. However, this compression can lead to:\nSlightly reduced accuracy due to loss of precision. Faster inference times, as lower-bit computations require less processing power. Lower memory usage, allowing larger models to fit within mobile device constraints. Setting Up and Running PocketPal on iPhone 12 1. Download and Install PocketPal Open the App Store and search for PocketPal AI by Asghar Ghorbani. Download and install the app. Open the app and allow necessary permissions. 2. Adding a Model Navigate to the Models section in the PocketPal app. Click the + button to add a new model. You will see two options: Add from Hugging Face Add Local Model Select Add from Hugging Face to browse available models. 3. Selecting and Downloading a Model Search for DeepSeek-R1-Distill-Qwen-1.5B-Q4_0. Select the model and start downloading it (size: 1.06GB, 1.78B parameters). Once downloaded, the model will appear under the Ready to Use section. 4. Running Benchmarks I ran benchmarks on my iPhone 12 using the DeepSeek-R1-Distill-Qwen-1.5B-Q4_0 model. Here are the key results:\nModel Size: 1.06 GB with 1.78 billion parameters. Benchmark Configuration: Prompt Processing: 512 Token Generation: 128 Pipeline Length: 1 Repetitions: 3 Model Settings: Context Length: 1024 tokens Batch Size: 512 CPU Threads: 4 GPU Layers: 0 (fully CPU-based execution) Flash Attention: Disabled Performance Metrics: Prompt Processing Speed: 26.93 tokens/sec (±2.37) Token Generation Speed: 18.05 tokens/sec (±0.75) Total Execution Time: 1 minute 18 seconds Peak Memory Usage: 35.0% (1GB / 4GB) Live Demo: Running PocketPal on iPhone 12 Watch a live demonstration of PocketPal running a distilled 4-bit quantized model on an iPhone 12: Image: Video demonstration is available here: Video\nAnalysis of Results Decent Processing Speed: With a distilled 4-bit quantized model, the 18.05 t/s token generation rate is quite reasonable for mobile inference. Low Memory Footprint: The 1GB RAM usage means this can run on even mid-range smartphones. CPU-Based Execution: Since 0 GPU layers were used, this proves mobile CPUs are capable of running quantized LLMs efficiently. Flash Attention Disabled: If supported, enabling it might further optimize speed and reduce lag. Final Thoughts Running an LLM locally on an iPhone 12 with PocketPal is feasible but comes with trade-offs. It’s a promising step toward self-hosted AI assistants, though optimization and hardware improvements will be crucial for broader adoption. If you’re privacy-conscious or need offline AI capabilities, it’s definitely worth exploring!\nFuture Improvements I\u0026rsquo;d Like to See: Better memory efficiency to reduce battery drain. Enhanced speed for real-time interaction. More user-friendly model importing and switching. ","permalink":"http://localhost:1313/posts/llmonmobile/","summary":"\u003ch1 id=\"running-a-local-llm-on-mobile-testing-pocketpal-on-iphone-12\"\u003eRunning a Local LLM on Mobile: Testing PocketPal on iPhone 12\u003c/h1\u003e\n\u003cp\u003eWith the increasing accessibility of large language models (LLMs), running them locally on mobile devices is an exciting prospect. I recently tested \u003cstrong\u003ePocketPal\u003c/strong\u003e, a mobile LLM interface, on my \u003cstrong\u003eiPhone 12\u003c/strong\u003e, using a \u003cstrong\u003edistilled 4-bit quantized model\u003c/strong\u003e. Here’s a breakdown of my experience, covering installation, performance, and overall usability.\u003c/p\u003e\n\u003ch2 id=\"why-run-an-llm-on-mobile\"\u003eWhy Run an LLM on Mobile?\u003c/h2\u003e\n\u003cp\u003eRunning an LLM locally on a mobile device comes with several advantages:\u003c/p\u003e","title":"Running Large Language Models on Mobile: DeepSeek R1 on iPhone 12"},{"content":"Running DeepSeek-R1 1.5B on Raspberry Pi 5 (CPU-Only) Technical Insights Why Can We Run This on Raspberry Pi 5? Thanks to open-source advancements, we can now run large-scale AI models on small devices like the Raspberry Pi 5. Key factors enabling this include:\nOptimized lightweight models: DeepSeek-R1 1.5B is built efficiently to run on limited hardware. ARM64 Support: Modern AI frameworks support ARM-based architectures, enabling their use on RPi5. Open-source software: Platforms like Ollama make AI deployment accessible to all. Performance Considerations Running this model on an RPi5 without a GPU will be CPU-intensive. Consider reducing active processes to free up memory. If performance lags, use a lighter model or external processing (cloud inference). No GPU acceleration was used in this setup, meaning all computations rely solely on the CPU, which may affect inference speeds. This guide covers the installation and execution of DeepSeek-R1 1.5B on a Raspberry Pi 5, following the steps demonstrated in your images.\nPrerequisites Raspberry Pi 5 (ARM64 architecture, more powerful than previous versions) Debian-based Linux installed An internet connection At least 4GB RAM recommended for smooth operation Step 1: Log in to Your Raspberry Pi Upon booting, log in using your credentials:\nraspberrypi login: hisam Password: ****** Example login screen: Step 2: Install Curl Curl is required to fetch the installation script. Run:\nsudo apt install curl If it\u0026rsquo;s already installed, you\u0026rsquo;ll see:\ncurl is already the newest version... Example output: Step 3: Install Ollama Ollama is the runtime needed to execute DeepSeek models.\ncurl -fsSL https://ollama.com/install.sh | sh This will download and install Ollama.\nExample installation screen: Step 4: Enable and Start Ollama Service After installation, Ollama sets up a system service.\nollama The output will indicate success:\n\u0026gt;\u0026gt;\u0026gt; Creating ollama user... \u0026gt;\u0026gt;\u0026gt; Enabling and starting ollama service... \u0026gt;\u0026gt;\u0026gt; The Ollama API is now available at 127.0.0.1:11434. Example setup screen: Step 5: Pull and Run DeepSeek-R1 1.5B Now, pull and run the model:\nollama run deepseek-r1:1.5b This will download the model, which is about 1.1 GB in size.\nExample download screen: Once downloaded, the model is ready to run.\nStep 6: Execute DeepSeek-R1 1.5B Run the model and start interacting:\nollama run deepseek-r1:1.5b You should see a prompt where you can start typing queries:\n\u0026gt;\u0026gt;\u0026gt; Hey! Hello! How can I assist you today? 😊 Example interaction: Final Setup Image Video Demonstration Watch Video\nConclusion You have successfully installed and executed DeepSeek-R1 1.5B on your Raspberry Pi 5. This demonstrates the power of open-source AI, making it possible to run advanced models on small-scale devices. If you encounter performance issues, consider optimizing your setup or offloading computations.\nHappy coding!\n","permalink":"http://localhost:1313/posts/deepseek/","summary":"\u003ch1 id=\"running-deepseek-r1-15b-on-raspberry-pi-5-cpu-only\"\u003eRunning DeepSeek-R1 1.5B on Raspberry Pi 5 (CPU-Only)\u003c/h1\u003e\n\u003ch2 id=\"technical-insights\"\u003eTechnical Insights\u003c/h2\u003e\n\u003ch3 id=\"why-can-we-run-this-on-raspberry-pi-5\"\u003eWhy Can We Run This on Raspberry Pi 5?\u003c/h3\u003e\n\u003cp\u003eThanks to open-source advancements, we can now run large-scale AI models on small devices like the Raspberry Pi 5. Key factors enabling this include:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eOptimized lightweight models\u003c/strong\u003e: DeepSeek-R1 1.5B is built efficiently to run on limited hardware.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eARM64 Support\u003c/strong\u003e: Modern AI frameworks support ARM-based architectures, enabling their use on RPi5.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eOpen-source software\u003c/strong\u003e: Platforms like Ollama make AI deployment accessible to all.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"performance-considerations\"\u003ePerformance Considerations\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eRunning this model on an RPi5 \u003cstrong\u003ewithout a GPU\u003c/strong\u003e will be CPU-intensive.\u003c/li\u003e\n\u003cli\u003eConsider \u003cstrong\u003ereducing active processes\u003c/strong\u003e to free up memory.\u003c/li\u003e\n\u003cli\u003eIf performance lags, use a \u003cstrong\u003elighter model\u003c/strong\u003e or \u003cstrong\u003eexternal processing (cloud inference).\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eNo GPU acceleration was used\u003c/strong\u003e in this setup, meaning all computations rely solely on the CPU, which may affect inference speeds.\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003cp\u003eThis guide covers the installation and execution of DeepSeek-R1 1.5B on a Raspberry Pi 5, following the steps demonstrated in your images.\u003c/p\u003e","title":"DeepSeek-R1 on Raspberry Pi 5: Open-Source AI Without a GPU"},{"content":"Setting Up Neovim: An Easy and Beginner\u0026rsquo;s Guide Neovim is a modern and extensible text editor that enhances Vim’s capabilities. If you\u0026rsquo;re using Linux, setting up Neovim can be a rewarding experience, allowing you to customize it for an efficient workflow. In this guide, we\u0026rsquo;ll cover installing Neovim, setting up a basic configuration, and enhancing it with essential plugins to turn it into a full-fledged IDE.\n1. Installing Neovim sudo pacman -S neovim 2. Setting Up Neovim Configuration Neovim’s configuration is stored in ~/.config/nvim/. Create the directory and initialize a basic configuration:\nmkdir -p ~/.config/nvim nvim ~/.config/nvim/init.lua Minimal Configuration (init.lua) Add the following settings to your init.lua file:\n-- Enable line numbers vim.opt.number = true vim.opt.relativenumber = true -- Set tab size vim.opt.expandtab = true vim.opt.shiftwidth = 4 vim.opt.tabstop = 4 -- Enable mouse support vim.opt.mouse = \u0026#34;a\u0026#34; -- Set clipboard to system clipboard vim.opt.clipboard = \u0026#34;unnamedplus\u0026#34; Save and exit Neovim.\n3. Installing a Plugin Manager The best plugin manager for Neovim is lazy.nvim. Install it by running:\ngit clone --depth 1 https://github.com/folke/lazy.nvim.git \\ ~/.local/share/nvim/lazy/lazy.nvim Then, update your init.lua to load it:\nlocal lazypath = vim.fn.stdpath(\u0026#34;data\u0026#34;) .. \u0026#34;/lazy/lazy.nvim\u0026#34; if not vim.loop.fs_stat(lazypath) then vim.fn.system({ \u0026#34;git\u0026#34;, \u0026#34;clone\u0026#34;, \u0026#34;--filter=blob:none\u0026#34;, \u0026#34;https://github.com/folke/lazy.nvim.git\u0026#34;, lazypath }) end vim.opt.rtp:prepend(lazypath) 4. Installing Essential Plugins With lazy.nvim installed, you can add plugins in init.lua:\nrequire(\u0026#34;lazy\u0026#34;).setup({ \u0026#34;nvim-treesitter/nvim-treesitter\u0026#34;, -- Syntax highlighting \u0026#34;nvim-telescope/telescope.nvim\u0026#34;, -- Fuzzy finder \u0026#34;neovim/nvim-lspconfig\u0026#34;, -- LSP support \u0026#34;hrsh7th/nvim-cmp\u0026#34;, -- Auto-completion \u0026#34;hrsh7th/cmp-nvim-lsp\u0026#34;, -- LSP completion source \u0026#34;hrsh7th/cmp-buffer\u0026#34;, -- Buffer completion \u0026#34;hrsh7th/cmp-path\u0026#34;, -- Path completion \u0026#34;hrsh7th/cmp-nvim-lua\u0026#34;, -- Neovim Lua API completion \u0026#34;L3MON4D3/LuaSnip\u0026#34;, -- Snippet engine \u0026#34;saadparwaiz1/cmp_luasnip\u0026#34;, -- Snippet completion \u0026#34;nvim-lualine/lualine.nvim\u0026#34;, -- Status line \u0026#34;nvim-tree/nvim-tree.lua\u0026#34;, -- File explorer \u0026#34;tpope/vim-surround\u0026#34;, -- Surround text objects \u0026#34;tpope/vim-commentary\u0026#34;, -- Commenting shortcuts \u0026#34;lewis6991/gitsigns.nvim\u0026#34;, -- Git integration \u0026#34;akinsho/toggleterm.nvim\u0026#34;, -- Terminal management }) Save and exit Neovim, then open it and run:\n:Lazy sync This will install the plugins automatically.\n5. Setting Up Treesitter Treesitter provides better syntax highlighting and code parsing. Install it by adding the following to your init.lua:\nrequire\u0026#39;nvim-treesitter.configs\u0026#39;.setup { ensure_installed = \u0026#34;all\u0026#34;, highlight = { enable = true, }, indent = { enable = true, }, } Then, update Treesitter by running:\n:TSUpdate 6. Setting Up LSP (Language Server Protocol) LSP enables features like code completion and linting. Install LSP servers for your language:\n# Python sudo pacman -S python-lsp-server # C++ sudo pacman -S clang # JavaScript/TypeScript npm install -g typescript-language-server Then, enable LSP support in Neovim:\nlocal lspconfig = require(\u0026#34;lspconfig\u0026#34;) lspconfig.pyright.setup({}) -- Python lspconfig.ts_ls.setup({}) -- JavaScript/TypeScript lspconfig.clangd.setup({}) -- C++ Restart Neovim and check LSP status:\n:LspInfo 7. Enhancing Auto-Completion with nvim-cmp To enable code auto-completion, update your init.lua:\nlocal cmp = require\u0026#39;cmp\u0026#39; cmp.setup({ mapping = { [\u0026#39;\u0026lt;C-Space\u0026gt;\u0026#39;] = cmp.mapping.complete(), [\u0026#39;\u0026lt;CR\u0026gt;\u0026#39;] = cmp.mapping.confirm({ select = true }), }, sources = { { name = \u0026#39;nvim_lsp\u0026#39; }, { name = \u0026#39;buffer\u0026#39; }, { name = \u0026#39;path\u0026#39; }, { name = \u0026#39;luasnip\u0026#39; }, { name = \u0026#39;nvim_lua\u0026#39; }, } }) 9. Final Thoughts Congratulations! You now have a powerful, customized Neovim setup that functions as a full-fledged IDE. With features like Treesitter, LSP support, auto-completion, syntax highlighting, Git integration, and a file explorer, your development workflow will be much smoother.\nIf you’d like to further improve your Neovim experience, explore more plugins and tweak your settings. Good luck with that!\nFurther Reading Neovim Documentation Awesome Neovim Plugins Arch Wiki: Neovim ","permalink":"http://localhost:1313/posts/setting-up-neovim-on-arch-linux-a-beginners-guide/","summary":"\u003ch1 id=\"setting-up-neovim-an-easy-and-beginners-guide\"\u003eSetting Up Neovim: An Easy and Beginner\u0026rsquo;s Guide\u003c/h1\u003e\n\u003cp\u003eNeovim is a modern and extensible text editor that enhances Vim’s capabilities. If you\u0026rsquo;re using Linux, setting up Neovim can be a rewarding experience, allowing you to customize it for an efficient workflow. In this guide, we\u0026rsquo;ll cover installing Neovim, setting up a basic configuration, and enhancing it with essential plugins to turn it into a full-fledged IDE.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"1-installing-neovim\"\u003e\u003cstrong\u003e1. Installing Neovim\u003c/strong\u003e\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003esudo pacman -S neovim\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003chr\u003e\n\u003ch2 id=\"2-setting-up-neovim-configuration\"\u003e\u003cstrong\u003e2. Setting Up Neovim Configuration\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003eNeovim’s configuration is stored in \u003ccode\u003e~/.config/nvim/\u003c/code\u003e. Create the directory and initialize a basic configuration:\u003c/p\u003e","title":"Setting Up Neovim: A Beginner's Guide"},{"content":"Linux Kernal The majority of the kernel\u0026rsquo;s code is written in C, leveraging extensions provided by the GNU Compiler Collection (GCC) beyond standard C. Additionally, it includes assembly code for architecture-specific functions, such as optimizing memory usage and task execution. Architecturally, the Linux kernel is monolithic, meaning the entire OS operates within kernel space. However, it features a modular design, allowing software components to be integrated as modules, including dynamic loading.\nWhat Is A Kernel Module? A Linux kernel module is precisely defined as a code segment capable of dynamic loading and unloading within the kernel as needed. These modules enhance kernel capabilities without necessitating a system reboot. A notable example is seen in the device driver module, which facilitates kernel interaction with hardware components linked to the system.\nWriting a Custom Linux Kernel Module Linux kernel modules (LKMs) allow developers to extend the functionality of the Linux kernel without modifying its source code. This guide walks through writing a simple kernel module from scratch. Kernel modules are pieces of code that can be dynamically loaded and unloaded from the Linux kernel at runtime. They enable functionality such as device drivers, file system support, and system call extensions without requiring a kernel recompilation. LKMs are particularly useful for developing hardware drivers and testing new kernel features without rebooting the system.\nPrerequisites Ensure you have the necessary development tools installed. On an Arch Linux system, install them with:\nsudo pacman -Syu linux-headers base-devel Creating a Simple Kernel Module 1. Writing the Module Source Code Create a file named hello_module.c:\n#include \u0026lt;linux/module.h\u0026gt; #include \u0026lt;linux/kernel.h\u0026gt; #include \u0026lt;linux/init.h\u0026gt; MODULE_LICENSE(\u0026#34;GPL\u0026#34;); MODULE_AUTHOR(\u0026#34;Your Name\u0026#34;); MODULE_DESCRIPTION(\u0026#34;A simple Hello World kernel module\u0026#34;); static int __init hello_init(void) { printk(KERN_INFO \u0026#34;Hello, Kernel!\\n\u0026#34;); return 0; } static void __exit hello_exit(void) { printk(KERN_INFO \u0026#34;Goodbye, Kernel!\\n\u0026#34;); } module_init(hello_init); module_exit(hello_exit); Understanding the Kernel Module Code #include \u0026lt;linux/module.h\u0026gt;: Includes the necessary module macros and functions. #include \u0026lt;linux/kernel.h\u0026gt;: Provides kernel logging functions. #include \u0026lt;linux/init.h\u0026gt;: Defines initialization and cleanup macros. MODULE_LICENSE(\u0026quot;GPL\u0026quot;): Specifies the module\u0026rsquo;s license. MODULE_AUTHOR(\u0026quot;Your Name\u0026quot;): Specifies the author of the module. MODULE_DESCRIPTION(\u0026quot;A simple Hello World kernel module\u0026quot;): Provides a brief description. static int __init hello_init(void): The function executed when the module is loaded. static void __exit hello_exit(void): The function executed when the module is unloaded. module_init(hello_init): Registers hello_init as the module\u0026rsquo;s initialization function. module_exit(hello_exit): Registers hello_exit as the module\u0026rsquo;s cleanup function. 2. Writing the Makefile Create a Makefile in the same directory:\nobj-m += hello_module.o all: make -C /lib/modules/$(shell uname -r)/build M=$(PWD) modules clean: make -C /lib/modules/$(shell uname -r)/build M=$(PWD) clean Understanding the Makefile obj-m += hello_module.o: Specifies that hello_module.o is the object to be built as a module. all:: Defines the build target. make -C /lib/modules/$(shell uname -r)/build M=$(PWD) modules: Directs the kernel build system to compile the module. clean:: Cleans up the generated files. make -C /lib/modules/$(shell uname -r)/build M=$(PWD) clean: Cleans the build artifacts. 3. Compiling the Module Run:\nmake 4. Loading and Unloading the Module To insert the module into the kernel:\nsudo insmod hello_module.ko Check the kernel log:\ndmesg | tail To remove the module:\nsudo rmmod hello_module 5. Verifying the Module List loaded modules:\nlsmod | grep hello_module Understanding the Generated Files After building the module, several files are generated:\nhello_module.c: The source code of the module. hello_module.ko: The compiled kernel module file, ready to be loaded into the kernel. hello_module.o: An intermediate object file generated during compilation. hello_module.mod.c: An automatically generated file containing module metadata. hello_module.mod.o: An object file containing metadata compiled from hello_module.mod.c. hello_module.mod: Another metadata file required for module loading. Makefile: Contains instructions for building the module. Module.symvers: Stores information about exported symbols, useful for module dependencies. modules.order: Lists the order in which modules should be loaded. Conclusion This simple kernel module demonstrates the basics of module development. You can expand upon this by adding functionality such as handling parameters or interacting with hardware.\nHappy kernel hacking!\n","permalink":"http://localhost:1313/posts/how-to-write-a-custom-kernel-module/","summary":"\u003ch1 id=\"linux-kernal\"\u003eLinux Kernal\u003c/h1\u003e\n\u003cp\u003eThe majority of the kernel\u0026rsquo;s code is written in C, leveraging extensions provided by the GNU Compiler Collection (GCC) beyond standard C. Additionally, it includes assembly code for architecture-specific functions, such as optimizing memory usage and task execution. Architecturally, the Linux kernel is monolithic, meaning the entire OS operates within kernel space. However, it features a modular design, allowing software components to be integrated as modules, including dynamic loading.\u003c/p\u003e","title":"How to Write a Custom Kernel Module"},{"content":"What is it? gh is GitHub\u0026rsquo;s official command-line tool designed to extend Git\u0026rsquo;s functionality with GitHub-specific features.\nPurpose: Simplifies interaction with GitHub\u0026rsquo;s ecosystem directly from the terminal. Allows you to manage repositories and use GitHub features like issues, pull requests, and workflows.\nKey Features: GitHub-specific tasks:\nAuthentication: Easier login (gh auth login) without dealing with tokens manually. Repository Management: Create, fork, or clone repositories. Issues \u0026amp; Pull Requests: Manage issues, PRs, and comments directly. Actions: Manage and view GitHub Actions workflows. Works alongside Git for basic version control tasks. Use Case: Best for developers heavily using GitHub and its features (for example: pull requests, issues, and actions).\nHow it works Install gh:\n\u0026gt; yay -S github-cli Verify the installation:\n\u0026gt; gh --version Login with GitHub CLI (gh)\n\u0026gt; gh auth login Follow the interactive prompts to log in:\nChoose HTTPS or SSH for connection. Log in via a browser using a one-time code or SSH keys. Verify authentication:\n\u0026gt; gh auth status What\u0026rsquo;s best about it that you can install and use both Git and gh (GitHub CLI) seamlessly. Here\u0026rsquo;s how to set them up:\nInstall Git\n\u0026gt;sudo pacman -S git Check the installation:\n\u0026gt; git --version Using Git and gh Together You can now: Use Git for version control:\n\u0026gt; git clone https://github.com/username/repo.git \u0026gt; git add . \u0026gt; git commit -m \u0026quot;message\u0026quot; \u0026gt; git push ","permalink":"http://localhost:1313/posts/github-cli-githubs-official-command-line-tools/","summary":"\u003ch2 id=\"what-is-it\"\u003eWhat is it?\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003egh\u003c/strong\u003e is GitHub\u0026rsquo;s official command-line tool designed to extend Git\u0026rsquo;s functionality with GitHub-specific features.\u003c/p\u003e\n\u003ch2 id=\"purpose\"\u003ePurpose:\u003c/h2\u003e\n\u003cp\u003eSimplifies interaction with GitHub\u0026rsquo;s ecosystem directly from the terminal. Allows you to manage repositories and use GitHub features like issues, pull requests, and workflows.\u003c/p\u003e\n\u003ch2 id=\"key-features\"\u003eKey Features:\u003c/h2\u003e\n\u003cp\u003eGitHub-specific tasks:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAuthentication: Easier login (gh auth login) without dealing with tokens manually.\u003c/li\u003e\n\u003cli\u003eRepository Management: Create, fork, or clone repositories.\u003c/li\u003e\n\u003cli\u003eIssues \u0026amp; Pull Requests: Manage issues, PRs, and comments directly.\u003c/li\u003e\n\u003cli\u003eActions: Manage and view GitHub Actions workflows.\u003c/li\u003e\n\u003cli\u003eWorks alongside Git for basic version control tasks.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"use-case\"\u003eUse Case:\u003c/h2\u003e\n\u003cp\u003eBest for developers heavily using GitHub and its features (for example: pull requests, issues, and actions).\u003c/p\u003e","title":"GitHub CLI: GitHub's Official Command Line Tools"},{"content":"Connecting a Raspberry Pi 5 to a USB TTY cable is a common way to interact with it through a serial connection, especially for debugging or setting up the device without using a display.\nPrerequists\nRaspberry Pi 5. USB TTY (serial) cable. Computer with a terminal emulator (minicom/screen). GPIO pinout diagram of Raspberry Pi 5 (for reference). Power source for Raspberry Pi (optional if USB TTY can power it, though not recommended). Before Starting! Issuse with firmware UART does NOT work on the RPI5 from the factory. We will need a firmware update to fix this that prevents the dtoverlays for UARTs from working.\nInstall rpi-update with the following commands:\n\u0026gt; sudo curl -L --output /usr/bin/rpi-update https://raw.githubusercontent.com/Hexxeh/rpi-update/master/rpi-update \u0026amp;\u0026amp; sudo chmod +x /usr/bin/rpi-update Then update the firmware on your RPI5 with:\n\u0026gt; sudo rpi-update Enable UART To manually configure UART, you can edit the config.txt file.\nEdit /boot/firmware/config.txt and add:\n\u0026gt; enable_uart=1 How to Connect Locate the GPIO Pins Find the GPIO header on the Raspberry Pi 5. Identify the following pins: GND (Ground): Usually black wire on the USB TTY cable. TX (Transmit): Sends data from the Pi to the computer. RX (Receive): Receives data from the computer to the Pi.\nUse a GPIO pinout chart to locate these pins. For Raspberry Pi 5, it will likely be similar to previous models. Making connections You will need to connect:\nGND with Ground - Pin# 06 TX with GPIO14 - Pin# 08 RX with GPIO15 - Pin# 10 Plug the USB TTY Cable into the Computer\nInsert the USB end of the TTY cable into your computer. The cable will create a virtual COM port (e.g /dev/ttyUSB0). Configure and Access Serial Console\nOpen a terminal.\nIdentify the port with:\n\u0026gt; ls /dev/ttyUSB* Use a terminal emulator like screen or minicom to connect:\n\u0026gt; screen /dev/ttyUSB0 115200 *Replace /dev/ttyUSB0 with the actual port name.\nTurn on the Raspberry Pi. If everything is set up correctly, you should see boot messages in the terminal. Log in to the Pi using the default username (pi) and password (raspberry), or your custom credentials. You should see something similar to this.\nThis is it! You have done it. Congrats!\n","permalink":"http://localhost:1313/posts/how-to-connect-a-raspberry-pi-5-to-usb-tty-cable/","summary":"\u003cp\u003eConnecting a Raspberry Pi 5 to a USB TTY cable is a common way to interact with it through a serial connection, especially for debugging or setting up the device without using a display.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003ePrerequists\u003c/strong\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eRaspberry Pi 5.\u003c/li\u003e\n\u003cli\u003eUSB TTY (serial) cable.\u003c/li\u003e\n\u003cli\u003eComputer with a terminal emulator (minicom/screen).\u003c/li\u003e\n\u003cli\u003eGPIO pinout diagram of Raspberry Pi 5 (for reference).\u003c/li\u003e\n\u003cli\u003ePower source for Raspberry Pi (optional if USB TTY can power it, though not recommended).\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"before-starting\"\u003e\u003cstrong\u003eBefore Starting!\u003c/strong\u003e\u003c/h3\u003e\n\u003ch3 id=\"issuse-with-firmware\"\u003e\u003cstrong\u003e\u003ca href=\"https://forums.raspberrypi.com/viewtopic.php?t=361397#p2171244\"\u003eIssuse with firmware\u003c/a\u003e\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003eUART does NOT work on the RPI5 from the factory. We will need a firmware update to fix this that prevents the dtoverlays for UARTs from working.\u003c/p\u003e","title":"How to Connect a Raspberry PI 5 to USB TTY Cable"},{"content":"Hosting a website on GitHub Pages with Hugo involves the following steps:\nCreating a website 1. Install Hugo and git\n\u0026gt; sudo pacman -S Hugo 2. Create a new Hugo site\n\u0026gt; hugo new site your-website 3. Add a Theme\nNavigate to your website directory and add a theme. You can choose one from the Hugo Themes .\n\u0026gt; cd your-website \u0026gt; git init \u0026gt; git submodule add https://github.com/adityatelange/hugo-PaperMod.git themes/hugo-PaperMod Now you will need to update the hugo.toml file for them to take effect. To do so you can either echo or addd it in the file.\n\u0026gt; echo \u0026quot;theme = 'hugo-PaperMod'\u0026quot; \u0026gt;\u0026gt; hugo.toml To view the website you can run it locally using Hugo\u0026rsquo;s development server to view the site. You can add -D to see your drafts.\n\u0026gt; hugo server 3. Add Content\nTo add a new page to your site.\n\u0026gt; hugo new content content/posts/yout-first-post.md This is it You have done it. YAY!\nHosting it on GitHub 1. Create a GitHub repository.\nClick the + icon in the top-right corner of:\u0026gt; [!WARNING] the GitHub interface and select New repository. Enter a repository name: yourusername.github.io Click Create repository. 2. Add Files for Your website\nClone the repository locally using Git:\ngit clone https://github.com//.git\nAdd your static site files (generated by Hugo) to the repository. Commit and push the changes:\n\u0026gt; git add -A \u0026gt; git commit -s -m \u0026quot;Initial commit\u0026quot; \u0026gt; git push origin main 3. Configure the Repository for GitHub Pages\nGo to the Settings tab of your new repository. Scroll down to the Pages section. Settings \u0026gt; Pages. In the center of your screen you will see this: Build and development Change the Source to GitHub Actions. 4. Create a file named hugo.yaml in a directory named .github/workflows.\n\u0026gt; mkdir -p .github/workflows \u0026gt; cd ./github/workflows touch hugo.yaml 5. Add content in the YAML file.\n# Sample workflow for building and deploying a Hugo site to GitHub Pages name: Deploy Hugo site to Pages on: # Runs on pushes targeting the default branch push: branches: - main # Allows you to run this workflow manually from the Actions tab workflow_dispatch: # Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages permissions: contents: read pages: write id-token: write # Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued. # However, do NOT cancel in-progress runs as we want to allow these production deployments to complete. concurrency: group: \u0026#34;pages\u0026#34; cancel-in-progress: false # Default to bash defaults: run: shell: bash jobs: # Build job build: runs-on: ubuntu-latest env: HUGO_VERSION: 0.141.0 steps: - name: Install Hugo CLI run: | wget -O ${{ runner.temp }}/hugo.deb https://github.com/gohugoio/hugo/releases/download/v${HUGO_VERSION}/hugo_extended_${HUGO_VERSION}_linux-amd64.deb \\ \u0026amp;\u0026amp; sudo dpkg -i ${{ runner.temp }}/hugo.deb - name: Install Dart Sass run: sudo snap install dart-sass - name: Checkout uses: actions/checkout@v4 with: submodules: recursive fetch-depth: 0 - name: Setup Pages id: pages uses: actions/configure-pages@v5 - name: Install Node.js dependencies run: \u0026#34;[[ -f package-lock.json || -f npm-shrinkwrap.json ]] \u0026amp;\u0026amp; npm ci || true\u0026#34; - name: Build with Hugo env: HUGO_CACHEDIR: ${{ runner.temp }}/hugo_cache HUGO_ENVIRONMENT: production TZ: America/Los_Angeles run: | hugo \\ --gc \\ --minify \\ --baseURL \u0026#34;${{ steps.pages.outputs.base_url }}/\u0026#34; - name: Upload artifact uses: actions/upload-pages-artifact@v3 with: path: ./public # Deployment job deploy: environment: name: github-pages url: ${{ steps.deployment.outputs.page_url }} runs-on: ubuntu-latest needs: build steps: - name: Deploy to GitHub Pages id: deployment uses: actions/deploy-pages@v4 5. Commit and push your GitHub repository.\n\u0026gt;git add -A \u0026gt;git commit -m \u0026quot;Create hugo.yaml\u0026quot; \u0026gt;git push 6. Deployment status From GitHub’s main menu, choose Actions. When GitHub has finished building and deploying your site, the color of the status indicator will change to green.\nStep 5: Verify Your GitHub Pages Site\nThe site will be live at https://yourusername.github.io.\n","permalink":"http://localhost:1313/posts/hosting-a-website-on-github-pages-with-hugo/","summary":"\u003cp\u003eHosting a website on GitHub Pages with Hugo involves the following steps:\u003c/p\u003e\n\u003ch1 id=\"creating-a-website\"\u003eCreating a website\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e1. Install Hugo and git\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; sudo pacman -S Hugo\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e2. Create a new Hugo site\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; hugo new site your-website\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e3. Add a Theme\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eNavigate to your website directory and add a theme. You can choose one from the \u003ca href=\"https://themes.gohugo.io/\"\u003eHugo Themes\u003c/a\u003e .\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; cd your-website\n\u0026gt; git init \n\u0026gt; git submodule add https://github.com/adityatelange/hugo-PaperMod.git themes/hugo-PaperMod\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow you will need to update the hugo.toml file for them to take effect. To do so you can either \u003cem\u003eecho\u003c/em\u003e or addd it in the file.\u003c/p\u003e","title":"Hosting a Website on Github Pages With Hugo"},{"content":"KVM Kernel-based Virtual Machine is a free and open-source virtualization module in the Linux kernel that allows the kernel to function as a hypervisor.\nInstallation For updates, run the following command:\n$ sudo pacman -Syu QEMU/KVM installation: We\u0026rsquo;ll install qemu and all the utils required:\n$ sudo pacman -S qemu vde2 ebtables iptables-nft nftables dms masq bridge-utils ovmf swptm Virtual Machine Manager installation: The virt-manager application is a graphical user interface for managing virtual machines through libvirt. It primarily targets KVM VMs.\n$ sudo pacman -S virt-manager Now everything is set to work. We can move towards downloading archlinux .iso file.\nDownload .iso file: Head towards: https://archlinux.org/download/ Scroll through and look for the server closest to you. Download archlinux-2024.10.01-x86_64.iso file. Setting up: Open terminal and run the following command:\n$ virt-manager You will see an interface similar to this:\nClick on \u0026lsquo;create a new virtual machine\u0026rsquo; (option with star). Select \u0026lsquo;Local install media\u0026rsquo;. Browse to your \u0026lsquo;archlinux-2024.10.01-x86_64.iso\u0026rsquo;. Add your desired VM configuration and create a disk image. Boot Menu: You will be prompted to a boot menu.\nSelect the topmost option to start the installation process. Archlinux Installer: You will be prompted to a terminal. The first step is to check if you are connected to the internet.\nRun:\n# ip addr show If it shows an IP address and says \u0026lsquo;UP\u0026rsquo;, that means you are good to go.\nIf not: You will need to connect to the internet using the \u0026lsquo;iwctl\u0026rsquo; method for Wi-Fi.\n# iwctl To search networks in your vicinity:\n[iwd]# station [your_wifi_interface] get-networks Get the name of the network you want to connect to. Exit from this prompt using \u0026rsquo;exit\u0026rsquo;.\nTo connect to the desired Wi-Fi network, run:\n# iwctl --passphrase \u0026#34;[wifi_password]\u0026#34; station [your_wifi_interface] connect [wifi_name] You can again run ip addr show to check if you are connected to the network.\nNow you can run the installation command. We\u0026rsquo;ll be using the archinstall method.\n# archinstall You will be prompted to an interface similar to this:\nWe will install Arch using this interface. Go through each option:\nArchinstall language: Choose your preferred language. Mirrors: Select the mirror region closest to you. Use \u0026lsquo;/\u0026rsquo; to search. Locales: Set language and keyboard layout. Disk configuration: Choose Best-effort default partition to format the system. Bootloader: Use the default \u0026lsquo;Grub\u0026rsquo; option. Swap: Select Swap on zram (default). Hostname: Leave as it is. Root password: Set the password for sudo/root privileges. User account: Set up a user account. Profile: Select Desktop. It includes essential packages. Others include Minimal, Server, and Xorg. In Desktop, select your desktop environment. We\u0026rsquo;ll use Gnome for simplicity.\nAudio: Use PipeWire (default) or PulseAudio. Kernels: Use the linux kernel. Additional packages: Install any required packages. Network Configuration: Use NetworkManager for a GUI in Gnome. Timezone: Set the timezone closest to you and enable time sync. Press Install. Congratulations! You\u0026rsquo;ve successfully installed Arch Linux.\n","permalink":"http://localhost:1313/posts/arch_kvm/","summary":"\u003ch1 id=\"kvm\"\u003eKVM\u003c/h1\u003e\n\u003cp\u003eKernel-based Virtual Machine is a free and open-source virtualization module in the Linux kernel that allows the kernel to function as a hypervisor.\u003c/p\u003e\n\u003ch2 id=\"installation\"\u003eInstallation\u003c/h2\u003e\n\u003cp\u003eFor updates, run the following command:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ sudo pacman -Syu\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"qemukvm-installation\"\u003eQEMU/KVM installation:\u003c/h3\u003e\n\u003cp\u003eWe\u0026rsquo;ll install qemu and all the utils required:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ sudo pacman -S qemu vde2 ebtables iptables-nft nftables dms masq bridge-utils ovmf swptm\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"virtual-machine-manager-installation\"\u003eVirtual Machine Manager installation:\u003c/h3\u003e\n\u003cp\u003eThe virt-manager application is a graphical user interface for managing virtual machines through libvirt. It primarily targets KVM VMs.\u003c/p\u003e","title":"archlinux installation in hypervisor through QEMU/KVM"},{"content":"","permalink":"http://localhost:1313/posts/github-cli-githubs-official-command-line-tool/","summary":"","title":""},{"content":"1. Introduction Sometimes you need to share a local application with the outside world, maybe to demo your project, test a webhook, or allow a teammate to access your development server.\nNormally, you’d need a public IP, port forwarding, or a cloud server. ngrok removes all that complexity by creating a secure tunnel from the internet directly to your machine, giving you a public URL instantly.\n2. Prerequisites Before we begin, make sure you have:\nA terminal A free ngrok account (for authentication token) A running local service (e.g., a Python HTTP server, web app, or API) 3. Installing ngrok on Linux We’ll cover installation for Arch Linux, Debian/Ubuntu, and Fedora.\n3.1 Arch Linux This package is not in the official repos, install it from the AUR:\nyay -S ngrok 3.2 Debian / Ubuntu sudo apt update sudo apt install snapd sudo snap install ngrok Alternatively, download the binary from the ngrok downloads page.\n3.3 Fedora sudo dnf install snapd sudo ln -s /var/lib/snapd/snap /snap sudo snap install ngrok 4. Authenticating ngrok Once installed, you need to connect it to your account so you can use custom domains, longer session times, and access the dashboard.\nSign in to ngrok dashboard. -\u0026gt; Your AuthToken Copy your AuthToken. Run: ngrok config add-authtoken \u0026lt;YOUR_TOKEN\u0026gt; You will see: Authtoken saved to configuration file: ~/.config/ngrok/ngrok.yml 5. Exposing a Local Service For example, if your local web server is running on port 8080:\nngrok http 8080 You’ll see output like:\nNow you can share the HTTPS URL with anyone. It wil be similar to: https://random.string.ngrok-free.app\n6. Adding Basic Security You can protect your tunnel with a simple username and password:\nngrok http --basic-auth=\u0026#34;user:password\u0026#34; 8080 Anyone visiting the public link will need credentials.\n7. The Inspector One of ngrok\u0026rsquo;s most powerful features is its built-in web interface, accessible at http://127.0.0.1:4040. This interface lets you inspect every single request that comes through your tunnel in real-time. You can see headers, request bodies, and response details, and even replay requests with a single click—an absolute lifesaver for debugging webhooks.\n8. Common Use Cases Webhook testing — Connect services like GitHub, Stripe, or Twilio to your local environment. Temporary demos — Share work-in-progress with clients without deployment. Remote device access — SSH into a Raspberry Pi without changing router settings. 9. Conclusion In just a few commands, you’ve learned how to:\nInstall ngrok on popular Linux distros Authenticate your installation Share a local service securely From here, you can explore ngrok’s advanced features like static domains, IP allowlists, and traffic inspection.\n","permalink":"http://localhost:1313/posts/ngrok/","summary":"\u003ch2 id=\"1-introduction\"\u003e1. Introduction\u003c/h2\u003e\n\u003cp\u003eSometimes you need to share a local application with the outside world, maybe to demo your project, test a webhook, or allow a teammate to access your development server.\u003c/p\u003e\n\u003cp\u003eNormally, you’d need a public IP, port forwarding, or a cloud server. \u003cstrong\u003engrok\u003c/strong\u003e removes all that complexity by creating a \u003cstrong\u003esecure tunnel\u003c/strong\u003e from the internet directly to your machine, giving you a public URL instantly.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"2-prerequisites\"\u003e2. Prerequisites\u003c/h2\u003e\n\u003cp\u003eBefore we begin, make sure you have:\u003c/p\u003e","title":"Ngrok: Expose Localhost to the Internet"},{"content":"Creating a WhatsApp AI Assistant Using n8n: A Step-by-Step Guide Build your own AI-powered WhatsApp chatbot using n8n, WhatsApp Business Cloud API, and OpenAI. This guide walks you through every step—from setup to testing—with real-world error handling, solutions, and an example production-ready workflow.\n1. Introduction Want to chat with an AI on WhatsApp? In this tutorial, you\u0026rsquo;ll learn how to build a WhatsApp AI Assistant using:\nn8n (automation tool) WhatsApp Business Cloud API OpenAI (for generating intelligent replies) By the end, you\u0026rsquo;ll have a working chatbot and gain hands-on experience with APIs, webhooks, and automation.\n2. Prerequisites n8n account (Cloud or self-hosted) Meta Developer account with WhatsApp Business Cloud API access OpenAI API key Basic understanding of APIs and webhook workflows 3. Registering Your WhatsApp Business App A. Create WhatsApp App in Meta Developer Visit Meta for Developers Create a new app: choose Business → WhatsApp Link or create a WhatsApp Business Account B. Obtain Testing Credentials Your app dashboard will show:\nTest phone number Phone Number ID Temporary access token (valid for only 24 hours) Tip: For long-term use, generate a 60-day system-user token later.\nC. Add Recipients to Test List By default, only approved numbers can receive messages:\nNavigate to WhatsApp → API Setup Add numbers in E.164 format (e.g., +923001234567) Users must accept the invite via WhatsApp to become valid recipients 4. Configuring Your Webhook in n8n A. Create a Webhook Node Method: GET (for initial verification) Endpoint example: https://yourname.app.n8n.cloud/webhook/your-unique-id/webhook B. Verify the Webhook with Meta In your app’s Webhook section:\nCallback URL: your n8n webhook URL Verify Token: any secret string you choose (e.g., mySecret2025) C. Echo Back Meta’s Challenge Configure n8n\u0026rsquo;s Webhook node response:\nField Value Response Mode On Received Response Body {{$json[\u0026quot;query\u0026quot;][\u0026quot;hub.challenge\u0026quot;]}} This ensures Meta can verify your endpoint successfully.\n5. Processing Incoming Messages WhatsApp sends JSON data with structure like:\n{ \u0026#34;entry\u0026#34;: [ { \u0026#34;changes\u0026#34;: [ { \u0026#34;value\u0026#34;: { \u0026#34;messages\u0026#34;: [ { \u0026#34;from\u0026#34;: \u0026#34;923001234567\u0026#34;, \u0026#34;text\u0026#34;: { \u0026#34;body\u0026#34;: \u0026#34;Hello bot!\u0026#34; } } ], \u0026#34;metadata\u0026#34;: { \u0026#34;phone_number_id\u0026#34;: \u0026#34;698352170035199\u0026#34; } } } ] } ] } Extract:\nfrom: user’s number text.body: user’s text metadata.phone_number_id: correct sender ID 6. Integrating OpenAI for Responses Obtaining Your OpenAI API Key Before integrating OpenAI into your n8n workflow, you’ll need to get an API key from OpenAI.\nStep-by-Step: Sign up or log in to OpenAI. Navigate to your API Keys page. Click \u0026ldquo;Create new secret key\u0026rdquo;. Optionally name your key, then copy it immediately (you won’t be able to view it again). In n8n: Go to Credentials → Add New → choose OpenAI or HTTP Request. Paste your API key into the key field. Save the credentials. Security Tip: Keep your key private. Do not share it or commit it to public repositories.\nUse an HTTP Request node to call OpenAI:\nPOST https://api.openai.com/v1/chat/completions Authorization: Bearer YOUR_OPENAI_API_KEY Content-Type: application/json { \u0026#34;model\u0026#34;: \u0026#34;gpt-4o-mini\u0026#34;, \u0026#34;messages\u0026#34;: [ { \u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;You are a helpful WhatsApp AI assistant.\u0026#34; }, { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;{{ $json[...] }}\u0026#34; } ] } Replace {{ $json[...] }} with the actual path to the user\u0026rsquo;s message text from the Webhook node.\n7. Sending Replies via WhatsApp Use another HTTP Request node to respond:\nPOST https://graph.facebook.com/v21.0/{{ $json[...] }}/messages Authorization: Bearer YOUR_LONG_LIVED_TOKEN Content-Type: application/json { \u0026#34;messaging_product\u0026#34;: \u0026#34;whatsapp\u0026#34;, \u0026#34;to\u0026#34;: \u0026#34;{{ $json[...] }}\u0026#34;, \u0026#34;text\u0026#34;: { \u0026#34;body\u0026#34;: \u0026#34;{{ $node[\u0026#39;OpenAI Response\u0026#39;].json.choices[0].message.content }}\u0026#34; } } Use the metadata’s phone_number_id for the endpoint and from for the recipient. This avoids hardcoding and ensures proper routing.\n8. Example n8n Workflow Here’s the actual n8n workflow I used for my WhatsApp AI assistant. It integrates a product brochure PDF into a vector store for AI-powered Q\u0026amp;A, and handles WhatsApp message flow.\nStep-by-Step Breakdown: 1. Download Product Brochure PDF Downloads the brochure from a given URL. Extracts text from the PDF. 2. Create Product Brochure Vector Store Splits large text into chunks. Generates embeddings using OpenAI. Saves them in a vector store for fast semantic search. 3. Use the WhatsApp Trigger Listens for incoming WhatsApp messages. Routes them to supported or unsupported handlers. 3a. Handle Unsupported Messages Replies with a friendly error if the message type is not text. 4. Sales AI Agent Responds Uses OpenAI with memory + vector store retrieval to answer based on brochure content. 5. Reply to WhatsApp User Sends the AI-generated message back to the sender. Why this is effective:\nContext-aware answers via buffer memory. Reduced hallucinations thanks to vector store grounding. Smooth error handling for unsupported message types. 9. Common Errors \u0026amp; Fixes Recipient phone number not in allowed list\n→ Add as test number or switch to Live mode\n401 – Session expired\n→ Refresh token via Graph API:\nGET https://graph.facebook.com/v21.0/oauth/access_token ?grant_type=fb_exchange_token \u0026amp;client_id=YOUR_APP_ID \u0026amp;client_secret=YOUR_APP_SECRET \u0026amp;fb_exchange_token=YOUR_CURRENT_TOKEN Webhook verification failed\n→ Ensure verify token matches between Meta and n8n and echo hub.challenge\nNo execution data available\n→ Trigger workflow via actual WhatsApp message, not manual run\n10. Going Live Add a Privacy Policy URL in Meta App → Settings → Basic (required for live access) Switch app to Live mode once all compliance items are met Remove restricted recipient list Use WhatsApp message templates for messages sent after 24 hours of user interaction 11. Conclusion \u0026amp; Next Steps Congrats! You now have a WhatsApp AI Assistant built with n8n and OpenAI.\nWhere to go from here: Wire up custom knowledge (PDFs, documents) Implement memory for conversation context Launch multilingual support Export n8n workflow as JSON for reuse Need help? Join the n8n Community Forum or OpenAI Discord to connect with fellow builders.\nHappy automating!\n","permalink":"http://localhost:1313/posts/creating-whatsapp-ai-assistant-using-n8n2/","summary":"\u003ch1 id=\"creating-a-whatsapp-ai-assistant-using-n8n-a-step-by-step-guide\"\u003eCreating a WhatsApp AI Assistant Using n8n: A Step-by-Step Guide\u003c/h1\u003e\n\u003cp\u003eBuild your own AI-powered WhatsApp chatbot using \u003cstrong\u003en8n\u003c/strong\u003e, \u003cstrong\u003eWhatsApp Business Cloud API\u003c/strong\u003e, and \u003cstrong\u003eOpenAI\u003c/strong\u003e. This guide walks you through every step—from setup to testing—with real-world error handling, solutions, and an example production-ready workflow.\u003c/p\u003e\n\u003ch2 id=\"1-introduction\"\u003e1. Introduction\u003c/h2\u003e\n\u003cp\u003eWant to chat with an AI on WhatsApp? In this tutorial, you\u0026rsquo;ll learn how to build a \u003cstrong\u003eWhatsApp AI Assistant\u003c/strong\u003e using:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003en8n\u003c/strong\u003e (automation tool)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eWhatsApp Business Cloud API\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eOpenAI\u003c/strong\u003e (for generating intelligent replies)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eBy the end, you\u0026rsquo;ll have a working chatbot and gain hands-on experience with APIs, webhooks, and automation.\u003c/p\u003e","title":"Creating Whatsapp Ai Assistant Using N8n"},{"content":"Introduction A memory leak occurs when a program allocates memory dynamically (e.g., using malloc) and fails to release it using free. This leftover allocation can lead to wasted memory resources, eventually causing slowdowns or system crashes in long-running programs.\nValgrind is a powerful command-line tool available on Linux systems. It helps developers detect:\nMemory leaks Invalid memory access Uninitialized memory usage Mismatched memory management In this guide, we\u0026rsquo;ll walk through examples in C to learn how to detect and fix memory leaks using Valgrind.\nInstalling Valgrind On Arch Linux sudo pacman -S valgrind On Ubuntu/Debian sudo apt install valgrind On Fedora sudo dnf install valgrind Troubleshooting: Valgrind \u0026ldquo;cannot find mandatory redirection\u0026rdquo; on Arch Linux If you run Valgrind and get an error like:\nvalgrind: Fatal error at startup: a function redirection\nvalgrind: which is mandatory for this platform-tool combination\nvalgrind: cannot be set up.\n…you might be running a 32-bit executable on a 64-bit Arch Linux system.\nWhy this happens Valgrind needs to hook into low-level glibc functions from your binary’s architecture.\nIf your binary is 32-bit, Arch requires the 32-bit glibc runtime (lib32-glibc).\nWithout it, Valgrind can’t find the right function symbols and quits.\nFix Install the 32-bit glibc package:\nsudo pacman -S lib32-glibc After installation, re-run:\nvalgrind ./your-binary and it should work.\nUbuntu/Debian equivalent: sudo apt install libc6-dbg:i386\nBasic Example: Hello World Code #include \u0026lt;stdio.h\u0026gt; int main() { printf(\u0026#34;Hello World\\n\u0026#34;); return 0; } Compile and Run gcc main.c -o main.out ./main.out Run with Valgrind valgrind ./main.out You should see no errors or memory leaks in the output.\nIntroducing a Memory Leak Static Allocation (Safe) #include \u0026lt;stdio.h\u0026gt; int main() { char str[20] = \u0026#34;Hello\u0026#34;; printf(\u0026#34;%s\\n\u0026#34;, str); return 0; } This uses stack memory, so Valgrind will report no leaks.\nDynamic Allocation (With Leak) #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; int main() { char *str = malloc(20); strcpy(str, \u0026#34;Hello\u0026#34;); printf(\u0026#34;%s\\n\u0026#34;, str); return 0; // Forgot to free memory } Valgrind Output valgrind ./main.out You should see:\ndefinitely lost: 20 bytes in 1 blocks\nFixing the Memory Leak Add free(str); before returning:\nfree(str); Fixed Code #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; int main() { char *str = malloc(20); strcpy(str, \u0026#34;Hello\u0026#34;); printf(\u0026#34;%s\\n\u0026#34;, str); free(str); return 0; } Detailed Valgrind Options Use for deeper analysis:\nvalgrind --leak-check=full ./main.out Or even more detailed:\nvalgrind --leak-check=full --show-leak-kinds=all --track-origins=yes ./main.out Explanation:\n--leak-check=full: Display detailed leak info --show-leak-kinds=all: Show all kinds of leaks (definitely, indirectly lost, etc.) --track-origins=yes: Show where uninitialized values originate Summary Always free() memory allocated with malloc(), calloc(), or realloc(). Close all file streams with fclose(). Use Valgrind to identify and fix: Memory leaks Invalid memory writes Use-after-free bugs Recommended command: valgrind --leak-check=full --track-origins=yes ./your_program Valgrind is a critical tool for writing safe, efficient, and bug-free C programs.\n","permalink":"http://localhost:1313/posts/introductiontovalgrind/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eA \u003cstrong\u003ememory leak\u003c/strong\u003e occurs when a program allocates memory dynamically (e.g., using \u003ccode\u003emalloc\u003c/code\u003e) and fails to release it using \u003ccode\u003efree\u003c/code\u003e. This leftover allocation can lead to wasted memory resources, eventually causing slowdowns or system crashes in long-running programs.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eValgrind\u003c/strong\u003e is a powerful command-line tool available on Linux systems. It helps developers detect:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eMemory leaks\u003c/li\u003e\n\u003cli\u003eInvalid memory access\u003c/li\u003e\n\u003cli\u003eUninitialized memory usage\u003c/li\u003e\n\u003cli\u003eMismatched memory management\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIn this guide, we\u0026rsquo;ll walk through examples in C to learn how to detect and fix memory leaks using Valgrind.\u003c/p\u003e","title":"Detecting and Fixing Memory Leaks with Valgrind"},{"content":"QEMU-KVM on Arch Linux: Running Tiny Core Linux in a Lightweight VM Virtualization is a powerful tool for developers, sysadmins, and tinkerers alike. On Linux, QEMU-KVM stands out as a robust, high-performance virtualization stack. In this blog, well walk through setting up QEMU-KVM on Arch Linux and using it to run Tiny Core Linuxa super-lightweight distro perfect for testing and experimentation.\nWhat is QEMU-KVM QEMU (Quick Emulator) is a generic and open-source machine emulator. On its own, it can emulate various hardware systems. However, when paired with **KVM (Kernel-based Virtual Machine)**a Linux kernel module for virtualizationit can run virtual machines with near-native performance.\nQEMU provides device emulation and user-space management. KVM integrates with the Linux kernel and handles hardware-level virtualization. Together, they effectively form a Type 1 hypervisor because the Linux kernel (with KVM) handles core virtualization tasks directly on hardware.\nStep-by-Step: Installing QEMU-KVM on Arch Linux Step 1: Install Required Packages sudo pacman -Syu sudo pacman -S qemu virt-manager virt-viewer dnsmasq vde2 bridge-utils openbsd-netcat libvirt edk2-ovmf edk2-ovmf is for UEFI firmware support in VMs.\nStep 2: Enable and Start libvirtd sudo systemctl enable --now libvirtd.service Step 3: Add Your User to the libvirt Group sudo usermod -aG libvirt (whoami) newgrp libvirt Step 4: Verify KVM Support lsmod grep kvm And check CPU virtualization support:\negrep -c (vmxsvm) /proc/cpuinfo A value of 1 or more indicates virtualization support.\nExample: Running Tiny Core Linux on QEMU-KVM Now that your system is ready, lets run Tiny Core Linux, a minimalist Linux distro thats only 16MB\nStep 1: Download Tiny Core ISO wget http://tinycorelinux.net/14.x/x86/release/Core-current.iso Or visit http://tinycorelinux.net for the latest release.\nStep 2: Create a Virtual Disk (Optional) qemu-img create -f qcow2 tinycore.qcow2 512M This creates a 512MB disk image. Optional for RAM-only usage.\nStep 3: Launch the VM with KVM Acceleration qemu-system-x86_64 -enable-kvm -m 512 -cpu host -smp 1 -cdrom Core-current.iso -hda tinycore.qcow2 -boot d -net nic -net user -vga virtio -display sdl Key Flags Explained:\n-enable-kvm: Enables KVM hardware acceleration -m 512: Allocates 512MB RAM -cpu host: Uses the host CPU features -cdrom: Points to the Tiny Core ISO -hda: Uses a QCOW2 disk image -boot d: Boots from CD first -net user: Enables simple user-mode networking (e.g., for internet access) -display sdl: Uses SDL window for graphics (you can replace with gtk or virt-manager) Alternate: Boot Tiny Core in RAM Without Disk qemu-system-x86_64 -enable-kvm -m 256 -cdrom Core-current.iso -boot d -net nic -net user -vga std Conclusion With QEMU-KVM, Arch Linux becomes a full-featured Type 1 hypervisor. By combining kernel-level virtualization (KVM) with the flexibility of QEMU, you get a fast, customizable virtualization platform. Running Tiny Core Linux showcases just how lightweight and efficient this setup can be.\nWhether youre building VMs for testing, learning Linux internals, or experimenting with custom environments, QEMU-KVM on Arch is a powerful combination.\nHappy virtualizing\n","permalink":"http://localhost:1313/posts/qemu/","summary":"\u003ch1 id=\"qemu-kvm-on-arch-linux-running-tiny-core-linux-in-a-lightweight-vm\"\u003eQEMU-KVM on Arch Linux: Running Tiny Core Linux in a Lightweight VM\u003c/h1\u003e\n\u003cp\u003eVirtualization is a powerful tool for developers, sysadmins, and tinkerers alike. On Linux, \u003cstrong\u003eQEMU-KVM\u003c/strong\u003e stands out as a robust, high-performance virtualization stack. In this blog, well walk through setting up QEMU-KVM on \u003cstrong\u003eArch Linux\u003c/strong\u003e and using it to run \u003cstrong\u003eTiny Core Linux\u003c/strong\u003ea super-lightweight distro perfect for testing and experimentation.\u003c/p\u003e\n\u003ch2 id=\"what-is-qemu-kvm\"\u003eWhat is QEMU-KVM\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eQEMU (Quick Emulator)\u003c/strong\u003e is a generic and open-source machine emulator. On its own, it can emulate various hardware systems. However, when paired with **KVM (Kernel-based Virtual Machine)**a Linux kernel module for virtualizationit can run virtual machines with near-native performance.\u003c/p\u003e","title":"QEMU-KVM on Arch Linux: Running Tiny Core Linux in a Lightweight VM"},{"content":"Building the Linux Kernel Compiling the Linux Kernel involves multiple steps and can take some time depending on your hardware specifications.\nStep 1: Download the Kernel Source Code Start by visiting the Official Linux Kernel Website and downloading the latest available kernel source code. The downloaded file will be a compressed archive containing all necessary source files.\nStep 2: Extract the Source Code Once the download completes, extract the contents of the compressed archive using the tar command:\ntar xvf linux-6.13.tar.xz If the tar utility is not installed on your system, you can install it using:\nsudo pacman -S tar Note: Always ensure you are using the correct version number in the file name.\nStep 3: Install Required Dependencies To compile the kernel, you need to install various development tools and libraries. Install them using the following command:\nsudo pacman -S git fakeroot ncurses xz bc flex bison base-devel kmod cpio perl binutils util-linux jfsutils e2fsprogs xfsprogs squashfs-tools quota-tools Step 4: Configure the Kernel Navigate into the kernel source directory: cd linux-6.13 Use your current system’s configuration as a base:\nIf zcat is available, run:\nzcat /proc/config.gz \u0026gt; .config Otherwise, use this alternative method:\ncp /proc/config.gz ./ gunzip config.gz mv config .config Customize the kernel using a menu-driven interface:\nmake menuconfig make xconfig make oldconfig Modify the .config file directly:\nOpen it with a text editor:\nsudo vim .config Search for the line:\nCONFIG_EXT4_FS=m And change it to:\nCONFIG_EXT4_FS=y Step 5: Compile the Kernel Determine the number of CPU cores available to speed up compilation: nproc Compile the kernel using the number of cores found above. Replace n with that number: make -j\u0026lt;n\u0026gt; If you encounter any errors during or after this step, back up your .config file and reset the source tree with:\nmake mrproper This command cleans the build environment and restores the source tree to its original state.\nStep 6: Install Kernel Modules Kernel modules are essential for extending the kernel’s functionality and ensuring compatibility with various hardware. Install them with:\nsudo make modules_install Step 7: Install the Kernel You can install the compiled kernel using one of the two methods below:\nAutomatic installation: sudo make install Manual installation (if the above doesn\u0026rsquo;t work):\nCopy the kernel image:\nsudo cp arch/x86/boot/bzImage /boot/vmlinuz-linux-custom Copy the System.map file:\nsudo cp System.map /boot/System.map-linux-custom Copy the kernel configuration file:\nsudo cp .config /boot/config-linux-custom Step 8: Update the Bootloader If you use GRUB, follow these steps to add an entry for your custom kernel:\nFind the UUID of your root partition: lsblk -f Open the custom GRUB configuration file: sudo nvim /etc/grub.d/40_custom Add the following entry (replace paste-your-root-partition-uuid-here with the actual UUID): menuentry \u0026#39;Custom Linux Kernel\u0026#39; { linux /boot/vmlinuz-linux-custom root=UUID=paste-your-root-partition-uuid-here initrd /boot/initramfs-linux.img } Step 9: Generate Initramfs As you\u0026rsquo;ve compiled a new kernel, installed modules, and modified boot entries, generating a new initramfs is necessary. Run:\nsudo mkinitcpio -k 6.13-custom -c /etc/mkinitcpio.conf -g /boot/initramfs-linux-custom.img Make sure the version (6.13-custom) matches your compiled kernel.\nStep 10: Update GRUB Configuration Finally, update the GRUB configuration so that it includes your new kernel entry:\nsudo grub-mkconfig -o /boot/grub/grub.cfg Done! Congratulations! You’ve successfully compiled and installed your custom Linux Kernel. Enjoy your personalized system!\n","permalink":"http://localhost:1313/posts/kernal_compilation/","summary":"\u003ch1 id=\"building-the-linux-kernel\"\u003eBuilding the Linux Kernel\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003eCompiling the Linux Kernel involves multiple steps and can take some time depending on your hardware specifications.\u003c/strong\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"step-1-download-the-kernel-source-code\"\u003eStep 1: Download the Kernel Source Code\u003c/h3\u003e\n\u003cp\u003eStart by visiting the \u003ca href=\"https://www.kernel.org/\"\u003eOfficial Linux Kernel Website\u003c/a\u003e and downloading the latest available kernel source code. The downloaded file will be a compressed archive containing all necessary source files.\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"step-2-extract-the-source-code\"\u003eStep 2: Extract the Source Code\u003c/h3\u003e\n\u003cp\u003eOnce the download completes, extract the contents of the compressed archive using the \u003ccode\u003etar\u003c/code\u003e command:\u003c/p\u003e","title":"How to build Linux Kernal: Step by Step Guide"},{"content":"Introduction So, you’ve built a sleek website with Hugo and deployed it to GitHub Pages. Now, you want to give it a professional touch with a custom domain like yourdomain.tech instead of the default username.github.io URL. This guide walks you through the process step-by-step.\nPrerequisites A Hugo website hosted on GitHub Pages (public repository). A custom domain (e.g., yourdomain.tech) purchased from a registrar like Namecheap, Google Domains, etc. Basic familiarity with DNS settings and GitHub repository configurations. Step 1: Configure Your GitHub Repository First, ensure your GitHub Pages site is set up correctly:\nYour repository should be named \u0026lt;username\u0026gt;.github.io (for user/organization sites) or \u0026lt;repo-name\u0026gt; (for project sites). The gh-pages branch (or the /docs folder) should contain your Hugo-generated static files. Step 2: Configure DNS Settings for Your Domain Option 1: Use an Apex Domain (e.g., yourdomain.tech) If you want your site to live at the root domain (e.g., yourdomain.tech), configure A records in your DNS settings:\nGo to your domain registrar’s DNS management page. Create four A records pointing to GitHub’s IP addresses: Host: @ Type: A Value: 185.199.108.153 TTL: Automatic ","permalink":"http://localhost:1313/posts/customdomain/","summary":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003eSo, you’ve built a sleek website with Hugo and deployed it to GitHub Pages. Now, you want to give it a professional touch with a custom domain like \u003ccode\u003eyourdomain.tech\u003c/code\u003e instead of the default \u003ccode\u003eusername.github.io\u003c/code\u003e URL. This guide walks you through the process step-by-step.\u003c/p\u003e\n\u003ch2 id=\"prerequisites\"\u003ePrerequisites\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003eA Hugo website hosted on GitHub Pages (public repository).\u003c/li\u003e\n\u003cli\u003eA custom domain (e.g., \u003ccode\u003eyourdomain.tech\u003c/code\u003e) purchased from a registrar like Namecheap, Google Domains, etc.\u003c/li\u003e\n\u003cli\u003eBasic familiarity with DNS settings and GitHub repository configurations.\u003c/li\u003e\n\u003c/ol\u003e\n\u003chr\u003e\n\u003ch2 id=\"step-1-configure-your-github-repository\"\u003eStep 1: Configure Your GitHub Repository\u003c/h2\u003e\n\u003cp\u003eFirst, ensure your GitHub Pages site is set up correctly:\u003c/p\u003e","title":"How to up custom domain for GitHub Pages"},{"content":"Exception handling is a crucial aspect of writing robust and reliable Python code. Whether you\u0026rsquo;re a beginner or an experienced developer, getting an error, or exception, in your Python program means the entire program will crash. You don’t want this to happen in real-world programs. Instead, you want the program to detect errors, handle them, and then continue to run. In this blog, we\u0026rsquo;ll explore the fundamentals of exception handling in Python, including syntax, best practices, and advanced techniques.\nWhat Are Exceptions? Exceptions are runtime errors that disrupt the normal flow of a program. For example, trying to open a non-existent file, dividing by zero, or accessing an invalid index in a list will raise exceptions. If unhandled, these exceptions cause your program to crash.\nBasic Syntax: try and except The primary mechanism for handling exceptions in Python is the try-except block. Errors can be handled with with this. The code that could potentially have an error is put in a try clause. The program execution moves to the start of a following except clause if an error happens.\nHere\u0026rsquo;s the basic structure:\ndef cal(value): try: return 10 / value except ZeroDivisionError: print(\u0026#34;Cannot divide by zero!\u0026#34;) print(cal(0)) print(cal(2)) print(cal(3)) How It Works: The code inside the try block is executed. If an exception occurs, Python checks the except blocks for a matching exception type. If a match is found, the corresponding except block runs. Catching Specific Exceptions Always catch specific exceptions to avoid silencing unexpected errors. Python has many built-in exceptions (e.g., ValueError, TypeError, FileNotFoundError).\nimport math x = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) try: print(f\u0026#39;Square Root of {x} is {math.sqrt(x)}\u0026#39;) except ValueError: print(\u0026#39;Number is less than 0\u0026#39;) Output\nThe else Clause The else block runs only if no exceptions were raised in the try block. Use it to separate \u0026ldquo;happy path\u0026rdquo; code from error handling.\nimport math def sqr(value): try: x = math.sqrt(value) except ValueError: print(\u0026#39;Number is less than 0\u0026#39;) else: print(f\u0026#39;The Answer is: {x}\u0026#39;) value = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) sqr(value) Output The finally Clause The finally block runs regardless of whether an exception occurred. It’s ideal for cleanup tasks (e.g., closing files or releasing resources).\nimport math def sqr(value): try: x = math.sqrt(value) except ValueError: print(\u0026#39;Error\u0026#39;) else: print(f\u0026#39;The Answer is: {x}\u0026#39;) finally: print(\u0026#39;Program Ends\u0026#39;) value = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) sqr(value) Output Raising Exceptions Manually Use the raise keyword to trigger exceptions intentionally. This is useful for enforcing constraints.\ndef validate_age(age): if age \u0026lt; 0: raise ValueError(\u0026#34;Age cannot be negative!\u0026#34;) return age try: validate_age(-5) except ValueError as e: print(e) Creating Custom Exceptions Define custom exceptions by subclassing Python’s built-in Exception class. This makes your code more readable and errors more descriptive. (note: I have used RegEx, for that blog will be out soon :) )\nimport re class InvalidEmailError(Exception): \u0026#34;\u0026#34;\u0026#34;Raised when an email format is invalid.\u0026#34;\u0026#34;\u0026#34; pass def send_email(valid,email): if not valid: raise InvalidEmailError(f\u0026#34;Invalid email: {email}\u0026#34;) email = input(\u0026#39;Please enter your email: \u0026#39;) valid = re.match(r\u0026#39;^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\u0026#39;, email) try: send_email(valid, email) except InvalidEmailError as e: print(e) Output Logging a Python Error We can Log an exception in Python with an error. This can be done in the logging.exception() method. This function logs a message with level ERROR on this logger.\nimport math import logging def sqr(value): try: x = math.sqrt(value) except ValueError: logging.exception(\u0026#34;Error\u0026#34;) else: print(f\u0026#39;The Answer is: {x}\u0026#39;) finally: print(\u0026#39;Program Ends\u0026#39;) value = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) sqr(value) Output Best Practices for Exception Handling Catch specific exceptions: Avoid broad except: clauses that hide bugs. Keep try blocks minimal: Only wrap code that might raise an exception. Use finally for cleanup: Ensure resources are released (e.g., closing files). Log exceptions: Use logging.error() instead of print() for production code. Provide meaningful messages: Help debug issues faster with clear error descriptions. Avoid empty except blocks: Silent failures make debugging harder. Conclusion Exception handling is essential for writing better Python applications. By using try-except blocks effectively, catching specific errors, and with else/finally clauses, you can create programs that handle unexpected scenarios.\nNow go forth and write bulletproof Python code!\n","permalink":"http://localhost:1313/posts/exception_handling_in_python/","summary":"\u003cp\u003eException handling is a crucial aspect of writing robust and reliable Python code. Whether you\u0026rsquo;re a beginner or an experienced developer, getting an error, or exception, in your Python program means the entire program will crash. You don’t want this to happen in real-world programs. Instead, you want the program to detect errors, handle them, and then continue to run. In this blog, we\u0026rsquo;ll explore the fundamentals of exception handling in Python, including syntax, best practices, and advanced techniques.\u003c/p\u003e","title":"Exception Handling in Python: A Comprehensive Guide"},{"content":"Have you ever wanted your Python program to do multiple things at once? For example, downloading files while updating the UI, or processing data while listening for user input? That’s where multithreading comes in.\nIn this post, we’ll explore multithreading in Python — what it is, when to use it, and how to use it with simple examples.\n🧠 What is Multithreading? Multithreading is a way to run multiple threads (smaller units of a process) at the same time. It helps make your program more responsive or perform tasks in parallel, especially when tasks are I/O-bound (e.g., network calls, file reading, etc.).\nPython has a built-in module called threading that makes it easy to create and manage threads.\n⚠️ But Wait — Python\u0026rsquo;s GIL Before you jump in, it\u0026rsquo;s important to understand the Global Interpreter Lock (GIL). In CPython (the standard Python implementation), the GIL allows only one thread to execute Python bytecode at a time.\nThis means multithreading in Python is best suited for I/O-bound tasks, not CPU-bound tasks like heavy computations. For CPU-bound tasks, consider multiprocessing instead.\n🛠️ Using the threading Module Here\u0026rsquo;s a basic example to demonstrate multithreading:\nimport threading import time def print_numbers(): for i in range(5): print(f\u0026#34;Number: {i}\u0026#34;) time.sleep(1) def print_letters(): for letter in \u0026#39;abcde\u0026#39;: print(f\u0026#34;Letter: {letter}\u0026#34;) time.sleep(1) # Creating threads t1 = threading.Thread(target=print_numbers) t2 = threading.Thread(target=print_letters) # Starting threads t1.start() t2.start() # Wait for both threads to complete t1.join() t2.join() print(\u0026#34;Both threads have finished.\u0026#34;) 🔍 Output (interleaved): Number: 0 Letter: a Number: 1 Letter: b ... Both functions run at the same time, and you can see their output interleave. That’s multithreading in action!\n📦 Real-World Use Cases Downloading multiple files at once Handling multiple client connections on a server Running background tasks like logging or monitoring Keeping your GUI app responsive while doing other work 🧰 Extra Tools For more advanced usage:\nconcurrent.futures.ThreadPoolExecutor — easier thread management queue.Queue — safe way to share data between threads threading.Lock — prevents race conditions 🧪 Example with ThreadPoolExecutor from concurrent.futures import ThreadPoolExecutor import time def task(name): print(f\u0026#34;{name} starting\u0026#34;) time.sleep(2) print(f\u0026#34;{name} done\u0026#34;) with ThreadPoolExecutor(max_workers=2) as executor: executor.submit(task, \u0026#34;Task 1\u0026#34;) executor.submit(task, \u0026#34;Task 2\u0026#34;) ✅ Final Thoughts Multithreading in Python is a powerful tool when used correctly — especially for I/O-bound programs. Just remember the GIL limitation and use the right tool (like multiprocessing) when working with CPU-heavy tasks.\nThanks for reading! Happy threading 🧵🐍\n","permalink":"http://localhost:1313/posts/multithreading/","summary":"\u003cp\u003eHave you ever wanted your Python program to do multiple things at once? For example, downloading files while updating the UI, or processing data while listening for user input? That’s where \u003cstrong\u003emultithreading\u003c/strong\u003e comes in.\u003c/p\u003e\n\u003cp\u003eIn this post, we’ll explore multithreading in Python — what it is, when to use it, and how to use it with simple examples.\u003c/p\u003e\n\u003ch2 id=\"-what-is-multithreading\"\u003e🧠 What is Multithreading?\u003c/h2\u003e\n\u003cp\u003eMultithreading is a way to run multiple threads (smaller units of a process) at the same time. It helps make your program more responsive or perform tasks in parallel, especially when tasks are I/O-bound (e.g., network calls, file reading, etc.).\u003c/p\u003e","title":"Multithreading in Python"},{"content":"Running a Local LLM on Mobile: Testing PocketPal on iPhone 12 With the increasing accessibility of large language models (LLMs), running them locally on mobile devices is an exciting prospect. I recently tested PocketPal, a mobile LLM interface, on my iPhone 12, using a distilled 4-bit quantized model. Here’s a breakdown of my experience, covering installation, performance, and overall usability.\nWhy Run an LLM on Mobile? Running an LLM locally on a mobile device comes with several advantages:\nPrivacy: No data is sent to external servers. Offline Access: Works without an internet connection. Lower Cost: Avoids API costs associated with cloud-based models. What is Quantization? Quantization is a technique used to reduce the memory and computational requirements of machine learning models by representing their weights with lower precision numbers. Instead of using 32-bit floating-point numbers, models can be compressed into 8-bit or even 4-bit integers while maintaining reasonable accuracy.\nFor LLMs on mobile, 4-bit quantization significantly reduces the model size, making it feasible to run on devices with limited resources. However, this compression can lead to:\nSlightly reduced accuracy due to loss of precision. Faster inference times, as lower-bit computations require less processing power. Lower memory usage, allowing larger models to fit within mobile device constraints. Setting Up and Running PocketPal on iPhone 12 1. Download and Install PocketPal Open the App Store and search for PocketPal AI by Asghar Ghorbani. Download and install the app. Open the app and allow necessary permissions. 2. Adding a Model Navigate to the Models section in the PocketPal app. Click the + button to add a new model. You will see two options: Add from Hugging Face Add Local Model Select Add from Hugging Face to browse available models. 3. Selecting and Downloading a Model Search for DeepSeek-R1-Distill-Qwen-1.5B-Q4_0. Select the model and start downloading it (size: 1.06GB, 1.78B parameters). Once downloaded, the model will appear under the Ready to Use section. 4. Running Benchmarks I ran benchmarks on my iPhone 12 using the DeepSeek-R1-Distill-Qwen-1.5B-Q4_0 model. Here are the key results:\nModel Size: 1.06 GB with 1.78 billion parameters. Benchmark Configuration: Prompt Processing: 512 Token Generation: 128 Pipeline Length: 1 Repetitions: 3 Model Settings: Context Length: 1024 tokens Batch Size: 512 CPU Threads: 4 GPU Layers: 0 (fully CPU-based execution) Flash Attention: Disabled Performance Metrics: Prompt Processing Speed: 26.93 tokens/sec (±2.37) Token Generation Speed: 18.05 tokens/sec (±0.75) Total Execution Time: 1 minute 18 seconds Peak Memory Usage: 35.0% (1GB / 4GB) Live Demo: Running PocketPal on iPhone 12 Watch a live demonstration of PocketPal running a distilled 4-bit quantized model on an iPhone 12: Image: Video demonstration is available here: Video\nAnalysis of Results Decent Processing Speed: With a distilled 4-bit quantized model, the 18.05 t/s token generation rate is quite reasonable for mobile inference. Low Memory Footprint: The 1GB RAM usage means this can run on even mid-range smartphones. CPU-Based Execution: Since 0 GPU layers were used, this proves mobile CPUs are capable of running quantized LLMs efficiently. Flash Attention Disabled: If supported, enabling it might further optimize speed and reduce lag. Final Thoughts Running an LLM locally on an iPhone 12 with PocketPal is feasible but comes with trade-offs. It’s a promising step toward self-hosted AI assistants, though optimization and hardware improvements will be crucial for broader adoption. If you’re privacy-conscious or need offline AI capabilities, it’s definitely worth exploring!\nFuture Improvements I\u0026rsquo;d Like to See: Better memory efficiency to reduce battery drain. Enhanced speed for real-time interaction. More user-friendly model importing and switching. ","permalink":"http://localhost:1313/posts/llmonmobile/","summary":"\u003ch1 id=\"running-a-local-llm-on-mobile-testing-pocketpal-on-iphone-12\"\u003eRunning a Local LLM on Mobile: Testing PocketPal on iPhone 12\u003c/h1\u003e\n\u003cp\u003eWith the increasing accessibility of large language models (LLMs), running them locally on mobile devices is an exciting prospect. I recently tested \u003cstrong\u003ePocketPal\u003c/strong\u003e, a mobile LLM interface, on my \u003cstrong\u003eiPhone 12\u003c/strong\u003e, using a \u003cstrong\u003edistilled 4-bit quantized model\u003c/strong\u003e. Here’s a breakdown of my experience, covering installation, performance, and overall usability.\u003c/p\u003e\n\u003ch2 id=\"why-run-an-llm-on-mobile\"\u003eWhy Run an LLM on Mobile?\u003c/h2\u003e\n\u003cp\u003eRunning an LLM locally on a mobile device comes with several advantages:\u003c/p\u003e","title":"Running Large Language Models on Mobile: DeepSeek R1 on iPhone 12"},{"content":"Running DeepSeek-R1 1.5B on Raspberry Pi 5 (CPU-Only) Technical Insights Why Can We Run This on Raspberry Pi 5? Thanks to open-source advancements, we can now run large-scale AI models on small devices like the Raspberry Pi 5. Key factors enabling this include:\nOptimized lightweight models: DeepSeek-R1 1.5B is built efficiently to run on limited hardware. ARM64 Support: Modern AI frameworks support ARM-based architectures, enabling their use on RPi5. Open-source software: Platforms like Ollama make AI deployment accessible to all. Performance Considerations Running this model on an RPi5 without a GPU will be CPU-intensive. Consider reducing active processes to free up memory. If performance lags, use a lighter model or external processing (cloud inference). No GPU acceleration was used in this setup, meaning all computations rely solely on the CPU, which may affect inference speeds. This guide covers the installation and execution of DeepSeek-R1 1.5B on a Raspberry Pi 5, following the steps demonstrated in your images.\nPrerequisites Raspberry Pi 5 (ARM64 architecture, more powerful than previous versions) Debian-based Linux installed An internet connection At least 4GB RAM recommended for smooth operation Step 1: Log in to Your Raspberry Pi Upon booting, log in using your credentials:\nraspberrypi login: hisam Password: ****** Example login screen: Step 2: Install Curl Curl is required to fetch the installation script. Run:\nsudo apt install curl If it\u0026rsquo;s already installed, you\u0026rsquo;ll see:\ncurl is already the newest version... Example output: Step 3: Install Ollama Ollama is the runtime needed to execute DeepSeek models.\ncurl -fsSL https://ollama.com/install.sh | sh This will download and install Ollama.\nExample installation screen: Step 4: Enable and Start Ollama Service After installation, Ollama sets up a system service.\nollama The output will indicate success:\n\u0026gt;\u0026gt;\u0026gt; Creating ollama user... \u0026gt;\u0026gt;\u0026gt; Enabling and starting ollama service... \u0026gt;\u0026gt;\u0026gt; The Ollama API is now available at 127.0.0.1:11434. Example setup screen: Step 5: Pull and Run DeepSeek-R1 1.5B Now, pull and run the model:\nollama run deepseek-r1:1.5b This will download the model, which is about 1.1 GB in size.\nExample download screen: Once downloaded, the model is ready to run.\nStep 6: Execute DeepSeek-R1 1.5B Run the model and start interacting:\nollama run deepseek-r1:1.5b You should see a prompt where you can start typing queries:\n\u0026gt;\u0026gt;\u0026gt; Hey! Hello! How can I assist you today? 😊 Example interaction: Final Setup Image Video Demonstration Watch Video\nConclusion You have successfully installed and executed DeepSeek-R1 1.5B on your Raspberry Pi 5. This demonstrates the power of open-source AI, making it possible to run advanced models on small-scale devices. If you encounter performance issues, consider optimizing your setup or offloading computations.\nHappy coding!\n","permalink":"http://localhost:1313/posts/deepseek/","summary":"\u003ch1 id=\"running-deepseek-r1-15b-on-raspberry-pi-5-cpu-only\"\u003eRunning DeepSeek-R1 1.5B on Raspberry Pi 5 (CPU-Only)\u003c/h1\u003e\n\u003ch2 id=\"technical-insights\"\u003eTechnical Insights\u003c/h2\u003e\n\u003ch3 id=\"why-can-we-run-this-on-raspberry-pi-5\"\u003eWhy Can We Run This on Raspberry Pi 5?\u003c/h3\u003e\n\u003cp\u003eThanks to open-source advancements, we can now run large-scale AI models on small devices like the Raspberry Pi 5. Key factors enabling this include:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eOptimized lightweight models\u003c/strong\u003e: DeepSeek-R1 1.5B is built efficiently to run on limited hardware.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eARM64 Support\u003c/strong\u003e: Modern AI frameworks support ARM-based architectures, enabling their use on RPi5.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eOpen-source software\u003c/strong\u003e: Platforms like Ollama make AI deployment accessible to all.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"performance-considerations\"\u003ePerformance Considerations\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eRunning this model on an RPi5 \u003cstrong\u003ewithout a GPU\u003c/strong\u003e will be CPU-intensive.\u003c/li\u003e\n\u003cli\u003eConsider \u003cstrong\u003ereducing active processes\u003c/strong\u003e to free up memory.\u003c/li\u003e\n\u003cli\u003eIf performance lags, use a \u003cstrong\u003elighter model\u003c/strong\u003e or \u003cstrong\u003eexternal processing (cloud inference).\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eNo GPU acceleration was used\u003c/strong\u003e in this setup, meaning all computations rely solely on the CPU, which may affect inference speeds.\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003cp\u003eThis guide covers the installation and execution of DeepSeek-R1 1.5B on a Raspberry Pi 5, following the steps demonstrated in your images.\u003c/p\u003e","title":"DeepSeek-R1 on Raspberry Pi 5: Open-Source AI Without a GPU"},{"content":"Setting Up Neovim: An Easy and Beginner\u0026rsquo;s Guide Neovim is a modern and extensible text editor that enhances Vim’s capabilities. If you\u0026rsquo;re using Linux, setting up Neovim can be a rewarding experience, allowing you to customize it for an efficient workflow. In this guide, we\u0026rsquo;ll cover installing Neovim, setting up a basic configuration, and enhancing it with essential plugins to turn it into a full-fledged IDE.\n1. Installing Neovim sudo pacman -S neovim 2. Setting Up Neovim Configuration Neovim’s configuration is stored in ~/.config/nvim/. Create the directory and initialize a basic configuration:\nmkdir -p ~/.config/nvim nvim ~/.config/nvim/init.lua Minimal Configuration (init.lua) Add the following settings to your init.lua file:\n-- Enable line numbers vim.opt.number = true vim.opt.relativenumber = true -- Set tab size vim.opt.expandtab = true vim.opt.shiftwidth = 4 vim.opt.tabstop = 4 -- Enable mouse support vim.opt.mouse = \u0026#34;a\u0026#34; -- Set clipboard to system clipboard vim.opt.clipboard = \u0026#34;unnamedplus\u0026#34; Save and exit Neovim.\n3. Installing a Plugin Manager The best plugin manager for Neovim is lazy.nvim. Install it by running:\ngit clone --depth 1 https://github.com/folke/lazy.nvim.git \\ ~/.local/share/nvim/lazy/lazy.nvim Then, update your init.lua to load it:\nlocal lazypath = vim.fn.stdpath(\u0026#34;data\u0026#34;) .. \u0026#34;/lazy/lazy.nvim\u0026#34; if not vim.loop.fs_stat(lazypath) then vim.fn.system({ \u0026#34;git\u0026#34;, \u0026#34;clone\u0026#34;, \u0026#34;--filter=blob:none\u0026#34;, \u0026#34;https://github.com/folke/lazy.nvim.git\u0026#34;, lazypath }) end vim.opt.rtp:prepend(lazypath) 4. Installing Essential Plugins With lazy.nvim installed, you can add plugins in init.lua:\nrequire(\u0026#34;lazy\u0026#34;).setup({ \u0026#34;nvim-treesitter/nvim-treesitter\u0026#34;, -- Syntax highlighting \u0026#34;nvim-telescope/telescope.nvim\u0026#34;, -- Fuzzy finder \u0026#34;neovim/nvim-lspconfig\u0026#34;, -- LSP support \u0026#34;hrsh7th/nvim-cmp\u0026#34;, -- Auto-completion \u0026#34;hrsh7th/cmp-nvim-lsp\u0026#34;, -- LSP completion source \u0026#34;hrsh7th/cmp-buffer\u0026#34;, -- Buffer completion \u0026#34;hrsh7th/cmp-path\u0026#34;, -- Path completion \u0026#34;hrsh7th/cmp-nvim-lua\u0026#34;, -- Neovim Lua API completion \u0026#34;L3MON4D3/LuaSnip\u0026#34;, -- Snippet engine \u0026#34;saadparwaiz1/cmp_luasnip\u0026#34;, -- Snippet completion \u0026#34;nvim-lualine/lualine.nvim\u0026#34;, -- Status line \u0026#34;nvim-tree/nvim-tree.lua\u0026#34;, -- File explorer \u0026#34;tpope/vim-surround\u0026#34;, -- Surround text objects \u0026#34;tpope/vim-commentary\u0026#34;, -- Commenting shortcuts \u0026#34;lewis6991/gitsigns.nvim\u0026#34;, -- Git integration \u0026#34;akinsho/toggleterm.nvim\u0026#34;, -- Terminal management }) Save and exit Neovim, then open it and run:\n:Lazy sync This will install the plugins automatically.\n5. Setting Up Treesitter Treesitter provides better syntax highlighting and code parsing. Install it by adding the following to your init.lua:\nrequire\u0026#39;nvim-treesitter.configs\u0026#39;.setup { ensure_installed = \u0026#34;all\u0026#34;, highlight = { enable = true, }, indent = { enable = true, }, } Then, update Treesitter by running:\n:TSUpdate 6. Setting Up LSP (Language Server Protocol) LSP enables features like code completion and linting. Install LSP servers for your language:\n# Python sudo pacman -S python-lsp-server # C++ sudo pacman -S clang # JavaScript/TypeScript npm install -g typescript-language-server Then, enable LSP support in Neovim:\nlocal lspconfig = require(\u0026#34;lspconfig\u0026#34;) lspconfig.pyright.setup({}) -- Python lspconfig.ts_ls.setup({}) -- JavaScript/TypeScript lspconfig.clangd.setup({}) -- C++ Restart Neovim and check LSP status:\n:LspInfo 7. Enhancing Auto-Completion with nvim-cmp To enable code auto-completion, update your init.lua:\nlocal cmp = require\u0026#39;cmp\u0026#39; cmp.setup({ mapping = { [\u0026#39;\u0026lt;C-Space\u0026gt;\u0026#39;] = cmp.mapping.complete(), [\u0026#39;\u0026lt;CR\u0026gt;\u0026#39;] = cmp.mapping.confirm({ select = true }), }, sources = { { name = \u0026#39;nvim_lsp\u0026#39; }, { name = \u0026#39;buffer\u0026#39; }, { name = \u0026#39;path\u0026#39; }, { name = \u0026#39;luasnip\u0026#39; }, { name = \u0026#39;nvim_lua\u0026#39; }, } }) 9. Final Thoughts Congratulations! You now have a powerful, customized Neovim setup that functions as a full-fledged IDE. With features like Treesitter, LSP support, auto-completion, syntax highlighting, Git integration, and a file explorer, your development workflow will be much smoother.\nIf you’d like to further improve your Neovim experience, explore more plugins and tweak your settings. Good luck with that!\nFurther Reading Neovim Documentation Awesome Neovim Plugins Arch Wiki: Neovim ","permalink":"http://localhost:1313/posts/setting-up-neovim-on-arch-linux-a-beginners-guide/","summary":"\u003ch1 id=\"setting-up-neovim-an-easy-and-beginners-guide\"\u003eSetting Up Neovim: An Easy and Beginner\u0026rsquo;s Guide\u003c/h1\u003e\n\u003cp\u003eNeovim is a modern and extensible text editor that enhances Vim’s capabilities. If you\u0026rsquo;re using Linux, setting up Neovim can be a rewarding experience, allowing you to customize it for an efficient workflow. In this guide, we\u0026rsquo;ll cover installing Neovim, setting up a basic configuration, and enhancing it with essential plugins to turn it into a full-fledged IDE.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"1-installing-neovim\"\u003e\u003cstrong\u003e1. Installing Neovim\u003c/strong\u003e\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003esudo pacman -S neovim\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003chr\u003e\n\u003ch2 id=\"2-setting-up-neovim-configuration\"\u003e\u003cstrong\u003e2. Setting Up Neovim Configuration\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003eNeovim’s configuration is stored in \u003ccode\u003e~/.config/nvim/\u003c/code\u003e. Create the directory and initialize a basic configuration:\u003c/p\u003e","title":"Setting Up Neovim: A Beginner's Guide"},{"content":"Linux Kernal The majority of the kernel\u0026rsquo;s code is written in C, leveraging extensions provided by the GNU Compiler Collection (GCC) beyond standard C. Additionally, it includes assembly code for architecture-specific functions, such as optimizing memory usage and task execution. Architecturally, the Linux kernel is monolithic, meaning the entire OS operates within kernel space. However, it features a modular design, allowing software components to be integrated as modules, including dynamic loading.\nWhat Is A Kernel Module? A Linux kernel module is precisely defined as a code segment capable of dynamic loading and unloading within the kernel as needed. These modules enhance kernel capabilities without necessitating a system reboot. A notable example is seen in the device driver module, which facilitates kernel interaction with hardware components linked to the system.\nWriting a Custom Linux Kernel Module Linux kernel modules (LKMs) allow developers to extend the functionality of the Linux kernel without modifying its source code. This guide walks through writing a simple kernel module from scratch. Kernel modules are pieces of code that can be dynamically loaded and unloaded from the Linux kernel at runtime. They enable functionality such as device drivers, file system support, and system call extensions without requiring a kernel recompilation. LKMs are particularly useful for developing hardware drivers and testing new kernel features without rebooting the system.\nPrerequisites Ensure you have the necessary development tools installed. On an Arch Linux system, install them with:\nsudo pacman -Syu linux-headers base-devel Creating a Simple Kernel Module 1. Writing the Module Source Code Create a file named hello_module.c:\n#include \u0026lt;linux/module.h\u0026gt; #include \u0026lt;linux/kernel.h\u0026gt; #include \u0026lt;linux/init.h\u0026gt; MODULE_LICENSE(\u0026#34;GPL\u0026#34;); MODULE_AUTHOR(\u0026#34;Your Name\u0026#34;); MODULE_DESCRIPTION(\u0026#34;A simple Hello World kernel module\u0026#34;); static int __init hello_init(void) { printk(KERN_INFO \u0026#34;Hello, Kernel!\\n\u0026#34;); return 0; } static void __exit hello_exit(void) { printk(KERN_INFO \u0026#34;Goodbye, Kernel!\\n\u0026#34;); } module_init(hello_init); module_exit(hello_exit); Understanding the Kernel Module Code #include \u0026lt;linux/module.h\u0026gt;: Includes the necessary module macros and functions. #include \u0026lt;linux/kernel.h\u0026gt;: Provides kernel logging functions. #include \u0026lt;linux/init.h\u0026gt;: Defines initialization and cleanup macros. MODULE_LICENSE(\u0026quot;GPL\u0026quot;): Specifies the module\u0026rsquo;s license. MODULE_AUTHOR(\u0026quot;Your Name\u0026quot;): Specifies the author of the module. MODULE_DESCRIPTION(\u0026quot;A simple Hello World kernel module\u0026quot;): Provides a brief description. static int __init hello_init(void): The function executed when the module is loaded. static void __exit hello_exit(void): The function executed when the module is unloaded. module_init(hello_init): Registers hello_init as the module\u0026rsquo;s initialization function. module_exit(hello_exit): Registers hello_exit as the module\u0026rsquo;s cleanup function. 2. Writing the Makefile Create a Makefile in the same directory:\nobj-m += hello_module.o all: make -C /lib/modules/$(shell uname -r)/build M=$(PWD) modules clean: make -C /lib/modules/$(shell uname -r)/build M=$(PWD) clean Understanding the Makefile obj-m += hello_module.o: Specifies that hello_module.o is the object to be built as a module. all:: Defines the build target. make -C /lib/modules/$(shell uname -r)/build M=$(PWD) modules: Directs the kernel build system to compile the module. clean:: Cleans up the generated files. make -C /lib/modules/$(shell uname -r)/build M=$(PWD) clean: Cleans the build artifacts. 3. Compiling the Module Run:\nmake 4. Loading and Unloading the Module To insert the module into the kernel:\nsudo insmod hello_module.ko Check the kernel log:\ndmesg | tail To remove the module:\nsudo rmmod hello_module 5. Verifying the Module List loaded modules:\nlsmod | grep hello_module Understanding the Generated Files After building the module, several files are generated:\nhello_module.c: The source code of the module. hello_module.ko: The compiled kernel module file, ready to be loaded into the kernel. hello_module.o: An intermediate object file generated during compilation. hello_module.mod.c: An automatically generated file containing module metadata. hello_module.mod.o: An object file containing metadata compiled from hello_module.mod.c. hello_module.mod: Another metadata file required for module loading. Makefile: Contains instructions for building the module. Module.symvers: Stores information about exported symbols, useful for module dependencies. modules.order: Lists the order in which modules should be loaded. Conclusion This simple kernel module demonstrates the basics of module development. You can expand upon this by adding functionality such as handling parameters or interacting with hardware.\nHappy kernel hacking!\n","permalink":"http://localhost:1313/posts/how-to-write-a-custom-kernel-module/","summary":"\u003ch1 id=\"linux-kernal\"\u003eLinux Kernal\u003c/h1\u003e\n\u003cp\u003eThe majority of the kernel\u0026rsquo;s code is written in C, leveraging extensions provided by the GNU Compiler Collection (GCC) beyond standard C. Additionally, it includes assembly code for architecture-specific functions, such as optimizing memory usage and task execution. Architecturally, the Linux kernel is monolithic, meaning the entire OS operates within kernel space. However, it features a modular design, allowing software components to be integrated as modules, including dynamic loading.\u003c/p\u003e","title":"How to Write a Custom Kernel Module"},{"content":"What is it? gh is GitHub\u0026rsquo;s official command-line tool designed to extend Git\u0026rsquo;s functionality with GitHub-specific features.\nPurpose: Simplifies interaction with GitHub\u0026rsquo;s ecosystem directly from the terminal. Allows you to manage repositories and use GitHub features like issues, pull requests, and workflows.\nKey Features: GitHub-specific tasks:\nAuthentication: Easier login (gh auth login) without dealing with tokens manually. Repository Management: Create, fork, or clone repositories. Issues \u0026amp; Pull Requests: Manage issues, PRs, and comments directly. Actions: Manage and view GitHub Actions workflows. Works alongside Git for basic version control tasks. Use Case: Best for developers heavily using GitHub and its features (for example: pull requests, issues, and actions).\nHow it works Install gh:\n\u0026gt; yay -S github-cli Verify the installation:\n\u0026gt; gh --version Login with GitHub CLI (gh)\n\u0026gt; gh auth login Follow the interactive prompts to log in:\nChoose HTTPS or SSH for connection. Log in via a browser using a one-time code or SSH keys. Verify authentication:\n\u0026gt; gh auth status What\u0026rsquo;s best about it that you can install and use both Git and gh (GitHub CLI) seamlessly. Here\u0026rsquo;s how to set them up:\nInstall Git\n\u0026gt;sudo pacman -S git Check the installation:\n\u0026gt; git --version Using Git and gh Together You can now: Use Git for version control:\n\u0026gt; git clone https://github.com/username/repo.git \u0026gt; git add . \u0026gt; git commit -m \u0026quot;message\u0026quot; \u0026gt; git push ","permalink":"http://localhost:1313/posts/github-cli-githubs-official-command-line-tools/","summary":"\u003ch2 id=\"what-is-it\"\u003eWhat is it?\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003egh\u003c/strong\u003e is GitHub\u0026rsquo;s official command-line tool designed to extend Git\u0026rsquo;s functionality with GitHub-specific features.\u003c/p\u003e\n\u003ch2 id=\"purpose\"\u003ePurpose:\u003c/h2\u003e\n\u003cp\u003eSimplifies interaction with GitHub\u0026rsquo;s ecosystem directly from the terminal. Allows you to manage repositories and use GitHub features like issues, pull requests, and workflows.\u003c/p\u003e\n\u003ch2 id=\"key-features\"\u003eKey Features:\u003c/h2\u003e\n\u003cp\u003eGitHub-specific tasks:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAuthentication: Easier login (gh auth login) without dealing with tokens manually.\u003c/li\u003e\n\u003cli\u003eRepository Management: Create, fork, or clone repositories.\u003c/li\u003e\n\u003cli\u003eIssues \u0026amp; Pull Requests: Manage issues, PRs, and comments directly.\u003c/li\u003e\n\u003cli\u003eActions: Manage and view GitHub Actions workflows.\u003c/li\u003e\n\u003cli\u003eWorks alongside Git for basic version control tasks.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"use-case\"\u003eUse Case:\u003c/h2\u003e\n\u003cp\u003eBest for developers heavily using GitHub and its features (for example: pull requests, issues, and actions).\u003c/p\u003e","title":"GitHub CLI: GitHub's Official Command Line Tools"},{"content":"Connecting a Raspberry Pi 5 to a USB TTY cable is a common way to interact with it through a serial connection, especially for debugging or setting up the device without using a display.\nPrerequists\nRaspberry Pi 5. USB TTY (serial) cable. Computer with a terminal emulator (minicom/screen). GPIO pinout diagram of Raspberry Pi 5 (for reference). Power source for Raspberry Pi (optional if USB TTY can power it, though not recommended). Before Starting! Issuse with firmware UART does NOT work on the RPI5 from the factory. We will need a firmware update to fix this that prevents the dtoverlays for UARTs from working.\nInstall rpi-update with the following commands:\n\u0026gt; sudo curl -L --output /usr/bin/rpi-update https://raw.githubusercontent.com/Hexxeh/rpi-update/master/rpi-update \u0026amp;\u0026amp; sudo chmod +x /usr/bin/rpi-update Then update the firmware on your RPI5 with:\n\u0026gt; sudo rpi-update Enable UART To manually configure UART, you can edit the config.txt file.\nEdit /boot/firmware/config.txt and add:\n\u0026gt; enable_uart=1 How to Connect Locate the GPIO Pins Find the GPIO header on the Raspberry Pi 5. Identify the following pins: GND (Ground): Usually black wire on the USB TTY cable. TX (Transmit): Sends data from the Pi to the computer. RX (Receive): Receives data from the computer to the Pi.\nUse a GPIO pinout chart to locate these pins. For Raspberry Pi 5, it will likely be similar to previous models. Making connections You will need to connect:\nGND with Ground - Pin# 06 TX with GPIO14 - Pin# 08 RX with GPIO15 - Pin# 10 Plug the USB TTY Cable into the Computer\nInsert the USB end of the TTY cable into your computer. The cable will create a virtual COM port (e.g /dev/ttyUSB0). Configure and Access Serial Console\nOpen a terminal.\nIdentify the port with:\n\u0026gt; ls /dev/ttyUSB* Use a terminal emulator like screen or minicom to connect:\n\u0026gt; screen /dev/ttyUSB0 115200 *Replace /dev/ttyUSB0 with the actual port name.\nTurn on the Raspberry Pi. If everything is set up correctly, you should see boot messages in the terminal. Log in to the Pi using the default username (pi) and password (raspberry), or your custom credentials. You should see something similar to this.\nThis is it! You have done it. Congrats!\n","permalink":"http://localhost:1313/posts/how-to-connect-a-raspberry-pi-5-to-usb-tty-cable/","summary":"\u003cp\u003eConnecting a Raspberry Pi 5 to a USB TTY cable is a common way to interact with it through a serial connection, especially for debugging or setting up the device without using a display.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003ePrerequists\u003c/strong\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eRaspberry Pi 5.\u003c/li\u003e\n\u003cli\u003eUSB TTY (serial) cable.\u003c/li\u003e\n\u003cli\u003eComputer with a terminal emulator (minicom/screen).\u003c/li\u003e\n\u003cli\u003eGPIO pinout diagram of Raspberry Pi 5 (for reference).\u003c/li\u003e\n\u003cli\u003ePower source for Raspberry Pi (optional if USB TTY can power it, though not recommended).\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"before-starting\"\u003e\u003cstrong\u003eBefore Starting!\u003c/strong\u003e\u003c/h3\u003e\n\u003ch3 id=\"issuse-with-firmware\"\u003e\u003cstrong\u003e\u003ca href=\"https://forums.raspberrypi.com/viewtopic.php?t=361397#p2171244\"\u003eIssuse with firmware\u003c/a\u003e\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003eUART does NOT work on the RPI5 from the factory. We will need a firmware update to fix this that prevents the dtoverlays for UARTs from working.\u003c/p\u003e","title":"How to Connect a Raspberry PI 5 to USB TTY Cable"},{"content":"Hosting a website on GitHub Pages with Hugo involves the following steps:\nCreating a website 1. Install Hugo and git\n\u0026gt; sudo pacman -S Hugo 2. Create a new Hugo site\n\u0026gt; hugo new site your-website 3. Add a Theme\nNavigate to your website directory and add a theme. You can choose one from the Hugo Themes .\n\u0026gt; cd your-website \u0026gt; git init \u0026gt; git submodule add https://github.com/adityatelange/hugo-PaperMod.git themes/hugo-PaperMod Now you will need to update the hugo.toml file for them to take effect. To do so you can either echo or addd it in the file.\n\u0026gt; echo \u0026quot;theme = 'hugo-PaperMod'\u0026quot; \u0026gt;\u0026gt; hugo.toml To view the website you can run it locally using Hugo\u0026rsquo;s development server to view the site. You can add -D to see your drafts.\n\u0026gt; hugo server 3. Add Content\nTo add a new page to your site.\n\u0026gt; hugo new content content/posts/yout-first-post.md This is it You have done it. YAY!\nHosting it on GitHub 1. Create a GitHub repository.\nClick the + icon in the top-right corner of:\u0026gt; [!WARNING] the GitHub interface and select New repository. Enter a repository name: yourusername.github.io Click Create repository. 2. Add Files for Your website\nClone the repository locally using Git:\ngit clone https://github.com//.git\nAdd your static site files (generated by Hugo) to the repository. Commit and push the changes:\n\u0026gt; git add -A \u0026gt; git commit -s -m \u0026quot;Initial commit\u0026quot; \u0026gt; git push origin main 3. Configure the Repository for GitHub Pages\nGo to the Settings tab of your new repository. Scroll down to the Pages section. Settings \u0026gt; Pages. In the center of your screen you will see this: Build and development Change the Source to GitHub Actions. 4. Create a file named hugo.yaml in a directory named .github/workflows.\n\u0026gt; mkdir -p .github/workflows \u0026gt; cd ./github/workflows touch hugo.yaml 5. Add content in the YAML file.\n# Sample workflow for building and deploying a Hugo site to GitHub Pages name: Deploy Hugo site to Pages on: # Runs on pushes targeting the default branch push: branches: - main # Allows you to run this workflow manually from the Actions tab workflow_dispatch: # Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages permissions: contents: read pages: write id-token: write # Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued. # However, do NOT cancel in-progress runs as we want to allow these production deployments to complete. concurrency: group: \u0026#34;pages\u0026#34; cancel-in-progress: false # Default to bash defaults: run: shell: bash jobs: # Build job build: runs-on: ubuntu-latest env: HUGO_VERSION: 0.141.0 steps: - name: Install Hugo CLI run: | wget -O ${{ runner.temp }}/hugo.deb https://github.com/gohugoio/hugo/releases/download/v${HUGO_VERSION}/hugo_extended_${HUGO_VERSION}_linux-amd64.deb \\ \u0026amp;\u0026amp; sudo dpkg -i ${{ runner.temp }}/hugo.deb - name: Install Dart Sass run: sudo snap install dart-sass - name: Checkout uses: actions/checkout@v4 with: submodules: recursive fetch-depth: 0 - name: Setup Pages id: pages uses: actions/configure-pages@v5 - name: Install Node.js dependencies run: \u0026#34;[[ -f package-lock.json || -f npm-shrinkwrap.json ]] \u0026amp;\u0026amp; npm ci || true\u0026#34; - name: Build with Hugo env: HUGO_CACHEDIR: ${{ runner.temp }}/hugo_cache HUGO_ENVIRONMENT: production TZ: America/Los_Angeles run: | hugo \\ --gc \\ --minify \\ --baseURL \u0026#34;${{ steps.pages.outputs.base_url }}/\u0026#34; - name: Upload artifact uses: actions/upload-pages-artifact@v3 with: path: ./public # Deployment job deploy: environment: name: github-pages url: ${{ steps.deployment.outputs.page_url }} runs-on: ubuntu-latest needs: build steps: - name: Deploy to GitHub Pages id: deployment uses: actions/deploy-pages@v4 5. Commit and push your GitHub repository.\n\u0026gt;git add -A \u0026gt;git commit -m \u0026quot;Create hugo.yaml\u0026quot; \u0026gt;git push 6. Deployment status From GitHub’s main menu, choose Actions. When GitHub has finished building and deploying your site, the color of the status indicator will change to green.\nStep 5: Verify Your GitHub Pages Site\nThe site will be live at https://yourusername.github.io.\n","permalink":"http://localhost:1313/posts/hosting-a-website-on-github-pages-with-hugo/","summary":"\u003cp\u003eHosting a website on GitHub Pages with Hugo involves the following steps:\u003c/p\u003e\n\u003ch1 id=\"creating-a-website\"\u003eCreating a website\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e1. Install Hugo and git\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; sudo pacman -S Hugo\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e2. Create a new Hugo site\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; hugo new site your-website\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e3. Add a Theme\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eNavigate to your website directory and add a theme. You can choose one from the \u003ca href=\"https://themes.gohugo.io/\"\u003eHugo Themes\u003c/a\u003e .\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; cd your-website\n\u0026gt; git init \n\u0026gt; git submodule add https://github.com/adityatelange/hugo-PaperMod.git themes/hugo-PaperMod\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow you will need to update the hugo.toml file for them to take effect. To do so you can either \u003cem\u003eecho\u003c/em\u003e or addd it in the file.\u003c/p\u003e","title":"Hosting a Website on Github Pages With Hugo"},{"content":"KVM Kernel-based Virtual Machine is a free and open-source virtualization module in the Linux kernel that allows the kernel to function as a hypervisor.\nInstallation For updates, run the following command:\n$ sudo pacman -Syu QEMU/KVM installation: We\u0026rsquo;ll install qemu and all the utils required:\n$ sudo pacman -S qemu vde2 ebtables iptables-nft nftables dms masq bridge-utils ovmf swptm Virtual Machine Manager installation: The virt-manager application is a graphical user interface for managing virtual machines through libvirt. It primarily targets KVM VMs.\n$ sudo pacman -S virt-manager Now everything is set to work. We can move towards downloading archlinux .iso file.\nDownload .iso file: Head towards: https://archlinux.org/download/ Scroll through and look for the server closest to you. Download archlinux-2024.10.01-x86_64.iso file. Setting up: Open terminal and run the following command:\n$ virt-manager You will see an interface similar to this:\nClick on \u0026lsquo;create a new virtual machine\u0026rsquo; (option with star). Select \u0026lsquo;Local install media\u0026rsquo;. Browse to your \u0026lsquo;archlinux-2024.10.01-x86_64.iso\u0026rsquo;. Add your desired VM configuration and create a disk image. Boot Menu: You will be prompted to a boot menu.\nSelect the topmost option to start the installation process. Archlinux Installer: You will be prompted to a terminal. The first step is to check if you are connected to the internet.\nRun:\n# ip addr show If it shows an IP address and says \u0026lsquo;UP\u0026rsquo;, that means you are good to go.\nIf not: You will need to connect to the internet using the \u0026lsquo;iwctl\u0026rsquo; method for Wi-Fi.\n# iwctl To search networks in your vicinity:\n[iwd]# station [your_wifi_interface] get-networks Get the name of the network you want to connect to. Exit from this prompt using \u0026rsquo;exit\u0026rsquo;.\nTo connect to the desired Wi-Fi network, run:\n# iwctl --passphrase \u0026#34;[wifi_password]\u0026#34; station [your_wifi_interface] connect [wifi_name] You can again run ip addr show to check if you are connected to the network.\nNow you can run the installation command. We\u0026rsquo;ll be using the archinstall method.\n# archinstall You will be prompted to an interface similar to this:\nWe will install Arch using this interface. Go through each option:\nArchinstall language: Choose your preferred language. Mirrors: Select the mirror region closest to you. Use \u0026lsquo;/\u0026rsquo; to search. Locales: Set language and keyboard layout. Disk configuration: Choose Best-effort default partition to format the system. Bootloader: Use the default \u0026lsquo;Grub\u0026rsquo; option. Swap: Select Swap on zram (default). Hostname: Leave as it is. Root password: Set the password for sudo/root privileges. User account: Set up a user account. Profile: Select Desktop. It includes essential packages. Others include Minimal, Server, and Xorg. In Desktop, select your desktop environment. We\u0026rsquo;ll use Gnome for simplicity.\nAudio: Use PipeWire (default) or PulseAudio. Kernels: Use the linux kernel. Additional packages: Install any required packages. Network Configuration: Use NetworkManager for a GUI in Gnome. Timezone: Set the timezone closest to you and enable time sync. Press Install. Congratulations! You\u0026rsquo;ve successfully installed Arch Linux.\n","permalink":"http://localhost:1313/posts/arch_kvm/","summary":"\u003ch1 id=\"kvm\"\u003eKVM\u003c/h1\u003e\n\u003cp\u003eKernel-based Virtual Machine is a free and open-source virtualization module in the Linux kernel that allows the kernel to function as a hypervisor.\u003c/p\u003e\n\u003ch2 id=\"installation\"\u003eInstallation\u003c/h2\u003e\n\u003cp\u003eFor updates, run the following command:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ sudo pacman -Syu\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"qemukvm-installation\"\u003eQEMU/KVM installation:\u003c/h3\u003e\n\u003cp\u003eWe\u0026rsquo;ll install qemu and all the utils required:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ sudo pacman -S qemu vde2 ebtables iptables-nft nftables dms masq bridge-utils ovmf swptm\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"virtual-machine-manager-installation\"\u003eVirtual Machine Manager installation:\u003c/h3\u003e\n\u003cp\u003eThe virt-manager application is a graphical user interface for managing virtual machines through libvirt. It primarily targets KVM VMs.\u003c/p\u003e","title":"archlinux installation in hypervisor through QEMU/KVM"},{"content":"","permalink":"http://localhost:1313/posts/github-cli-githubs-official-command-line-tool/","summary":"","title":""},{"content":"1. Introduction Sometimes you need to share a local application with the outside world, maybe to demo your project, test a webhook, or allow a teammate to access your development server.\nNormally, you’d need a public IP, port forwarding, or a cloud server. ngrok removes all that complexity by creating a secure tunnel from the internet directly to your machine, giving you a public URL instantly.\n2. Prerequisites Before we begin, make sure you have:\nA terminal A free ngrok account (for authentication token) A running local service (e.g., a Python HTTP server, web app, or API) 3. Installing ngrok on Linux We’ll cover installation for Arch Linux, Debian/Ubuntu, and Fedora.\n3.1 Arch Linux This package is not in the official repos, install it from the AUR:\nyay -S ngrok 3.2 Debian / Ubuntu sudo apt update sudo apt install snapd sudo snap install ngrok Alternatively, download the binary from the ngrok downloads page.\n3.3 Fedora sudo dnf install snapd sudo ln -s /var/lib/snapd/snap /snap sudo snap install ngrok 4. Authenticating ngrok Once installed, you need to connect it to your account so you can use custom domains, longer session times, and access the dashboard.\nSign in to ngrok dashboard. -\u0026gt; Your AuthToken Copy your AuthToken. Run: ngrok config add-authtoken \u0026lt;YOUR_TOKEN\u0026gt; You will see: Authtoken saved to configuration file: ~/.config/ngrok/ngrok.yml 5. Exposing a Local Service For example, if your local web server is running on port 8080:\nngrok http 8080 You’ll see output like:\nNow you can share the HTTPS URL with anyone. It wil be similar to: https://random.string.ngrok-free.app\n6. Adding Basic Security You can protect your tunnel with a simple username and password:\nngrok http --basic-auth=\u0026#34;user:password\u0026#34; 8080 Anyone visiting the public link will need credentials.\n7. The Inspector One of ngrok\u0026rsquo;s most powerful features is its built-in web interface, accessible at http://127.0.0.1:4040. This interface lets you inspect every single request that comes through your tunnel in real-time. You can see headers, request bodies, and response details, and even replay requests with a single click—an absolute lifesaver for debugging webhooks.\n8. Common Use Cases Webhook testing — Connect services like GitHub, Stripe, or Twilio to your local environment. Temporary demos — Share work-in-progress with clients without deployment. Remote device access — SSH into a Raspberry Pi without changing router settings. 9. Conclusion In just a few commands, you’ve learned how to:\nInstall ngrok on popular Linux distros Authenticate your installation Share a local service securely From here, you can explore ngrok’s advanced features like static domains, IP allowlists, and traffic inspection.\n","permalink":"http://localhost:1313/posts/ngrok/","summary":"\u003ch2 id=\"1-introduction\"\u003e1. Introduction\u003c/h2\u003e\n\u003cp\u003eSometimes you need to share a local application with the outside world, maybe to demo your project, test a webhook, or allow a teammate to access your development server.\u003c/p\u003e\n\u003cp\u003eNormally, you’d need a public IP, port forwarding, or a cloud server. \u003cstrong\u003engrok\u003c/strong\u003e removes all that complexity by creating a \u003cstrong\u003esecure tunnel\u003c/strong\u003e from the internet directly to your machine, giving you a public URL instantly.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"2-prerequisites\"\u003e2. Prerequisites\u003c/h2\u003e\n\u003cp\u003eBefore we begin, make sure you have:\u003c/p\u003e","title":"Ngrok: Expose Localhost to the Internet"},{"content":"Creating a WhatsApp AI Assistant Using n8n: A Step-by-Step Guide Build your own AI-powered WhatsApp chatbot using n8n, WhatsApp Business Cloud API, and OpenAI. This guide walks you through every step—from setup to testing—with real-world error handling, solutions, and an example production-ready workflow.\n1. Introduction Want to chat with an AI on WhatsApp? In this tutorial, you\u0026rsquo;ll learn how to build a WhatsApp AI Assistant using:\nn8n (automation tool) WhatsApp Business Cloud API OpenAI (for generating intelligent replies) By the end, you\u0026rsquo;ll have a working chatbot and gain hands-on experience with APIs, webhooks, and automation.\n2. Prerequisites n8n account (Cloud or self-hosted) Meta Developer account with WhatsApp Business Cloud API access OpenAI API key Basic understanding of APIs and webhook workflows 3. Registering Your WhatsApp Business App A. Create WhatsApp App in Meta Developer Visit Meta for Developers Create a new app: choose Business → WhatsApp Link or create a WhatsApp Business Account B. Obtain Testing Credentials Your app dashboard will show:\nTest phone number Phone Number ID Temporary access token (valid for only 24 hours) Tip: For long-term use, generate a 60-day system-user token later.\nC. Add Recipients to Test List By default, only approved numbers can receive messages:\nNavigate to WhatsApp → API Setup Add numbers in E.164 format (e.g., +923001234567) Users must accept the invite via WhatsApp to become valid recipients 4. Configuring Your Webhook in n8n A. Create a Webhook Node Method: GET (for initial verification) Endpoint example: https://yourname.app.n8n.cloud/webhook/your-unique-id/webhook B. Verify the Webhook with Meta In your app’s Webhook section:\nCallback URL: your n8n webhook URL Verify Token: any secret string you choose (e.g., mySecret2025) C. Echo Back Meta’s Challenge Configure n8n\u0026rsquo;s Webhook node response:\nField Value Response Mode On Received Response Body {{$json[\u0026quot;query\u0026quot;][\u0026quot;hub.challenge\u0026quot;]}} This ensures Meta can verify your endpoint successfully.\n5. Processing Incoming Messages WhatsApp sends JSON data with structure like:\n{ \u0026#34;entry\u0026#34;: [ { \u0026#34;changes\u0026#34;: [ { \u0026#34;value\u0026#34;: { \u0026#34;messages\u0026#34;: [ { \u0026#34;from\u0026#34;: \u0026#34;923001234567\u0026#34;, \u0026#34;text\u0026#34;: { \u0026#34;body\u0026#34;: \u0026#34;Hello bot!\u0026#34; } } ], \u0026#34;metadata\u0026#34;: { \u0026#34;phone_number_id\u0026#34;: \u0026#34;698352170035199\u0026#34; } } } ] } ] } Extract:\nfrom: user’s number text.body: user’s text metadata.phone_number_id: correct sender ID 6. Integrating OpenAI for Responses Obtaining Your OpenAI API Key Before integrating OpenAI into your n8n workflow, you’ll need to get an API key from OpenAI.\nStep-by-Step: Sign up or log in to OpenAI. Navigate to your API Keys page. Click \u0026ldquo;Create new secret key\u0026rdquo;. Optionally name your key, then copy it immediately (you won’t be able to view it again). In n8n: Go to Credentials → Add New → choose OpenAI or HTTP Request. Paste your API key into the key field. Save the credentials. Security Tip: Keep your key private. Do not share it or commit it to public repositories.\nUse an HTTP Request node to call OpenAI:\nPOST https://api.openai.com/v1/chat/completions Authorization: Bearer YOUR_OPENAI_API_KEY Content-Type: application/json { \u0026#34;model\u0026#34;: \u0026#34;gpt-4o-mini\u0026#34;, \u0026#34;messages\u0026#34;: [ { \u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;You are a helpful WhatsApp AI assistant.\u0026#34; }, { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;{{ $json[...] }}\u0026#34; } ] } Replace {{ $json[...] }} with the actual path to the user\u0026rsquo;s message text from the Webhook node.\n7. Sending Replies via WhatsApp Use another HTTP Request node to respond:\nPOST https://graph.facebook.com/v21.0/{{ $json[...] }}/messages Authorization: Bearer YOUR_LONG_LIVED_TOKEN Content-Type: application/json { \u0026#34;messaging_product\u0026#34;: \u0026#34;whatsapp\u0026#34;, \u0026#34;to\u0026#34;: \u0026#34;{{ $json[...] }}\u0026#34;, \u0026#34;text\u0026#34;: { \u0026#34;body\u0026#34;: \u0026#34;{{ $node[\u0026#39;OpenAI Response\u0026#39;].json.choices[0].message.content }}\u0026#34; } } Use the metadata’s phone_number_id for the endpoint and from for the recipient. This avoids hardcoding and ensures proper routing.\n8. Example n8n Workflow Here’s the actual n8n workflow I used for my WhatsApp AI assistant. It integrates a product brochure PDF into a vector store for AI-powered Q\u0026amp;A, and handles WhatsApp message flow.\nStep-by-Step Breakdown: 1. Download Product Brochure PDF Downloads the brochure from a given URL. Extracts text from the PDF. 2. Create Product Brochure Vector Store Splits large text into chunks. Generates embeddings using OpenAI. Saves them in a vector store for fast semantic search. 3. Use the WhatsApp Trigger Listens for incoming WhatsApp messages. Routes them to supported or unsupported handlers. 3a. Handle Unsupported Messages Replies with a friendly error if the message type is not text. 4. Sales AI Agent Responds Uses OpenAI with memory + vector store retrieval to answer based on brochure content. 5. Reply to WhatsApp User Sends the AI-generated message back to the sender. Why this is effective:\nContext-aware answers via buffer memory. Reduced hallucinations thanks to vector store grounding. Smooth error handling for unsupported message types. 9. Common Errors \u0026amp; Fixes Recipient phone number not in allowed list\n→ Add as test number or switch to Live mode\n401 – Session expired\n→ Refresh token via Graph API:\nGET https://graph.facebook.com/v21.0/oauth/access_token ?grant_type=fb_exchange_token \u0026amp;client_id=YOUR_APP_ID \u0026amp;client_secret=YOUR_APP_SECRET \u0026amp;fb_exchange_token=YOUR_CURRENT_TOKEN Webhook verification failed\n→ Ensure verify token matches between Meta and n8n and echo hub.challenge\nNo execution data available\n→ Trigger workflow via actual WhatsApp message, not manual run\n10. Going Live Add a Privacy Policy URL in Meta App → Settings → Basic (required for live access) Switch app to Live mode once all compliance items are met Remove restricted recipient list Use WhatsApp message templates for messages sent after 24 hours of user interaction 11. Conclusion \u0026amp; Next Steps Congrats! You now have a WhatsApp AI Assistant built with n8n and OpenAI.\nWhere to go from here: Wire up custom knowledge (PDFs, documents) Implement memory for conversation context Launch multilingual support Export n8n workflow as JSON for reuse Need help? Join the n8n Community Forum or OpenAI Discord to connect with fellow builders.\nHappy automating!\n","permalink":"http://localhost:1313/posts/creating-whatsapp-ai-assistant-using-n8n2/","summary":"\u003ch1 id=\"creating-a-whatsapp-ai-assistant-using-n8n-a-step-by-step-guide\"\u003eCreating a WhatsApp AI Assistant Using n8n: A Step-by-Step Guide\u003c/h1\u003e\n\u003cp\u003eBuild your own AI-powered WhatsApp chatbot using \u003cstrong\u003en8n\u003c/strong\u003e, \u003cstrong\u003eWhatsApp Business Cloud API\u003c/strong\u003e, and \u003cstrong\u003eOpenAI\u003c/strong\u003e. This guide walks you through every step—from setup to testing—with real-world error handling, solutions, and an example production-ready workflow.\u003c/p\u003e\n\u003ch2 id=\"1-introduction\"\u003e1. Introduction\u003c/h2\u003e\n\u003cp\u003eWant to chat with an AI on WhatsApp? In this tutorial, you\u0026rsquo;ll learn how to build a \u003cstrong\u003eWhatsApp AI Assistant\u003c/strong\u003e using:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003en8n\u003c/strong\u003e (automation tool)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eWhatsApp Business Cloud API\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eOpenAI\u003c/strong\u003e (for generating intelligent replies)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eBy the end, you\u0026rsquo;ll have a working chatbot and gain hands-on experience with APIs, webhooks, and automation.\u003c/p\u003e","title":"Creating Whatsapp Ai Assistant Using N8n"},{"content":"Introduction A memory leak occurs when a program allocates memory dynamically (e.g., using malloc) and fails to release it using free. This leftover allocation can lead to wasted memory resources, eventually causing slowdowns or system crashes in long-running programs.\nValgrind is a powerful command-line tool available on Linux systems. It helps developers detect:\nMemory leaks Invalid memory access Uninitialized memory usage Mismatched memory management In this guide, we\u0026rsquo;ll walk through examples in C to learn how to detect and fix memory leaks using Valgrind.\nInstalling Valgrind On Arch Linux sudo pacman -S valgrind On Ubuntu/Debian sudo apt install valgrind On Fedora sudo dnf install valgrind Troubleshooting: Valgrind \u0026ldquo;cannot find mandatory redirection\u0026rdquo; on Arch Linux If you run Valgrind and get an error like:\nvalgrind: Fatal error at startup: a function redirection\nvalgrind: which is mandatory for this platform-tool combination\nvalgrind: cannot be set up.\n…you might be running a 32-bit executable on a 64-bit Arch Linux system.\nWhy this happens Valgrind needs to hook into low-level glibc functions from your binary’s architecture.\nIf your binary is 32-bit, Arch requires the 32-bit glibc runtime (lib32-glibc).\nWithout it, Valgrind can’t find the right function symbols and quits.\nFix Install the 32-bit glibc package:\nsudo pacman -S lib32-glibc After installation, re-run:\nvalgrind ./your-binary and it should work.\nUbuntu/Debian equivalent: sudo apt install libc6-dbg:i386\nBasic Example: Hello World Code #include \u0026lt;stdio.h\u0026gt; int main() { printf(\u0026#34;Hello World\\n\u0026#34;); return 0; } Compile and Run gcc main.c -o main.out ./main.out Run with Valgrind valgrind ./main.out You should see no errors or memory leaks in the output.\nIntroducing a Memory Leak Static Allocation (Safe) #include \u0026lt;stdio.h\u0026gt; int main() { char str[20] = \u0026#34;Hello\u0026#34;; printf(\u0026#34;%s\\n\u0026#34;, str); return 0; } This uses stack memory, so Valgrind will report no leaks.\nDynamic Allocation (With Leak) #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; int main() { char *str = malloc(20); strcpy(str, \u0026#34;Hello\u0026#34;); printf(\u0026#34;%s\\n\u0026#34;, str); return 0; // Forgot to free memory } Valgrind Output valgrind ./main.out You should see:\ndefinitely lost: 20 bytes in 1 blocks\nFixing the Memory Leak Add free(str); before returning:\nfree(str); Fixed Code #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; int main() { char *str = malloc(20); strcpy(str, \u0026#34;Hello\u0026#34;); printf(\u0026#34;%s\\n\u0026#34;, str); free(str); return 0; } Detailed Valgrind Options Use for deeper analysis:\nvalgrind --leak-check=full ./main.out Or even more detailed:\nvalgrind --leak-check=full --show-leak-kinds=all --track-origins=yes ./main.out Explanation:\n--leak-check=full: Display detailed leak info --show-leak-kinds=all: Show all kinds of leaks (definitely, indirectly lost, etc.) --track-origins=yes: Show where uninitialized values originate Summary Always free() memory allocated with malloc(), calloc(), or realloc(). Close all file streams with fclose(). Use Valgrind to identify and fix: Memory leaks Invalid memory writes Use-after-free bugs Recommended command: valgrind --leak-check=full --track-origins=yes ./your_program Valgrind is a critical tool for writing safe, efficient, and bug-free C programs.\n","permalink":"http://localhost:1313/posts/introductiontovalgrind/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eA \u003cstrong\u003ememory leak\u003c/strong\u003e occurs when a program allocates memory dynamically (e.g., using \u003ccode\u003emalloc\u003c/code\u003e) and fails to release it using \u003ccode\u003efree\u003c/code\u003e. This leftover allocation can lead to wasted memory resources, eventually causing slowdowns or system crashes in long-running programs.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eValgrind\u003c/strong\u003e is a powerful command-line tool available on Linux systems. It helps developers detect:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eMemory leaks\u003c/li\u003e\n\u003cli\u003eInvalid memory access\u003c/li\u003e\n\u003cli\u003eUninitialized memory usage\u003c/li\u003e\n\u003cli\u003eMismatched memory management\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIn this guide, we\u0026rsquo;ll walk through examples in C to learn how to detect and fix memory leaks using Valgrind.\u003c/p\u003e","title":"Detecting and Fixing Memory Leaks with Valgrind"},{"content":"QEMU-KVM on Arch Linux: Running Tiny Core Linux in a Lightweight VM Virtualization is a powerful tool for developers, sysadmins, and tinkerers alike. On Linux, QEMU-KVM stands out as a robust, high-performance virtualization stack. In this blog, well walk through setting up QEMU-KVM on Arch Linux and using it to run Tiny Core Linuxa super-lightweight distro perfect for testing and experimentation.\nWhat is QEMU-KVM QEMU (Quick Emulator) is a generic and open-source machine emulator. On its own, it can emulate various hardware systems. However, when paired with **KVM (Kernel-based Virtual Machine)**a Linux kernel module for virtualizationit can run virtual machines with near-native performance.\nQEMU provides device emulation and user-space management. KVM integrates with the Linux kernel and handles hardware-level virtualization. Together, they effectively form a Type 1 hypervisor because the Linux kernel (with KVM) handles core virtualization tasks directly on hardware.\nStep-by-Step: Installing QEMU-KVM on Arch Linux Step 1: Install Required Packages sudo pacman -Syu sudo pacman -S qemu virt-manager virt-viewer dnsmasq vde2 bridge-utils openbsd-netcat libvirt edk2-ovmf edk2-ovmf is for UEFI firmware support in VMs.\nStep 2: Enable and Start libvirtd sudo systemctl enable --now libvirtd.service Step 3: Add Your User to the libvirt Group sudo usermod -aG libvirt (whoami) newgrp libvirt Step 4: Verify KVM Support lsmod grep kvm And check CPU virtualization support:\negrep -c (vmxsvm) /proc/cpuinfo A value of 1 or more indicates virtualization support.\nExample: Running Tiny Core Linux on QEMU-KVM Now that your system is ready, lets run Tiny Core Linux, a minimalist Linux distro thats only 16MB\nStep 1: Download Tiny Core ISO wget http://tinycorelinux.net/14.x/x86/release/Core-current.iso Or visit http://tinycorelinux.net for the latest release.\nStep 2: Create a Virtual Disk (Optional) qemu-img create -f qcow2 tinycore.qcow2 512M This creates a 512MB disk image. Optional for RAM-only usage.\nStep 3: Launch the VM with KVM Acceleration qemu-system-x86_64 -enable-kvm -m 512 -cpu host -smp 1 -cdrom Core-current.iso -hda tinycore.qcow2 -boot d -net nic -net user -vga virtio -display sdl Key Flags Explained:\n-enable-kvm: Enables KVM hardware acceleration -m 512: Allocates 512MB RAM -cpu host: Uses the host CPU features -cdrom: Points to the Tiny Core ISO -hda: Uses a QCOW2 disk image -boot d: Boots from CD first -net user: Enables simple user-mode networking (e.g., for internet access) -display sdl: Uses SDL window for graphics (you can replace with gtk or virt-manager) Alternate: Boot Tiny Core in RAM Without Disk qemu-system-x86_64 -enable-kvm -m 256 -cdrom Core-current.iso -boot d -net nic -net user -vga std Conclusion With QEMU-KVM, Arch Linux becomes a full-featured Type 1 hypervisor. By combining kernel-level virtualization (KVM) with the flexibility of QEMU, you get a fast, customizable virtualization platform. Running Tiny Core Linux showcases just how lightweight and efficient this setup can be.\nWhether youre building VMs for testing, learning Linux internals, or experimenting with custom environments, QEMU-KVM on Arch is a powerful combination.\nHappy virtualizing\n","permalink":"http://localhost:1313/posts/qemu/","summary":"\u003ch1 id=\"qemu-kvm-on-arch-linux-running-tiny-core-linux-in-a-lightweight-vm\"\u003eQEMU-KVM on Arch Linux: Running Tiny Core Linux in a Lightweight VM\u003c/h1\u003e\n\u003cp\u003eVirtualization is a powerful tool for developers, sysadmins, and tinkerers alike. On Linux, \u003cstrong\u003eQEMU-KVM\u003c/strong\u003e stands out as a robust, high-performance virtualization stack. In this blog, well walk through setting up QEMU-KVM on \u003cstrong\u003eArch Linux\u003c/strong\u003e and using it to run \u003cstrong\u003eTiny Core Linux\u003c/strong\u003ea super-lightweight distro perfect for testing and experimentation.\u003c/p\u003e\n\u003ch2 id=\"what-is-qemu-kvm\"\u003eWhat is QEMU-KVM\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eQEMU (Quick Emulator)\u003c/strong\u003e is a generic and open-source machine emulator. On its own, it can emulate various hardware systems. However, when paired with **KVM (Kernel-based Virtual Machine)**a Linux kernel module for virtualizationit can run virtual machines with near-native performance.\u003c/p\u003e","title":"QEMU-KVM on Arch Linux: Running Tiny Core Linux in a Lightweight VM"},{"content":"Building the Linux Kernel Compiling the Linux Kernel involves multiple steps and can take some time depending on your hardware specifications.\nStep 1: Download the Kernel Source Code Start by visiting the Official Linux Kernel Website and downloading the latest available kernel source code. The downloaded file will be a compressed archive containing all necessary source files.\nStep 2: Extract the Source Code Once the download completes, extract the contents of the compressed archive using the tar command:\ntar xvf linux-6.13.tar.xz If the tar utility is not installed on your system, you can install it using:\nsudo pacman -S tar Note: Always ensure you are using the correct version number in the file name.\nStep 3: Install Required Dependencies To compile the kernel, you need to install various development tools and libraries. Install them using the following command:\nsudo pacman -S git fakeroot ncurses xz bc flex bison base-devel kmod cpio perl binutils util-linux jfsutils e2fsprogs xfsprogs squashfs-tools quota-tools Step 4: Configure the Kernel Navigate into the kernel source directory: cd linux-6.13 Use your current system’s configuration as a base:\nIf zcat is available, run:\nzcat /proc/config.gz \u0026gt; .config Otherwise, use this alternative method:\ncp /proc/config.gz ./ gunzip config.gz mv config .config Customize the kernel using a menu-driven interface:\nmake menuconfig make xconfig make oldconfig Modify the .config file directly:\nOpen it with a text editor:\nsudo vim .config Search for the line:\nCONFIG_EXT4_FS=m And change it to:\nCONFIG_EXT4_FS=y Step 5: Compile the Kernel Determine the number of CPU cores available to speed up compilation: nproc Compile the kernel using the number of cores found above. Replace n with that number: make -j\u0026lt;n\u0026gt; If you encounter any errors during or after this step, back up your .config file and reset the source tree with:\nmake mrproper This command cleans the build environment and restores the source tree to its original state.\nStep 6: Install Kernel Modules Kernel modules are essential for extending the kernel’s functionality and ensuring compatibility with various hardware. Install them with:\nsudo make modules_install Step 7: Install the Kernel You can install the compiled kernel using one of the two methods below:\nAutomatic installation: sudo make install Manual installation (if the above doesn\u0026rsquo;t work):\nCopy the kernel image:\nsudo cp arch/x86/boot/bzImage /boot/vmlinuz-linux-custom Copy the System.map file:\nsudo cp System.map /boot/System.map-linux-custom Copy the kernel configuration file:\nsudo cp .config /boot/config-linux-custom Step 8: Update the Bootloader If you use GRUB, follow these steps to add an entry for your custom kernel:\nFind the UUID of your root partition: lsblk -f Open the custom GRUB configuration file: sudo nvim /etc/grub.d/40_custom Add the following entry (replace paste-your-root-partition-uuid-here with the actual UUID): menuentry \u0026#39;Custom Linux Kernel\u0026#39; { linux /boot/vmlinuz-linux-custom root=UUID=paste-your-root-partition-uuid-here initrd /boot/initramfs-linux.img } Step 9: Generate Initramfs As you\u0026rsquo;ve compiled a new kernel, installed modules, and modified boot entries, generating a new initramfs is necessary. Run:\nsudo mkinitcpio -k 6.13-custom -c /etc/mkinitcpio.conf -g /boot/initramfs-linux-custom.img Make sure the version (6.13-custom) matches your compiled kernel.\nStep 10: Update GRUB Configuration Finally, update the GRUB configuration so that it includes your new kernel entry:\nsudo grub-mkconfig -o /boot/grub/grub.cfg Done! Congratulations! You’ve successfully compiled and installed your custom Linux Kernel. Enjoy your personalized system!\n","permalink":"http://localhost:1313/posts/kernal_compilation/","summary":"\u003ch1 id=\"building-the-linux-kernel\"\u003eBuilding the Linux Kernel\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003eCompiling the Linux Kernel involves multiple steps and can take some time depending on your hardware specifications.\u003c/strong\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"step-1-download-the-kernel-source-code\"\u003eStep 1: Download the Kernel Source Code\u003c/h3\u003e\n\u003cp\u003eStart by visiting the \u003ca href=\"https://www.kernel.org/\"\u003eOfficial Linux Kernel Website\u003c/a\u003e and downloading the latest available kernel source code. The downloaded file will be a compressed archive containing all necessary source files.\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"step-2-extract-the-source-code\"\u003eStep 2: Extract the Source Code\u003c/h3\u003e\n\u003cp\u003eOnce the download completes, extract the contents of the compressed archive using the \u003ccode\u003etar\u003c/code\u003e command:\u003c/p\u003e","title":"How to build Linux Kernal: Step by Step Guide"},{"content":"Introduction So, you’ve built a sleek website with Hugo and deployed it to GitHub Pages. Now, you want to give it a professional touch with a custom domain like yourdomain.tech instead of the default username.github.io URL. This guide walks you through the process step-by-step.\nPrerequisites A Hugo website hosted on GitHub Pages (public repository). A custom domain (e.g., yourdomain.tech) purchased from a registrar like Namecheap, Google Domains, etc. Basic familiarity with DNS settings and GitHub repository configurations. Step 1: Configure Your GitHub Repository First, ensure your GitHub Pages site is set up correctly:\nYour repository should be named \u0026lt;username\u0026gt;.github.io (for user/organization sites) or \u0026lt;repo-name\u0026gt; (for project sites). The gh-pages branch (or the /docs folder) should contain your Hugo-generated static files. Step 2: Configure DNS Settings for Your Domain Option 1: Use an Apex Domain (e.g., yourdomain.tech) If you want your site to live at the root domain (e.g., yourdomain.tech), configure A records in your DNS settings:\nGo to your domain registrar’s DNS management page. Create four A records pointing to GitHub’s IP addresses: Host: @ Type: A Value: 185.199.108.153 TTL: Automatic ","permalink":"http://localhost:1313/posts/customdomain/","summary":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003eSo, you’ve built a sleek website with Hugo and deployed it to GitHub Pages. Now, you want to give it a professional touch with a custom domain like \u003ccode\u003eyourdomain.tech\u003c/code\u003e instead of the default \u003ccode\u003eusername.github.io\u003c/code\u003e URL. This guide walks you through the process step-by-step.\u003c/p\u003e\n\u003ch2 id=\"prerequisites\"\u003ePrerequisites\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003eA Hugo website hosted on GitHub Pages (public repository).\u003c/li\u003e\n\u003cli\u003eA custom domain (e.g., \u003ccode\u003eyourdomain.tech\u003c/code\u003e) purchased from a registrar like Namecheap, Google Domains, etc.\u003c/li\u003e\n\u003cli\u003eBasic familiarity with DNS settings and GitHub repository configurations.\u003c/li\u003e\n\u003c/ol\u003e\n\u003chr\u003e\n\u003ch2 id=\"step-1-configure-your-github-repository\"\u003eStep 1: Configure Your GitHub Repository\u003c/h2\u003e\n\u003cp\u003eFirst, ensure your GitHub Pages site is set up correctly:\u003c/p\u003e","title":"How to up custom domain for GitHub Pages"},{"content":"Exception handling is a crucial aspect of writing robust and reliable Python code. Whether you\u0026rsquo;re a beginner or an experienced developer, getting an error, or exception, in your Python program means the entire program will crash. You don’t want this to happen in real-world programs. Instead, you want the program to detect errors, handle them, and then continue to run. In this blog, we\u0026rsquo;ll explore the fundamentals of exception handling in Python, including syntax, best practices, and advanced techniques.\nWhat Are Exceptions? Exceptions are runtime errors that disrupt the normal flow of a program. For example, trying to open a non-existent file, dividing by zero, or accessing an invalid index in a list will raise exceptions. If unhandled, these exceptions cause your program to crash.\nBasic Syntax: try and except The primary mechanism for handling exceptions in Python is the try-except block. Errors can be handled with with this. The code that could potentially have an error is put in a try clause. The program execution moves to the start of a following except clause if an error happens.\nHere\u0026rsquo;s the basic structure:\ndef cal(value): try: return 10 / value except ZeroDivisionError: print(\u0026#34;Cannot divide by zero!\u0026#34;) print(cal(0)) print(cal(2)) print(cal(3)) How It Works: The code inside the try block is executed. If an exception occurs, Python checks the except blocks for a matching exception type. If a match is found, the corresponding except block runs. Catching Specific Exceptions Always catch specific exceptions to avoid silencing unexpected errors. Python has many built-in exceptions (e.g., ValueError, TypeError, FileNotFoundError).\nimport math x = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) try: print(f\u0026#39;Square Root of {x} is {math.sqrt(x)}\u0026#39;) except ValueError: print(\u0026#39;Number is less than 0\u0026#39;) Output\nThe else Clause The else block runs only if no exceptions were raised in the try block. Use it to separate \u0026ldquo;happy path\u0026rdquo; code from error handling.\nimport math def sqr(value): try: x = math.sqrt(value) except ValueError: print(\u0026#39;Number is less than 0\u0026#39;) else: print(f\u0026#39;The Answer is: {x}\u0026#39;) value = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) sqr(value) Output The finally Clause The finally block runs regardless of whether an exception occurred. It’s ideal for cleanup tasks (e.g., closing files or releasing resources).\nimport math def sqr(value): try: x = math.sqrt(value) except ValueError: print(\u0026#39;Error\u0026#39;) else: print(f\u0026#39;The Answer is: {x}\u0026#39;) finally: print(\u0026#39;Program Ends\u0026#39;) value = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) sqr(value) Output Raising Exceptions Manually Use the raise keyword to trigger exceptions intentionally. This is useful for enforcing constraints.\ndef validate_age(age): if age \u0026lt; 0: raise ValueError(\u0026#34;Age cannot be negative!\u0026#34;) return age try: validate_age(-5) except ValueError as e: print(e) Creating Custom Exceptions Define custom exceptions by subclassing Python’s built-in Exception class. This makes your code more readable and errors more descriptive. (note: I have used RegEx, for that blog will be out soon :) )\nimport re class InvalidEmailError(Exception): \u0026#34;\u0026#34;\u0026#34;Raised when an email format is invalid.\u0026#34;\u0026#34;\u0026#34; pass def send_email(valid,email): if not valid: raise InvalidEmailError(f\u0026#34;Invalid email: {email}\u0026#34;) email = input(\u0026#39;Please enter your email: \u0026#39;) valid = re.match(r\u0026#39;^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\u0026#39;, email) try: send_email(valid, email) except InvalidEmailError as e: print(e) Output Logging a Python Error We can Log an exception in Python with an error. This can be done in the logging.exception() method. This function logs a message with level ERROR on this logger.\nimport math import logging def sqr(value): try: x = math.sqrt(value) except ValueError: logging.exception(\u0026#34;Error\u0026#34;) else: print(f\u0026#39;The Answer is: {x}\u0026#39;) finally: print(\u0026#39;Program Ends\u0026#39;) value = int(input(\u0026#39;Please enter a positive number: \u0026#39;)) sqr(value) Output Best Practices for Exception Handling Catch specific exceptions: Avoid broad except: clauses that hide bugs. Keep try blocks minimal: Only wrap code that might raise an exception. Use finally for cleanup: Ensure resources are released (e.g., closing files). Log exceptions: Use logging.error() instead of print() for production code. Provide meaningful messages: Help debug issues faster with clear error descriptions. Avoid empty except blocks: Silent failures make debugging harder. Conclusion Exception handling is essential for writing better Python applications. By using try-except blocks effectively, catching specific errors, and with else/finally clauses, you can create programs that handle unexpected scenarios.\nNow go forth and write bulletproof Python code!\n","permalink":"http://localhost:1313/posts/exception_handling_in_python/","summary":"\u003cp\u003eException handling is a crucial aspect of writing robust and reliable Python code. Whether you\u0026rsquo;re a beginner or an experienced developer, getting an error, or exception, in your Python program means the entire program will crash. You don’t want this to happen in real-world programs. Instead, you want the program to detect errors, handle them, and then continue to run. In this blog, we\u0026rsquo;ll explore the fundamentals of exception handling in Python, including syntax, best practices, and advanced techniques.\u003c/p\u003e","title":"Exception Handling in Python: A Comprehensive Guide"},{"content":"Have you ever wanted your Python program to do multiple things at once? For example, downloading files while updating the UI, or processing data while listening for user input? That’s where multithreading comes in.\nIn this post, we’ll explore multithreading in Python — what it is, when to use it, and how to use it with simple examples.\n🧠 What is Multithreading? Multithreading is a way to run multiple threads (smaller units of a process) at the same time. It helps make your program more responsive or perform tasks in parallel, especially when tasks are I/O-bound (e.g., network calls, file reading, etc.).\nPython has a built-in module called threading that makes it easy to create and manage threads.\n⚠️ But Wait — Python\u0026rsquo;s GIL Before you jump in, it\u0026rsquo;s important to understand the Global Interpreter Lock (GIL). In CPython (the standard Python implementation), the GIL allows only one thread to execute Python bytecode at a time.\nThis means multithreading in Python is best suited for I/O-bound tasks, not CPU-bound tasks like heavy computations. For CPU-bound tasks, consider multiprocessing instead.\n🛠️ Using the threading Module Here\u0026rsquo;s a basic example to demonstrate multithreading:\nimport threading import time def print_numbers(): for i in range(5): print(f\u0026#34;Number: {i}\u0026#34;) time.sleep(1) def print_letters(): for letter in \u0026#39;abcde\u0026#39;: print(f\u0026#34;Letter: {letter}\u0026#34;) time.sleep(1) # Creating threads t1 = threading.Thread(target=print_numbers) t2 = threading.Thread(target=print_letters) # Starting threads t1.start() t2.start() # Wait for both threads to complete t1.join() t2.join() print(\u0026#34;Both threads have finished.\u0026#34;) 🔍 Output (interleaved): Number: 0 Letter: a Number: 1 Letter: b ... Both functions run at the same time, and you can see their output interleave. That’s multithreading in action!\n📦 Real-World Use Cases Downloading multiple files at once Handling multiple client connections on a server Running background tasks like logging or monitoring Keeping your GUI app responsive while doing other work 🧰 Extra Tools For more advanced usage:\nconcurrent.futures.ThreadPoolExecutor — easier thread management queue.Queue — safe way to share data between threads threading.Lock — prevents race conditions 🧪 Example with ThreadPoolExecutor from concurrent.futures import ThreadPoolExecutor import time def task(name): print(f\u0026#34;{name} starting\u0026#34;) time.sleep(2) print(f\u0026#34;{name} done\u0026#34;) with ThreadPoolExecutor(max_workers=2) as executor: executor.submit(task, \u0026#34;Task 1\u0026#34;) executor.submit(task, \u0026#34;Task 2\u0026#34;) ✅ Final Thoughts Multithreading in Python is a powerful tool when used correctly — especially for I/O-bound programs. Just remember the GIL limitation and use the right tool (like multiprocessing) when working with CPU-heavy tasks.\nThanks for reading! Happy threading 🧵🐍\n","permalink":"http://localhost:1313/posts/multithreading/","summary":"\u003cp\u003eHave you ever wanted your Python program to do multiple things at once? For example, downloading files while updating the UI, or processing data while listening for user input? That’s where \u003cstrong\u003emultithreading\u003c/strong\u003e comes in.\u003c/p\u003e\n\u003cp\u003eIn this post, we’ll explore multithreading in Python — what it is, when to use it, and how to use it with simple examples.\u003c/p\u003e\n\u003ch2 id=\"-what-is-multithreading\"\u003e🧠 What is Multithreading?\u003c/h2\u003e\n\u003cp\u003eMultithreading is a way to run multiple threads (smaller units of a process) at the same time. It helps make your program more responsive or perform tasks in parallel, especially when tasks are I/O-bound (e.g., network calls, file reading, etc.).\u003c/p\u003e","title":"Multithreading in Python"},{"content":"Running a Local LLM on Mobile: Testing PocketPal on iPhone 12 With the increasing accessibility of large language models (LLMs), running them locally on mobile devices is an exciting prospect. I recently tested PocketPal, a mobile LLM interface, on my iPhone 12, using a distilled 4-bit quantized model. Here’s a breakdown of my experience, covering installation, performance, and overall usability.\nWhy Run an LLM on Mobile? Running an LLM locally on a mobile device comes with several advantages:\nPrivacy: No data is sent to external servers. Offline Access: Works without an internet connection. Lower Cost: Avoids API costs associated with cloud-based models. What is Quantization? Quantization is a technique used to reduce the memory and computational requirements of machine learning models by representing their weights with lower precision numbers. Instead of using 32-bit floating-point numbers, models can be compressed into 8-bit or even 4-bit integers while maintaining reasonable accuracy.\nFor LLMs on mobile, 4-bit quantization significantly reduces the model size, making it feasible to run on devices with limited resources. However, this compression can lead to:\nSlightly reduced accuracy due to loss of precision. Faster inference times, as lower-bit computations require less processing power. Lower memory usage, allowing larger models to fit within mobile device constraints. Setting Up and Running PocketPal on iPhone 12 1. Download and Install PocketPal Open the App Store and search for PocketPal AI by Asghar Ghorbani. Download and install the app. Open the app and allow necessary permissions. 2. Adding a Model Navigate to the Models section in the PocketPal app. Click the + button to add a new model. You will see two options: Add from Hugging Face Add Local Model Select Add from Hugging Face to browse available models. 3. Selecting and Downloading a Model Search for DeepSeek-R1-Distill-Qwen-1.5B-Q4_0. Select the model and start downloading it (size: 1.06GB, 1.78B parameters). Once downloaded, the model will appear under the Ready to Use section. 4. Running Benchmarks I ran benchmarks on my iPhone 12 using the DeepSeek-R1-Distill-Qwen-1.5B-Q4_0 model. Here are the key results:\nModel Size: 1.06 GB with 1.78 billion parameters. Benchmark Configuration: Prompt Processing: 512 Token Generation: 128 Pipeline Length: 1 Repetitions: 3 Model Settings: Context Length: 1024 tokens Batch Size: 512 CPU Threads: 4 GPU Layers: 0 (fully CPU-based execution) Flash Attention: Disabled Performance Metrics: Prompt Processing Speed: 26.93 tokens/sec (±2.37) Token Generation Speed: 18.05 tokens/sec (±0.75) Total Execution Time: 1 minute 18 seconds Peak Memory Usage: 35.0% (1GB / 4GB) Live Demo: Running PocketPal on iPhone 12 Watch a live demonstration of PocketPal running a distilled 4-bit quantized model on an iPhone 12: Image: Video demonstration is available here: Video\nAnalysis of Results Decent Processing Speed: With a distilled 4-bit quantized model, the 18.05 t/s token generation rate is quite reasonable for mobile inference. Low Memory Footprint: The 1GB RAM usage means this can run on even mid-range smartphones. CPU-Based Execution: Since 0 GPU layers were used, this proves mobile CPUs are capable of running quantized LLMs efficiently. Flash Attention Disabled: If supported, enabling it might further optimize speed and reduce lag. Final Thoughts Running an LLM locally on an iPhone 12 with PocketPal is feasible but comes with trade-offs. It’s a promising step toward self-hosted AI assistants, though optimization and hardware improvements will be crucial for broader adoption. If you’re privacy-conscious or need offline AI capabilities, it’s definitely worth exploring!\nFuture Improvements I\u0026rsquo;d Like to See: Better memory efficiency to reduce battery drain. Enhanced speed for real-time interaction. More user-friendly model importing and switching. ","permalink":"http://localhost:1313/posts/llmonmobile/","summary":"\u003ch1 id=\"running-a-local-llm-on-mobile-testing-pocketpal-on-iphone-12\"\u003eRunning a Local LLM on Mobile: Testing PocketPal on iPhone 12\u003c/h1\u003e\n\u003cp\u003eWith the increasing accessibility of large language models (LLMs), running them locally on mobile devices is an exciting prospect. I recently tested \u003cstrong\u003ePocketPal\u003c/strong\u003e, a mobile LLM interface, on my \u003cstrong\u003eiPhone 12\u003c/strong\u003e, using a \u003cstrong\u003edistilled 4-bit quantized model\u003c/strong\u003e. Here’s a breakdown of my experience, covering installation, performance, and overall usability.\u003c/p\u003e\n\u003ch2 id=\"why-run-an-llm-on-mobile\"\u003eWhy Run an LLM on Mobile?\u003c/h2\u003e\n\u003cp\u003eRunning an LLM locally on a mobile device comes with several advantages:\u003c/p\u003e","title":"Running Large Language Models on Mobile: DeepSeek R1 on iPhone 12"},{"content":"Running DeepSeek-R1 1.5B on Raspberry Pi 5 (CPU-Only) Technical Insights Why Can We Run This on Raspberry Pi 5? Thanks to open-source advancements, we can now run large-scale AI models on small devices like the Raspberry Pi 5. Key factors enabling this include:\nOptimized lightweight models: DeepSeek-R1 1.5B is built efficiently to run on limited hardware. ARM64 Support: Modern AI frameworks support ARM-based architectures, enabling their use on RPi5. Open-source software: Platforms like Ollama make AI deployment accessible to all. Performance Considerations Running this model on an RPi5 without a GPU will be CPU-intensive. Consider reducing active processes to free up memory. If performance lags, use a lighter model or external processing (cloud inference). No GPU acceleration was used in this setup, meaning all computations rely solely on the CPU, which may affect inference speeds. This guide covers the installation and execution of DeepSeek-R1 1.5B on a Raspberry Pi 5, following the steps demonstrated in your images.\nPrerequisites Raspberry Pi 5 (ARM64 architecture, more powerful than previous versions) Debian-based Linux installed An internet connection At least 4GB RAM recommended for smooth operation Step 1: Log in to Your Raspberry Pi Upon booting, log in using your credentials:\nraspberrypi login: hisam Password: ****** Example login screen: Step 2: Install Curl Curl is required to fetch the installation script. Run:\nsudo apt install curl If it\u0026rsquo;s already installed, you\u0026rsquo;ll see:\ncurl is already the newest version... Example output: Step 3: Install Ollama Ollama is the runtime needed to execute DeepSeek models.\ncurl -fsSL https://ollama.com/install.sh | sh This will download and install Ollama.\nExample installation screen: Step 4: Enable and Start Ollama Service After installation, Ollama sets up a system service.\nollama The output will indicate success:\n\u0026gt;\u0026gt;\u0026gt; Creating ollama user... \u0026gt;\u0026gt;\u0026gt; Enabling and starting ollama service... \u0026gt;\u0026gt;\u0026gt; The Ollama API is now available at 127.0.0.1:11434. Example setup screen: Step 5: Pull and Run DeepSeek-R1 1.5B Now, pull and run the model:\nollama run deepseek-r1:1.5b This will download the model, which is about 1.1 GB in size.\nExample download screen: Once downloaded, the model is ready to run.\nStep 6: Execute DeepSeek-R1 1.5B Run the model and start interacting:\nollama run deepseek-r1:1.5b You should see a prompt where you can start typing queries:\n\u0026gt;\u0026gt;\u0026gt; Hey! Hello! How can I assist you today? 😊 Example interaction: Final Setup Image Video Demonstration Watch Video\nConclusion You have successfully installed and executed DeepSeek-R1 1.5B on your Raspberry Pi 5. This demonstrates the power of open-source AI, making it possible to run advanced models on small-scale devices. If you encounter performance issues, consider optimizing your setup or offloading computations.\nHappy coding!\n","permalink":"http://localhost:1313/posts/deepseek/","summary":"\u003ch1 id=\"running-deepseek-r1-15b-on-raspberry-pi-5-cpu-only\"\u003eRunning DeepSeek-R1 1.5B on Raspberry Pi 5 (CPU-Only)\u003c/h1\u003e\n\u003ch2 id=\"technical-insights\"\u003eTechnical Insights\u003c/h2\u003e\n\u003ch3 id=\"why-can-we-run-this-on-raspberry-pi-5\"\u003eWhy Can We Run This on Raspberry Pi 5?\u003c/h3\u003e\n\u003cp\u003eThanks to open-source advancements, we can now run large-scale AI models on small devices like the Raspberry Pi 5. Key factors enabling this include:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eOptimized lightweight models\u003c/strong\u003e: DeepSeek-R1 1.5B is built efficiently to run on limited hardware.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eARM64 Support\u003c/strong\u003e: Modern AI frameworks support ARM-based architectures, enabling their use on RPi5.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eOpen-source software\u003c/strong\u003e: Platforms like Ollama make AI deployment accessible to all.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"performance-considerations\"\u003ePerformance Considerations\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eRunning this model on an RPi5 \u003cstrong\u003ewithout a GPU\u003c/strong\u003e will be CPU-intensive.\u003c/li\u003e\n\u003cli\u003eConsider \u003cstrong\u003ereducing active processes\u003c/strong\u003e to free up memory.\u003c/li\u003e\n\u003cli\u003eIf performance lags, use a \u003cstrong\u003elighter model\u003c/strong\u003e or \u003cstrong\u003eexternal processing (cloud inference).\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eNo GPU acceleration was used\u003c/strong\u003e in this setup, meaning all computations rely solely on the CPU, which may affect inference speeds.\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003cp\u003eThis guide covers the installation and execution of DeepSeek-R1 1.5B on a Raspberry Pi 5, following the steps demonstrated in your images.\u003c/p\u003e","title":"DeepSeek-R1 on Raspberry Pi 5: Open-Source AI Without a GPU"},{"content":"Setting Up Neovim: An Easy and Beginner\u0026rsquo;s Guide Neovim is a modern and extensible text editor that enhances Vim’s capabilities. If you\u0026rsquo;re using Linux, setting up Neovim can be a rewarding experience, allowing you to customize it for an efficient workflow. In this guide, we\u0026rsquo;ll cover installing Neovim, setting up a basic configuration, and enhancing it with essential plugins to turn it into a full-fledged IDE.\n1. Installing Neovim sudo pacman -S neovim 2. Setting Up Neovim Configuration Neovim’s configuration is stored in ~/.config/nvim/. Create the directory and initialize a basic configuration:\nmkdir -p ~/.config/nvim nvim ~/.config/nvim/init.lua Minimal Configuration (init.lua) Add the following settings to your init.lua file:\n-- Enable line numbers vim.opt.number = true vim.opt.relativenumber = true -- Set tab size vim.opt.expandtab = true vim.opt.shiftwidth = 4 vim.opt.tabstop = 4 -- Enable mouse support vim.opt.mouse = \u0026#34;a\u0026#34; -- Set clipboard to system clipboard vim.opt.clipboard = \u0026#34;unnamedplus\u0026#34; Save and exit Neovim.\n3. Installing a Plugin Manager The best plugin manager for Neovim is lazy.nvim. Install it by running:\ngit clone --depth 1 https://github.com/folke/lazy.nvim.git \\ ~/.local/share/nvim/lazy/lazy.nvim Then, update your init.lua to load it:\nlocal lazypath = vim.fn.stdpath(\u0026#34;data\u0026#34;) .. \u0026#34;/lazy/lazy.nvim\u0026#34; if not vim.loop.fs_stat(lazypath) then vim.fn.system({ \u0026#34;git\u0026#34;, \u0026#34;clone\u0026#34;, \u0026#34;--filter=blob:none\u0026#34;, \u0026#34;https://github.com/folke/lazy.nvim.git\u0026#34;, lazypath }) end vim.opt.rtp:prepend(lazypath) 4. Installing Essential Plugins With lazy.nvim installed, you can add plugins in init.lua:\nrequire(\u0026#34;lazy\u0026#34;).setup({ \u0026#34;nvim-treesitter/nvim-treesitter\u0026#34;, -- Syntax highlighting \u0026#34;nvim-telescope/telescope.nvim\u0026#34;, -- Fuzzy finder \u0026#34;neovim/nvim-lspconfig\u0026#34;, -- LSP support \u0026#34;hrsh7th/nvim-cmp\u0026#34;, -- Auto-completion \u0026#34;hrsh7th/cmp-nvim-lsp\u0026#34;, -- LSP completion source \u0026#34;hrsh7th/cmp-buffer\u0026#34;, -- Buffer completion \u0026#34;hrsh7th/cmp-path\u0026#34;, -- Path completion \u0026#34;hrsh7th/cmp-nvim-lua\u0026#34;, -- Neovim Lua API completion \u0026#34;L3MON4D3/LuaSnip\u0026#34;, -- Snippet engine \u0026#34;saadparwaiz1/cmp_luasnip\u0026#34;, -- Snippet completion \u0026#34;nvim-lualine/lualine.nvim\u0026#34;, -- Status line \u0026#34;nvim-tree/nvim-tree.lua\u0026#34;, -- File explorer \u0026#34;tpope/vim-surround\u0026#34;, -- Surround text objects \u0026#34;tpope/vim-commentary\u0026#34;, -- Commenting shortcuts \u0026#34;lewis6991/gitsigns.nvim\u0026#34;, -- Git integration \u0026#34;akinsho/toggleterm.nvim\u0026#34;, -- Terminal management }) Save and exit Neovim, then open it and run:\n:Lazy sync This will install the plugins automatically.\n5. Setting Up Treesitter Treesitter provides better syntax highlighting and code parsing. Install it by adding the following to your init.lua:\nrequire\u0026#39;nvim-treesitter.configs\u0026#39;.setup { ensure_installed = \u0026#34;all\u0026#34;, highlight = { enable = true, }, indent = { enable = true, }, } Then, update Treesitter by running:\n:TSUpdate 6. Setting Up LSP (Language Server Protocol) LSP enables features like code completion and linting. Install LSP servers for your language:\n# Python sudo pacman -S python-lsp-server # C++ sudo pacman -S clang # JavaScript/TypeScript npm install -g typescript-language-server Then, enable LSP support in Neovim:\nlocal lspconfig = require(\u0026#34;lspconfig\u0026#34;) lspconfig.pyright.setup({}) -- Python lspconfig.ts_ls.setup({}) -- JavaScript/TypeScript lspconfig.clangd.setup({}) -- C++ Restart Neovim and check LSP status:\n:LspInfo 7. Enhancing Auto-Completion with nvim-cmp To enable code auto-completion, update your init.lua:\nlocal cmp = require\u0026#39;cmp\u0026#39; cmp.setup({ mapping = { [\u0026#39;\u0026lt;C-Space\u0026gt;\u0026#39;] = cmp.mapping.complete(), [\u0026#39;\u0026lt;CR\u0026gt;\u0026#39;] = cmp.mapping.confirm({ select = true }), }, sources = { { name = \u0026#39;nvim_lsp\u0026#39; }, { name = \u0026#39;buffer\u0026#39; }, { name = \u0026#39;path\u0026#39; }, { name = \u0026#39;luasnip\u0026#39; }, { name = \u0026#39;nvim_lua\u0026#39; }, } }) 9. Final Thoughts Congratulations! You now have a powerful, customized Neovim setup that functions as a full-fledged IDE. With features like Treesitter, LSP support, auto-completion, syntax highlighting, Git integration, and a file explorer, your development workflow will be much smoother.\nIf you’d like to further improve your Neovim experience, explore more plugins and tweak your settings. Good luck with that!\nFurther Reading Neovim Documentation Awesome Neovim Plugins Arch Wiki: Neovim ","permalink":"http://localhost:1313/posts/setting-up-neovim-on-arch-linux-a-beginners-guide/","summary":"\u003ch1 id=\"setting-up-neovim-an-easy-and-beginners-guide\"\u003eSetting Up Neovim: An Easy and Beginner\u0026rsquo;s Guide\u003c/h1\u003e\n\u003cp\u003eNeovim is a modern and extensible text editor that enhances Vim’s capabilities. If you\u0026rsquo;re using Linux, setting up Neovim can be a rewarding experience, allowing you to customize it for an efficient workflow. In this guide, we\u0026rsquo;ll cover installing Neovim, setting up a basic configuration, and enhancing it with essential plugins to turn it into a full-fledged IDE.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"1-installing-neovim\"\u003e\u003cstrong\u003e1. Installing Neovim\u003c/strong\u003e\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003esudo pacman -S neovim\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003chr\u003e\n\u003ch2 id=\"2-setting-up-neovim-configuration\"\u003e\u003cstrong\u003e2. Setting Up Neovim Configuration\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003eNeovim’s configuration is stored in \u003ccode\u003e~/.config/nvim/\u003c/code\u003e. Create the directory and initialize a basic configuration:\u003c/p\u003e","title":"Setting Up Neovim: A Beginner's Guide"},{"content":"Linux Kernal The majority of the kernel\u0026rsquo;s code is written in C, leveraging extensions provided by the GNU Compiler Collection (GCC) beyond standard C. Additionally, it includes assembly code for architecture-specific functions, such as optimizing memory usage and task execution. Architecturally, the Linux kernel is monolithic, meaning the entire OS operates within kernel space. However, it features a modular design, allowing software components to be integrated as modules, including dynamic loading.\nWhat Is A Kernel Module? A Linux kernel module is precisely defined as a code segment capable of dynamic loading and unloading within the kernel as needed. These modules enhance kernel capabilities without necessitating a system reboot. A notable example is seen in the device driver module, which facilitates kernel interaction with hardware components linked to the system.\nWriting a Custom Linux Kernel Module Linux kernel modules (LKMs) allow developers to extend the functionality of the Linux kernel without modifying its source code. This guide walks through writing a simple kernel module from scratch. Kernel modules are pieces of code that can be dynamically loaded and unloaded from the Linux kernel at runtime. They enable functionality such as device drivers, file system support, and system call extensions without requiring a kernel recompilation. LKMs are particularly useful for developing hardware drivers and testing new kernel features without rebooting the system.\nPrerequisites Ensure you have the necessary development tools installed. On an Arch Linux system, install them with:\nsudo pacman -Syu linux-headers base-devel Creating a Simple Kernel Module 1. Writing the Module Source Code Create a file named hello_module.c:\n#include \u0026lt;linux/module.h\u0026gt; #include \u0026lt;linux/kernel.h\u0026gt; #include \u0026lt;linux/init.h\u0026gt; MODULE_LICENSE(\u0026#34;GPL\u0026#34;); MODULE_AUTHOR(\u0026#34;Your Name\u0026#34;); MODULE_DESCRIPTION(\u0026#34;A simple Hello World kernel module\u0026#34;); static int __init hello_init(void) { printk(KERN_INFO \u0026#34;Hello, Kernel!\\n\u0026#34;); return 0; } static void __exit hello_exit(void) { printk(KERN_INFO \u0026#34;Goodbye, Kernel!\\n\u0026#34;); } module_init(hello_init); module_exit(hello_exit); Understanding the Kernel Module Code #include \u0026lt;linux/module.h\u0026gt;: Includes the necessary module macros and functions. #include \u0026lt;linux/kernel.h\u0026gt;: Provides kernel logging functions. #include \u0026lt;linux/init.h\u0026gt;: Defines initialization and cleanup macros. MODULE_LICENSE(\u0026quot;GPL\u0026quot;): Specifies the module\u0026rsquo;s license. MODULE_AUTHOR(\u0026quot;Your Name\u0026quot;): Specifies the author of the module. MODULE_DESCRIPTION(\u0026quot;A simple Hello World kernel module\u0026quot;): Provides a brief description. static int __init hello_init(void): The function executed when the module is loaded. static void __exit hello_exit(void): The function executed when the module is unloaded. module_init(hello_init): Registers hello_init as the module\u0026rsquo;s initialization function. module_exit(hello_exit): Registers hello_exit as the module\u0026rsquo;s cleanup function. 2. Writing the Makefile Create a Makefile in the same directory:\nobj-m += hello_module.o all: make -C /lib/modules/$(shell uname -r)/build M=$(PWD) modules clean: make -C /lib/modules/$(shell uname -r)/build M=$(PWD) clean Understanding the Makefile obj-m += hello_module.o: Specifies that hello_module.o is the object to be built as a module. all:: Defines the build target. make -C /lib/modules/$(shell uname -r)/build M=$(PWD) modules: Directs the kernel build system to compile the module. clean:: Cleans up the generated files. make -C /lib/modules/$(shell uname -r)/build M=$(PWD) clean: Cleans the build artifacts. 3. Compiling the Module Run:\nmake 4. Loading and Unloading the Module To insert the module into the kernel:\nsudo insmod hello_module.ko Check the kernel log:\ndmesg | tail To remove the module:\nsudo rmmod hello_module 5. Verifying the Module List loaded modules:\nlsmod | grep hello_module Understanding the Generated Files After building the module, several files are generated:\nhello_module.c: The source code of the module. hello_module.ko: The compiled kernel module file, ready to be loaded into the kernel. hello_module.o: An intermediate object file generated during compilation. hello_module.mod.c: An automatically generated file containing module metadata. hello_module.mod.o: An object file containing metadata compiled from hello_module.mod.c. hello_module.mod: Another metadata file required for module loading. Makefile: Contains instructions for building the module. Module.symvers: Stores information about exported symbols, useful for module dependencies. modules.order: Lists the order in which modules should be loaded. Conclusion This simple kernel module demonstrates the basics of module development. You can expand upon this by adding functionality such as handling parameters or interacting with hardware.\nHappy kernel hacking!\n","permalink":"http://localhost:1313/posts/how-to-write-a-custom-kernel-module/","summary":"\u003ch1 id=\"linux-kernal\"\u003eLinux Kernal\u003c/h1\u003e\n\u003cp\u003eThe majority of the kernel\u0026rsquo;s code is written in C, leveraging extensions provided by the GNU Compiler Collection (GCC) beyond standard C. Additionally, it includes assembly code for architecture-specific functions, such as optimizing memory usage and task execution. Architecturally, the Linux kernel is monolithic, meaning the entire OS operates within kernel space. However, it features a modular design, allowing software components to be integrated as modules, including dynamic loading.\u003c/p\u003e","title":"How to Write a Custom Kernel Module"},{"content":"What is it? gh is GitHub\u0026rsquo;s official command-line tool designed to extend Git\u0026rsquo;s functionality with GitHub-specific features.\nPurpose: Simplifies interaction with GitHub\u0026rsquo;s ecosystem directly from the terminal. Allows you to manage repositories and use GitHub features like issues, pull requests, and workflows.\nKey Features: GitHub-specific tasks:\nAuthentication: Easier login (gh auth login) without dealing with tokens manually. Repository Management: Create, fork, or clone repositories. Issues \u0026amp; Pull Requests: Manage issues, PRs, and comments directly. Actions: Manage and view GitHub Actions workflows. Works alongside Git for basic version control tasks. Use Case: Best for developers heavily using GitHub and its features (for example: pull requests, issues, and actions).\nHow it works Install gh:\n\u0026gt; yay -S github-cli Verify the installation:\n\u0026gt; gh --version Login with GitHub CLI (gh)\n\u0026gt; gh auth login Follow the interactive prompts to log in:\nChoose HTTPS or SSH for connection. Log in via a browser using a one-time code or SSH keys. Verify authentication:\n\u0026gt; gh auth status What\u0026rsquo;s best about it that you can install and use both Git and gh (GitHub CLI) seamlessly. Here\u0026rsquo;s how to set them up:\nInstall Git\n\u0026gt;sudo pacman -S git Check the installation:\n\u0026gt; git --version Using Git and gh Together You can now: Use Git for version control:\n\u0026gt; git clone https://github.com/username/repo.git \u0026gt; git add . \u0026gt; git commit -m \u0026quot;message\u0026quot; \u0026gt; git push ","permalink":"http://localhost:1313/posts/github-cli-githubs-official-command-line-tools/","summary":"\u003ch2 id=\"what-is-it\"\u003eWhat is it?\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003egh\u003c/strong\u003e is GitHub\u0026rsquo;s official command-line tool designed to extend Git\u0026rsquo;s functionality with GitHub-specific features.\u003c/p\u003e\n\u003ch2 id=\"purpose\"\u003ePurpose:\u003c/h2\u003e\n\u003cp\u003eSimplifies interaction with GitHub\u0026rsquo;s ecosystem directly from the terminal. Allows you to manage repositories and use GitHub features like issues, pull requests, and workflows.\u003c/p\u003e\n\u003ch2 id=\"key-features\"\u003eKey Features:\u003c/h2\u003e\n\u003cp\u003eGitHub-specific tasks:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAuthentication: Easier login (gh auth login) without dealing with tokens manually.\u003c/li\u003e\n\u003cli\u003eRepository Management: Create, fork, or clone repositories.\u003c/li\u003e\n\u003cli\u003eIssues \u0026amp; Pull Requests: Manage issues, PRs, and comments directly.\u003c/li\u003e\n\u003cli\u003eActions: Manage and view GitHub Actions workflows.\u003c/li\u003e\n\u003cli\u003eWorks alongside Git for basic version control tasks.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"use-case\"\u003eUse Case:\u003c/h2\u003e\n\u003cp\u003eBest for developers heavily using GitHub and its features (for example: pull requests, issues, and actions).\u003c/p\u003e","title":"GitHub CLI: GitHub's Official Command Line Tools"},{"content":"Connecting a Raspberry Pi 5 to a USB TTY cable is a common way to interact with it through a serial connection, especially for debugging or setting up the device without using a display.\nPrerequists\nRaspberry Pi 5. USB TTY (serial) cable. Computer with a terminal emulator (minicom/screen). GPIO pinout diagram of Raspberry Pi 5 (for reference). Power source for Raspberry Pi (optional if USB TTY can power it, though not recommended). Before Starting! Issuse with firmware UART does NOT work on the RPI5 from the factory. We will need a firmware update to fix this that prevents the dtoverlays for UARTs from working.\nInstall rpi-update with the following commands:\n\u0026gt; sudo curl -L --output /usr/bin/rpi-update https://raw.githubusercontent.com/Hexxeh/rpi-update/master/rpi-update \u0026amp;\u0026amp; sudo chmod +x /usr/bin/rpi-update Then update the firmware on your RPI5 with:\n\u0026gt; sudo rpi-update Enable UART To manually configure UART, you can edit the config.txt file.\nEdit /boot/firmware/config.txt and add:\n\u0026gt; enable_uart=1 How to Connect Locate the GPIO Pins Find the GPIO header on the Raspberry Pi 5. Identify the following pins: GND (Ground): Usually black wire on the USB TTY cable. TX (Transmit): Sends data from the Pi to the computer. RX (Receive): Receives data from the computer to the Pi.\nUse a GPIO pinout chart to locate these pins. For Raspberry Pi 5, it will likely be similar to previous models. Making connections You will need to connect:\nGND with Ground - Pin# 06 TX with GPIO14 - Pin# 08 RX with GPIO15 - Pin# 10 Plug the USB TTY Cable into the Computer\nInsert the USB end of the TTY cable into your computer. The cable will create a virtual COM port (e.g /dev/ttyUSB0). Configure and Access Serial Console\nOpen a terminal.\nIdentify the port with:\n\u0026gt; ls /dev/ttyUSB* Use a terminal emulator like screen or minicom to connect:\n\u0026gt; screen /dev/ttyUSB0 115200 *Replace /dev/ttyUSB0 with the actual port name.\nTurn on the Raspberry Pi. If everything is set up correctly, you should see boot messages in the terminal. Log in to the Pi using the default username (pi) and password (raspberry), or your custom credentials. You should see something similar to this.\nThis is it! You have done it. Congrats!\n","permalink":"http://localhost:1313/posts/how-to-connect-a-raspberry-pi-5-to-usb-tty-cable/","summary":"\u003cp\u003eConnecting a Raspberry Pi 5 to a USB TTY cable is a common way to interact with it through a serial connection, especially for debugging or setting up the device without using a display.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003ePrerequists\u003c/strong\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eRaspberry Pi 5.\u003c/li\u003e\n\u003cli\u003eUSB TTY (serial) cable.\u003c/li\u003e\n\u003cli\u003eComputer with a terminal emulator (minicom/screen).\u003c/li\u003e\n\u003cli\u003eGPIO pinout diagram of Raspberry Pi 5 (for reference).\u003c/li\u003e\n\u003cli\u003ePower source for Raspberry Pi (optional if USB TTY can power it, though not recommended).\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"before-starting\"\u003e\u003cstrong\u003eBefore Starting!\u003c/strong\u003e\u003c/h3\u003e\n\u003ch3 id=\"issuse-with-firmware\"\u003e\u003cstrong\u003e\u003ca href=\"https://forums.raspberrypi.com/viewtopic.php?t=361397#p2171244\"\u003eIssuse with firmware\u003c/a\u003e\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003eUART does NOT work on the RPI5 from the factory. We will need a firmware update to fix this that prevents the dtoverlays for UARTs from working.\u003c/p\u003e","title":"How to Connect a Raspberry PI 5 to USB TTY Cable"},{"content":"Hosting a website on GitHub Pages with Hugo involves the following steps:\nCreating a website 1. Install Hugo and git\n\u0026gt; sudo pacman -S Hugo 2. Create a new Hugo site\n\u0026gt; hugo new site your-website 3. Add a Theme\nNavigate to your website directory and add a theme. You can choose one from the Hugo Themes .\n\u0026gt; cd your-website \u0026gt; git init \u0026gt; git submodule add https://github.com/adityatelange/hugo-PaperMod.git themes/hugo-PaperMod Now you will need to update the hugo.toml file for them to take effect. To do so you can either echo or addd it in the file.\n\u0026gt; echo \u0026quot;theme = 'hugo-PaperMod'\u0026quot; \u0026gt;\u0026gt; hugo.toml To view the website you can run it locally using Hugo\u0026rsquo;s development server to view the site. You can add -D to see your drafts.\n\u0026gt; hugo server 3. Add Content\nTo add a new page to your site.\n\u0026gt; hugo new content content/posts/yout-first-post.md This is it You have done it. YAY!\nHosting it on GitHub 1. Create a GitHub repository.\nClick the + icon in the top-right corner of:\u0026gt; [!WARNING] the GitHub interface and select New repository. Enter a repository name: yourusername.github.io Click Create repository. 2. Add Files for Your website\nClone the repository locally using Git:\ngit clone https://github.com//.git\nAdd your static site files (generated by Hugo) to the repository. Commit and push the changes:\n\u0026gt; git add -A \u0026gt; git commit -s -m \u0026quot;Initial commit\u0026quot; \u0026gt; git push origin main 3. Configure the Repository for GitHub Pages\nGo to the Settings tab of your new repository. Scroll down to the Pages section. Settings \u0026gt; Pages. In the center of your screen you will see this: Build and development Change the Source to GitHub Actions. 4. Create a file named hugo.yaml in a directory named .github/workflows.\n\u0026gt; mkdir -p .github/workflows \u0026gt; cd ./github/workflows touch hugo.yaml 5. Add content in the YAML file.\n# Sample workflow for building and deploying a Hugo site to GitHub Pages name: Deploy Hugo site to Pages on: # Runs on pushes targeting the default branch push: branches: - main # Allows you to run this workflow manually from the Actions tab workflow_dispatch: # Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages permissions: contents: read pages: write id-token: write # Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued. # However, do NOT cancel in-progress runs as we want to allow these production deployments to complete. concurrency: group: \u0026#34;pages\u0026#34; cancel-in-progress: false # Default to bash defaults: run: shell: bash jobs: # Build job build: runs-on: ubuntu-latest env: HUGO_VERSION: 0.141.0 steps: - name: Install Hugo CLI run: | wget -O ${{ runner.temp }}/hugo.deb https://github.com/gohugoio/hugo/releases/download/v${HUGO_VERSION}/hugo_extended_${HUGO_VERSION}_linux-amd64.deb \\ \u0026amp;\u0026amp; sudo dpkg -i ${{ runner.temp }}/hugo.deb - name: Install Dart Sass run: sudo snap install dart-sass - name: Checkout uses: actions/checkout@v4 with: submodules: recursive fetch-depth: 0 - name: Setup Pages id: pages uses: actions/configure-pages@v5 - name: Install Node.js dependencies run: \u0026#34;[[ -f package-lock.json || -f npm-shrinkwrap.json ]] \u0026amp;\u0026amp; npm ci || true\u0026#34; - name: Build with Hugo env: HUGO_CACHEDIR: ${{ runner.temp }}/hugo_cache HUGO_ENVIRONMENT: production TZ: America/Los_Angeles run: | hugo \\ --gc \\ --minify \\ --baseURL \u0026#34;${{ steps.pages.outputs.base_url }}/\u0026#34; - name: Upload artifact uses: actions/upload-pages-artifact@v3 with: path: ./public # Deployment job deploy: environment: name: github-pages url: ${{ steps.deployment.outputs.page_url }} runs-on: ubuntu-latest needs: build steps: - name: Deploy to GitHub Pages id: deployment uses: actions/deploy-pages@v4 5. Commit and push your GitHub repository.\n\u0026gt;git add -A \u0026gt;git commit -m \u0026quot;Create hugo.yaml\u0026quot; \u0026gt;git push 6. Deployment status From GitHub’s main menu, choose Actions. When GitHub has finished building and deploying your site, the color of the status indicator will change to green.\nStep 5: Verify Your GitHub Pages Site\nThe site will be live at https://yourusername.github.io.\n","permalink":"http://localhost:1313/posts/hosting-a-website-on-github-pages-with-hugo/","summary":"\u003cp\u003eHosting a website on GitHub Pages with Hugo involves the following steps:\u003c/p\u003e\n\u003ch1 id=\"creating-a-website\"\u003eCreating a website\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e1. Install Hugo and git\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; sudo pacman -S Hugo\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e2. Create a new Hugo site\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; hugo new site your-website\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003e3. Add a Theme\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eNavigate to your website directory and add a theme. You can choose one from the \u003ca href=\"https://themes.gohugo.io/\"\u003eHugo Themes\u003c/a\u003e .\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; cd your-website\n\u0026gt; git init \n\u0026gt; git submodule add https://github.com/adityatelange/hugo-PaperMod.git themes/hugo-PaperMod\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow you will need to update the hugo.toml file for them to take effect. To do so you can either \u003cem\u003eecho\u003c/em\u003e or addd it in the file.\u003c/p\u003e","title":"Hosting a Website on Github Pages With Hugo"},{"content":"KVM Kernel-based Virtual Machine is a free and open-source virtualization module in the Linux kernel that allows the kernel to function as a hypervisor.\nInstallation For updates, run the following command:\n$ sudo pacman -Syu QEMU/KVM installation: We\u0026rsquo;ll install qemu and all the utils required:\n$ sudo pacman -S qemu vde2 ebtables iptables-nft nftables dms masq bridge-utils ovmf swptm Virtual Machine Manager installation: The virt-manager application is a graphical user interface for managing virtual machines through libvirt. It primarily targets KVM VMs.\n$ sudo pacman -S virt-manager Now everything is set to work. We can move towards downloading archlinux .iso file.\nDownload .iso file: Head towards: https://archlinux.org/download/ Scroll through and look for the server closest to you. Download archlinux-2024.10.01-x86_64.iso file. Setting up: Open terminal and run the following command:\n$ virt-manager You will see an interface similar to this:\nClick on \u0026lsquo;create a new virtual machine\u0026rsquo; (option with star). Select \u0026lsquo;Local install media\u0026rsquo;. Browse to your \u0026lsquo;archlinux-2024.10.01-x86_64.iso\u0026rsquo;. Add your desired VM configuration and create a disk image. Boot Menu: You will be prompted to a boot menu.\nSelect the topmost option to start the installation process. Archlinux Installer: You will be prompted to a terminal. The first step is to check if you are connected to the internet.\nRun:\n# ip addr show If it shows an IP address and says \u0026lsquo;UP\u0026rsquo;, that means you are good to go.\nIf not: You will need to connect to the internet using the \u0026lsquo;iwctl\u0026rsquo; method for Wi-Fi.\n# iwctl To search networks in your vicinity:\n[iwd]# station [your_wifi_interface] get-networks Get the name of the network you want to connect to. Exit from this prompt using \u0026rsquo;exit\u0026rsquo;.\nTo connect to the desired Wi-Fi network, run:\n# iwctl --passphrase \u0026#34;[wifi_password]\u0026#34; station [your_wifi_interface] connect [wifi_name] You can again run ip addr show to check if you are connected to the network.\nNow you can run the installation command. We\u0026rsquo;ll be using the archinstall method.\n# archinstall You will be prompted to an interface similar to this:\nWe will install Arch using this interface. Go through each option:\nArchinstall language: Choose your preferred language. Mirrors: Select the mirror region closest to you. Use \u0026lsquo;/\u0026rsquo; to search. Locales: Set language and keyboard layout. Disk configuration: Choose Best-effort default partition to format the system. Bootloader: Use the default \u0026lsquo;Grub\u0026rsquo; option. Swap: Select Swap on zram (default). Hostname: Leave as it is. Root password: Set the password for sudo/root privileges. User account: Set up a user account. Profile: Select Desktop. It includes essential packages. Others include Minimal, Server, and Xorg. In Desktop, select your desktop environment. We\u0026rsquo;ll use Gnome for simplicity.\nAudio: Use PipeWire (default) or PulseAudio. Kernels: Use the linux kernel. Additional packages: Install any required packages. Network Configuration: Use NetworkManager for a GUI in Gnome. Timezone: Set the timezone closest to you and enable time sync. Press Install. Congratulations! You\u0026rsquo;ve successfully installed Arch Linux.\n","permalink":"http://localhost:1313/posts/arch_kvm/","summary":"\u003ch1 id=\"kvm\"\u003eKVM\u003c/h1\u003e\n\u003cp\u003eKernel-based Virtual Machine is a free and open-source virtualization module in the Linux kernel that allows the kernel to function as a hypervisor.\u003c/p\u003e\n\u003ch2 id=\"installation\"\u003eInstallation\u003c/h2\u003e\n\u003cp\u003eFor updates, run the following command:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ sudo pacman -Syu\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"qemukvm-installation\"\u003eQEMU/KVM installation:\u003c/h3\u003e\n\u003cp\u003eWe\u0026rsquo;ll install qemu and all the utils required:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ sudo pacman -S qemu vde2 ebtables iptables-nft nftables dms masq bridge-utils ovmf swptm\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"virtual-machine-manager-installation\"\u003eVirtual Machine Manager installation:\u003c/h3\u003e\n\u003cp\u003eThe virt-manager application is a graphical user interface for managing virtual machines through libvirt. It primarily targets KVM VMs.\u003c/p\u003e","title":"archlinux installation in hypervisor through QEMU/KVM"},{"content":"","permalink":"http://localhost:1313/posts/github-cli-githubs-official-command-line-tool/","summary":"","title":""}]